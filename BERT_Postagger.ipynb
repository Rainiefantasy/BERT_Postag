{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "numerous-savings",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import nltk.corpus \n",
    "import nltk\n",
    "from keras.utils import np_utils\n",
    "from numpy import savez_compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-calcium",
   "metadata": {},
   "source": [
    "Retrieving dataset (George Orweil's 1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ambient-desert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package mte_teip5 to\n",
      "[nltk_data]     /Users/Mahwish/nltk_data...\n",
      "[nltk_data]   Package mte_teip5 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('mte_teip5')\n",
    "data = nltk.corpus.multext_east.tagged_sents(\"oana-en.xml\", \"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-enforcement",
   "metadata": {},
   "source": [
    "Retrieving saved variables from below queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "continuing-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "# load dict of arrays + extract the first array\n",
    "dict_data = load('BERT_labels_xx.npz')\n",
    "xx = dict_data['arr_0'] # contextual embeddings tensor saved for range(0,400)\n",
    "dict_data = load('BERT_labels_yy.npz')\n",
    "yy = dict_data['arr_0'] # corresponding labels saved in list\n",
    "dict_data = load('BERT_bubu2_yy.npz')\n",
    "bubu2 = dict_data['arr_0'] # to check the text corresponding to label\n",
    "dict_data = load('BERT_extra_set_list_xx.npz')\n",
    "extra_set_list = dict_data['arr_0'] # to check the text corresponding to embedding\n",
    "dict_data = load('BERT_dev_labels_yy.npz')\n",
    "dev_labels = dict_data['arr_0'] # previously computed labels (extension of yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-richmond",
   "metadata": {},
   "source": [
    "Checking transformer version is correct -- older version causes problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gothic-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers --upgrade\n",
    "#import transformers\n",
    "#print(transformers.__version__)\n",
    "#4.9.0.dev0 + required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-lawyer",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "creative-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reproducibility\n",
    "seed=20\n",
    "cust_seed = np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-sample",
   "metadata": {},
   "source": [
    "Checking how indexing works when splitting sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "limited-anatomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing splitting methods\n",
    "st = 'The cat sat on the mat'\n",
    "st.split(\" \").index('mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-girlfriend",
   "metadata": {},
   "source": [
    "The below function creates chunks of words splitting the text after 40 tokens. Chose this based on average sentence length to ensure 'context' is kept to give an idea of syntactic structure of the sentence when retrieving a particular words embedding, but not too much context as to diminish the attention given to the particular tokens. This should help when POS tagging (a noun came before i'th token, punctuation after, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "contrary-cycling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_creator(chunk):\n",
    "    text = []\n",
    "    tag_counter = 0\n",
    "    for idx3, k in enumerate(data):\n",
    "        for idx4, m in enumerate(k):\n",
    "            if chunk*40 <= tag_counter < (chunk+1)*40:\n",
    "                text.append(m[0])\n",
    "            tag_counter += 1\n",
    "    text = ' '.join(text)\n",
    "    input_string = text\n",
    "    \n",
    "    #Here I'm trying to experiment on how to pad the string so that the punctuation is separated when grabbing the embedding\n",
    "    # if the string isn't padded, it'll try to find 'pumpkin.' instead of 'pumpkin', '.'\n",
    "    pattern = '([:;.,!?()])'\n",
    "    input_string = re.sub(pattern, r' \\1 ', input_string)\n",
    "    input_string = re.sub('\\s\\s*',' ',input_string)\n",
    "    input_string = re.sub(\" '\",\"'\",input_string)\n",
    "    input_string = re.sub(\"s' \",\"s ' \",input_string)\n",
    "    return input_string   \n",
    "#print(set_creator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-independence",
   "metadata": {},
   "source": [
    "The two functions below (from huggingface blog) used to retrieve the contextual embeddings of each token given a context string generated from the above. Comments added for info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "specialized-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(encoded, token_ids_word, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum 'layers' (last four by default).\n",
    "       Select only those subword token outputs that belong to our word of interest\n",
    "       and average them.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "        #print(output)\n",
    "        \n",
    "    # Gets all hidden states from model\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers (defined which ones later - using -4, -3, -2, -1)\n",
    "    output = torch.stack([states[o] for o in layers]).sum(0).squeeze()\n",
    "    \n",
    "    print('output',np.shape(output))\n",
    "    # Only select the tokens that constitute the requested word (since subtokens can be generated)\n",
    "    word_tokens_output = output[token_ids_word]\n",
    "    #print('word_tokens_output',word_tokens_output[0][0], np.shape(word_tokens_output))\n",
    "    #print('avg subcomp word',word_tokens_output.mean(dim=0)[0],np.shape((word_tokens_output.mean(dim=0))))\n",
    "    return word_tokens_output.mean(dim=0) # this averages the sub components of the word\n",
    "\n",
    "def get_word_vector(sent, idx, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "       that make up the word of interest, and then 'get_hidden_states'.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "    print('encoded',encoded)\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    "    #print('token_ids_word',token_ids_word)\n",
    "    print('encoded.word_ids-idx',(np.array(encoded.word_ids()) == idx))\n",
    "    return get_hidden_states(encoded, token_ids_word, model, layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-evidence",
   "metadata": {},
   "source": [
    "Example below printing sections of above code, and retrieving the contextual embeddings of word 'mat' from sentence 'The cat sat on the mat'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accredited-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded {'input_ids': tensor([[  101,  1996,  4937,  2938,  2006,  1996, 13523,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False]\n",
      "output torch.Size([8, 768])\n",
      "word_tokens_output tensor(2.5789) torch.Size([1, 768])\n",
      "avg subcomp word tensor(2.5789) torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "layers = [-4, -3, -2, -1]\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "config = AutoConfig.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\", output_hidden_states=True)\n",
    "model = AutoModel.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\", config=config)\n",
    "\n",
    "sent = \"The cat sat on the mat\" \n",
    "idx = sent.split(\" \").index('mat')\n",
    "word_embedding = get_word_vector(sent, idx, tokenizer, model, layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-satisfaction",
   "metadata": {},
   "source": [
    "Below script retrieves embeddings for each token within a context chunk ( of length 40), and concatenates them into a contextual embedding tensor (tens). The tens for which results are beneath is for range(0,400) but this takes a while to run so I've changed to range (0,10) for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "overall-awareness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q 0\n",
      "0 It\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "tensor([ 1.7538e+00, -4.0755e+00,  1.4447e-02,  5.9480e-01,  1.9120e-01,\n",
      "         1.1187e+00,  1.8802e+00,  6.6475e+00,  4.9068e+00,  5.4331e-01,\n",
      "        -1.2831e+00, -6.0172e-01, -1.7040e+00,  7.5291e-01,  1.9342e+00,\n",
      "         5.6875e+00,  3.0025e+00,  3.1749e+00,  2.3344e+00, -2.9435e-01,\n",
      "         1.6427e+00, -1.1979e+00,  4.9335e-01, -4.9814e-01, -2.7067e-01,\n",
      "        -1.9250e+00, -2.4319e-01,  3.7911e-01, -2.9498e+00,  3.2545e+00,\n",
      "        -9.1278e-01, -1.4441e+00,  2.7065e+00, -1.9520e+00,  1.1566e+00,\n",
      "        -2.1656e+00, -1.4107e+00, -1.4889e+00, -6.1995e-01,  3.4011e+00,\n",
      "        -6.9012e-02,  2.0331e-01, -2.3294e+00, -2.8671e+00, -1.0692e+00,\n",
      "         2.1212e+00,  3.7559e+00,  2.8851e+00,  1.9222e+00,  1.3686e-01,\n",
      "        -2.7229e+00,  2.4236e+00, -4.0017e+00, -2.0715e+00,  7.2687e-01,\n",
      "        -3.5663e+00, -1.2630e+00, -7.1586e-01, -8.3904e-01,  3.9555e+00,\n",
      "         4.9601e-01, -5.6036e+00,  4.1159e+00,  1.0545e+00, -2.6512e+00,\n",
      "         5.9603e-01, -1.1360e+00,  7.3080e-01,  6.0945e-01, -4.4012e-01,\n",
      "        -3.0366e+00, -1.4196e+00,  8.7964e-01, -2.3219e+00, -1.5893e-01,\n",
      "         1.9996e+00,  1.3924e+00,  1.1512e+00, -6.9502e+00,  2.7083e+00,\n",
      "        -1.1115e+00,  1.4592e+00,  1.3705e+00,  2.6135e+00, -1.7612e+00,\n",
      "         1.0062e+00, -3.6392e+00,  2.2189e+00,  3.8731e+00,  1.5505e-01,\n",
      "         2.1793e-01, -2.2425e+00,  1.2431e+00, -7.0839e-01, -3.2831e+00,\n",
      "        -3.9397e+00, -6.1007e-01,  7.9905e-01,  1.1309e+00, -4.5179e+00,\n",
      "         1.2587e+00, -3.1832e+00, -2.0651e+00, -3.0223e+00, -1.4237e+00,\n",
      "        -2.3773e+00,  1.6885e+00,  5.4270e+00,  6.2378e+00, -3.9552e+00,\n",
      "         2.1906e+00,  7.9448e-01, -3.9794e+00, -3.6520e+00, -1.0546e+00,\n",
      "         2.8689e+00, -1.3367e-01,  1.1434e+00, -2.4754e+00, -7.9683e-01,\n",
      "         2.6924e+00, -2.1401e+00,  2.8503e-01, -1.5663e+00,  3.8581e-01,\n",
      "        -3.9031e+00,  2.2838e+00,  8.0898e-01,  1.6827e+00, -2.3385e+00,\n",
      "        -2.0071e+00, -5.9455e-01,  3.0571e-01, -4.2804e+00,  1.3173e+00,\n",
      "        -3.1509e+00, -5.0595e-02,  3.7805e-02, -3.6104e+00, -1.7664e+00,\n",
      "         4.1047e-01, -2.4028e+00,  4.3040e-01,  1.5603e+00,  2.7132e+00,\n",
      "        -1.3893e+00,  4.6769e-01,  4.3164e+00,  4.4105e+00, -6.8331e-01,\n",
      "        -4.0948e-01, -2.4511e+00,  9.2972e-01,  3.7203e+00, -3.0127e-01,\n",
      "        -6.8476e-01, -1.8272e-01,  1.1464e+00, -6.0112e-02,  5.2631e-01,\n",
      "         2.4986e+00,  9.9667e-01, -6.4592e-01,  3.6054e+00, -2.7775e-01,\n",
      "        -3.4881e+00,  8.2108e-01, -2.2571e-01,  1.0766e+00, -4.4642e+00,\n",
      "         1.8611e+00, -1.4285e-01,  3.4230e+00, -2.2003e+00,  1.4991e+00,\n",
      "        -2.7616e+00,  7.5232e-01,  4.6221e-01, -2.0717e+00,  6.4058e-01,\n",
      "         1.6757e+00, -4.4762e-01, -1.6681e+00,  4.7987e+00,  3.2463e-01,\n",
      "         2.2255e+00, -4.2563e+00, -4.4708e-01,  1.1802e+00,  6.3793e+00,\n",
      "        -1.1034e+00, -3.4255e-03,  5.7371e+00, -3.8963e-01, -3.7530e+00,\n",
      "        -2.8394e+00,  9.1168e-01, -4.7478e+00, -2.9632e+00, -1.4604e+00,\n",
      "        -9.9296e-01, -8.9081e-01,  3.6735e-01,  2.1723e+00, -2.0188e+00,\n",
      "         5.2399e-01, -1.9751e+00,  9.0290e-01, -1.0045e-01, -2.1969e+00,\n",
      "        -2.6900e+00,  9.9913e-01, -4.5384e+00, -2.4438e-01,  2.0590e-01,\n",
      "         1.8299e+00, -1.7207e+00, -4.8682e-01, -1.9588e+00,  8.1581e-01,\n",
      "         8.3553e-01, -3.5323e+00, -1.9663e+00,  4.3283e+00, -4.4719e+00,\n",
      "         8.1867e-01,  1.5377e+00, -2.0300e+00, -3.8144e+00,  2.1012e+00,\n",
      "         1.1993e+00,  1.6806e-02, -9.7495e-01, -2.1686e+00,  1.0722e+00,\n",
      "         4.7556e+00,  5.3380e-01, -3.5250e+00, -1.8827e+00,  1.9785e-01,\n",
      "         2.9899e+00,  2.0395e+00,  1.5440e+00,  1.3521e+00, -1.1562e+00,\n",
      "        -5.1947e-02, -1.9587e-01,  1.4202e+00,  1.9654e+00,  1.3130e+00,\n",
      "        -1.8842e-03,  3.6108e+00,  1.8701e-01, -5.8513e-01,  2.6026e-01,\n",
      "        -4.4829e-01, -2.5336e+00, -1.4777e+00,  1.8077e+00,  4.8518e-01,\n",
      "         1.5152e-01, -4.1006e+00,  7.8648e-01, -4.7555e+00, -1.8725e+00,\n",
      "        -2.8620e+00,  2.4272e+00, -1.0699e+00,  2.6470e-01,  2.1946e+00,\n",
      "         1.8083e-01,  3.5382e+00, -1.7974e+00,  1.4746e+00,  1.9310e+00,\n",
      "         6.9722e-01,  2.0081e+00,  3.9496e-01, -1.3209e+00, -1.9481e+00,\n",
      "         2.9040e+00,  2.9166e-01, -2.8219e+00, -1.8690e+00,  5.8656e-01,\n",
      "         1.6258e+00, -1.4169e+00,  3.9390e-01, -6.7351e-01, -4.2192e+00,\n",
      "        -2.2182e-01,  1.3078e-01, -3.1278e-01, -2.9265e+00,  3.6116e+00,\n",
      "         2.6920e+00, -1.6079e-01,  3.7355e+00,  1.4228e+00, -3.3456e+00,\n",
      "         4.5865e-01, -8.3023e-01, -2.6838e+00, -2.2954e+00,  3.5314e+00,\n",
      "        -3.1182e+00, -2.8878e+00, -6.6943e-01, -8.9694e+00,  1.8676e+00,\n",
      "        -8.0899e-01, -1.7346e+00, -2.8985e+00, -3.9528e+00,  6.8949e-02,\n",
      "        -9.1233e-01,  5.9300e-01, -3.6941e+00, -2.1531e+00, -1.8880e+00,\n",
      "         2.2361e+00,  1.6920e+00,  5.1782e+00, -4.9663e+00,  1.0244e+00,\n",
      "        -1.3981e+00, -2.0839e+00,  3.1624e-01, -2.5199e+00, -2.8971e+00,\n",
      "         2.2582e+00,  3.5569e-02, -2.4274e+00, -1.2735e+00,  2.2594e+00,\n",
      "        -3.9242e+00, -1.1004e+00,  7.0565e-01, -1.7809e+00, -5.3130e-02,\n",
      "         4.1699e+00,  2.2658e+00,  2.9166e+00,  8.1564e-01, -2.0108e+00,\n",
      "         2.3616e+00,  2.8570e+00, -2.0040e+00, -9.3070e-01, -1.7297e-01,\n",
      "        -7.5023e-01,  1.7643e+00,  1.1789e+00, -4.8342e-01, -2.4945e+00,\n",
      "        -8.3890e-01, -5.8204e-01,  4.0325e+00,  5.3289e-01, -1.6013e+00,\n",
      "        -3.5343e+00, -5.5839e+00,  9.6802e-01,  1.9994e+00,  1.1747e+00,\n",
      "         1.4106e+00,  3.4175e+00,  2.2606e+00, -1.3901e+00, -2.2994e+00,\n",
      "        -4.5473e+00, -4.8277e-01,  4.7132e+00,  4.0105e-01, -1.6080e+00,\n",
      "         4.1316e+00,  4.2681e-01, -9.7203e-01, -2.2939e+00,  2.0646e+00,\n",
      "         3.4219e-01, -6.4129e+00,  2.1797e+00, -1.5061e+00, -1.9678e+00,\n",
      "         1.1050e+00,  2.1535e+00, -3.5755e+00, -1.3034e+00, -6.2342e-01,\n",
      "        -4.9897e-01,  1.4531e-01, -1.4159e+00, -6.9995e-01, -1.0012e+00,\n",
      "        -8.5624e-01, -3.9811e+00, -1.0819e+00,  3.7401e+00,  2.4811e+00,\n",
      "         2.6580e+00,  4.7286e+00, -3.5357e+00, -9.9934e-02,  3.4923e-01,\n",
      "        -1.9987e+00,  1.9716e-01,  3.6645e+00,  1.3777e+00,  1.7384e+00,\n",
      "        -2.0160e-01,  3.6469e+00,  6.0747e+00, -2.7811e+00, -1.7201e+00,\n",
      "        -1.3455e+00,  3.8708e+00,  2.6759e+00, -8.7573e-01, -4.2206e+00,\n",
      "        -1.5228e+00, -7.9014e-01, -2.8824e+00, -2.7206e+00,  1.4497e+00,\n",
      "        -8.5663e-01, -4.2495e-01,  3.5741e-02, -7.0973e-01,  2.2218e+00,\n",
      "        -3.1465e+00, -3.1390e+00, -3.3849e+00,  2.7174e+00, -4.3079e+00,\n",
      "        -9.6737e-01, -2.2679e+00,  5.5745e-01, -2.6873e+00,  1.6089e+00,\n",
      "        -6.2299e+00,  2.4904e+00,  1.9309e+00,  1.5285e+00, -1.3878e+00,\n",
      "        -2.9839e+00,  3.9422e-01, -1.8347e+00, -2.2986e+00,  2.6990e+00,\n",
      "         1.4332e+00,  1.1561e+00, -4.2877e+00, -6.8575e-01, -1.9484e+00,\n",
      "        -9.7284e-01, -7.4598e-01,  1.6844e+00, -2.5900e-01,  2.0651e+00,\n",
      "        -3.7822e+00,  1.8601e+00, -1.0621e+00, -1.2712e+00, -1.5180e+00,\n",
      "        -2.0748e+00,  1.4854e+00, -2.3545e+00,  2.3761e+00, -5.0009e-01,\n",
      "        -5.6132e+00,  1.3555e+00,  2.5960e+00,  1.2019e+00,  1.0427e+00,\n",
      "         7.1948e-01, -6.5317e-01,  9.6812e-01, -4.8392e+00, -2.8874e-01,\n",
      "         8.5464e-03,  1.6488e-01, -5.2757e-01,  3.0568e+00,  1.0908e+00,\n",
      "        -2.6389e+00,  1.7473e+00,  6.8301e-01, -8.8673e-01,  1.1457e+00,\n",
      "         1.0059e+00,  1.2144e+00,  3.7073e+00, -3.4987e-01, -3.0482e-01,\n",
      "         7.8291e-01,  1.7731e+00,  5.0681e-01,  3.3666e-01,  2.6195e+00,\n",
      "        -3.8780e+00, -2.9690e+00,  6.9029e-02, -4.8222e+00,  1.6365e+00,\n",
      "         9.6260e-01, -9.8498e-01, -1.2424e-01,  2.6943e+00,  2.2582e+00,\n",
      "        -9.6480e-01, -1.0821e+00, -1.6122e+00, -3.6668e+00, -2.6067e+00,\n",
      "        -3.3347e+00, -8.3301e-02, -2.3464e+00,  9.9880e-01,  5.6203e+00,\n",
      "        -4.0996e+00, -1.4429e+00, -4.9806e-01, -1.1841e+00,  1.3225e+00,\n",
      "        -3.7104e-01, -3.5029e+00,  1.7193e+00, -9.7864e-01,  5.2717e-01,\n",
      "         3.1907e+00,  5.3159e-01, -2.2536e+00, -3.1704e+00, -1.7887e+00,\n",
      "        -2.2580e+00,  2.3379e+00, -7.5301e+00, -2.8143e-01, -5.1729e+00,\n",
      "         6.4955e-01,  5.8749e-01, -3.6271e+00, -1.4257e+00,  4.3407e-01,\n",
      "         2.4362e-01,  2.3323e+00,  1.8652e+00, -1.4486e+00, -3.5643e+00,\n",
      "        -1.3406e+00, -2.4912e+00, -2.2862e+00, -2.7400e+00, -1.2085e+00,\n",
      "         2.1467e+00, -3.2029e+00, -1.5883e+00,  1.4533e+00, -1.8316e+00,\n",
      "        -3.2308e-01, -1.7666e+00,  7.1883e-01,  3.5605e-01,  2.9749e+00,\n",
      "        -2.2662e-01,  8.6703e-01,  1.7950e+00, -9.6401e-01, -9.5307e-01,\n",
      "        -5.0900e-01, -2.8869e+00, -1.2524e+00,  8.5513e-01,  2.1624e+00,\n",
      "         1.8200e+00, -7.6659e-01,  1.6659e-01, -9.6134e-02, -2.4604e+00,\n",
      "         1.8630e+00, -3.8948e+00,  1.4120e+00, -1.5198e+00, -1.2402e+00,\n",
      "         8.7051e-01,  2.5859e+00, -2.8749e+00,  1.3656e+00, -2.4310e+00,\n",
      "         1.0264e+00, -8.6463e-01, -4.8963e+00,  8.1934e-01,  2.2953e+00,\n",
      "         2.6316e+00,  2.8184e+00,  1.0173e+00, -9.5099e-01,  1.4926e-01,\n",
      "         6.3927e-01,  2.3582e+00, -7.4080e-01,  1.0547e+00,  4.8590e+00,\n",
      "         1.0071e+00, -1.9030e+00,  5.6598e-01, -1.5025e+00,  2.3242e+00,\n",
      "        -1.1154e+00, -2.6873e+00,  1.4311e+00,  2.0836e+00,  2.3773e+00,\n",
      "         1.6962e+00, -5.0824e+00,  9.0979e-01,  4.5731e+00, -3.8300e-01,\n",
      "         1.4937e+00,  3.6976e-01, -5.8123e-01,  1.4171e+00, -8.0217e-01,\n",
      "        -3.7282e+00,  9.0538e-01,  2.3398e+00,  3.8085e-01, -2.3365e+00,\n",
      "         4.1862e+00, -2.3336e-01, -6.3887e-01, -2.1345e+00,  1.4468e+00,\n",
      "         2.4129e+00, -1.7683e+00,  1.0536e+00, -5.5145e-01, -2.7416e+00,\n",
      "        -1.2880e+00,  8.6795e-01,  4.7079e+00,  1.7584e+00, -2.9015e+00,\n",
      "        -1.3984e+00, -2.0109e+00,  1.1508e+00, -3.8867e+00, -2.6706e+00,\n",
      "         4.9741e+00,  1.7954e+00,  1.1536e+00, -1.5388e+00,  8.4969e-01,\n",
      "         2.0806e+00,  4.9435e+00, -2.5009e+00,  2.7981e+00,  3.1533e+00,\n",
      "        -5.5944e+00, -3.8864e-01,  2.8248e+00,  4.3490e+00, -2.7692e+00,\n",
      "         8.2292e-01, -2.7497e+00, -1.8160e+00, -8.0073e-01,  3.2055e+00,\n",
      "        -5.1261e-01,  2.8529e-01, -1.8814e+00,  3.1409e+00,  3.9932e+00,\n",
      "        -1.5479e+00,  4.3526e-01,  1.9017e+00, -2.2861e-01,  2.7291e+00,\n",
      "         8.4129e-01,  1.7094e+00, -3.1697e+00, -3.0109e+00,  1.8448e+00,\n",
      "         9.9107e-01, -1.7292e-01, -7.1276e-01,  7.8897e-01, -2.4841e+00,\n",
      "        -1.7594e+00, -1.2380e+00, -4.3444e-01, -1.2650e+00,  1.7502e-01,\n",
      "        -1.4094e+00, -2.5841e+00,  3.5461e+00,  2.1350e-01, -9.4651e-01,\n",
      "         2.3608e-01,  1.1314e+00,  3.2016e+00, -6.8921e-01, -1.3685e-01,\n",
      "         7.5437e-01, -1.2088e+00, -5.0904e-01,  2.3648e+00,  5.7641e-01,\n",
      "         2.9640e+00,  9.9711e-01, -2.6065e-02, -5.4713e-01,  2.4596e-01,\n",
      "         2.9625e+00,  8.6868e-01, -4.3452e+00,  3.3918e-01,  1.3330e+00,\n",
      "        -2.7316e+00, -4.4593e-02, -7.7099e-01,  3.6700e+00, -2.2124e-01,\n",
      "        -3.5709e-01, -3.8196e+00,  2.6359e+00, -9.8603e-01,  2.3627e+00,\n",
      "        -2.2783e+00, -2.1375e+00,  2.3108e+00,  6.6616e-01, -2.0644e+00,\n",
      "         1.5622e+00, -1.1245e+00, -1.5658e-02,  3.8426e+00,  3.1706e+00,\n",
      "        -8.4066e-01,  2.6564e+00, -1.3377e+00, -9.9882e-01,  2.4313e+00,\n",
      "        -2.4392e+00,  3.8017e-01, -9.8499e-01,  6.4951e+00,  2.9477e+00,\n",
      "        -2.9490e-01,  1.3578e+00, -1.2188e+00,  6.5639e-01,  6.9141e-01,\n",
      "        -1.3687e+00,  2.5922e+00,  1.4183e+00,  1.7563e-03, -6.4554e-01,\n",
      "         1.6148e+00, -2.1160e+00, -5.8185e-01, -2.0616e-01, -1.5168e+00,\n",
      "         1.2121e+00,  4.9801e+00,  6.5753e-01])\n",
      "1 was\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([43, 768])\n",
      "1 was tens shape torch.Size([2, 768])\n",
      "tensor(0.5775)\n",
      "counter 1\n",
      "2 a\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "2 a tens shape torch.Size([3, 768])\n",
      "tensor(-4.3772)\n",
      "counter 2\n",
      "3 bright\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "3 bright tens shape torch.Size([4, 768])\n",
      "tensor(-0.7954)\n",
      "counter 3\n",
      "4 cold\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "4 cold tens shape torch.Size([5, 768])\n",
      "tensor(0.6912)\n",
      "counter 4\n",
      "5 day\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "5 day tens shape torch.Size([6, 768])\n",
      "tensor(2.5300)\n",
      "counter 5\n",
      "6 in\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "6 in tens shape torch.Size([7, 768])\n",
      "tensor(-4.1366)\n",
      "counter 6\n",
      "7 April\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "7 April tens shape torch.Size([8, 768])\n",
      "tensor(1.4610)\n",
      "counter 7\n",
      "8 ,\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "8 , tens shape torch.Size([9, 768])\n",
      "tensor(0.4316)\n",
      "counter 8\n",
      "9 and\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([43, 768])\n",
      "9 and tens shape torch.Size([10, 768])\n",
      "tensor(-1.8758)\n",
      "counter 9\n",
      "10 the\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "10 the tens shape torch.Size([11, 768])\n",
      "tensor(-3.8996)\n",
      "counter 10\n",
      "11 clocks\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "11 clocks tens shape torch.Size([12, 768])\n",
      "tensor(4.2557)\n",
      "counter 11\n",
      "12 were\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "12 were tens shape torch.Size([13, 768])\n",
      "tensor(1.2797)\n",
      "counter 12\n",
      "13 striking\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "13 striking tens shape torch.Size([14, 768])\n",
      "tensor(1.2858)\n",
      "counter 13\n",
      "14 thirteen\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "14 thirteen tens shape torch.Size([15, 768])\n",
      "tensor(2.5924)\n",
      "counter 14\n",
      "15 .\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "15 . tens shape torch.Size([16, 768])\n",
      "tensor(0.0896)\n",
      "counter 15\n",
      "16 Winston\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "16 Winston tens shape torch.Size([17, 768])\n",
      "tensor(1.1738)\n",
      "counter 16\n",
      "17 Smith\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([43, 768])\n",
      "17 Smith tens shape torch.Size([18, 768])\n",
      "tensor(3.2208)\n",
      "counter 17\n",
      "18 ,\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "18 , tens shape torch.Size([19, 768])\n",
      "tensor(-0.7021)\n",
      "counter 18\n",
      "19 his\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "19 his tens shape torch.Size([20, 768])\n",
      "tensor(2.9851)\n",
      "counter 19\n",
      "20 chin\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "20 chin tens shape torch.Size([21, 768])\n",
      "tensor(4.6064)\n",
      "counter 20\n",
      "21 nuzzled\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "21 nuzzled tens shape torch.Size([22, 768])\n",
      "tensor(1.2460)\n",
      "counter 21\n",
      "22 into\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "22 into tens shape torch.Size([23, 768])\n",
      "tensor(-3.3702)\n",
      "counter 22\n",
      "23 his\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "23 his tens shape torch.Size([24, 768])\n",
      "tensor(5.1920)\n",
      "counter 23\n",
      "24 breast\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "24 breast tens shape torch.Size([25, 768])\n",
      "tensor(3.8761)\n",
      "counter 24\n",
      "25 in\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([43, 768])\n",
      "25 in tens shape torch.Size([26, 768])\n",
      "tensor(-3.7581)\n",
      "counter 25\n",
      "26 an\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "26 an tens shape torch.Size([27, 768])\n",
      "tensor(-4.2725)\n",
      "counter 26\n",
      "27 effort\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "27 effort tens shape torch.Size([28, 768])\n",
      "tensor(0.9861)\n",
      "counter 27\n",
      "28 to\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "28 to tens shape torch.Size([29, 768])\n",
      "tensor(-0.3446)\n",
      "counter 28\n",
      "29 escape\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "29 escape tens shape torch.Size([30, 768])\n",
      "tensor(0.1179)\n",
      "counter 29\n",
      "30 the\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "30 the tens shape torch.Size([31, 768])\n",
      "tensor(-5.7085)\n",
      "counter 30\n",
      "31 vile\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "31 vile tens shape torch.Size([32, 768])\n",
      "tensor(2.2212)\n",
      "counter 31\n",
      "32 wind\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "32 wind tens shape torch.Size([33, 768])\n",
      "tensor(2.1242)\n",
      "counter 32\n",
      "33 ,\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([43, 768])\n",
      "33 , tens shape torch.Size([34, 768])\n",
      "tensor(0.6717)\n",
      "counter 33\n",
      "34 slipped\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "34 slipped tens shape torch.Size([35, 768])\n",
      "tensor(0.4269)\n",
      "counter 34\n",
      "35 quickly\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False]\n",
      "output torch.Size([43, 768])\n",
      "35 quickly tens shape torch.Size([36, 768])\n",
      "tensor(-1.3792)\n",
      "counter 35\n",
      "36 through\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False]\n",
      "output torch.Size([43, 768])\n",
      "36 through tens shape torch.Size([37, 768])\n",
      "tensor(-2.5549)\n",
      "counter 36\n",
      "37 the\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False]\n",
      "output torch.Size([43, 768])\n",
      "37 the tens shape torch.Size([38, 768])\n",
      "tensor(-3.7420)\n",
      "counter 37\n",
      "38 glass\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False]\n",
      "output torch.Size([43, 768])\n",
      "38 glass tens shape torch.Size([39, 768])\n",
      "tensor(3.8690)\n",
      "counter 38\n",
      "39 doors\n",
      "encoded {'input_ids': tensor([[  101,  2009,  2001,  1037,  4408,  3147,  2154,  1999,  2258,  1010,\n",
      "          1998,  1996, 20940,  2020,  8478,  7093,  1012, 10180,  3044,  1010,\n",
      "          2010,  5413, 16371, 17269,  2046,  2010,  7388,  1999,  2019,  3947,\n",
      "          2000,  4019,  1996, 25047,  3612,  1010,  5707,  2855,  2083,  1996,\n",
      "          3221,  4303,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False]\n",
      "output torch.Size([43, 768])\n",
      "39 doors tens shape torch.Size([40, 768])\n",
      "tensor(4.1760)\n",
      "counter 39\n",
      "q 1\n",
      "0 of\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "tensor([-2.3588e+00,  1.2315e+00,  5.8642e+00,  3.7165e-01,  2.8437e+00,\n",
      "         1.2152e+00,  1.6570e+00, -7.7299e-01, -5.7989e-01,  2.1259e+00,\n",
      "         5.7406e-01, -2.4121e+00,  6.7745e-01,  2.7850e+00, -1.2366e-01,\n",
      "         2.8910e+00,  2.0605e+00,  1.8221e+00,  2.7836e+00,  4.0714e+00,\n",
      "        -3.6996e+00, -1.0553e+00, -3.9992e+00, -5.6920e-01, -8.0665e-01,\n",
      "         4.2740e-01,  1.1571e+00,  3.4397e+00,  9.6607e-01,  1.3643e+00,\n",
      "         4.2271e+00,  4.3519e+00,  1.2235e+00,  1.1411e+00,  1.7454e+00,\n",
      "        -4.3058e+00, -5.6704e-01, -4.2513e+00, -1.6346e+00,  1.3147e+00,\n",
      "         2.0204e+00, -2.1831e+00, -1.5324e+00,  1.4882e+00, -3.7278e+00,\n",
      "        -2.8927e+00, -1.0385e+00, -2.4196e-01,  2.7312e+00, -1.2178e+00,\n",
      "         5.1342e+00, -7.0507e-01,  2.7798e+00, -1.1848e+00, -1.9609e+00,\n",
      "        -1.5004e-01, -4.8784e+00,  2.4992e+00, -1.2268e+00, -4.7139e+00,\n",
      "        -3.3882e+00, -1.4427e-02, -5.8019e-01,  2.9241e+00, -2.5706e+00,\n",
      "        -3.7716e+00, -9.5578e-01,  1.4516e+00,  4.6142e-01,  2.3020e+00,\n",
      "         4.2067e+00,  8.8388e-01,  2.7026e+00, -6.5524e+00,  5.3103e-01,\n",
      "        -5.1142e-01, -7.8008e-01, -8.0319e-01, -3.9136e+00,  6.2307e-02,\n",
      "        -4.0584e-01,  2.4207e+00, -3.6020e+00,  2.1930e-01, -1.3604e+00,\n",
      "        -1.9290e+00,  2.9705e-01,  5.7581e-01,  1.6045e+00,  6.5070e+00,\n",
      "        -1.0130e+00, -1.4805e+00, -1.0434e+00, -1.3861e+00, -2.1787e+00,\n",
      "        -3.5657e+00,  1.1600e+00,  3.3765e+00, -5.3062e+00,  2.9093e+00,\n",
      "         8.0256e-01, -1.6754e+00, -4.9063e+00,  3.4121e+00,  7.6779e-01,\n",
      "         9.8984e-01,  7.6993e-01,  3.3454e+00, -2.6671e+00,  2.0499e+00,\n",
      "         2.1827e+00,  6.1449e-01,  4.6702e+00, -4.6160e+00,  2.3315e+00,\n",
      "        -1.2882e-02, -1.3756e+00, -3.1776e+00, -9.9486e-01, -1.9673e+00,\n",
      "         2.6307e+00, -2.3406e+00,  2.6121e+00, -1.5959e+00,  1.5621e+00,\n",
      "         9.3267e-01, -1.7899e+00, -5.1698e-01,  3.2668e+00, -4.8723e+00,\n",
      "        -4.0918e+00, -1.3545e+00,  2.4726e+00, -2.0148e-01,  2.0317e+00,\n",
      "        -2.9854e+00,  5.5421e+00, -2.2258e-02, -1.4267e+00, -4.1560e+00,\n",
      "        -2.2581e+00, -3.5415e+00,  2.6006e+00,  9.3455e-01, -1.3119e+00,\n",
      "         2.1432e+00, -4.1096e+00,  3.7766e-01,  1.9658e+00,  8.2979e-01,\n",
      "        -4.3946e+00, -3.4980e+00,  1.6917e+00,  3.6517e+00, -2.3502e+00,\n",
      "         9.3448e-01, -2.5187e+00,  1.6004e+00, -4.6019e-01, -1.0886e+00,\n",
      "         3.4251e+00, -1.9057e+00, -2.2945e+00, -1.0822e+00,  6.2108e-02,\n",
      "        -4.6967e-01,  2.0727e-02, -1.8412e+00,  8.9399e-01,  1.3315e+00,\n",
      "         2.1864e+00, -3.2694e+00,  3.3495e-01,  2.0422e+00,  6.1470e-01,\n",
      "         2.7382e-01, -6.0433e-01, -5.4905e+00,  2.6282e-01,  1.9888e+00,\n",
      "         7.2811e-01,  1.4555e-01, -6.4368e-03, -7.8343e-01,  2.3409e+00,\n",
      "        -2.3914e+00, -4.1323e+00, -1.4203e+00,  2.6245e+00, -1.8017e-01,\n",
      "         1.3556e+00,  3.1356e+00, -3.8487e-02, -3.2037e+00,  3.4767e-01,\n",
      "         1.7488e+00, -8.6270e-01,  1.2212e+00, -1.3478e+00,  8.2388e-01,\n",
      "        -2.5249e+00, -2.2957e+00, -3.7863e-01,  5.2458e-01,  4.8312e-01,\n",
      "        -1.7574e+00,  2.6165e-01,  2.0226e+00,  5.0689e-01,  4.8636e-01,\n",
      "        -1.8407e-01,  8.5885e-01,  1.0770e-01, -3.3404e+00, -3.5582e+00,\n",
      "        -1.3207e+00, -3.1953e-01, -2.5133e+00, -1.8485e+00, -2.9877e+00,\n",
      "         5.3861e-01,  5.3135e-01,  2.4337e+00, -1.0758e+00, -1.5580e+00,\n",
      "         1.3959e-01,  1.5823e+00, -2.9417e+00, -3.9081e+00,  4.0676e+00,\n",
      "        -2.6763e+00, -1.2535e-01, -2.8409e-01, -3.3680e-01,  3.0776e+00,\n",
      "        -1.6076e+00, -1.6510e+00,  5.5437e-01,  3.0557e+00,  1.3241e-01,\n",
      "        -1.0888e+00, -1.5459e+00,  5.2017e+00, -2.2201e+00, -4.2927e+00,\n",
      "        -3.6295e+00, -3.5889e+00, -3.7076e+00,  1.8561e+00, -1.4395e+00,\n",
      "         2.8806e+00, -2.1310e+00, -2.5152e+00, -2.7393e+00,  5.0071e-01,\n",
      "         3.9122e-01, -1.8955e+00, -1.0582e+00,  1.2002e+00,  4.6651e-01,\n",
      "        -3.5799e+00, -4.1634e+00, -3.9392e+00,  2.4867e-01, -2.3914e-01,\n",
      "         2.3519e+00, -1.6219e+00,  2.3172e+00, -2.8401e+00, -3.2472e+00,\n",
      "        -2.0438e+00, -6.8221e-01,  3.7756e-01,  1.7126e+00,  2.4208e+00,\n",
      "         3.4752e+00, -1.0312e+00,  4.5825e+00,  7.2124e-01, -6.6267e-01,\n",
      "        -4.2069e-01, -3.6959e-01,  1.1754e+00,  2.1624e+00,  3.3916e-01,\n",
      "         2.6729e+00,  6.8579e+00, -1.7930e+00, -2.5020e+00, -2.0246e+00,\n",
      "         2.7736e-02,  3.4987e-01, -2.2107e-01, -7.9908e-01,  1.4666e+00,\n",
      "         3.9845e+00, -3.0320e+00,  3.4418e+00,  8.1557e-01, -2.1829e+00,\n",
      "        -1.5968e+00,  5.9431e-01,  1.8251e+00,  1.3497e+00,  2.2611e+00,\n",
      "         9.7803e-01, -4.8484e+00, -7.1550e-01, -1.0257e+01, -3.6002e+00,\n",
      "         2.6434e+00,  1.9670e+00,  1.5129e+00, -1.4302e+00, -4.9240e+00,\n",
      "        -3.8950e-01, -4.6472e+00,  1.6622e+00,  2.5037e+00, -2.3621e-01,\n",
      "        -1.8592e+00,  2.9570e+00, -2.6760e-01, -3.2258e+00, -1.1139e+00,\n",
      "        -3.7961e+00, -3.3812e-01,  1.9504e+00,  2.3806e+00, -5.2864e-01,\n",
      "        -3.7401e+00,  1.4029e+00, -1.6127e+00,  9.3523e-01,  2.7457e+00,\n",
      "         1.2261e+00,  5.8988e-01,  3.3138e+00,  9.0523e-03,  1.3264e+00,\n",
      "        -1.8383e+00, -2.5250e+00, -6.5783e-01, -3.5776e+00,  1.1655e+00,\n",
      "        -5.7537e-01, -5.4793e-01, -4.9445e+00,  2.1631e+00, -6.2806e+00,\n",
      "        -1.0529e+00,  8.7275e-01, -1.4511e+00,  1.7955e+00,  9.2581e-01,\n",
      "        -1.8822e+00,  2.8607e-01,  1.6058e+00, -1.6763e+00, -1.8624e+00,\n",
      "         8.1221e-01,  7.2700e-01,  1.5621e-02, -1.2103e+00,  1.0007e+00,\n",
      "         6.1404e+00,  1.9353e+00, -4.6814e+00,  3.8713e-01,  8.1984e-03,\n",
      "        -2.7624e+00,  3.5617e+00, -9.9724e-02,  7.2919e-01, -9.7438e-01,\n",
      "        -8.0238e-01, -7.3380e-01,  2.2336e+00, -2.9234e+00,  4.2130e+00,\n",
      "         2.2009e-01, -4.5722e+00,  3.4786e-01, -1.9590e-01, -5.5397e+00,\n",
      "        -5.7496e-01,  1.3697e+00,  6.5999e-01,  5.5496e+00, -2.5650e+00,\n",
      "        -4.4727e+00, -4.7726e+00, -6.8152e+00, -3.4421e+00, -6.9261e-01,\n",
      "         9.9667e-01, -6.8414e-01, -3.2856e+00,  1.9991e+00, -3.1087e+00,\n",
      "         2.2075e+00,  4.8177e-01,  2.1486e+00, -1.8368e+00,  2.6882e+00,\n",
      "        -4.6018e+00,  4.0644e+00,  1.8794e-01,  2.6716e+00,  3.2325e-01,\n",
      "         8.7057e-01,  2.2502e+00, -7.3146e-01, -1.0443e+00, -1.3159e-01,\n",
      "        -1.0712e+00,  4.0334e-01, -2.2119e+00, -1.4523e+00, -2.3170e+00,\n",
      "        -3.1451e+00,  4.2414e+00, -5.0228e-01,  1.1234e+00,  2.6185e+00,\n",
      "         3.2526e+00,  4.1852e+00,  4.1363e-01,  1.7323e+00,  4.9357e+00,\n",
      "         8.5747e-01, -2.8039e+00, -1.6827e+00, -4.4160e+00, -4.8448e+00,\n",
      "         1.0736e+00,  1.2615e-01,  2.9613e-01, -1.9635e+00, -3.4224e+00,\n",
      "         5.2032e+00,  1.4764e+00,  2.0975e+00, -7.7892e-01, -2.6207e+00,\n",
      "         1.6520e+00,  5.5401e+00, -4.5985e-01, -4.2745e+00,  6.3887e-01,\n",
      "        -6.9841e-01,  4.7355e+00, -5.0615e+00, -1.9727e+00,  3.4226e+00,\n",
      "         1.9495e-01,  9.7508e-01, -6.3228e+00, -1.1653e+00, -2.5372e-01,\n",
      "         1.0384e+00, -2.8918e+00, -2.0138e+00, -6.3302e-01,  2.5248e+00,\n",
      "         1.9499e+00, -3.6039e+00, -8.8428e-01,  1.2486e+00,  1.7057e+00,\n",
      "         3.4156e+00, -1.4654e+00, -1.3829e+00,  7.8937e-01,  7.9257e-01,\n",
      "         2.9625e+00,  1.1858e+00,  1.4331e+00,  2.2407e+00,  9.4643e-01,\n",
      "        -1.0173e+00, -1.3757e+00, -2.8048e+00,  1.8752e+00, -3.6748e-01,\n",
      "         1.2959e+00,  2.2651e+00,  4.6013e+00,  3.2253e-01, -3.4946e+00,\n",
      "         3.1881e+00, -2.7811e+00,  5.4911e+00,  1.0961e+00,  6.8478e+00,\n",
      "         1.9145e+00, -1.2752e+00,  3.5895e+00, -1.8093e+00,  4.3896e+00,\n",
      "         2.5919e+00, -4.2504e+00, -2.1853e+00, -1.3303e+00, -1.1024e+00,\n",
      "        -1.4524e+00,  1.6876e+00,  1.8318e+00, -3.8451e+00, -6.3515e-02,\n",
      "        -5.2881e+00, -1.8268e+00, -1.1312e+00, -6.5196e-02, -3.9489e-02,\n",
      "        -6.4836e-01, -1.6257e+00,  1.0841e+00, -1.7551e+00, -4.1739e-01,\n",
      "        -2.9933e+00, -2.2170e+00, -3.2074e+00, -1.5563e+00, -6.1508e-01,\n",
      "         7.6443e-01, -2.6830e+00,  3.3468e-01,  7.4126e-01,  2.2157e+00,\n",
      "         2.5756e-01,  5.5475e-01,  3.9855e+00,  1.4741e+00,  6.5171e-01,\n",
      "         2.4038e+00, -2.9009e+00, -2.4937e+00,  1.4195e+00, -1.2201e+00,\n",
      "        -6.1926e-01,  5.7821e-01,  4.5218e+00, -1.5421e+00, -1.0535e+00,\n",
      "        -2.0703e+00,  5.4029e+00,  1.1764e+00, -2.1989e-01, -7.6718e-01,\n",
      "        -4.6883e-01, -9.8249e-01,  4.6627e+00,  1.7118e+00, -1.7659e+00,\n",
      "        -1.5736e+00,  1.4919e+00,  4.1850e+00,  7.1875e-01,  3.1795e+00,\n",
      "         3.2884e+00, -1.0312e+00, -4.3352e+00, -2.2203e+00,  3.1435e-01,\n",
      "        -9.0913e-01, -1.3562e+00, -5.2023e+00,  9.5653e-01, -4.2561e+00,\n",
      "        -2.1710e+00,  2.2778e+00,  1.4760e+00,  4.3440e-01,  2.3004e+00,\n",
      "         2.0993e+00,  1.2763e+00,  3.0456e+00,  2.1837e+00,  1.7013e-01,\n",
      "        -1.8851e+00,  1.2303e+00,  1.8651e+00,  4.9282e+00,  1.1067e+00,\n",
      "        -2.3534e-01, -5.5266e-01, -7.0418e-01, -1.3334e+00, -9.2567e-01,\n",
      "         4.9242e-01, -5.5219e+00, -3.4001e+00,  1.9127e-01, -8.6207e-01,\n",
      "         5.1978e-01, -5.6113e+00, -1.3647e+00,  2.8764e+00, -1.3527e+00,\n",
      "        -1.8265e+00,  2.5646e-01, -2.7536e+00, -3.6298e+00,  3.6097e+00,\n",
      "        -1.8570e+00, -2.8090e+00,  2.6894e+00, -1.5113e+00, -3.0066e+00,\n",
      "        -1.6093e+00,  2.7189e+00, -6.8958e-01,  3.0639e+00, -2.8218e+00,\n",
      "        -4.5047e-01,  2.2534e+00,  7.2141e-01,  2.9678e+00, -1.5421e-01,\n",
      "        -1.2355e+00, -4.8345e-01, -1.1504e+00,  1.8792e+00,  4.6142e-02,\n",
      "         1.1228e+00, -9.4294e-01,  2.2277e+00,  2.7578e+00, -6.1784e+00,\n",
      "         8.3419e-01,  2.1411e+00,  1.9793e+00,  2.0560e-01, -5.1366e+00,\n",
      "        -5.1392e+00,  1.6813e+00, -2.6523e+00,  4.3492e+00,  7.4837e-01,\n",
      "         2.2428e+00, -5.3098e-01, -1.8754e+00, -1.5127e-01,  9.7124e-01,\n",
      "        -1.0904e+00, -3.4766e-02,  1.9193e-01, -4.6937e-01, -9.4082e-01,\n",
      "         2.5882e+00,  3.6077e+00, -1.2189e+00, -1.8094e+00,  1.8107e+00,\n",
      "        -2.0119e+00,  2.4953e+00,  3.7803e+00,  5.4465e-01, -3.3369e+00,\n",
      "        -7.8456e-01, -2.7078e+00, -4.0959e+00, -7.2996e+00, -1.6110e+00,\n",
      "         1.3083e+00, -2.6369e+00,  1.7525e+00,  3.5523e+00,  3.9974e+00,\n",
      "        -2.2581e+00,  4.9973e+00,  3.2281e+00,  2.0453e+00,  5.7822e-01,\n",
      "        -7.6691e-01, -1.0839e+00,  1.3786e+00,  5.2701e-01, -3.8165e+00,\n",
      "         2.9284e-01,  2.0289e+00,  7.4074e-01,  3.2151e+00, -4.7570e+00,\n",
      "        -7.5807e-01,  2.1412e+00,  1.8552e+00, -4.2666e+00, -7.1965e-01,\n",
      "         5.0125e+00, -2.2792e+00, -2.4238e-01, -7.4185e+00,  3.7173e-01,\n",
      "         3.2312e+00, -2.7349e+00, -3.2530e+00, -3.7129e-01,  1.3875e+00,\n",
      "        -2.0763e+00, -8.9308e-01, -6.4036e-01, -2.8082e+00, -1.3689e+00,\n",
      "         1.1502e+00,  5.3044e-01, -6.6141e-02, -1.1374e+00, -8.1296e-01,\n",
      "         4.9741e-01,  4.7657e+00,  1.8840e+00,  2.6177e+00, -4.4895e+00,\n",
      "        -7.6084e-01, -3.1870e-01,  2.4393e+00,  2.0634e+00,  8.9479e-01,\n",
      "         3.6355e-01, -4.2179e+00, -9.9434e-01,  3.2483e+00, -1.6277e+00,\n",
      "        -2.1036e+00, -2.9851e+00, -1.2140e-01, -9.1216e-01, -4.7611e-02,\n",
      "         3.3056e+00,  3.2116e+00,  1.4720e+00, -2.2325e+00,  6.3820e-01,\n",
      "        -1.0781e+00,  1.0106e+00,  1.7345e+00,  8.5914e-01,  1.3916e+00,\n",
      "         4.1208e+00, -4.4244e+00,  2.3523e+00,  7.5747e-02, -4.8993e+00,\n",
      "         3.1275e+00,  4.6341e+00, -2.2910e+00,  9.1207e-01, -2.5457e+00,\n",
      "         1.6591e+00, -7.7029e-01, -5.0853e+00,  1.9219e+00,  4.4111e+00,\n",
      "        -9.0514e-01, -5.3953e-01,  3.3229e-01, -9.8272e-01, -2.5611e+00,\n",
      "         1.3921e+00,  1.9202e+00,  3.0176e+00,  2.2719e+00, -3.2103e+00,\n",
      "         1.3770e+00,  9.2008e-02, -2.0838e-01])\n",
      "1 Victory\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "1 Victory tens shape torch.Size([2, 768])\n",
      "tensor(0.4362)\n",
      "counter 41\n",
      "2 Mansions\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "2 Mansions tens shape torch.Size([3, 768])\n",
      "tensor(4.8293)\n",
      "counter 42\n",
      "3 ,\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "3 , tens shape torch.Size([4, 768])\n",
      "tensor(0.1126)\n",
      "counter 43\n",
      "4 though\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "4 though tens shape torch.Size([5, 768])\n",
      "tensor(-3.2648)\n",
      "counter 44\n",
      "5 not\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "5 not tens shape torch.Size([6, 768])\n",
      "tensor(-0.8248)\n",
      "counter 45\n",
      "6 quickly\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "6 quickly tens shape torch.Size([7, 768])\n",
      "tensor(-0.9757)\n",
      "counter 46\n",
      "7 enough\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "7 enough tens shape torch.Size([8, 768])\n",
      "tensor(2.6440)\n",
      "counter 47\n",
      "8 to\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "8 to tens shape torch.Size([9, 768])\n",
      "tensor(-0.2474)\n",
      "counter 48\n",
      "9 prevent\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "9 prevent tens shape torch.Size([10, 768])\n",
      "tensor(-2.5119)\n",
      "counter 49\n",
      "10 a\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "10 a tens shape torch.Size([11, 768])\n",
      "tensor(-4.6513)\n",
      "counter 50\n",
      "11 swirl\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "11 swirl tens shape torch.Size([12, 768])\n",
      "tensor(3.9480)\n",
      "counter 51\n",
      "12 of\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "12 of tens shape torch.Size([13, 768])\n",
      "tensor(-2.5802)\n",
      "counter 52\n",
      "13 gritty\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "13 gritty tens shape torch.Size([14, 768])\n",
      "tensor(-0.3720)\n",
      "counter 53\n",
      "14 dust\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "14 dust tens shape torch.Size([15, 768])\n",
      "tensor(3.5061)\n",
      "counter 54\n",
      "15 from\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "15 from tens shape torch.Size([16, 768])\n",
      "tensor(-2.2138)\n",
      "counter 55\n",
      "16 entering\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "16 entering tens shape torch.Size([17, 768])\n",
      "tensor(1.4793)\n",
      "counter 56\n",
      "17 along\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "17 along tens shape torch.Size([18, 768])\n",
      "tensor(-0.9473)\n",
      "counter 57\n",
      "18 with\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "18 with tens shape torch.Size([19, 768])\n",
      "tensor(-2.1342)\n",
      "counter 58\n",
      "19 him\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "19 him tens shape torch.Size([20, 768])\n",
      "tensor(5.0262)\n",
      "counter 59\n",
      "20 .\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "20 . tens shape torch.Size([21, 768])\n",
      "tensor(0.0586)\n",
      "counter 60\n",
      "21 The\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "21 The tens shape torch.Size([22, 768])\n",
      "tensor(-3.2810)\n",
      "counter 61\n",
      "22 hallway\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "22 hallway tens shape torch.Size([23, 768])\n",
      "tensor(6.6300)\n",
      "counter 62\n",
      "23 smelt\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "23 smelt tens shape torch.Size([24, 768])\n",
      "tensor(4.3278)\n",
      "counter 63\n",
      "24 of\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "24 of tens shape torch.Size([25, 768])\n",
      "tensor(-2.2126)\n",
      "counter 64\n",
      "25 boiled\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "25 boiled tens shape torch.Size([26, 768])\n",
      "tensor(4.1905)\n",
      "counter 65\n",
      "26 cabbage\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "26 cabbage tens shape torch.Size([27, 768])\n",
      "tensor(5.4356)\n",
      "counter 66\n",
      "27 and\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "27 and tens shape torch.Size([28, 768])\n",
      "tensor(-2.8112)\n",
      "counter 67\n",
      "28 old\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "28 old tens shape torch.Size([29, 768])\n",
      "tensor(0.8668)\n",
      "counter 68\n",
      "29 rag\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "29 rag tens shape torch.Size([30, 768])\n",
      "tensor(6.1818)\n",
      "counter 69\n",
      "30 mats\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "30 mats tens shape torch.Size([31, 768])\n",
      "tensor(3.5220)\n",
      "counter 70\n",
      "31 .\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "31 . tens shape torch.Size([32, 768])\n",
      "tensor(0.4471)\n",
      "counter 71\n",
      "32 At\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "32 At tens shape torch.Size([33, 768])\n",
      "tensor(-4.3928)\n",
      "counter 72\n",
      "33 one\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "33 one tens shape torch.Size([34, 768])\n",
      "tensor(-3.1514)\n",
      "counter 73\n",
      "34 end\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "34 end tens shape torch.Size([35, 768])\n",
      "tensor(1.6079)\n",
      "counter 74\n",
      "35 of\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "35 of tens shape torch.Size([36, 768])\n",
      "tensor(-0.7748)\n",
      "counter 75\n",
      "36 it\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False]\n",
      "output torch.Size([44, 768])\n",
      "36 it tens shape torch.Size([37, 768])\n",
      "tensor(3.8863)\n",
      "counter 76\n",
      "37 a\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False]\n",
      "output torch.Size([44, 768])\n",
      "37 a tens shape torch.Size([38, 768])\n",
      "tensor(-3.2763)\n",
      "counter 77\n",
      "38 coloured\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False]\n",
      "output torch.Size([44, 768])\n",
      "38 coloured tens shape torch.Size([39, 768])\n",
      "tensor(1.9030)\n",
      "counter 78\n",
      "39 poster\n",
      "encoded {'input_ids': tensor([[  101,  1997,  3377, 26842,  1010,  2295,  2025,  2855,  2438,  2000,\n",
      "          4652,  1037, 28693,  1997, 24842,  3723,  6497,  2013,  5738,  2247,\n",
      "          2007,  2032,  1012,  1996,  6797, 15488, 20042,  1997, 17020, 28540,\n",
      "          1998,  2214, 17768, 22281,  1012,  2012,  2028,  2203,  1997,  2009,\n",
      "          1037, 11401, 13082,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False]\n",
      "output torch.Size([44, 768])\n",
      "39 poster tens shape torch.Size([40, 768])\n",
      "tensor(5.0816)\n",
      "counter 79\n",
      "q 2\n",
      "0 \n",
      "1 ,\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "1 , tens shape torch.Size([41, 768])\n",
      "tensor(-0.9332)\n",
      "counter 80\n",
      "2 too\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "2 too tens shape torch.Size([42, 768])\n",
      "tensor(0.5539)\n",
      "counter 81\n",
      "3 large\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "3 large tens shape torch.Size([43, 768])\n",
      "tensor(-2.3762)\n",
      "counter 82\n",
      "4 for\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "4 for tens shape torch.Size([44, 768])\n",
      "tensor(-1.3842)\n",
      "counter 83\n",
      "5 indoor\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "5 indoor tens shape torch.Size([45, 768])\n",
      "tensor(4.3739)\n",
      "counter 84\n",
      "6 display\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "6 display tens shape torch.Size([46, 768])\n",
      "tensor(0.3733)\n",
      "counter 85\n",
      "7 ,\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "7 , tens shape torch.Size([47, 768])\n",
      "tensor(3.7330)\n",
      "counter 86\n",
      "8 had\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "8 had tens shape torch.Size([48, 768])\n",
      "tensor(1.4066)\n",
      "counter 87\n",
      "9 been\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "9 been tens shape torch.Size([49, 768])\n",
      "tensor(2.2019)\n",
      "counter 88\n",
      "10 tacked\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "10 tacked tens shape torch.Size([50, 768])\n",
      "tensor(-1.9800)\n",
      "counter 89\n",
      "11 to\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "11 to tens shape torch.Size([51, 768])\n",
      "tensor(-2.9046)\n",
      "counter 90\n",
      "12 the\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "12 the tens shape torch.Size([52, 768])\n",
      "tensor(0.7692)\n",
      "counter 91\n",
      "13 wall\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "13 wall tens shape torch.Size([53, 768])\n",
      "tensor(0.2796)\n",
      "counter 92\n",
      "14 .\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "14 . tens shape torch.Size([54, 768])\n",
      "tensor(2.3688)\n",
      "counter 93\n",
      "15 It\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "15 It tens shape torch.Size([55, 768])\n",
      "tensor(-1.2444)\n",
      "counter 94\n",
      "16 depicted\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "16 depicted tens shape torch.Size([56, 768])\n",
      "tensor(2.0901)\n",
      "counter 95\n",
      "17 simply\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "17 simply tens shape torch.Size([57, 768])\n",
      "tensor(-4.7679)\n",
      "counter 96\n",
      "18 an\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "18 an tens shape torch.Size([58, 768])\n",
      "tensor(0.6239)\n",
      "counter 97\n",
      "19 enormous\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "19 enormous tens shape torch.Size([59, 768])\n",
      "tensor(4.7461)\n",
      "counter 98\n",
      "20 face\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "20 face tens shape torch.Size([60, 768])\n",
      "tensor(0.0745)\n",
      "counter 99\n",
      "21 ,\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "21 , tens shape torch.Size([61, 768])\n",
      "tensor(0.4459)\n",
      "counter 100\n",
      "22 more\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "22 more tens shape torch.Size([62, 768])\n",
      "tensor(-0.7603)\n",
      "counter 101\n",
      "23 than\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "23 than tens shape torch.Size([63, 768])\n",
      "tensor(-3.3365)\n",
      "counter 102\n",
      "24 a\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "24 a tens shape torch.Size([64, 768])\n",
      "tensor(3.4117)\n",
      "counter 103\n",
      "25 metre\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "25 metre tens shape torch.Size([65, 768])\n",
      "tensor(2.6223)\n",
      "counter 104\n",
      "26 wide\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "26 wide tens shape torch.Size([66, 768])\n",
      "tensor(0.0591)\n",
      "counter 105\n",
      "27 :\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "27 : tens shape torch.Size([67, 768])\n",
      "tensor(-2.5503)\n",
      "counter 106\n",
      "28 the\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "28 the tens shape torch.Size([68, 768])\n",
      "tensor(4.3279)\n",
      "counter 107\n",
      "29 face\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "29 face tens shape torch.Size([69, 768])\n",
      "tensor(-4.1442)\n",
      "counter 108\n",
      "30 of\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "30 of tens shape torch.Size([70, 768])\n",
      "tensor(-3.5629)\n",
      "counter 109\n",
      "31 a\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "31 a tens shape torch.Size([71, 768])\n",
      "tensor(3.1779)\n",
      "counter 110\n",
      "32 man\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "32 man tens shape torch.Size([72, 768])\n",
      "tensor(-1.3872)\n",
      "counter 111\n",
      "33 of\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "33 of tens shape torch.Size([73, 768])\n",
      "tensor(-0.6409)\n",
      "counter 112\n",
      "34 about\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "34 about tens shape torch.Size([74, 768])\n",
      "tensor(2.5633)\n",
      "counter 113\n",
      "35 forty-five\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "35 forty-five tens shape torch.Size([75, 768])\n",
      "tensor(1.3844)\n",
      "counter 114\n",
      "36 ,\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "36 , tens shape torch.Size([76, 768])\n",
      "tensor(1.7509)\n",
      "counter 115\n",
      "37 with\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "37 with tens shape torch.Size([77, 768])\n",
      "tensor(0.2284)\n",
      "counter 116\n",
      "38 a\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False]\n",
      "output torch.Size([45, 768])\n",
      "38 a tens shape torch.Size([78, 768])\n",
      "tensor(-1.9741)\n",
      "counter 117\n",
      "39 heavy\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False]\n",
      "output torch.Size([45, 768])\n",
      "39 heavy tens shape torch.Size([79, 768])\n",
      "tensor(-4.2893)\n",
      "counter 118\n",
      "40 black\n",
      "encoded {'input_ids': tensor([[  101,  1010,  2205,  2312,  2005,  7169,  4653,  1010,  2018,  2042,\n",
      "         26997,  2098,  2000,  1996,  2813,  1012,  2009,  8212,  3432,  2019,\n",
      "          8216,  2227,  1010,  2062,  2084,  1037,  7924,  2898,  1024,  1996,\n",
      "          2227,  1997,  1037,  2158,  1997,  2055,  5659,  1011,  2274,  1010,\n",
      "          2007,  1037,  3082,  2304,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False]\n",
      "output torch.Size([45, 768])\n",
      "40 black tens shape torch.Size([80, 768])\n",
      "tensor(1.3117)\n",
      "counter 119\n",
      "q 3\n",
      "0 moustache\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "tensor([ 2.0940e+00,  2.9149e+00,  1.4607e+00, -7.7487e-01,  1.4413e+00,\n",
      "         2.7139e+00, -3.1266e+00,  2.8012e+00,  1.4416e+00, -3.5591e+00,\n",
      "         6.1241e-01, -3.4291e+00,  8.3125e-02,  5.0714e+00, -6.7185e-01,\n",
      "         9.6920e-01, -4.4712e-01,  1.8681e+00, -6.1996e+00, -4.5725e+00,\n",
      "         3.7409e+00,  5.8340e-01,  2.1209e+00,  2.9351e+00,  4.2423e-01,\n",
      "        -6.1334e-01,  3.2411e+00,  2.2214e+00, -1.8693e+00, -3.5394e-03,\n",
      "         4.4374e+00,  2.1339e-01,  4.2264e+00, -1.6895e+00,  3.8933e-01,\n",
      "        -4.9786e+00, -1.4763e+00, -1.3211e+00,  5.4999e-01,  3.1607e+00,\n",
      "         2.8528e+00, -5.8462e-01,  4.0881e-01,  2.5310e-01,  5.5388e-01,\n",
      "         4.1823e-01, -6.7667e-01,  8.9948e-01,  1.3273e+00, -1.0504e-01,\n",
      "         8.5244e-01,  1.0082e+00, -2.1893e+00, -2.0364e+00,  7.7210e-01,\n",
      "         1.7014e+00,  2.1177e+00, -2.2461e+00,  8.4661e-02,  9.4427e-01,\n",
      "        -2.4192e-01,  5.9632e-01,  2.8457e+00,  2.8951e-01,  3.3000e+00,\n",
      "        -3.5896e-01, -2.1191e+00,  1.1684e+00, -4.5267e+00,  1.5703e+00,\n",
      "         3.7961e+00,  3.3709e+00, -2.8529e+00, -1.6820e+00,  2.9127e+00,\n",
      "         1.6239e-01,  1.3831e+00,  5.6955e-01, -2.5016e+00, -1.7219e+00,\n",
      "        -2.6267e+00, -3.4179e-01, -3.8060e+00, -1.2596e+00,  1.2987e+00,\n",
      "         5.3627e-01,  8.3781e+00, -1.6612e+00,  2.2123e-01,  5.7709e+00,\n",
      "        -1.4874e+00,  3.1604e-01,  5.4747e+00,  2.4133e+00,  1.0556e+00,\n",
      "         6.6097e-01, -1.0422e+00,  1.1929e+00, -1.9465e+00,  2.8818e+00,\n",
      "         2.1458e+00, -1.4119e+00, -3.6021e+00,  3.1709e+00, -3.4640e+00,\n",
      "         4.4898e-01,  1.7016e+00,  4.3014e+00, -1.6296e+00,  1.0026e-01,\n",
      "         1.7964e+00, -1.1667e+00, -3.0539e+00, -3.0983e+00,  3.2576e-01,\n",
      "        -3.0194e-01, -3.3577e+00, -2.6845e+00, -1.6387e+00, -1.6634e+00,\n",
      "        -1.2014e+00, -1.1660e+00,  4.9001e-01,  1.1469e+00,  9.3604e-01,\n",
      "        -8.2378e-01, -5.1325e+00, -8.6325e-01,  7.7156e-01, -4.8812e-01,\n",
      "        -5.3114e-01,  4.4020e-01, -1.0559e+00,  3.0794e+00, -7.0342e-01,\n",
      "        -1.9308e+00, -1.6147e+00, -4.6146e-01, -1.7186e+00, -3.8407e+00,\n",
      "        -1.1325e+00, -3.2922e+00,  1.3068e+00,  4.5951e+00, -2.0997e+00,\n",
      "        -1.6865e+00, -1.9736e+00, -1.7430e+00,  2.0413e+00,  1.0183e+00,\n",
      "        -1.6815e+00,  4.6283e-01,  1.4739e+00,  1.1749e+00, -4.0130e+00,\n",
      "         2.5794e+00, -8.0871e-01,  5.3732e-01,  6.3469e-01, -1.4559e-01,\n",
      "         2.0181e+00,  8.9960e-01,  1.7032e+00,  3.2740e+00,  1.0009e+00,\n",
      "         3.6858e+00, -1.9013e+00,  1.3349e+00,  1.6661e-01,  3.1376e-01,\n",
      "        -9.0978e-01, -1.2285e+00,  5.9872e+00, -2.8391e+00,  2.7934e+00,\n",
      "         3.4241e+00,  1.2760e+00, -3.1797e+00,  1.6361e+00,  6.6776e-01,\n",
      "        -7.1765e-01,  2.5462e+00,  1.3445e+00,  4.5431e+00,  3.1904e+00,\n",
      "        -2.7641e-01,  1.3659e+00,  8.6648e-01, -1.9596e+00,  1.6190e+00,\n",
      "        -1.3971e+00, -2.6462e-02,  7.9942e-01, -2.0446e+00,  2.1845e+00,\n",
      "         4.4420e-01, -3.4979e-01, -4.0641e-01, -2.6618e+00, -2.7206e+00,\n",
      "        -5.2815e+00, -2.9479e+00,  3.7640e-01, -2.5027e+00,  2.6156e-01,\n",
      "        -5.2052e-01, -1.5964e+00,  4.0466e+00, -2.8975e+00, -4.1167e-01,\n",
      "         1.2425e-01, -1.4853e+00,  1.8598e+00, -4.1590e-01, -1.4978e+00,\n",
      "         1.6051e+00, -9.5555e-01, -4.7291e+00,  4.5744e-01, -5.5589e-02,\n",
      "         7.7843e-01,  2.3848e+00, -3.3464e+00,  1.7198e+00, -2.6991e+00,\n",
      "         1.3683e+00,  3.0076e+00, -3.1943e-01,  2.0584e+00, -5.2417e-01,\n",
      "        -9.4141e-01, -3.2025e-01,  2.3602e+00,  5.2240e-01, -8.7717e-02,\n",
      "         2.4949e+00,  5.1352e-01, -5.8281e-01, -4.3761e+00, -2.1240e-01,\n",
      "        -3.1553e+00,  4.8047e+00, -8.6935e-01, -2.3683e+00,  5.8792e-01,\n",
      "        -2.0750e+00,  1.1426e+00,  9.7223e-01, -1.7646e-01, -4.6326e-01,\n",
      "        -2.6646e+00,  3.6132e+00,  2.9726e+00,  2.2968e-01, -9.4590e-02,\n",
      "         4.0038e+00, -1.7215e+00,  2.3612e-01,  2.8935e+00, -1.8701e-01,\n",
      "        -1.5828e+00, -2.2422e+00,  1.1980e-01,  1.0820e+00, -7.0564e-01,\n",
      "        -9.7166e-02, -4.1236e-01, -8.2663e-01, -2.6040e+00, -4.6403e+00,\n",
      "        -1.7508e+00,  6.6952e-02,  1.7680e+00, -2.5797e+00,  3.2676e+00,\n",
      "         6.1065e-01, -2.7670e+00, -9.2410e-01,  1.5015e+00, -3.0972e+00,\n",
      "         7.5031e-01,  4.0572e-01, -1.3901e+00, -8.6641e-01, -7.8558e-01,\n",
      "         2.1828e+00,  6.6598e+00,  3.2705e+00, -2.3051e+00,  1.1451e+00,\n",
      "        -1.0472e+00,  2.9788e+00,  1.7575e+00,  3.6204e+00,  2.4658e+00,\n",
      "         4.1675e-01,  1.0950e+00,  1.7652e+00, -3.0736e+00, -8.5930e-02,\n",
      "        -7.0942e-01, -3.7644e+00,  7.5349e-01,  8.5828e-01,  4.2515e+00,\n",
      "         3.3812e-01, -1.3444e+00, -8.0516e-01, -1.2510e+00, -1.1954e+00,\n",
      "        -1.8644e+00, -3.8709e+00,  1.5777e+00,  5.5784e-01, -4.2327e+00,\n",
      "         1.7850e+00, -4.0009e+00,  1.0987e+00, -3.0449e+00,  2.7267e+00,\n",
      "         1.2760e+00,  6.3325e-01, -3.6303e-01, -4.4426e+00, -1.7878e+00,\n",
      "        -1.9172e+00, -3.1895e+00,  1.8520e+00, -3.6880e+00, -1.1215e+00,\n",
      "        -7.2483e-01, -1.6385e+00, -2.5447e+00,  1.5226e+00,  3.7350e+00,\n",
      "        -2.8502e+00,  2.4491e+00,  3.7740e+00, -2.2923e+00,  4.1089e-01,\n",
      "         1.7506e+00, -4.3110e+00,  4.2415e+00, -4.6616e+00,  2.0795e-01,\n",
      "        -1.4663e+00, -1.9211e+00, -4.1210e+00,  1.4327e+00, -4.0474e+00,\n",
      "        -8.7988e-01,  2.4072e+00,  1.6990e+00, -7.7717e-01, -6.0787e+00,\n",
      "        -8.1058e+00,  2.6605e-01, -2.0293e+00, -4.3217e+00, -2.5127e+00,\n",
      "        -3.2312e+00, -1.3643e+00, -1.5963e+00, -5.3216e+00,  3.0027e+00,\n",
      "        -1.1111e+00,  8.2274e-01, -1.8926e+00, -6.3042e-01, -1.3994e+00,\n",
      "         1.1155e+00, -2.9210e+00,  6.3179e+00, -2.2773e+00, -6.7063e+00,\n",
      "        -3.0687e+00, -2.3565e+00, -3.0781e+00, -2.1919e-01, -2.9046e+00,\n",
      "         2.2117e-01, -3.9836e+00,  1.5679e+00, -1.5861e+00, -9.7573e-01,\n",
      "         6.3964e-01, -1.7064e+00,  7.8857e-01,  2.0886e+00, -1.7912e+00,\n",
      "         7.9620e-01, -2.0848e-01, -3.6921e-01,  6.8881e-02, -3.4728e+00,\n",
      "         3.6985e-01, -2.9572e+00,  2.5248e+00,  1.1994e+00,  2.0730e+00,\n",
      "        -5.5835e-01,  5.3406e-01,  7.6546e-01,  9.6226e-01, -5.1828e+00,\n",
      "        -1.2780e+00,  3.2765e+00,  1.7073e+00,  1.0705e-01, -2.5388e+00,\n",
      "         1.7656e+00,  7.9508e-01, -3.9824e+00, -1.5918e+00, -4.8608e-01,\n",
      "         7.3526e-01, -1.0963e+00,  1.7850e+00, -1.5438e+00, -4.7050e+00,\n",
      "         3.8775e-01, -1.0949e+00,  2.0184e+00,  6.6811e-01,  3.3983e+00,\n",
      "         2.0845e-01, -1.4158e+00, -2.1150e+00, -3.2307e+00,  2.8033e+00,\n",
      "         2.8371e-01, -5.5702e-01,  1.7188e+00,  2.5367e+00, -3.7616e-01,\n",
      "         1.1501e+00, -4.4842e-01, -2.4168e+00, -2.3719e+00,  3.1082e-01,\n",
      "         4.6874e+00, -1.9402e+00,  3.8560e+00, -1.3389e+00,  7.1644e-01,\n",
      "        -4.1813e+00, -5.0612e+00,  1.6904e+00,  2.4039e-01,  6.4351e-01,\n",
      "         1.5030e+00,  6.7406e+00,  2.0383e+00, -2.3227e-01,  2.6229e+00,\n",
      "        -4.5427e+00, -1.8713e+00, -1.2713e+00, -2.1490e+00, -1.5334e+00,\n",
      "        -2.2922e+00,  1.1858e+00,  1.8099e+00,  2.8387e+00, -1.3078e+00,\n",
      "         2.0243e+00, -2.0255e+00, -1.6281e+00,  2.3225e+00,  1.5555e-01,\n",
      "         1.2813e+00,  2.0068e+00, -1.6253e-01,  4.6588e+00, -1.1855e+00,\n",
      "         1.3167e+00, -1.5094e+00,  9.9226e-01, -3.1148e+00,  3.2451e-01,\n",
      "        -3.7251e+00,  4.5055e+00, -1.1971e+00,  5.6177e-01, -5.9576e-01,\n",
      "        -2.2578e+00, -7.6437e-01,  3.1762e+00, -6.6478e-01,  1.4982e-01,\n",
      "        -3.4858e+00, -4.6240e-01, -5.7039e-01,  1.3408e+00,  2.9791e+00,\n",
      "        -1.7574e+00,  8.3136e-01, -1.7111e+00,  2.0866e+00, -9.1543e-01,\n",
      "         2.8534e+00, -4.3925e-01, -8.4607e-01, -2.6214e+00,  3.5797e+00,\n",
      "        -2.7855e+00, -1.7269e+00,  1.2636e+00, -1.1466e-01, -1.2947e+00,\n",
      "        -7.9924e-01, -1.5425e+00, -2.1927e+00,  2.3953e+00,  1.9364e-01,\n",
      "        -1.6328e-01,  6.0935e-01,  5.3173e-01,  1.2574e+00,  1.1895e+00,\n",
      "        -1.8950e+00, -1.8063e+00,  9.8593e-01,  1.0733e+00, -2.7961e+00,\n",
      "         4.0968e+00, -3.4567e+00,  3.6609e+00,  7.6098e-01,  1.5083e+00,\n",
      "         1.3908e+00, -5.1135e+00, -1.5932e-01,  3.7298e+00, -5.0453e-01,\n",
      "         1.6154e+00,  1.3882e-01, -3.6525e+00,  3.9039e+00, -4.1249e+00,\n",
      "        -3.7266e+00, -1.5471e+00, -2.0872e+00, -2.1137e+00,  1.8546e+00,\n",
      "        -1.3037e-02,  3.4102e+00, -1.3242e+00,  2.0283e+00, -3.3488e+00,\n",
      "         2.8602e-01, -3.5921e+00, -1.9810e+00,  3.4298e+00, -5.5521e-01,\n",
      "         2.5135e+00,  1.2038e+00,  1.0934e+00, -1.7879e+00,  4.7961e-01,\n",
      "        -7.5341e-01, -2.3100e+00,  1.0096e+00, -2.4437e+00, -5.3841e+00,\n",
      "         1.1624e+00,  4.0997e-01, -3.2704e-01, -1.4745e+00, -6.6090e-01,\n",
      "        -5.0445e+00, -2.4870e+00, -1.0985e+00, -2.5264e+00,  1.0808e+00,\n",
      "         3.5834e-01, -3.5401e+00, -1.5147e+00,  3.3625e+00, -2.9727e+00,\n",
      "         1.9485e+00, -3.6268e+00, -3.6858e+00,  9.2076e-01,  1.3946e+00,\n",
      "        -2.6409e+00,  4.8776e+00, -1.3923e+00, -2.5413e+00,  1.5547e+00,\n",
      "        -2.6456e-01, -2.5842e-01, -5.7391e+00,  9.8012e-01,  7.8955e-01,\n",
      "        -4.5671e-01, -2.5951e+00, -2.1463e+00,  2.2398e+00,  8.3554e-02,\n",
      "         2.7437e+00, -6.6515e-01, -9.7603e-01, -4.4792e-01,  8.6654e-01,\n",
      "         3.4357e+00, -3.7827e+00,  3.4273e+00,  2.8499e+00,  2.4622e+00,\n",
      "         2.9106e-02, -2.8185e+00, -7.8790e-01,  2.2355e+00,  3.3974e-01,\n",
      "        -2.1681e+00, -1.4796e+00, -5.7833e+00,  1.8421e+00, -1.7250e+00,\n",
      "         3.6913e+00, -1.4760e+00, -3.1702e+00, -1.7992e+00, -1.3356e+00,\n",
      "         9.8301e-01,  2.8081e+00,  7.5857e-01, -1.5793e+00,  2.9704e+00,\n",
      "         2.5363e+00,  1.5019e+00,  2.2321e+00,  2.4045e+00, -1.5888e+00,\n",
      "         1.3413e+00, -1.8468e+00, -3.4811e+00,  2.5156e+00,  1.1210e+00,\n",
      "         2.9805e-01,  1.3344e-01,  2.7047e+00, -3.0886e-01,  1.2387e+00,\n",
      "         1.1319e+00,  7.5991e-01,  7.9279e-01,  2.8019e-01, -1.1957e+00,\n",
      "        -5.9416e-01,  1.1548e+00,  2.1117e+00,  1.1984e+00,  3.2332e+00,\n",
      "        -2.3010e+00,  7.8001e-01,  2.7512e+00,  3.6373e+00, -1.9579e+00,\n",
      "        -3.4376e+00, -1.2009e+00,  3.8973e-01, -2.1187e+00, -4.4121e+00,\n",
      "        -1.0275e+00,  3.6984e+00,  3.2332e+00,  1.2890e+00, -1.7081e+00,\n",
      "        -1.6104e+00, -7.1575e+00,  1.0313e+00,  9.2688e-01, -1.2097e+00,\n",
      "         4.5250e-01,  6.7166e-01,  3.8322e+00,  3.9625e+00,  3.3924e-01,\n",
      "        -3.2860e+00,  3.0145e+00, -4.4091e-01,  9.7327e-01, -5.6555e+00,\n",
      "         1.2134e+00, -7.1291e-01, -3.1473e+00,  2.5315e+00,  2.4279e+00,\n",
      "        -2.8550e+00,  1.1082e+00, -5.2296e+00, -3.1420e-01, -1.5590e+00,\n",
      "        -2.0244e+00,  1.5603e+00, -2.7408e+00,  6.0274e-01,  2.8869e+00,\n",
      "         1.8544e+00,  2.2332e+00, -3.1787e+00,  7.5830e-01, -3.2432e+00,\n",
      "        -1.2251e+00, -1.0952e+00,  4.2780e-02,  2.7420e+00, -3.1608e+00,\n",
      "         7.8782e-01, -2.7546e+00,  3.9653e+00, -6.5892e-01,  5.2585e+00,\n",
      "         4.3525e+00,  7.0172e-01, -3.2249e+00, -4.4500e+00, -3.0402e+00,\n",
      "         9.7187e-01,  1.1764e+00,  1.5227e-01, -2.1994e+00, -1.3480e+00,\n",
      "         3.7809e-01, -3.1014e+00, -6.5771e-01,  1.0088e+00, -2.6683e+00,\n",
      "        -1.7329e+00, -1.9048e+00,  4.3213e+00, -4.2155e-01,  9.4897e-01,\n",
      "         6.4243e-01, -1.4489e+00,  1.6936e+00, -1.5222e+00,  3.1673e-01,\n",
      "         7.9711e-01, -3.8683e+00, -4.7789e-03, -6.8717e-01, -1.9923e+00,\n",
      "         3.7626e+00,  4.0726e+00, -2.2760e+00,  2.2650e+00,  1.6670e+00,\n",
      "         6.3749e+00, -1.3306e+00, -2.5346e-01,  2.2045e+00,  4.0981e+00,\n",
      "         2.4794e+00,  3.9564e+00,  1.6311e+00,  3.8421e-01, -3.0139e+00,\n",
      "        -8.3492e-01, -7.9735e-01,  1.9730e+00,  3.3030e-01, -5.3110e+00,\n",
      "        -2.3935e+00, -1.1541e+00, -7.6106e-01])\n",
      "1 and\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "1 and tens shape torch.Size([2, 768])\n",
      "tensor(-3.8513)\n",
      "counter 121\n",
      "2 ruggedly\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "2 ruggedly tens shape torch.Size([3, 768])\n",
      "tensor(0.0789)\n",
      "counter 122\n",
      "3 handsome\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "3 handsome tens shape torch.Size([4, 768])\n",
      "tensor(1.1554)\n",
      "counter 123\n",
      "4 features\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "4 features tens shape torch.Size([5, 768])\n",
      "tensor(4.3740)\n",
      "counter 124\n",
      "5 .\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "5 . tens shape torch.Size([6, 768])\n",
      "tensor(0.1551)\n",
      "counter 125\n",
      "6 Winston\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "6 Winston tens shape torch.Size([7, 768])\n",
      "tensor(0.3309)\n",
      "counter 126\n",
      "7 made\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "7 made tens shape torch.Size([8, 768])\n",
      "tensor(1.5364)\n",
      "counter 127\n",
      "8 for\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "8 for tens shape torch.Size([9, 768])\n",
      "tensor(-1.6406)\n",
      "counter 128\n",
      "9 the\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "9 the tens shape torch.Size([10, 768])\n",
      "tensor(-2.4984)\n",
      "counter 129\n",
      "10 stairs\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "10 stairs tens shape torch.Size([11, 768])\n",
      "tensor(3.7176)\n",
      "counter 130\n",
      "11 .\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "11 . tens shape torch.Size([12, 768])\n",
      "tensor(0.4011)\n",
      "counter 131\n",
      "12 It\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "12 It tens shape torch.Size([13, 768])\n",
      "tensor(2.1606)\n",
      "counter 132\n",
      "13 was\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "13 was tens shape torch.Size([14, 768])\n",
      "tensor(0.5451)\n",
      "counter 133\n",
      "14 no\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "14 no tens shape torch.Size([15, 768])\n",
      "tensor(-2.9228)\n",
      "counter 134\n",
      "15 use\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "15 use tens shape torch.Size([16, 768])\n",
      "tensor(-0.2468)\n",
      "counter 135\n",
      "16 trying\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "16 trying tens shape torch.Size([17, 768])\n",
      "tensor(1.2191)\n",
      "counter 136\n",
      "17 the\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "17 the tens shape torch.Size([18, 768])\n",
      "tensor(-2.5956)\n",
      "counter 137\n",
      "18 lift\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "18 lift tens shape torch.Size([19, 768])\n",
      "tensor(5.4827)\n",
      "counter 138\n",
      "19 .\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "19 . tens shape torch.Size([20, 768])\n",
      "tensor(0.3275)\n",
      "counter 139\n",
      "20 Even\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "20 Even tens shape torch.Size([21, 768])\n",
      "tensor(-3.2569)\n",
      "counter 140\n",
      "21 at\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "21 at tens shape torch.Size([22, 768])\n",
      "tensor(-6.0677)\n",
      "counter 141\n",
      "22 the\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "22 the tens shape torch.Size([23, 768])\n",
      "tensor(-4.3156)\n",
      "counter 142\n",
      "23 best\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "23 best tens shape torch.Size([24, 768])\n",
      "tensor(-3.3922)\n",
      "counter 143\n",
      "24 of\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "24 of tens shape torch.Size([25, 768])\n",
      "tensor(-4.0903)\n",
      "counter 144\n",
      "25 times\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "25 times tens shape torch.Size([26, 768])\n",
      "tensor(1.1977)\n",
      "counter 145\n",
      "26 it\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "26 it tens shape torch.Size([27, 768])\n",
      "tensor(2.7012)\n",
      "counter 146\n",
      "27 was\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "27 was tens shape torch.Size([28, 768])\n",
      "tensor(-0.4346)\n",
      "counter 147\n",
      "28 seldom\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "28 seldom tens shape torch.Size([29, 768])\n",
      "tensor(0.2772)\n",
      "counter 148\n",
      "29 working\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "29 working tens shape torch.Size([30, 768])\n",
      "tensor(3.2328)\n",
      "counter 149\n",
      "30 ,\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "30 , tens shape torch.Size([31, 768])\n",
      "tensor(0.6288)\n",
      "counter 150\n",
      "31 and\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "31 and tens shape torch.Size([32, 768])\n",
      "tensor(-1.1282)\n",
      "counter 151\n",
      "32 at\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "32 at tens shape torch.Size([33, 768])\n",
      "tensor(-3.7711)\n",
      "counter 152\n",
      "33 present\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "33 present tens shape torch.Size([34, 768])\n",
      "tensor(0.6188)\n",
      "counter 153\n",
      "34 the\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([45, 768])\n",
      "34 the tens shape torch.Size([35, 768])\n",
      "tensor(-4.9372)\n",
      "counter 154\n",
      "35 electric\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False]\n",
      "output torch.Size([45, 768])\n",
      "35 electric tens shape torch.Size([36, 768])\n",
      "tensor(1.2616)\n",
      "counter 155\n",
      "36 current\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False]\n",
      "output torch.Size([45, 768])\n",
      "36 current tens shape torch.Size([37, 768])\n",
      "tensor(4.3923)\n",
      "counter 156\n",
      "37 was\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False]\n",
      "output torch.Size([45, 768])\n",
      "37 was tens shape torch.Size([38, 768])\n",
      "tensor(1.0268)\n",
      "counter 157\n",
      "38 cut\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False]\n",
      "output torch.Size([45, 768])\n",
      "38 cut tens shape torch.Size([39, 768])\n",
      "tensor(3.4565)\n",
      "counter 158\n",
      "39 off\n",
      "encoded {'input_ids': tensor([[  101,  9587, 19966, 15395,  1998, 17638,  2135,  8502,  2838,  1012,\n",
      "         10180,  2081,  2005,  1996,  5108,  1012,  2009,  2001,  2053,  2224,\n",
      "          2667,  1996,  6336,  1012,  2130,  2012,  1996,  2190,  1997,  2335,\n",
      "          2009,  2001, 15839,  2551,  1010,  1998,  2012,  2556,  1996,  3751,\n",
      "          2783,  2001,  3013,  2125,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False]\n",
      "output torch.Size([45, 768])\n",
      "39 off tens shape torch.Size([40, 768])\n",
      "tensor(-2.4230)\n",
      "counter 159\n",
      "q 4\n",
      "0 during\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "tensor([-4.9222e+00,  2.7494e+00,  2.9716e+00,  1.1420e-01,  1.8727e+00,\n",
      "         6.8058e-01,  1.5272e+00,  1.7629e+00, -1.1362e+00,  1.9022e+00,\n",
      "         6.2194e-01, -2.6223e-01, -1.0210e+00,  2.9520e+00, -4.7310e-01,\n",
      "         3.2853e+00,  1.4505e+00,  1.8548e+00,  4.3421e+00,  2.5496e+00,\n",
      "        -3.1724e+00, -2.6440e+00, -1.2181e+00, -1.3993e+00, -2.2993e+00,\n",
      "         1.4674e+00,  1.3496e+00,  1.8358e+00,  1.8273e+00, -1.5992e+00,\n",
      "         3.8053e+00,  2.3026e+00,  2.0452e+00, -1.1328e+00, -2.5685e-01,\n",
      "        -3.0550e+00,  9.0212e-01, -4.5089e+00, -1.7126e+00,  3.2416e+00,\n",
      "         2.4030e+00, -2.9688e+00,  1.7731e-01, -3.6848e-01, -4.8225e+00,\n",
      "        -1.0157e+00,  1.9251e-02,  8.6825e-01,  1.7569e+00, -2.3259e-01,\n",
      "         4.1742e+00,  3.2399e+00,  5.3161e+00, -6.4657e-01, -3.4501e+00,\n",
      "        -7.3072e-01, -1.6490e+00,  1.4629e+00,  1.8919e+00, -3.1095e+00,\n",
      "        -2.1917e+00, -2.1845e-01, -3.4446e-01,  3.3063e+00, -9.9557e-01,\n",
      "        -5.6916e+00,  1.0461e+00,  3.1859e+00,  1.6757e+00, -4.8382e-01,\n",
      "         3.7859e+00, -5.7015e-01, -6.4887e-01, -5.2987e+00, -5.5730e-01,\n",
      "        -2.0924e+00,  1.6677e-01, -8.1933e-01, -6.6134e-01, -1.6590e+00,\n",
      "         3.4629e-01,  1.7581e+00, -3.6187e+00,  2.5374e+00, -4.3704e+00,\n",
      "        -4.0452e+00,  3.1644e+00,  1.2379e+00,  4.7935e+00,  5.4859e+00,\n",
      "        -5.4463e-01, -3.5784e+00,  2.1624e-01,  8.4667e-01, -9.6476e-01,\n",
      "        -4.5689e+00,  3.1210e-01,  3.0619e+00, -2.8819e+00,  3.5794e+00,\n",
      "        -2.1274e+00, -9.1808e-01, -2.2458e+00,  2.7372e+00,  1.5768e+00,\n",
      "         1.5187e+00,  1.1412e+00,  3.2858e+00, -1.2981e+00,  2.2561e+00,\n",
      "         1.8951e+00, -1.3208e+00,  6.7743e+00, -5.3215e+00,  3.9260e+00,\n",
      "         9.6264e-01, -1.9312e+00, -1.3002e+00, -1.5375e+00, -3.3069e+00,\n",
      "         1.7991e+00, -3.3268e+00,  1.5703e+00, -1.7808e+00,  1.1965e+00,\n",
      "        -9.7645e-01, -2.5726e+00, -6.8186e-01,  2.7775e+00, -5.9865e+00,\n",
      "        -2.6169e+00, -3.5474e+00,  2.8203e+00,  1.0384e-01,  2.1144e+00,\n",
      "        -3.5941e+00,  6.4033e+00, -1.5655e+00, -4.6527e-01, -1.9474e+00,\n",
      "        -3.5215e+00, -2.1776e+00,  3.6312e+00,  2.4516e-02, -1.5503e-01,\n",
      "         2.4645e+00, -4.7680e+00, -2.0173e+00,  1.2206e+00, -1.1875e+00,\n",
      "        -3.8101e+00, -6.2734e+00,  2.6988e+00,  1.3121e+00, -4.9431e+00,\n",
      "         1.8922e-01, -2.7707e+00,  8.6409e-01,  1.4276e+00, -1.0381e+00,\n",
      "         3.9460e+00, -7.7221e-01, -2.6792e-01, -2.7487e+00,  4.0858e-02,\n",
      "         7.0971e-01,  1.5430e-01, -1.3077e+00, -1.2341e+00,  1.3507e+00,\n",
      "         1.4582e+00, -2.4099e+00, -5.4737e-01,  1.4016e+00, -1.4617e+00,\n",
      "        -5.2909e-01, -4.6498e-01, -3.1252e+00, -1.0595e-01,  1.2646e+00,\n",
      "         9.5258e-01, -3.7780e-01, -1.0729e+00, -2.1697e+00,  4.0860e+00,\n",
      "        -1.9651e+00, -7.0222e+00, -5.9625e-01,  1.1682e-01, -9.7017e-01,\n",
      "         1.3966e-01,  2.9399e+00,  5.0041e-01, -1.6569e+00,  2.0871e+00,\n",
      "         9.3809e-01,  9.9259e-01, -7.1098e-01, -2.9171e+00, -9.7073e-01,\n",
      "        -2.0704e+00, -1.7158e+00, -1.9744e+00, -4.1485e-01,  1.9551e+00,\n",
      "        -2.5085e+00, -1.9383e+00, -2.0788e-01, -8.4484e-01,  1.4940e-01,\n",
      "         1.2694e-01,  5.8693e-01, -1.3022e+00, -3.4716e-01, -3.3322e+00,\n",
      "         1.4520e-01, -2.2138e+00, -3.5868e+00, -1.3754e+00, -3.8982e+00,\n",
      "         3.7372e+00, -3.6911e-01,  1.7480e+00, -1.2764e-01, -1.4711e+00,\n",
      "         1.1105e-01, -1.3947e+00, -1.0320e+00, -2.8240e+00, -7.3232e-02,\n",
      "        -3.1227e+00, -2.3614e+00, -3.1544e+00, -1.9936e+00,  3.6741e+00,\n",
      "        -2.6206e-02, -5.6451e-01,  2.5239e+00,  2.8891e+00, -1.1738e+00,\n",
      "        -3.8872e-01,  2.6381e+00,  3.0873e+00, -1.6199e+00, -2.8195e+00,\n",
      "        -1.1491e+00, -3.6099e+00, -2.9885e+00, -1.4518e+00,  1.3040e+00,\n",
      "         2.6894e+00, -3.2473e+00, -2.7631e+00, -5.7238e+00,  1.6453e-01,\n",
      "         2.0439e-02, -2.1335e+00, -8.7308e-01,  1.4649e+00,  5.4243e-01,\n",
      "        -3.1808e+00, -2.2197e+00, -3.2685e+00,  4.7535e-01,  1.6181e+00,\n",
      "         2.6964e+00,  2.3313e-01,  1.3040e+00, -2.1919e+00, -4.2431e+00,\n",
      "        -2.0180e+00, -4.6014e-01,  2.2182e+00,  9.5717e-01,  1.8427e+00,\n",
      "         5.6716e+00, -2.9259e+00,  1.4834e+00, -2.3951e-01, -8.6905e-01,\n",
      "        -2.0737e+00,  4.2550e-01,  7.2422e-01,  1.2396e+00,  1.8945e-01,\n",
      "         2.4400e+00,  8.3139e+00, -1.5789e+00, -1.2696e+00, -1.1609e+00,\n",
      "         1.6306e+00, -5.2417e-01, -1.4150e+00, -1.0276e+00,  5.0012e-01,\n",
      "         3.4376e+00, -2.5102e+00,  9.5622e-01, -8.8655e-01, -5.4162e-01,\n",
      "         4.0160e-01,  1.6708e-01,  3.3158e+00,  7.1389e-02,  1.0177e+00,\n",
      "         1.4292e+00, -3.0937e+00, -1.7452e+00, -1.6260e+01, -2.0719e+00,\n",
      "        -4.7625e-01,  2.2865e+00, -2.0759e-02, -1.4500e+00, -4.0407e+00,\n",
      "        -3.5447e-01, -2.1353e+00,  3.9359e-01,  2.9940e+00, -2.6229e+00,\n",
      "        -1.5272e+00, -8.9109e-02, -1.2416e+00, -2.1078e+00, -1.1200e+00,\n",
      "        -1.8074e+00, -2.3717e+00,  1.9387e+00,  9.3086e-01, -9.7185e-01,\n",
      "        -3.2106e+00,  1.8711e+00, -5.7147e-01,  8.2455e-01,  1.7772e+00,\n",
      "         3.0629e+00,  1.0580e+00,  1.2135e+00,  3.5177e+00,  1.6389e+00,\n",
      "         8.9265e-01, -3.0190e+00, -1.4225e-01, -2.6145e+00,  2.3463e-01,\n",
      "        -1.0037e+00,  2.1455e+00, -4.4546e+00, -4.0369e-01, -4.6425e+00,\n",
      "        -2.3411e-01,  3.8229e-02, -1.4581e+00,  3.1943e+00,  4.9913e-01,\n",
      "         8.8683e-02,  1.5669e+00,  3.3977e+00, -1.7724e+00, -6.2299e-02,\n",
      "        -1.3118e+00,  3.7012e-01,  1.4470e+00, -1.1961e-01,  1.4727e+00,\n",
      "         4.4828e+00,  3.7322e+00, -3.5166e+00, -2.5012e-01,  4.4462e-01,\n",
      "        -1.7370e+00,  2.4013e+00,  1.4129e+00, -3.8630e-03, -1.6569e+00,\n",
      "        -1.8981e+00, -8.3103e-01,  1.7402e+00, -1.1723e+00,  5.2307e+00,\n",
      "        -4.9912e-01, -5.9762e+00, -4.1234e-01, -5.5132e-01, -6.0325e+00,\n",
      "        -1.1200e+00,  1.5430e-01,  3.3834e+00,  4.3090e+00, -3.4019e+00,\n",
      "        -2.7166e+00, -6.1267e+00, -5.5697e+00, -2.2210e+00,  8.0802e-01,\n",
      "        -2.4518e+00, -8.3501e-01, -6.9147e-01,  1.1471e+00, -9.5115e-01,\n",
      "         1.8082e+00, -1.2741e+00,  2.4485e+00,  2.0963e+00,  5.4369e-01,\n",
      "        -3.8649e+00,  1.5930e+00, -5.8878e-01,  2.3700e+00, -9.4528e-01,\n",
      "         7.8163e-01,  1.2446e+00, -3.3107e-02, -2.7030e+00, -1.0443e+00,\n",
      "        -1.8336e-01, -1.7407e-01, -2.3041e+00, -2.1020e+00, -2.4507e+00,\n",
      "        -1.9396e+00,  4.8036e+00,  1.6485e+00,  1.0895e+00,  8.6127e-02,\n",
      "         6.9065e-01,  2.0103e+00, -3.2803e-01,  3.4566e+00,  2.9594e+00,\n",
      "         3.3951e-01, -3.2739e+00, -3.5927e+00, -4.9730e+00, -4.3726e+00,\n",
      "        -5.5109e-01,  2.8612e-01,  2.3742e+00, -3.6813e+00, -2.0019e+00,\n",
      "         6.4593e+00, -6.5539e-01, -1.6139e-01, -1.7324e-01,  3.8311e-01,\n",
      "         2.8333e+00,  2.7813e+00, -1.0565e+00, -3.4892e+00,  1.4765e+00,\n",
      "        -7.0376e-01,  9.3140e-01, -5.6675e+00, -1.1150e-01,  2.1761e+00,\n",
      "         7.8426e-01, -1.7056e+00, -3.2698e+00, -8.5471e-01,  2.1630e+00,\n",
      "         1.9627e+00, -1.1482e+00, -1.4048e+00, -1.5018e+00,  2.6653e+00,\n",
      "         1.8599e-01, -4.9504e+00, -2.9975e+00,  8.4521e-01, -1.5347e+00,\n",
      "         6.3089e-01, -3.7481e+00, -2.5174e+00,  4.1293e+00,  2.9370e-01,\n",
      "         2.9335e+00,  1.1056e+00,  2.2609e+00,  2.9138e+00, -6.2052e-01,\n",
      "        -6.1205e-01,  1.3273e+00, -2.2632e+00,  3.6587e-01, -1.4596e+00,\n",
      "         3.8617e+00, -7.5258e-01,  6.4087e+00, -1.1962e+00, -1.3362e+00,\n",
      "         1.0883e+00, -3.1400e-02,  4.3122e+00, -2.0533e+00,  5.9291e+00,\n",
      "         1.1414e+00,  7.4247e-01,  2.7285e+00,  1.2555e-01,  3.1433e+00,\n",
      "         3.8503e+00, -3.3688e+00, -3.6086e+00,  1.4100e-01,  5.7571e-01,\n",
      "        -1.0464e+00,  7.9073e-01, -7.3611e-01, -3.8938e+00, -2.2800e+00,\n",
      "        -4.2057e+00, -1.1479e+00, -6.0987e-01, -4.6290e-01, -1.0463e+00,\n",
      "        -2.5924e-01,  1.8919e-01, -3.2861e-01, -1.1890e-01,  4.6269e-01,\n",
      "        -9.1667e-01,  1.7793e+00, -1.1274e+00,  1.0077e+00,  1.3766e-01,\n",
      "         1.0210e+00, -2.1332e+00,  1.1937e+00, -9.1909e-01,  1.2367e+00,\n",
      "        -1.5803e-01, -4.1625e-01,  2.4289e+00,  1.9767e+00,  1.4831e+00,\n",
      "         2.9267e+00, -1.7346e+00, -1.4167e+00, -8.7281e-01, -3.5426e+00,\n",
      "         6.6225e-01,  1.9083e+00,  2.1989e+00,  6.3807e-01,  4.7384e-01,\n",
      "        -2.6027e+00,  4.6796e+00, -1.0962e+00, -9.2800e-01,  9.9807e-02,\n",
      "        -3.0303e+00,  1.6224e-01,  3.8549e+00,  1.6860e+00,  3.0728e-03,\n",
      "        -1.8916e+00,  1.1211e+00,  4.5917e+00,  6.0993e-01,  1.1975e+00,\n",
      "         2.5979e+00, -2.4098e-01, -1.0154e+00, -6.6138e+00, -2.9967e+00,\n",
      "        -1.3569e+00,  7.9722e-01, -1.5431e+00,  1.6751e+00, -5.9562e+00,\n",
      "        -1.6797e+00, -6.9924e-01,  1.4464e+00,  1.0665e+00,  2.9601e+00,\n",
      "         2.5105e+00,  1.5090e+00,  3.6914e+00,  6.4239e-01,  1.8409e-01,\n",
      "        -1.5369e+00, -3.1582e+00,  7.0274e-01,  3.8798e+00,  1.3449e+00,\n",
      "        -1.6427e+00,  2.2065e+00,  2.8656e-02, -2.6801e+00, -1.2421e+00,\n",
      "         1.4617e+00, -2.0551e+00, -1.2551e+00, -5.1089e-01,  8.6376e-01,\n",
      "         1.0755e+00, -5.5900e+00,  9.4829e-02,  4.4750e+00,  3.9672e+00,\n",
      "         1.3575e+00,  1.3404e+00, -2.4481e+00, -2.2829e+00,  3.7873e+00,\n",
      "        -7.1288e-01, -5.6075e+00,  3.1554e+00, -3.0000e+00, -4.3021e+00,\n",
      "        -2.8708e+00,  2.0418e+00, -1.1663e+00,  3.2089e+00, -2.9754e+00,\n",
      "        -2.7939e+00,  3.6664e+00, -1.2819e+00,  2.0327e+00, -3.3489e+00,\n",
      "        -1.0465e+00, -7.1132e-01, -8.2189e-01,  1.1834e+00,  3.5794e+00,\n",
      "         2.4291e+00,  4.9852e-01,  4.8795e+00,  3.0189e+00, -3.3078e+00,\n",
      "         5.4872e-01,  4.1949e+00,  2.0830e+00, -7.0119e-02, -5.6080e+00,\n",
      "        -3.0342e+00,  1.9359e+00, -1.9272e+00,  2.8385e+00,  3.7183e+00,\n",
      "         1.6968e+00, -1.6011e+00, -5.4091e-01, -8.5289e-01, -1.6603e+00,\n",
      "        -2.5121e+00, -1.6002e+00, -2.4345e+00,  1.5157e+00,  9.3712e-01,\n",
      "         3.9607e+00,  1.7597e+00, -1.2874e+00, -1.6578e+00,  3.7945e+00,\n",
      "        -2.6115e+00,  1.3238e+00,  3.2730e+00,  3.7016e+00, -1.7586e+00,\n",
      "         2.4906e+00, -2.0865e+00, -3.4097e+00, -7.4420e+00, -2.6900e+00,\n",
      "         2.8579e+00, -2.3565e+00,  7.0625e-01,  5.9279e+00,  2.9729e+00,\n",
      "        -2.7432e+00,  1.0325e+00,  5.4413e+00,  1.0279e+00,  1.2050e+00,\n",
      "        -2.4910e+00,  1.9346e+00, -2.8603e+00,  1.1265e+00, -4.3519e+00,\n",
      "         1.7738e+00,  2.2691e+00,  1.7341e+00,  2.3562e+00, -3.5814e+00,\n",
      "        -1.0668e+00, -1.3134e+00,  1.8580e+00, -2.6936e+00, -1.4948e+00,\n",
      "         4.9834e+00, -1.6592e+00,  3.5294e-01, -3.6963e+00, -9.9074e-01,\n",
      "         4.8004e+00, -3.4512e+00, -1.9552e+00,  2.8876e+00,  2.3286e-01,\n",
      "        -6.6394e-01, -3.9342e+00,  3.4853e-01, -1.2317e+00, -3.2895e+00,\n",
      "         4.2665e-01, -1.6760e-01,  1.1742e+00, -2.8282e+00, -3.6280e-01,\n",
      "        -1.7016e-01,  1.8520e+00,  1.3825e+00,  2.8298e+00, -4.1594e+00,\n",
      "         7.6435e-01, -2.3445e-01,  1.5382e+00,  3.2462e+00,  7.5588e-01,\n",
      "        -2.7833e-01, -6.7665e+00, -1.2276e+00,  5.1020e+00, -1.0194e+00,\n",
      "        -3.7609e+00, -6.7047e-01,  3.2964e-01,  2.7773e+00,  3.1020e-01,\n",
      "         1.7458e+00,  1.4783e+00, -9.9705e-02, -4.8706e-01,  2.2742e+00,\n",
      "         1.4085e-01,  3.0242e+00, -1.8039e-01,  1.8517e+00,  2.7652e+00,\n",
      "         2.2172e+00, -3.6370e+00,  7.9291e-01, -1.6536e+00, -3.7383e+00,\n",
      "         3.2005e+00,  4.6960e+00, -9.9662e-01,  6.4979e-02, -3.5220e+00,\n",
      "         2.7991e+00, -7.4157e-01, -4.8534e+00,  2.2737e+00,  5.9047e+00,\n",
      "         1.3015e+00, -1.7763e+00,  1.4525e-01,  1.6519e+00, -3.4650e+00,\n",
      "         1.4128e+00,  3.4381e+00,  3.0487e+00,  2.8966e+00, -2.8393e+00,\n",
      "        -4.7136e-01, -7.8396e-01,  6.0673e-01])\n",
      "1 daylight\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "1 daylight tens shape torch.Size([2, 768])\n",
      "tensor(0.2879)\n",
      "counter 161\n",
      "2 hours\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "2 hours tens shape torch.Size([3, 768])\n",
      "tensor(3.5174)\n",
      "counter 162\n",
      "3 .\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "3 . tens shape torch.Size([4, 768])\n",
      "tensor(0.3233)\n",
      "counter 163\n",
      "4 It\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "4 It tens shape torch.Size([5, 768])\n",
      "tensor(2.2616)\n",
      "counter 164\n",
      "5 was\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "5 was tens shape torch.Size([6, 768])\n",
      "tensor(1.7507)\n",
      "counter 165\n",
      "6 part\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "6 part tens shape torch.Size([7, 768])\n",
      "tensor(1.3767)\n",
      "counter 166\n",
      "7 of\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "7 of tens shape torch.Size([8, 768])\n",
      "tensor(-3.9603)\n",
      "counter 167\n",
      "8 the\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "8 the tens shape torch.Size([9, 768])\n",
      "tensor(-4.0135)\n",
      "counter 168\n",
      "9 economy\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "9 economy tens shape torch.Size([10, 768])\n",
      "tensor(-0.0948)\n",
      "counter 169\n",
      "10 drive\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "10 drive tens shape torch.Size([11, 768])\n",
      "tensor(5.4572)\n",
      "counter 170\n",
      "11 in\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "11 in tens shape torch.Size([12, 768])\n",
      "tensor(-4.7834)\n",
      "counter 171\n",
      "12 preparation\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "12 preparation tens shape torch.Size([13, 768])\n",
      "tensor(2.1295)\n",
      "counter 172\n",
      "13 for\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "13 for tens shape torch.Size([14, 768])\n",
      "tensor(-3.7206)\n",
      "counter 173\n",
      "14 Hate\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "14 Hate tens shape torch.Size([15, 768])\n",
      "tensor(5.2097)\n",
      "counter 174\n",
      "15 Week\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "15 Week tens shape torch.Size([16, 768])\n",
      "tensor(2.8733)\n",
      "counter 175\n",
      "16 .\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "16 . tens shape torch.Size([17, 768])\n",
      "tensor(0.2090)\n",
      "counter 176\n",
      "17 The\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "17 The tens shape torch.Size([18, 768])\n",
      "tensor(-3.0996)\n",
      "counter 177\n",
      "18 flat\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "18 flat tens shape torch.Size([19, 768])\n",
      "tensor(4.4615)\n",
      "counter 178\n",
      "19 was\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "19 was tens shape torch.Size([20, 768])\n",
      "tensor(1.6798)\n",
      "counter 179\n",
      "20 seven\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "20 seven tens shape torch.Size([21, 768])\n",
      "tensor(2.4591)\n",
      "counter 180\n",
      "21 flights\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "21 flights tens shape torch.Size([22, 768])\n",
      "tensor(3.1565)\n",
      "counter 181\n",
      "22 up\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "22 up tens shape torch.Size([23, 768])\n",
      "tensor(-0.2190)\n",
      "counter 182\n",
      "23 ,\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "23 , tens shape torch.Size([24, 768])\n",
      "tensor(0.6847)\n",
      "counter 183\n",
      "24 and\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "24 and tens shape torch.Size([25, 768])\n",
      "tensor(-1.1323)\n",
      "counter 184\n",
      "25 Winston\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "25 Winston tens shape torch.Size([26, 768])\n",
      "tensor(0.5422)\n",
      "counter 185\n",
      "26 ,\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "26 , tens shape torch.Size([27, 768])\n",
      "tensor(-0.2534)\n",
      "counter 186\n",
      "27 who\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "27 who tens shape torch.Size([28, 768])\n",
      "tensor(2.1731)\n",
      "counter 187\n",
      "28 was\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "28 was tens shape torch.Size([29, 768])\n",
      "tensor(2.0455)\n",
      "counter 188\n",
      "29 thirty-nine\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "29 thirty-nine tens shape torch.Size([30, 768])\n",
      "tensor(3.4064)\n",
      "counter 189\n",
      "30 and\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "30 and tens shape torch.Size([31, 768])\n",
      "tensor(0.6834)\n",
      "counter 190\n",
      "31 had\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "31 had tens shape torch.Size([32, 768])\n",
      "tensor(3.1712)\n",
      "counter 191\n",
      "32 a\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "32 a tens shape torch.Size([33, 768])\n",
      "tensor(-1.9266)\n",
      "counter 192\n",
      "33 varicose\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "33 varicose tens shape torch.Size([34, 768])\n",
      "tensor(-0.7512)\n",
      "counter 193\n",
      "34 ulcer\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "34 ulcer tens shape torch.Size([35, 768])\n",
      "tensor(-3.2075)\n",
      "counter 194\n",
      "35 above\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "35 above tens shape torch.Size([36, 768])\n",
      "tensor(-0.4006)\n",
      "counter 195\n",
      "36 his\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "36 his tens shape torch.Size([37, 768])\n",
      "tensor(1.8875)\n",
      "counter 196\n",
      "37 right\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "37 right tens shape torch.Size([38, 768])\n",
      "tensor(-0.6562)\n",
      "counter 197\n",
      "38 ankle\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False]\n",
      "output torch.Size([47, 768])\n",
      "38 ankle tens shape torch.Size([39, 768])\n",
      "tensor(5.5369)\n",
      "counter 198\n",
      "39 ,\n",
      "encoded {'input_ids': tensor([[  101,  2076, 11695,  2847,  1012,  2009,  2001,  2112,  1997,  1996,\n",
      "          4610,  3298,  1999,  7547,  2005,  5223,  2733,  1012,  1996,  4257,\n",
      "          2001,  2698,  7599,  2039,  1010,  1998, 10180,  1010,  2040,  2001,\n",
      "          4228,  1011,  3157,  1998,  2018,  1037, 13075, 11261,  3366, 17359,\n",
      "         17119,  2682,  2010,  2157, 10792,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False]\n",
      "output torch.Size([47, 768])\n",
      "39 , tens shape torch.Size([40, 768])\n",
      "tensor(-1.7493)\n",
      "counter 199\n",
      "40 \n",
      "q 5\n",
      "0 went\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "tensor([ 1.5073e+00, -3.1371e+00,  2.2519e+00,  1.3626e+00,  1.3872e+00,\n",
      "         5.2664e+00,  1.0596e+00,  7.9170e-01,  3.4731e+00, -2.0960e+00,\n",
      "        -1.4514e+00,  8.6683e-01,  3.2337e+00, -9.2163e-01,  1.3678e+00,\n",
      "        -8.9809e-01, -2.5350e+00,  8.0680e-01,  1.0386e+00, -1.4385e+00,\n",
      "        -9.3691e-01,  3.7817e-01, -1.4381e-02,  2.2022e+00, -7.8714e-01,\n",
      "        -3.8719e+00, -2.4934e+00, -4.3505e-02, -4.4786e+00, -3.3115e+00,\n",
      "         1.3490e+00,  3.8100e+00,  4.7619e+00, -1.8272e+00, -3.2542e+00,\n",
      "        -5.7996e+00,  2.7870e-01, -1.1647e+00, -3.4714e+00,  3.2371e+00,\n",
      "         2.0209e+00, -2.2686e+00, -1.1848e+00, -9.9962e-01,  2.1691e+00,\n",
      "         2.0420e-01,  6.1594e+00,  1.2014e+00,  1.2447e+00, -8.7538e-02,\n",
      "        -4.7180e-01,  4.4080e+00,  4.1024e+00,  6.1900e-01,  1.1768e+00,\n",
      "         3.3867e-03, -4.8560e-01,  2.6698e+00,  1.1383e+00, -4.1247e+00,\n",
      "        -2.6259e+00, -1.7057e+00,  1.8154e+00,  2.5836e-01,  1.0385e+00,\n",
      "         1.7425e+00, -3.7040e+00,  2.3212e+00, -2.7644e+00,  1.0606e+00,\n",
      "         1.3534e+00, -1.3851e+00, -6.0403e+00, -2.9670e+00, -1.3853e+00,\n",
      "         2.3878e+00, -4.9128e-02,  1.4524e+00, -2.3929e+00,  1.3989e+00,\n",
      "        -5.1762e+00,  2.2996e+00, -5.1503e+00, -1.1467e-01, -1.6013e+00,\n",
      "        -2.6168e+00,  2.1376e+00, -1.7656e+00,  3.3714e+00, -1.2662e+00,\n",
      "        -1.4094e+00, -2.3768e+00,  4.3749e+00,  6.3383e-01,  3.8482e+00,\n",
      "         5.7660e-01,  1.1169e+00, -2.6105e+00,  1.1381e+00, -1.0758e+00,\n",
      "        -3.1821e+00,  1.9368e+00, -3.3046e+00, -1.6486e+00, -4.9852e-01,\n",
      "         2.6057e+00, -2.8281e+00,  5.5889e+00, -7.1830e-01,  4.1644e-01,\n",
      "        -2.3561e+00, -2.4937e+00, -2.7275e+00, -1.4398e+00, -1.6640e+00,\n",
      "         2.3957e+00,  1.3989e+00, -1.2245e+00, -2.6842e+00,  1.1910e+00,\n",
      "         3.7923e+00,  9.3091e-01, -1.8577e+00,  9.3273e-01,  6.7706e-01,\n",
      "        -1.7494e+00, -4.9866e-01,  7.3668e-01,  3.6666e+00,  5.3098e-01,\n",
      "         2.5420e+00, -1.0365e+00, -8.4327e-01, -2.7992e-01,  4.7045e+00,\n",
      "        -6.4444e+00,  1.5384e+00, -2.8257e-01, -1.8710e+00, -1.0814e+00,\n",
      "         1.0797e+00,  4.5774e+00,  4.5871e+00,  2.0938e+00, -1.4086e+00,\n",
      "        -1.4864e+00, -1.3901e+00,  7.9785e-01,  7.9335e-01, -2.8019e+00,\n",
      "         2.7628e+00,  5.2012e-01, -1.2640e+00,  1.6755e+00, -2.6744e+00,\n",
      "         1.6433e+00, -2.5470e+00, -1.8855e+00,  2.8950e+00,  1.5673e+00,\n",
      "         1.6186e+00, -2.3355e+00,  1.8957e-01, -5.3566e-01,  4.9444e-01,\n",
      "         2.2385e+00,  9.1168e-01,  8.9679e-01,  1.6926e+00, -1.6129e+00,\n",
      "         2.2740e+00, -1.0059e+00,  3.5084e+00, -2.4570e+00,  1.9969e+00,\n",
      "        -1.8810e+00,  4.8942e+00,  9.0301e-01, -1.2175e+00,  2.3030e+00,\n",
      "        -6.8743e-01, -2.5653e+00,  1.2336e+00, -1.2998e+00,  4.4752e+00,\n",
      "         1.1724e+00,  1.3007e+00, -1.4500e+00,  4.7882e+00,  3.0459e+00,\n",
      "         3.0324e+00,  4.2836e-01,  2.9544e+00, -4.0598e+00,  3.7743e+00,\n",
      "         3.4818e+00,  5.2053e-01,  1.3393e+00,  1.0166e+00, -8.9359e-01,\n",
      "         1.7306e+00,  2.6303e-01, -1.9605e-01,  2.4142e+00,  4.6806e-02,\n",
      "         1.4758e+00,  1.4784e+00,  3.0259e+00, -1.4704e-01,  1.1203e+00,\n",
      "         1.2949e+00, -1.0477e+00, -2.0658e+00, -3.3534e+00, -3.8240e+00,\n",
      "        -1.3861e+00, -1.7347e+00, -3.1148e+00,  6.4527e-01, -1.1083e+00,\n",
      "        -2.7357e+00,  7.9488e-01, -1.7707e+00,  2.7053e+00, -5.9615e+00,\n",
      "         2.8062e+00,  5.1005e+00,  1.7458e+00,  1.1887e+00, -3.8946e+00,\n",
      "        -2.0079e+00, -3.7500e+00, -1.9560e+00,  8.1943e-01, -3.3172e+00,\n",
      "         2.3946e+00,  2.3755e+00, -3.6304e+00, -2.3899e+00,  1.0374e+00,\n",
      "         1.6901e+00,  3.4085e+00,  3.5217e-01,  7.9377e-01, -2.1643e+00,\n",
      "        -8.6776e-01, -4.6749e+00, -5.0508e+00, -3.5388e-01,  1.7869e+00,\n",
      "         7.5235e-01, -1.3973e+00,  3.6632e-01, -4.0238e+00,  1.5986e+00,\n",
      "         2.6792e+00,  7.3524e-01, -3.9563e+00,  1.4154e+00, -2.8840e+00,\n",
      "        -8.9197e-01,  1.7853e+00, -6.5785e+00,  1.9626e+00, -1.3789e+00,\n",
      "        -6.4227e-01,  2.5823e+00,  2.6845e+00,  1.9190e-01, -1.5845e+00,\n",
      "        -1.9520e+00, -1.6797e+00, -7.1569e-01,  4.9202e+00,  9.6806e-02,\n",
      "         6.5487e-01, -1.0042e+00, -4.2878e-01,  3.8410e+00, -5.5120e+00,\n",
      "        -8.8854e-01,  1.6603e-01, -1.6090e+00,  3.8636e+00,  3.0490e+00,\n",
      "        -4.1470e+00,  6.6919e-01, -3.2529e+00, -7.5339e-01, -8.5813e-01,\n",
      "         5.0048e+00,  2.6997e+00, -3.3248e+00, -2.2988e+00, -2.9135e-02,\n",
      "        -1.2181e+00,  6.4660e-01, -6.3615e-02, -1.6622e+00, -3.3150e-01,\n",
      "         1.4536e+00, -3.9077e+00,  1.2963e+00, -4.2340e+00,  4.1525e+00,\n",
      "         1.2431e+00, -2.2965e+00,  7.6799e-01, -3.8791e+00, -2.5189e+00,\n",
      "        -8.8700e-01,  1.3580e+00, -1.5217e+00, -3.4322e+00, -2.7843e-01,\n",
      "        -1.1482e-01, -6.6289e+00, -1.3464e+00,  3.3011e-01,  3.8841e-01,\n",
      "         1.8917e-01,  4.9681e+00,  5.0661e+00, -8.7938e-01, -2.7095e+00,\n",
      "        -6.0368e+00, -3.1127e+00,  2.3260e+00, -1.8914e+00, -1.7706e+00,\n",
      "         1.1309e+00,  2.9441e-01, -1.6207e+00, -8.9809e-01,  4.3419e+00,\n",
      "        -9.4843e-01,  3.7367e+00,  1.6486e+00, -2.1344e+00,  3.1003e+00,\n",
      "        -1.3599e+00,  2.7682e+00,  5.2072e+00, -7.3867e-01,  8.6375e-01,\n",
      "         1.4065e+00,  2.6267e+00, -4.9339e+00,  8.2577e-02, -2.6602e+00,\n",
      "        -5.7461e+00,  3.1166e+00, -7.3552e-01,  5.9545e-01, -1.0752e+00,\n",
      "         1.8082e+00, -1.0149e+00,  5.8926e+00, -9.7751e-01, -2.4024e+00,\n",
      "        -2.8883e+00, -2.5324e+00,  2.9084e+00, -6.3903e-01, -1.7800e+00,\n",
      "         1.5387e+00, -2.0153e+00, -2.8800e-01,  3.8977e+00, -5.2500e-01,\n",
      "         5.0154e+00,  1.6097e+00,  3.5453e-01,  3.5829e+00,  6.4872e-01,\n",
      "         3.6224e+00, -4.9285e-01, -1.7885e+00, -3.6808e+00,  3.6789e+00,\n",
      "        -1.5830e+00, -5.6489e+00, -4.7316e+00, -2.1673e+00, -7.4642e-01,\n",
      "        -2.9511e+00, -7.1125e-01, -4.1065e-01, -4.8527e+00, -4.4806e+00,\n",
      "        -1.2948e+00, -1.6707e+00, -1.1510e+00, -1.8452e+00, -4.7462e+00,\n",
      "        -1.9577e+00, -2.6888e+00,  9.8322e-01, -1.4924e+00, -2.3886e+00,\n",
      "         1.7212e+00,  3.3864e+00,  8.9358e-01,  2.7131e+00, -8.5275e-01,\n",
      "        -5.0480e-01,  1.3560e-01,  2.6271e+00,  5.4473e+00,  2.3859e+00,\n",
      "         2.0338e+00, -1.6516e+00,  1.5271e+00,  1.7599e-01, -2.3627e+00,\n",
      "         2.1053e+00,  2.6961e-01,  2.3491e+00, -1.3209e+00, -2.4779e+00,\n",
      "         3.2401e+00, -2.8592e+00, -2.2782e+00, -2.1953e+00, -1.2273e-02,\n",
      "        -2.4791e+00,  9.7604e-01, -1.0504e+00, -1.1997e+00,  2.6400e+00,\n",
      "        -9.4914e-01, -4.9958e+00, -1.1703e+00, -1.1377e+00, -1.9327e+00,\n",
      "        -1.0119e-01, -3.2094e+00, -2.5580e+00, -1.7514e+00,  2.0887e+00,\n",
      "         1.9788e+00,  4.2969e+00, -3.1920e+00, -1.2089e+00,  1.5128e+00,\n",
      "        -1.7905e-01, -2.9001e-01, -6.9618e-01, -2.9675e-01, -3.2842e-01,\n",
      "         4.6410e-01,  2.8562e-01,  1.4399e+00, -4.5140e-01,  3.6708e-01,\n",
      "        -2.8495e+00, -1.6094e+00,  1.5679e+00, -2.2732e+00, -2.2568e-01,\n",
      "        -1.8361e+00,  1.4177e+00, -4.9601e+00, -7.0104e-01,  1.9879e-01,\n",
      "        -5.3831e-01, -5.3096e+00, -1.3211e+00,  1.3112e+00,  2.7090e+00,\n",
      "        -4.3376e+00, -2.1741e+00, -5.8855e+00,  5.3604e+00, -1.2511e+00,\n",
      "        -3.3623e+00, -5.8335e-01,  6.7695e+00,  1.2710e+00,  2.8884e+00,\n",
      "         1.4438e+00,  4.5655e+00,  2.1574e+00, -2.2427e+00, -2.0659e+00,\n",
      "        -1.8454e+00,  8.0236e-01,  4.5208e+00,  8.8880e-01, -2.8764e+00,\n",
      "        -4.0217e+00, -4.5576e+00, -5.9026e-04, -1.5874e+00,  3.3489e+00,\n",
      "        -2.5059e+00, -8.5797e-01,  5.5329e-01,  3.0356e+00,  1.0855e+00,\n",
      "         1.5656e+00,  2.5013e+00,  3.2657e+00, -6.3050e+00,  1.3709e+00,\n",
      "        -1.1030e+00,  1.4964e+00,  9.3150e-01, -5.4000e-01, -5.4948e-01,\n",
      "         2.5985e+00, -7.2086e-01, -8.5329e-01, -8.8024e-01,  6.2779e+00,\n",
      "         3.8713e+00,  3.7923e+00,  6.3363e-01, -3.6672e-01, -9.4161e-01,\n",
      "         1.5202e+00,  9.6350e-01, -3.9764e+00,  6.9565e+00, -1.7196e+00,\n",
      "        -1.4212e+00,  1.0632e-01,  1.4499e+00, -9.7664e-01, -2.6212e+00,\n",
      "         5.8557e-01, -1.3480e+00, -1.5174e+00,  6.1839e-01, -5.7849e-01,\n",
      "         7.1872e-01,  1.3354e+00, -1.9513e+00,  1.1634e+00, -3.5246e+00,\n",
      "        -2.0967e+00,  2.4809e+00, -1.7336e+00,  5.1601e-01,  1.0206e+00,\n",
      "        -3.1559e+00,  5.8947e-01,  1.1795e+00, -1.3674e+00, -1.5551e+00,\n",
      "        -3.4398e+00, -3.7706e+00,  2.5749e+00, -3.6430e-01, -2.0276e+00,\n",
      "         4.3328e+00, -8.6796e-01,  4.4960e+00, -1.9847e+00,  1.2357e+00,\n",
      "         4.9417e+00,  4.7504e-01,  2.5554e-01, -3.9548e+00, -2.4483e-01,\n",
      "         4.6596e+00, -2.3289e+00, -2.4709e+00, -4.7283e-02,  4.0625e+00,\n",
      "        -1.7292e+00, -5.3036e+00,  3.1198e+00,  3.1785e+00,  2.4571e+00,\n",
      "        -1.3667e+00, -4.8293e+00, -3.6572e+00, -1.7433e+00,  8.2555e-01,\n",
      "         2.6838e+00, -9.8463e-01, -3.0115e+00, -6.4332e-01, -3.5497e+00,\n",
      "         1.3593e+00,  3.8657e+00, -2.2543e+00, -6.0321e+00, -1.1825e+00,\n",
      "         1.1129e-01,  1.4076e+00,  4.3016e+00, -2.4298e-01,  1.6761e+00,\n",
      "         2.6341e+00, -7.7954e-01,  1.0440e+00, -2.9550e+00, -4.2598e-01,\n",
      "         1.6054e+00, -2.6688e+00,  2.4632e-01,  2.1848e-01, -1.0558e+00,\n",
      "        -1.3680e+00, -1.2812e+00,  2.8694e+00, -1.7216e+00,  4.1862e+00,\n",
      "        -4.0349e+00, -2.9629e+00,  3.3307e+00,  4.5870e+00,  9.1650e-01,\n",
      "        -1.5163e+00, -4.1305e+00,  4.8427e+00,  2.5147e+00, -5.1874e+00,\n",
      "        -5.8569e-01, -2.9054e+00, -2.3417e+00, -3.7781e+00, -1.6623e+00,\n",
      "        -5.3262e+00,  4.4365e-01,  1.7255e-01,  2.5906e+00, -2.1012e-01,\n",
      "         3.0443e+00,  5.0709e+00, -1.7182e+00,  2.5849e-02, -1.3076e+00,\n",
      "        -1.7056e+00,  2.4181e+00, -1.6687e+00, -6.0681e-02, -1.0441e+00,\n",
      "        -2.2061e+00, -3.6464e-01, -2.2160e+00, -1.3261e+00, -1.3151e+00,\n",
      "         1.9877e+00,  1.9318e+00,  1.8276e+00, -2.9947e+00,  2.2885e+00,\n",
      "         5.1361e+00,  2.8518e+00, -8.8011e-01,  4.4374e+00, -1.6164e-02,\n",
      "        -6.4426e-01,  1.8274e+00, -1.6105e+00,  4.7520e+00, -1.1990e+00,\n",
      "        -3.7895e+00, -5.0666e+00, -2.2598e+00,  4.8456e-02, -3.5848e+00,\n",
      "         2.7729e+00, -4.8310e+00, -1.5310e+00,  3.6211e+00,  2.6540e+00,\n",
      "         8.0994e-01, -2.9333e+00, -3.9320e-01,  1.6808e+00,  3.5942e+00,\n",
      "         7.1412e-01, -3.7192e+00,  3.1987e-01, -8.1954e-01,  3.5249e+00,\n",
      "        -2.7160e+00, -2.1575e+00, -6.4610e-01,  4.6053e+00, -1.3651e-01,\n",
      "        -7.2921e-01, -4.4333e+00, -3.8685e+00, -1.0796e+00, -2.7400e+00,\n",
      "         1.8862e-01, -4.3749e-02, -6.9365e-01, -1.1951e+00, -1.7393e+00,\n",
      "        -1.0190e+00,  2.7198e+00,  1.3015e+00,  1.5127e+00,  1.1994e+00,\n",
      "        -3.5782e-01,  2.9502e+00, -6.2527e+00,  1.4086e+00, -2.3659e+00,\n",
      "        -7.6549e-01, -3.5014e+00,  1.5047e-01,  1.8929e+00, -2.4649e+00,\n",
      "         3.7116e+00, -1.9656e+00, -1.8494e+00,  9.5397e-01,  1.0101e+00,\n",
      "         2.2597e+00, -8.6138e-01,  8.6902e-01, -9.6127e-01, -8.3262e-01,\n",
      "         8.7806e-02,  1.0954e+00,  1.1724e+00,  1.5214e+00,  1.4184e+00,\n",
      "        -7.5292e-01, -2.6114e-02, -2.9832e-01, -2.4919e+00,  7.1889e-01,\n",
      "        -3.0522e+00,  2.8952e+00,  1.2528e+00, -5.0709e+00,  5.3400e-01,\n",
      "         1.1710e+00, -1.0009e+00, -2.7967e+00, -3.2542e+00,  1.0792e+00,\n",
      "         1.7549e+00, -1.5452e+00,  1.4087e+00,  8.5523e-02, -2.3147e+00,\n",
      "         2.0737e+00,  3.8296e+00,  7.1133e-01, -2.0073e+00, -2.3324e-01,\n",
      "         2.4495e-01, -3.8660e-01,  6.7673e-01,  3.1446e+00, -5.4583e-01,\n",
      "         2.7976e+00, -4.1812e+00,  2.8666e+00,  4.4297e+00, -7.0918e+00,\n",
      "         9.8152e-03,  1.9643e+00,  8.6453e-01, -1.0923e+00, -2.4200e+00,\n",
      "        -1.3028e+00,  1.1917e-01,  4.9475e-01])\n",
      "1 slowly\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([46, 768])\n",
      "1 slowly tens shape torch.Size([2, 768])\n",
      "tensor(-0.7769)\n",
      "counter 201\n",
      "2 ,\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "2 , tens shape torch.Size([3, 768])\n",
      "tensor(0.3864)\n",
      "counter 202\n",
      "3 resting\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "3 resting tens shape torch.Size([4, 768])\n",
      "tensor(1.8965)\n",
      "counter 203\n",
      "4 several\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "4 several tens shape torch.Size([5, 768])\n",
      "tensor(0.9339)\n",
      "counter 204\n",
      "5 times\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "5 times tens shape torch.Size([6, 768])\n",
      "tensor(1.6813)\n",
      "counter 205\n",
      "6 on\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "6 on tens shape torch.Size([7, 768])\n",
      "tensor(-3.8558)\n",
      "counter 206\n",
      "7 the\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "7 the tens shape torch.Size([8, 768])\n",
      "tensor(-4.4177)\n",
      "counter 207\n",
      "8 way\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "8 way tens shape torch.Size([9, 768])\n",
      "tensor(1.6473)\n",
      "counter 208\n",
      "9 .\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([46, 768])\n",
      "9 . tens shape torch.Size([10, 768])\n",
      "tensor(0.3038)\n",
      "counter 209\n",
      "10 On\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "10 On tens shape torch.Size([11, 768])\n",
      "tensor(-5.9800)\n",
      "counter 210\n",
      "11 each\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "11 each tens shape torch.Size([12, 768])\n",
      "tensor(-6.2011)\n",
      "counter 211\n",
      "12 landing\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "12 landing tens shape torch.Size([13, 768])\n",
      "tensor(3.1950)\n",
      "counter 212\n",
      "13 ,\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "13 , tens shape torch.Size([14, 768])\n",
      "tensor(-0.1453)\n",
      "counter 213\n",
      "14 opposite\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "14 opposite tens shape torch.Size([15, 768])\n",
      "tensor(-3.2934)\n",
      "counter 214\n",
      "15 the\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "15 the tens shape torch.Size([16, 768])\n",
      "tensor(-3.6606)\n",
      "counter 215\n",
      "16 lift-shaft\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "16 lift-shaft tens shape torch.Size([17, 768])\n",
      "tensor(4.1182)\n",
      "counter 216\n",
      "17 ,\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([46, 768])\n",
      "17 , tens shape torch.Size([18, 768])\n",
      "tensor(0.4407)\n",
      "counter 217\n",
      "18 the\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "18 the tens shape torch.Size([19, 768])\n",
      "tensor(5.9872)\n",
      "counter 218\n",
      "19 poster\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "19 poster tens shape torch.Size([20, 768])\n",
      "tensor(0.2314)\n",
      "counter 219\n",
      "20 with\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "20 with tens shape torch.Size([21, 768])\n",
      "tensor(-2.7663)\n",
      "counter 220\n",
      "21 the\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "21 the tens shape torch.Size([22, 768])\n",
      "tensor(4.0354)\n",
      "counter 221\n",
      "22 enormous\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "22 enormous tens shape torch.Size([23, 768])\n",
      "tensor(-1.5653)\n",
      "counter 222\n",
      "23 face\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "23 face tens shape torch.Size([24, 768])\n",
      "tensor(-3.9915)\n",
      "counter 223\n",
      "24 gazed\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "24 gazed tens shape torch.Size([25, 768])\n",
      "tensor(0.3560)\n",
      "counter 224\n",
      "25 from\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([46, 768])\n",
      "25 from tens shape torch.Size([26, 768])\n",
      "tensor(4.1014)\n",
      "counter 225\n",
      "26 the\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "26 the tens shape torch.Size([27, 768])\n",
      "tensor(1.6581)\n",
      "counter 226\n",
      "27 wall\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "27 wall tens shape torch.Size([28, 768])\n",
      "tensor(-2.8254)\n",
      "counter 227\n",
      "28 .\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "28 . tens shape torch.Size([29, 768])\n",
      "tensor(-3.7290)\n",
      "counter 228\n",
      "29 It\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "29 It tens shape torch.Size([30, 768])\n",
      "tensor(0.9682)\n",
      "counter 229\n",
      "30 was\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "30 was tens shape torch.Size([31, 768])\n",
      "tensor(0.3260)\n",
      "counter 230\n",
      "31 one\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "31 one tens shape torch.Size([32, 768])\n",
      "tensor(2.0656)\n",
      "counter 231\n",
      "32 of\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "32 of tens shape torch.Size([33, 768])\n",
      "tensor(1.3448)\n",
      "counter 232\n",
      "33 those\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([46, 768])\n",
      "33 those tens shape torch.Size([34, 768])\n",
      "tensor(1.3464)\n",
      "counter 233\n",
      "34 pictures\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "34 pictures tens shape torch.Size([35, 768])\n",
      "tensor(-3.8380)\n",
      "counter 234\n",
      "35 which\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "35 which tens shape torch.Size([36, 768])\n",
      "tensor(-3.4318)\n",
      "counter 235\n",
      "36 are\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "36 are tens shape torch.Size([37, 768])\n",
      "tensor(4.3236)\n",
      "counter 236\n",
      "37 so\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "37 so tens shape torch.Size([38, 768])\n",
      "tensor(0.7296)\n",
      "counter 237\n",
      "38 contrived\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "38 contrived tens shape torch.Size([39, 768])\n",
      "tensor(2.0800)\n",
      "counter 238\n",
      "39 that\n",
      "encoded {'input_ids': tensor([[  101,  2253,  3254,  1010,  8345,  2195,  2335,  2006,  1996,  2126,\n",
      "          1012,  2006,  2169,  4899,  1010,  4500,  1996,  6336,  1011,  9093,\n",
      "          1010,  1996, 13082,  2007,  1996,  8216,  2227, 11114,  2013,  1996,\n",
      "          2813,  1012,  2009,  2001,  2028,  1997,  2216,  4620,  2029,  2024,\n",
      "          2061,  9530, 18886,  7178,  2008,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False]\n",
      "output torch.Size([46, 768])\n",
      "39 that tens shape torch.Size([40, 768])\n",
      "tensor(-0.0739)\n",
      "counter 239\n",
      "q 6\n",
      "0 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "tensor([-4.0649e+00, -2.3242e+00,  1.1888e+00,  2.9237e+00,  1.6219e+00,\n",
      "        -2.0161e+00, -2.5114e+00,  3.7955e+00, -4.6972e+00, -1.3997e+00,\n",
      "        -1.4555e+00,  4.4190e+00, -3.4985e+00, -2.6378e+00, -3.3292e+00,\n",
      "         2.3074e+00,  1.7959e+00,  2.3311e+00,  2.1256e+00, -1.8968e+00,\n",
      "        -4.1795e+00, -5.1838e+00, -1.3936e+00,  3.0936e+00,  9.0242e-01,\n",
      "         3.7198e+00,  1.0255e+00,  1.8942e+00, -2.6468e+00, -2.6197e+00,\n",
      "        -5.9611e-01, -1.5052e+00, -3.7498e+00, -5.8979e-01, -6.5022e-01,\n",
      "        -1.9168e+00, -2.3214e+00, -2.4120e+00, -1.4785e-01,  4.1859e-01,\n",
      "         3.3814e+00,  1.0402e+00, -1.7303e+00, -4.0117e+00, -1.6584e+00,\n",
      "        -3.7324e+00,  1.0794e-01, -2.8133e+00, -8.2280e-02, -5.8246e+00,\n",
      "         4.1500e-01, -6.0975e-01, -1.9482e-02,  5.3437e-01, -2.7643e+00,\n",
      "         9.6842e-01,  2.3921e+00, -1.5509e+00, -1.6402e+00, -7.5889e-01,\n",
      "        -2.4519e+00,  7.3876e-01,  7.1074e-01,  5.1030e-01,  9.5824e-01,\n",
      "        -3.4711e+00, -9.9252e-02,  3.0171e+00, -3.1476e+00,  4.6623e+00,\n",
      "         5.8774e-01, -2.4177e+00,  1.2987e+00, -1.6745e-01, -2.1490e+00,\n",
      "        -1.6399e+00, -1.8716e+00, -1.4239e+00, -4.1607e+00,  3.5283e+00,\n",
      "        -3.4836e-01, -1.3605e-01, -4.3811e-01,  3.0108e+00, -3.5330e+00,\n",
      "         1.7455e+00,  8.5991e-02,  4.2414e+00,  1.9817e+00,  3.3444e+00,\n",
      "         1.4000e+00,  1.0959e+00, -2.3363e+00, -8.1482e-01,  1.6212e-02,\n",
      "        -3.5419e+00, -1.3610e+00,  3.8589e-01, -1.6697e-01,  2.3163e+00,\n",
      "        -1.5767e+00,  1.0590e+00, -1.1156e+00,  1.8293e+00,  7.2580e-01,\n",
      "        -9.2867e-01, -1.3394e+00,  3.6067e+00, -2.2563e+00, -1.7541e+00,\n",
      "         1.0754e+00, -4.9149e-01, -6.0647e+00,  1.7420e-01,  6.9577e-01,\n",
      "         2.1890e+00, -4.7098e-01, -5.4686e-01, -7.3111e-01, -3.4184e-01,\n",
      "         1.4317e+00, -1.3772e+00, -9.2891e-01, -6.7867e-03, -1.7386e+00,\n",
      "         9.1158e-01, -2.1402e+00, -2.9717e+00,  2.9676e+00, -5.6011e+00,\n",
      "         8.8291e-01,  5.3094e-02,  8.8447e-01, -3.0456e+00, -2.3257e-01,\n",
      "         6.0983e-01, -8.5371e-01, -3.5259e+00, -8.0120e-01, -1.2010e+00,\n",
      "        -2.5174e+00, -1.7141e+00, -1.7582e+00, -8.2404e-01,  9.9544e-01,\n",
      "        -2.9641e+00, -3.3954e+00, -1.5895e+00,  2.4651e+00,  6.2098e+00,\n",
      "         1.3439e+00,  5.8127e-01, -3.8675e-01,  1.8812e+00, -3.6877e+00,\n",
      "        -1.3717e+00, -1.6343e+00,  2.2834e+00, -5.2646e+00,  4.5596e-01,\n",
      "         4.9049e+00, -3.2983e+00,  2.1964e+00, -3.6587e+00, -2.6711e+00,\n",
      "        -2.5059e+00, -1.3585e+00,  6.8396e-01, -6.1116e-01,  1.6928e+00,\n",
      "         2.0671e+00, -1.0468e+00,  4.3890e+00, -8.3216e-01, -4.3945e-01,\n",
      "        -1.4848e+00,  2.9623e+00,  1.1356e+00, -9.0593e-01, -8.7368e-01,\n",
      "        -5.3403e-01,  1.8197e-01, -9.5924e-01,  2.9826e+00, -1.0661e+00,\n",
      "         1.9006e+00,  7.6466e-01, -2.1864e+00,  2.0195e+00, -2.5131e-01,\n",
      "         4.4045e+00, -6.7700e-01,  9.7629e-01, -3.8746e-02,  1.5326e+00,\n",
      "        -1.1171e+00, -2.6304e+00,  1.3921e+00, -2.1540e+00,  1.7859e+00,\n",
      "         1.8619e+00, -2.5367e+00,  2.3612e+00,  2.8383e-01, -1.5459e+00,\n",
      "        -8.2945e-02,  6.7340e-01, -1.0325e+00, -1.3953e+00, -5.2061e-01,\n",
      "        -5.5752e-01, -3.8436e+00, -5.9114e-01, -1.4355e+00, -2.1649e+00,\n",
      "        -6.4508e-01, -1.4394e+00, -1.4018e+00,  4.1299e-01, -4.2129e-01,\n",
      "         1.1185e+00,  4.7166e+00, -1.1668e+00, -1.2895e+00,  1.3661e+00,\n",
      "         4.4597e+00,  3.3010e+00, -1.6125e+00, -2.6554e+00,  4.9317e+00,\n",
      "        -3.6446e+00, -3.6680e-01, -2.3723e+00, -1.3094e+00, -7.8122e-01,\n",
      "        -1.7013e+00,  5.0433e-01, -3.0830e-01,  5.0655e-01, -5.5862e-01,\n",
      "        -4.9461e-01,  2.2454e+00,  1.7954e+00,  1.8300e+00, -3.8645e+00,\n",
      "        -1.4982e+00,  7.6311e-01,  1.9798e+00,  3.2271e+00,  7.2846e-01,\n",
      "        -4.0417e+00,  5.6159e-01, -2.9895e+00, -4.2936e+00, -2.3620e+00,\n",
      "        -2.3315e+00,  7.8454e-01, -2.0629e+00,  1.6278e+00, -2.7971e+00,\n",
      "        -2.1345e+00,  3.6605e-01, -2.1168e+00,  3.6209e-02, -1.1095e+00,\n",
      "         4.1858e-02,  3.2112e+00,  7.7346e-01,  5.6918e-01, -9.7655e-01,\n",
      "         1.5005e-01, -4.3442e+00,  9.6896e-01,  1.8009e+00,  4.1755e-01,\n",
      "         1.3225e+00,  8.4900e-01, -2.6320e+00,  3.6014e-01, -4.0465e+00,\n",
      "        -1.9376e+00, -4.8154e-01, -1.9223e+00, -2.3084e+00, -2.7501e+00,\n",
      "        -3.0142e+00,  4.3083e+00,  2.5128e+00, -3.3979e-01, -6.5037e-01,\n",
      "         1.2313e+00, -7.2406e-01, -2.0045e+00, -3.4495e+00, -2.6564e+00,\n",
      "        -3.6248e+00, -8.4413e-03,  4.3269e+00, -2.2182e+00,  4.9157e-01,\n",
      "         7.3743e-01,  2.3099e+00,  1.3535e+00, -6.6604e-01,  8.7984e-01,\n",
      "         1.4358e-01, -5.0085e+00,  1.6255e+00, -8.0132e+00, -3.6138e+00,\n",
      "         2.4031e-02, -2.3566e+00,  4.3247e-01,  2.0924e+00, -7.1194e-01,\n",
      "        -3.7050e+00,  3.8830e+00, -1.0758e+00, -4.9330e+00,  1.6892e-01,\n",
      "         3.1882e+00, -1.1534e+00,  2.7187e+00, -2.6984e+00,  8.5747e-01,\n",
      "        -2.2892e+00, -3.6051e-01, -2.4898e+00,  7.6892e-01, -4.5040e-01,\n",
      "         1.5578e+00,  5.2727e-01,  3.0476e+00,  3.9217e-01,  1.6550e+00,\n",
      "        -4.7721e+00,  1.8926e+00, -1.3105e+00, -8.7442e-01, -4.1126e+00,\n",
      "        -1.7206e+00,  1.2279e+00,  2.4798e+00,  3.3928e-01, -5.9782e-01,\n",
      "         3.3179e+00,  6.7604e-01,  9.7884e-01,  3.5507e+00, -1.8825e+00,\n",
      "         3.8059e+00, -8.8562e-01,  6.9282e+00, -1.1618e+00, -6.2428e-01,\n",
      "        -9.6201e-01,  4.5287e+00,  1.7178e+00,  2.4648e+00, -2.2527e+00,\n",
      "         1.6716e+00,  3.7417e+00, -3.8066e+00,  2.6844e-01, -1.9850e+00,\n",
      "        -1.0751e+00, -7.3014e-01, -1.1156e+00, -1.3967e+00, -3.2235e+00,\n",
      "        -4.5192e+00,  2.2803e+00, -2.7748e+00, -5.6419e-01,  2.9392e+00,\n",
      "         1.7456e-01,  3.9313e+00,  2.2406e+00, -3.5996e+00,  9.6411e-01,\n",
      "        -4.8747e+00, -5.2733e+00, -2.2742e+00, -1.0375e+00,  1.3029e+00,\n",
      "         2.6118e+00,  2.7408e+00, -3.3118e+00,  6.0621e-02, -2.1067e-02,\n",
      "         2.3045e+00, -1.9002e-01,  3.4823e+00, -3.6410e+00,  3.9507e-01,\n",
      "        -1.4303e+00, -4.9453e+00, -5.0327e-01,  8.5703e-01, -2.3286e+00,\n",
      "         1.5136e+00,  3.7207e+00, -3.3310e-01,  1.1558e+00,  4.1171e+00,\n",
      "        -4.5306e+00, -1.4910e+00,  4.6618e-01, -9.1308e-01, -1.6186e+00,\n",
      "         4.5254e+00,  3.0630e+00, -2.5198e+00, -2.1458e+00,  1.6063e-01,\n",
      "        -2.9391e+00, -1.1706e+00, -3.0399e-01, -2.6744e+00, -2.8949e-01,\n",
      "         4.2124e+00,  4.5312e+00, -1.5848e+00, -9.6367e-01,  2.2483e+00,\n",
      "        -3.8240e+00, -5.2941e-01,  1.3800e+00,  2.3908e+00,  2.2217e+00,\n",
      "         1.4188e+00, -5.5045e-01, -4.3422e+00, -2.1632e+00, -1.2590e-01,\n",
      "        -3.7868e+00, -4.8483e+00, -3.8239e+00, -1.5426e+00, -1.0545e+00,\n",
      "        -3.9305e-01,  1.5057e+00, -7.2150e-02,  2.1554e+00, -8.1293e-01,\n",
      "         1.2017e+00,  8.6881e-01, -5.1183e+00,  6.0810e-01,  1.7853e+00,\n",
      "         2.2319e+00,  1.5970e+00,  5.5108e-01, -9.7303e-01,  5.2780e-01,\n",
      "        -1.9881e+00,  3.1053e+00,  1.9523e+00, -2.4038e+00, -2.0372e+00,\n",
      "         9.1232e-01,  6.9468e+00, -4.0016e+00,  1.3721e+00,  7.8078e-01,\n",
      "         1.4215e+00, -4.3875e+00,  6.8565e+00, -7.6475e-01, -2.1000e+00,\n",
      "        -2.2087e+00, -2.6928e-01,  1.0590e-01, -1.9815e+00,  7.0800e-01,\n",
      "         3.3315e+00, -5.0914e-01, -1.7217e+00,  1.5361e+00, -9.8003e-01,\n",
      "         1.2923e+00,  1.5253e+00, -8.6687e-02,  5.0410e-01,  1.5996e+00,\n",
      "         1.6346e+00, -1.6950e+00, -2.1196e+00, -1.1770e+00,  6.1825e-01,\n",
      "        -1.2010e-01, -2.3145e+00, -6.8955e-01,  1.5537e+00,  4.3476e+00,\n",
      "        -2.3976e+00,  3.6021e+00,  5.1000e-01,  4.9364e-01,  4.5879e-01,\n",
      "        -1.9435e+00, -2.6741e+00, -1.1032e+00, -1.7340e+00,  1.9092e-01,\n",
      "         3.0906e+00,  1.9405e+00, -9.4869e-01,  2.6595e+00, -1.5517e-01,\n",
      "         1.2262e+00, -9.6679e-01, -2.9148e-02, -2.5251e+00,  1.3959e+00,\n",
      "        -4.3712e+00, -2.5433e+00,  2.0170e+00,  1.2792e+00, -1.2437e-01,\n",
      "        -5.9531e-01, -3.6560e+00,  6.8898e-01, -1.0551e+00, -4.4176e+00,\n",
      "         1.1341e+00, -2.8742e+00,  1.9930e+00,  1.2435e+00,  1.0531e+00,\n",
      "        -7.0706e-01, -2.7520e+00,  2.8829e-01, -7.2963e-01,  1.3149e+00,\n",
      "        -5.4116e-01, -1.0648e+00, -3.8147e+00, -4.2003e-01, -3.8498e+00,\n",
      "         3.8659e+00, -1.0281e-03, -4.6781e+00,  3.8549e+00,  5.0889e+00,\n",
      "        -3.0229e+00, -9.9488e-01,  1.0967e+00,  9.7188e-01, -5.0516e-01,\n",
      "         1.7750e-01,  3.5694e-01,  2.2810e+00, -2.0595e+00,  6.2899e-01,\n",
      "         1.3374e+00, -2.2396e+00,  1.5890e+00,  2.8199e+00,  5.6786e-01,\n",
      "         2.0343e+00, -3.1637e+00, -5.5233e+00,  2.2757e+00,  2.2863e+00,\n",
      "         2.9319e+00,  2.3998e+00,  5.6232e-02, -2.3241e+00, -3.5043e+00,\n",
      "         3.5141e-01,  4.1293e+00, -1.1408e+00, -4.7327e-01, -2.5849e+00,\n",
      "        -2.5770e+00, -3.7950e+00,  2.9678e+00, -8.6988e-01,  6.4747e-01,\n",
      "         1.7667e+00, -3.0332e-01, -4.0337e-01,  1.8158e+00, -1.0564e+00,\n",
      "        -1.4055e+00, -2.2543e+00,  1.1293e+00, -2.0999e+00, -6.1239e-01,\n",
      "         1.0089e+00, -2.3443e+00, -5.7126e+00, -1.5334e+00, -1.8913e-01,\n",
      "         6.6900e-01, -3.7999e-01, -2.3231e+00,  8.1794e-01, -2.8871e+00,\n",
      "         5.2113e+00, -8.7495e-01,  2.0496e+00, -9.5723e-01,  3.3391e+00,\n",
      "         7.5690e-01, -2.4115e+00,  5.4923e-01,  4.8610e+00,  1.4804e+00,\n",
      "         1.1890e+00,  1.4765e+00,  4.5474e+00,  1.7267e+00,  1.4136e+00,\n",
      "        -1.8372e+00,  2.6051e+00, -3.6362e-01, -1.5492e-01, -3.5436e-01,\n",
      "         1.6316e+00, -4.0252e+00, -1.2799e+00,  3.0745e+00, -3.9157e+00,\n",
      "         1.6067e+00,  6.1099e-01,  1.8897e+00,  3.2965e+00,  1.5247e+00,\n",
      "         1.3247e+00,  1.8643e+00,  8.8312e-01,  1.5306e+00, -4.5497e+00,\n",
      "        -2.8170e-02, -3.8109e+00, -1.9153e+00, -1.1946e+00,  2.2622e+00,\n",
      "        -1.2441e+00, -1.1748e+00,  4.6397e+00, -9.9378e-01, -3.0340e+00,\n",
      "         6.5199e-02, -3.7201e+00,  3.1265e+00, -3.8158e+00,  7.9634e-01,\n",
      "        -3.3418e-01,  3.8219e+00,  1.5820e+00,  1.6878e+00,  1.7425e+00,\n",
      "         1.4385e+00,  1.2842e+00,  1.8753e+00,  9.3192e-01, -1.5272e+00,\n",
      "         9.7296e-02,  4.2802e+00,  3.3260e-01,  2.2118e+00, -3.1244e-01,\n",
      "        -1.6098e-01, -1.7238e+00, -1.4498e+00,  4.6004e+00,  1.4014e+00,\n",
      "        -1.8364e+00, -1.4502e+00,  1.1632e+00,  6.6854e-01,  3.8723e+00,\n",
      "        -7.3892e-01, -3.3609e-01,  1.3367e+00, -3.1424e+00,  1.8537e+00,\n",
      "         1.1129e+00, -3.1533e+00, -2.9725e+00,  1.4475e+00,  1.3696e+00,\n",
      "         9.1355e-01,  5.7533e-01,  3.1098e+00,  3.9948e+00,  4.0558e+00,\n",
      "        -2.1776e+00, -3.3526e+00, -1.7838e+00, -3.0348e+00, -4.9341e-01,\n",
      "        -3.9611e-01,  2.3628e+00, -8.6642e-01, -6.0351e-01,  9.8115e-01,\n",
      "         3.3586e+00,  5.6267e+00, -1.2643e+00, -1.0628e+00, -3.4771e+00,\n",
      "        -1.0676e+00, -3.2903e+00, -2.1599e+00, -1.2649e-01,  4.9602e-01,\n",
      "        -2.7387e+00,  1.0846e+00,  2.5291e+00, -1.1015e+00, -1.1477e+00,\n",
      "         5.2959e-03,  2.5014e+00,  7.2591e-01,  2.5650e+00, -8.9955e-01,\n",
      "         3.0143e-01,  6.6356e-02,  1.2196e+00,  2.8639e+00,  3.3126e+00,\n",
      "         1.5412e+00, -5.2782e+00, -2.8452e+00, -3.6748e-01,  3.6928e+00,\n",
      "         3.2179e+00, -2.6545e-01,  1.4610e+00,  1.1017e-01, -8.5543e-01,\n",
      "         5.0050e+00, -2.8473e+00,  7.1199e-01,  4.7902e-01,  2.0018e+00,\n",
      "         4.0455e+00, -3.6385e+00, -1.3507e+00, -6.1277e+00, -1.8902e+00,\n",
      "        -2.4001e+00,  2.4670e+00,  4.4127e+00,  4.9792e+00,  2.0060e+00,\n",
      "         2.5952e+00,  3.9511e+00,  1.7141e+00,  1.5455e+00,  1.6246e+00,\n",
      "        -2.0144e+00,  1.0339e-01,  1.2236e-01,  2.6245e+00,  7.7544e-01,\n",
      "         3.7966e+00,  8.7523e-01, -3.4091e-01,  3.3941e+00, -2.0119e+00,\n",
      "         2.8294e+00,  5.0128e+00, -7.3220e-01])\n",
      "1 eyes\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "1 eyes tens shape torch.Size([2, 768])\n",
      "tensor(2.3030)\n",
      "counter 241\n",
      "2 follow\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "2 follow tens shape torch.Size([3, 768])\n",
      "tensor(3.0296)\n",
      "counter 242\n",
      "3 you\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "3 you tens shape torch.Size([4, 768])\n",
      "tensor(1.8527)\n",
      "counter 243\n",
      "4 about\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "4 about tens shape torch.Size([5, 768])\n",
      "tensor(0.9538)\n",
      "counter 244\n",
      "5 when\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "5 when tens shape torch.Size([6, 768])\n",
      "tensor(-4.6135)\n",
      "counter 245\n",
      "6 you\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "6 you tens shape torch.Size([7, 768])\n",
      "tensor(2.9457)\n",
      "counter 246\n",
      "7 move\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "7 move tens shape torch.Size([8, 768])\n",
      "tensor(1.5428)\n",
      "counter 247\n",
      "8 .\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "8 . tens shape torch.Size([9, 768])\n",
      "tensor(0.1800)\n",
      "counter 248\n",
      "9 Big\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "9 Big tens shape torch.Size([10, 768])\n",
      "tensor(1.7216)\n",
      "counter 249\n",
      "10 Brother\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "10 Brother tens shape torch.Size([11, 768])\n",
      "tensor(2.6039)\n",
      "counter 250\n",
      "11 is\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "11 is tens shape torch.Size([12, 768])\n",
      "tensor(2.0097)\n",
      "counter 251\n",
      "12 watching\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "12 watching tens shape torch.Size([13, 768])\n",
      "tensor(1.2077)\n",
      "counter 252\n",
      "13 you\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "13 you tens shape torch.Size([14, 768])\n",
      "tensor(2.5214)\n",
      "counter 253\n",
      "14 ,\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "14 , tens shape torch.Size([15, 768])\n",
      "tensor(0.2231)\n",
      "counter 254\n",
      "15 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "15 the tens shape torch.Size([16, 768])\n",
      "tensor(-2.0283)\n",
      "counter 255\n",
      "16 caption\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "16 caption tens shape torch.Size([17, 768])\n",
      "tensor(0.3914)\n",
      "counter 256\n",
      "17 beneath\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "17 beneath tens shape torch.Size([18, 768])\n",
      "tensor(-1.7936)\n",
      "counter 257\n",
      "18 it\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "18 it tens shape torch.Size([19, 768])\n",
      "tensor(2.6732)\n",
      "counter 258\n",
      "19 ran\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "19 ran tens shape torch.Size([20, 768])\n",
      "tensor(4.0330)\n",
      "counter 259\n",
      "20 .\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "20 . tens shape torch.Size([21, 768])\n",
      "tensor(0.2760)\n",
      "counter 260\n",
      "21 Inside\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "21 Inside tens shape torch.Size([22, 768])\n",
      "tensor(-3.0356)\n",
      "counter 261\n",
      "22 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "22 the tens shape torch.Size([23, 768])\n",
      "tensor(-4.3588)\n",
      "counter 262\n",
      "23 flat\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "23 flat tens shape torch.Size([24, 768])\n",
      "tensor(3.7716)\n",
      "counter 263\n",
      "24 a\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "24 a tens shape torch.Size([25, 768])\n",
      "tensor(-5.0637)\n",
      "counter 264\n",
      "25 fruity\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "25 fruity tens shape torch.Size([26, 768])\n",
      "tensor(-1.6655)\n",
      "counter 265\n",
      "26 voice\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "26 voice tens shape torch.Size([27, 768])\n",
      "tensor(1.9665)\n",
      "counter 266\n",
      "27 was\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "27 was tens shape torch.Size([28, 768])\n",
      "tensor(-0.0640)\n",
      "counter 267\n",
      "28 reading\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "28 reading tens shape torch.Size([29, 768])\n",
      "tensor(-0.1398)\n",
      "counter 268\n",
      "29 out\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "29 out tens shape torch.Size([30, 768])\n",
      "tensor(-1.2847)\n",
      "counter 269\n",
      "30 a\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "30 a tens shape torch.Size([31, 768])\n",
      "tensor(-3.1501)\n",
      "counter 270\n",
      "31 list\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "31 list tens shape torch.Size([32, 768])\n",
      "tensor(5.3845)\n",
      "counter 271\n",
      "32 of\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "32 of tens shape torch.Size([33, 768])\n",
      "tensor(-1.2375)\n",
      "counter 272\n",
      "33 figures\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([44, 768])\n",
      "33 figures tens shape torch.Size([34, 768])\n",
      "tensor(4.4888)\n",
      "counter 273\n",
      "34 which\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "34 which tens shape torch.Size([35, 768])\n",
      "tensor(2.0773)\n",
      "counter 274\n",
      "35 had\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False]\n",
      "output torch.Size([44, 768])\n",
      "35 had tens shape torch.Size([36, 768])\n",
      "tensor(0.5628)\n",
      "counter 275\n",
      "36 something\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False]\n",
      "output torch.Size([44, 768])\n",
      "36 something tens shape torch.Size([37, 768])\n",
      "tensor(0.0228)\n",
      "counter 276\n",
      "37 to\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False]\n",
      "output torch.Size([44, 768])\n",
      "37 to tens shape torch.Size([38, 768])\n",
      "tensor(0.2810)\n",
      "counter 277\n",
      "38 do\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False]\n",
      "output torch.Size([44, 768])\n",
      "38 do tens shape torch.Size([39, 768])\n",
      "tensor(-1.6921)\n",
      "counter 278\n",
      "39 with\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2159,  3582,  2017,  2055,  2043,  2017,  2693,  1012,\n",
      "          2502,  2567,  2003,  3666,  2017,  1010,  1996, 14408,  3258,  4218,\n",
      "          2009,  2743,  1012,  2503,  1996,  4257,  1037,  5909,  2100,  2376,\n",
      "          2001,  3752,  2041,  1037,  2862,  1997,  4481,  2029,  2018,  2242,\n",
      "          2000,  2079,  2007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False]\n",
      "output torch.Size([44, 768])\n",
      "39 with tens shape torch.Size([40, 768])\n",
      "tensor(-2.0681)\n",
      "counter 279\n",
      "q 7\n",
      "0 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "tensor([-3.1099e+00, -2.7360e+00,  4.6506e-01,  3.4568e+00,  2.4284e+00,\n",
      "        -7.9390e-01, -1.6033e+00,  2.4300e+00, -5.9067e+00, -2.2478e+00,\n",
      "        -1.5397e+00,  3.1834e+00, -2.1753e+00, -7.1412e-01, -3.4193e+00,\n",
      "         1.4629e+00, -1.3408e+00,  2.4812e+00,  3.3663e+00, -7.8567e-01,\n",
      "        -5.9266e+00, -3.0581e+00, -1.3146e+00,  3.5767e+00,  6.0301e-01,\n",
      "         2.4968e+00, -1.1047e+00,  2.4864e+00, -2.8389e+00, -4.5091e+00,\n",
      "        -2.8509e+00,  1.1653e+00, -3.0157e+00, -2.1291e-01,  3.1050e-01,\n",
      "        -3.0905e+00, -9.1655e-01, -2.5575e+00,  1.0875e-01,  3.3214e-01,\n",
      "         1.4747e+00, -2.2414e-01, -8.9659e-01, -3.0854e+00, -4.0738e+00,\n",
      "        -3.7114e+00, -1.4332e+00, -2.9913e+00, -4.7661e-01, -6.7519e+00,\n",
      "         2.8126e+00, -5.2946e-01,  1.1516e+00,  1.1974e+00, -3.9600e+00,\n",
      "        -4.8031e-02,  2.6675e-01, -5.2784e-01,  2.5556e-01, -9.8828e-01,\n",
      "        -3.8128e+00,  1.3302e+00,  6.3943e-01,  3.3054e-01, -1.1399e-02,\n",
      "        -4.3180e+00, -9.0033e-01,  3.0159e+00, -6.9264e-01,  6.1211e+00,\n",
      "        -4.0576e-01, -3.8447e+00, -1.5892e-01, -1.1576e+00, -2.2208e+00,\n",
      "        -1.4205e+00, -1.5409e+00, -3.4600e+00, -8.0953e-01,  2.3360e+00,\n",
      "         1.9511e+00,  8.9865e-01, -3.0519e+00,  4.7940e+00, -4.4081e+00,\n",
      "         2.0916e+00, -9.4923e-01,  4.8322e+00,  1.0526e+00,  6.8194e-01,\n",
      "         2.3651e+00,  6.6232e-01, -2.6326e+00, -2.3389e+00, -2.0249e+00,\n",
      "        -4.4245e+00, -2.4742e+00,  1.8108e+00, -1.5184e+00,  9.4064e-01,\n",
      "        -2.2482e+00,  2.8126e+00, -6.8450e-01,  4.5628e+00, -1.3496e+00,\n",
      "        -9.5325e-01,  2.2671e+00,  3.5323e+00, -1.8845e+00, -7.9293e-01,\n",
      "         1.8009e+00,  7.2590e-01, -4.6059e+00,  2.0961e-01,  2.1451e+00,\n",
      "         5.1661e+00,  7.0579e-01, -1.0191e+00,  8.4635e-01, -4.1008e-01,\n",
      "         3.6492e+00, -5.0335e-01, -2.0755e+00,  1.6826e-01, -6.8763e-01,\n",
      "         1.2466e+00, -2.4407e+00,  1.3380e-03,  2.9009e-01, -5.3432e+00,\n",
      "         5.9351e-01,  1.3375e+00,  3.1274e-01, -8.2792e-01,  7.4257e-01,\n",
      "         1.0608e+00, -1.5997e+00, -2.0238e+00,  4.4415e-01, -6.6624e-01,\n",
      "        -4.1770e+00, -2.7771e+00, -2.2698e+00, -3.0872e+00,  4.1408e-01,\n",
      "        -3.1311e+00, -6.9177e-01, -1.2820e+00,  2.7474e-01,  6.6274e+00,\n",
      "         2.2310e+00,  9.4557e-01, -1.1213e+00, -7.6712e-02, -3.3354e+00,\n",
      "        -6.1276e-01,  5.6287e-02,  2.1875e+00, -5.1943e+00,  3.0922e+00,\n",
      "         5.5155e+00, -1.7267e+00,  8.2744e-01, -2.6130e+00, -1.3942e+00,\n",
      "        -3.0183e+00, -7.1040e-01, -4.8913e-02, -6.6848e-02,  1.8803e-01,\n",
      "         2.0329e+00, -1.5197e+00,  2.4320e+00, -7.2189e-03, -1.3524e+00,\n",
      "        -5.3932e-01,  1.1819e+00,  2.5606e-01, -7.7268e-01, -3.8264e-01,\n",
      "        -4.6773e-01, -8.2079e-01, -6.4038e-01, -7.8996e-01, -6.9493e-01,\n",
      "         1.0507e-01,  1.2862e+00, -1.2428e+00,  2.5207e+00, -4.9352e-02,\n",
      "         4.4256e+00,  3.6153e-01,  1.3519e+00, -2.0075e+00, -1.5835e-01,\n",
      "        -9.3871e-02, -3.7042e+00,  7.7189e-01,  1.6898e-01,  2.5487e+00,\n",
      "        -1.2531e-01, -2.5103e+00,  2.9641e+00, -1.1597e+00, -3.3478e+00,\n",
      "         1.5468e+00,  4.8790e-01, -7.0096e-01,  1.1161e-02,  1.5376e+00,\n",
      "         6.2630e-01, -3.4426e+00,  1.4795e+00, -6.9495e-01, -1.8362e+00,\n",
      "        -3.3727e+00, -7.1996e-01, -2.2149e+00, -6.9846e-01, -6.1799e-01,\n",
      "         2.2359e+00,  6.1269e+00, -1.4889e+00, -1.6744e+00,  2.5192e+00,\n",
      "         3.6200e+00,  4.2618e+00, -3.8108e+00, -2.3017e+00,  5.0783e+00,\n",
      "        -3.2891e+00, -3.4332e+00, -1.8576e+00, -2.2198e+00, -1.5029e+00,\n",
      "        -1.1478e-01,  7.7535e-01,  3.4237e-01,  1.1571e-01, -1.7356e+00,\n",
      "         1.1130e+00,  6.4660e-01,  2.4223e+00,  2.9007e+00, -4.4528e+00,\n",
      "        -3.6445e-01, -8.0540e-01,  2.3064e+00,  2.2402e+00,  3.7840e-01,\n",
      "        -1.1269e+00, -4.3476e+00, -4.3612e+00, -4.4496e+00, -1.9679e+00,\n",
      "        -2.3519e-02,  3.0617e+00, -2.9373e+00,  7.5207e-01,  1.7177e-01,\n",
      "        -1.0049e+00, -1.8006e+00, -1.5468e+00, -9.0880e-01, -1.4583e+00,\n",
      "         5.6660e-01,  3.0636e+00, -6.2239e-01, -9.6014e-01, -1.4635e+00,\n",
      "        -1.6152e-01, -3.4543e+00,  3.1722e-01,  2.8718e+00, -3.2934e-01,\n",
      "         3.1402e+00, -1.8734e+00, -2.5839e+00,  2.0098e+00, -2.7825e+00,\n",
      "        -1.5730e+00, -2.4456e-01, -2.1768e+00,  1.2346e+00, -1.4157e+00,\n",
      "        -2.9977e+00,  2.4692e+00,  4.6056e-01,  3.1712e+00, -6.5607e-01,\n",
      "         2.8063e+00, -3.6038e-02, -8.6993e-01, -3.0679e+00, -1.3410e+00,\n",
      "        -3.9900e+00, -1.3356e+00,  4.5206e+00, -5.3375e-01,  2.0028e-01,\n",
      "        -1.0803e+00,  6.3616e-01, -1.2837e+00,  2.1988e+00,  7.3866e-01,\n",
      "        -7.3278e-01, -2.7025e+00,  2.4518e-01, -1.2175e+01, -1.9397e+00,\n",
      "        -1.5192e+00, -1.9636e+00,  3.3618e-01,  3.0448e+00, -4.1435e+00,\n",
      "        -4.8384e+00,  4.4005e+00, -1.0998e+00, -4.2164e+00, -3.4299e-02,\n",
      "         4.6839e+00, -1.8832e+00,  1.4863e+00, -1.5474e+00,  1.6335e+00,\n",
      "        -3.5128e+00,  1.4765e+00, -2.4793e+00,  5.0793e-01, -1.0867e+00,\n",
      "         2.0507e+00,  2.4506e-01,  1.6421e+00,  1.7009e+00,  1.2224e+00,\n",
      "        -6.5108e+00,  4.8940e-01, -1.9508e-02, -1.9359e+00, -4.0272e+00,\n",
      "        -1.4771e+00,  5.9843e-01,  2.8388e-01,  3.3001e-01,  2.1484e-01,\n",
      "         4.1734e+00,  8.8865e-01,  2.7760e+00,  5.1788e+00, -1.7029e+00,\n",
      "         3.2450e+00,  5.6714e-01,  5.8622e+00, -1.4131e-01,  1.8698e+00,\n",
      "        -3.7405e-01,  4.9534e+00, -3.6483e-01,  9.5704e-01, -1.9846e+00,\n",
      "         1.2962e+00,  4.3734e+00, -2.4325e+00, -2.3246e+00, -9.1715e-01,\n",
      "        -2.3052e+00,  1.6230e-01, -2.7329e+00, -1.0741e+00, -1.3890e+00,\n",
      "        -3.6018e+00,  3.3985e+00, -2.7885e+00, -1.0678e+00,  2.5098e+00,\n",
      "        -1.7379e+00,  3.3903e+00,  2.2106e+00, -4.4036e+00,  7.2121e-01,\n",
      "        -2.1627e+00, -5.1609e+00, -3.0917e+00, -1.8675e+00, -6.7258e-01,\n",
      "         1.8577e+00,  3.0550e+00, -4.1865e+00,  6.8611e-01,  5.9905e-01,\n",
      "         2.7247e+00,  3.5640e-01,  5.3411e+00, -1.1574e+00,  1.6018e+00,\n",
      "        -2.7343e+00, -3.0626e+00,  4.4495e-01, -1.7628e+00, -1.6201e+00,\n",
      "         2.6994e-01,  3.7292e+00, -3.3606e-01, -4.7825e-01,  4.3478e+00,\n",
      "        -3.8168e+00,  8.0305e-01,  1.7009e+00,  3.9386e-01, -2.1172e+00,\n",
      "         3.8325e+00,  2.5257e+00, -2.6649e+00, -3.3451e+00, -6.0928e-01,\n",
      "        -1.6559e+00, -4.4566e-01,  1.6420e+00, -3.0830e+00, -1.6250e+00,\n",
      "         1.3648e+00,  2.9070e+00, -1.0207e+00, -4.0167e-01,  1.0841e+00,\n",
      "        -4.2363e+00,  1.0830e+00,  2.2721e+00,  3.2870e+00,  1.3409e+00,\n",
      "         5.9714e-01, -4.7853e-01, -1.6927e+00, -3.3487e+00,  3.5259e-01,\n",
      "        -4.4311e-01, -4.2372e+00, -2.1891e+00, -3.3322e+00, -6.3550e-01,\n",
      "        -1.9509e-01,  1.0002e+00, -2.2156e-01,  4.3784e+00, -1.9582e+00,\n",
      "         1.6627e+00, -2.7633e-01, -2.5562e+00,  1.8039e+00,  2.2326e+00,\n",
      "        -3.6560e-02, -3.2587e-01, -3.6107e-01, -4.3531e-01,  2.4012e+00,\n",
      "        -3.0852e+00,  2.8344e+00, -1.8357e+00, -2.2701e+00, -2.4415e-01,\n",
      "         8.2906e-01,  4.9746e+00, -3.4292e+00, -8.0857e-01,  2.2248e+00,\n",
      "         1.8560e+00, -3.5513e+00,  5.1892e+00, -6.4218e-01, -1.2846e+00,\n",
      "        -2.2080e+00, -4.8353e-02, -2.0440e+00,  1.8728e+00,  1.3845e+00,\n",
      "         5.2154e+00, -2.9255e-01, -1.0339e+00,  9.4788e-01,  7.1508e-01,\n",
      "        -5.5956e-01, -2.5475e+00, -1.6806e+00, -3.2100e-01,  1.4336e+00,\n",
      "         1.6355e+00, -2.8765e+00, -2.6228e+00,  3.7445e-01,  1.4973e+00,\n",
      "         2.7901e-01, -1.3806e+00, -1.4798e-01,  6.3292e-01,  5.6800e+00,\n",
      "        -1.2189e+00,  2.7800e+00,  1.1862e+00, -4.6932e-01, -1.4753e+00,\n",
      "        -1.2617e+00, -2.8484e+00, -2.2852e-01, -2.1715e+00, -1.2614e+00,\n",
      "         4.2047e+00,  2.8626e+00,  7.9364e-01, -1.3016e-01, -3.8848e-01,\n",
      "         1.6950e+00, -1.6737e+00,  1.4834e+00, -2.7046e+00,  2.0727e+00,\n",
      "        -3.0602e+00, -1.3470e+00,  9.1444e-01,  1.2705e+00, -1.8735e-01,\n",
      "        -7.2869e-02, -1.3895e+00,  1.5695e-01, -5.6523e-01, -5.3453e+00,\n",
      "         3.7268e-01, -4.2619e+00,  1.7019e+00,  2.4385e+00,  2.8440e+00,\n",
      "        -8.2556e-01, -1.8698e+00, -5.3729e-02,  1.5824e+00,  1.3593e+00,\n",
      "         2.3656e-01, -1.2969e+00, -1.5075e+00,  9.3777e-01, -5.4785e+00,\n",
      "         2.2263e+00,  9.6268e-01, -1.6052e+00,  5.3459e+00,  4.0725e+00,\n",
      "        -1.6880e+00, -2.0429e+00, -3.7856e-01,  2.8361e+00, -1.7465e+00,\n",
      "         5.7713e-02, -6.2620e-01,  3.7905e+00, -1.2896e+00, -1.8430e+00,\n",
      "         3.3508e-02,  6.1763e-01,  1.7572e+00,  2.0646e+00,  2.6864e+00,\n",
      "         2.9754e+00, -4.6890e+00, -4.7181e+00, -3.2008e-01,  1.6167e+00,\n",
      "         1.2147e+00,  3.7719e+00,  8.2640e-01, -2.2048e+00, -2.6740e+00,\n",
      "         1.5484e-01,  3.6609e+00,  6.4870e-01, -1.9539e+00, -2.2096e+00,\n",
      "        -1.4538e+00, -1.9620e+00,  3.3993e+00, -8.8333e-01, -6.9177e-01,\n",
      "        -4.2572e-01,  3.7242e-01,  2.7246e+00,  6.1271e-01, -2.5977e+00,\n",
      "        -2.1186e+00, -2.6146e+00,  2.8372e+00, -8.9862e-01, -1.3952e+00,\n",
      "        -9.4750e-01, -1.7891e+00, -4.3760e+00, -1.6488e+00,  2.3867e+00,\n",
      "        -1.1539e+00,  1.8547e+00, -3.4091e+00,  2.4465e+00, -4.1828e+00,\n",
      "         2.7700e+00, -1.9343e-01, -5.0518e-01, -3.8458e-01,  1.1046e+00,\n",
      "         4.7751e-01, -2.5332e+00,  9.1594e-01,  4.7477e+00,  1.0299e-01,\n",
      "         1.4074e+00,  1.1351e+00,  3.0382e+00,  5.4311e-01, -2.1888e+00,\n",
      "        -1.0734e+00,  6.6866e-01, -7.9992e-01,  1.0502e+00, -8.7580e-01,\n",
      "         2.1139e+00, -2.8786e+00, -2.3640e+00,  1.2608e+00, -1.9067e+00,\n",
      "         2.9424e+00, -3.7342e+00,  3.0321e+00,  1.0050e+00,  2.3197e+00,\n",
      "         8.1796e-01,  1.0163e+00,  2.3519e+00,  1.7745e+00, -6.5607e-01,\n",
      "         1.8123e-01, -2.3684e+00, -2.6513e-01, -1.8449e+00,  3.6674e+00,\n",
      "         1.7039e+00, -2.6592e+00,  2.6819e+00, -3.8035e-01, -3.5972e+00,\n",
      "        -2.1927e+00, -2.1041e+00,  2.1981e+00, -2.4951e+00,  1.4816e+00,\n",
      "         6.8274e-01,  4.3971e+00,  1.8442e-01,  2.5499e+00,  1.2640e+00,\n",
      "        -1.4289e+00,  1.5072e+00,  4.8633e-01, -6.1632e-01, -1.2530e+00,\n",
      "        -1.6629e-01,  3.1122e+00,  3.1122e+00,  2.6362e+00, -1.2917e-01,\n",
      "         6.5757e-01,  4.0998e-01,  5.1520e-01,  5.8435e+00, -9.9633e-02,\n",
      "         8.1168e-01, -2.3477e+00, -2.2141e+00,  2.2005e+00,  3.8811e+00,\n",
      "        -1.1736e+00,  3.9712e-01,  8.9837e-01, -1.8857e+00,  8.2824e-02,\n",
      "        -2.1671e+00, -2.1203e+00, -5.8754e+00,  1.8920e+00,  1.4838e+00,\n",
      "         1.2341e+00,  2.1954e-01,  7.6447e-01,  3.7230e+00,  2.9767e+00,\n",
      "        -1.4147e+00, -4.7751e+00, -3.5060e+00, -4.7638e+00, -1.0521e+00,\n",
      "         1.8347e-01,  2.3568e+00, -1.0174e+00,  7.4016e-01,  8.9274e-01,\n",
      "         2.2517e+00,  8.3811e+00, -2.8425e+00, -1.3107e+00, -3.9471e+00,\n",
      "        -2.2930e+00, -1.1209e+00, -1.6314e+00,  1.9783e+00, -1.2389e+00,\n",
      "        -3.1735e+00, -4.0055e-01,  3.5981e-01,  1.7180e+00, -2.1271e+00,\n",
      "         1.4255e+00,  2.6621e+00,  6.8696e-01,  4.1314e+00, -9.0022e-01,\n",
      "        -4.5452e-01,  2.9447e+00, -1.5220e-01,  4.2920e+00,  4.1282e-01,\n",
      "         3.9839e-01, -3.6645e+00, -3.6155e+00, -1.3870e+00,  4.2861e-01,\n",
      "         2.0835e+00,  5.7352e-01, -1.2737e-01, -3.7302e+00, -1.8008e+00,\n",
      "         5.0756e+00, -2.5998e-01,  1.0313e+00, -1.0133e+00,  2.1605e+00,\n",
      "         3.1202e+00, -2.2304e+00, -5.8956e-01, -4.7660e+00, -3.6995e-01,\n",
      "        -2.1775e+00,  3.9660e+00,  5.2890e+00,  3.5431e+00,  2.0516e+00,\n",
      "         2.1344e+00,  3.2101e+00,  3.2719e+00,  2.3123e+00,  1.1430e+00,\n",
      "        -3.4275e+00, -8.4878e-01,  5.6053e-01,  3.1797e+00, -8.1747e-01,\n",
      "         5.0428e+00,  6.0379e-01, -1.4826e+00,  3.0543e+00, -3.9447e+00,\n",
      "         3.7643e+00,  4.4614e+00, -8.9069e-01])\n",
      "1 production\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([48, 768])\n",
      "1 production tens shape torch.Size([2, 768])\n",
      "tensor(2.7239)\n",
      "counter 281\n",
      "2 of\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "2 of tens shape torch.Size([3, 768])\n",
      "tensor(-3.1473)\n",
      "counter 282\n",
      "3 pig-iron\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "3 pig-iron tens shape torch.Size([4, 768])\n",
      "tensor(5.0306)\n",
      "counter 283\n",
      "4 .\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "4 . tens shape torch.Size([5, 768])\n",
      "tensor(0.2663)\n",
      "counter 284\n",
      "5 The\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "5 The tens shape torch.Size([6, 768])\n",
      "tensor(5.0118)\n",
      "counter 285\n",
      "6 voice\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "6 voice tens shape torch.Size([7, 768])\n",
      "tensor(0.0873)\n",
      "counter 286\n",
      "7 came\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "7 came tens shape torch.Size([8, 768])\n",
      "tensor(-4.3196)\n",
      "counter 287\n",
      "8 from\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([48, 768])\n",
      "8 from tens shape torch.Size([9, 768])\n",
      "tensor(1.4111)\n",
      "counter 288\n",
      "9 an\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "9 an tens shape torch.Size([10, 768])\n",
      "tensor(-1.1875)\n",
      "counter 289\n",
      "10 oblong\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "10 oblong tens shape torch.Size([11, 768])\n",
      "tensor(-4.3785)\n",
      "counter 290\n",
      "11 metal\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "11 metal tens shape torch.Size([12, 768])\n",
      "tensor(-3.8989)\n",
      "counter 291\n",
      "12 plaque\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "12 plaque tens shape torch.Size([13, 768])\n",
      "tensor(0.6538)\n",
      "counter 292\n",
      "13 like\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "13 like tens shape torch.Size([14, 768])\n",
      "tensor(5.3498)\n",
      "counter 293\n",
      "14 a\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "14 a tens shape torch.Size([15, 768])\n",
      "tensor(3.9660)\n",
      "counter 294\n",
      "15 dulled\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([48, 768])\n",
      "15 dulled tens shape torch.Size([16, 768])\n",
      "tensor(0.2061)\n",
      "counter 295\n",
      "16 mirror\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "16 mirror tens shape torch.Size([17, 768])\n",
      "tensor(-4.0951)\n",
      "counter 296\n",
      "17 which\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "17 which tens shape torch.Size([18, 768])\n",
      "tensor(0.2949)\n",
      "counter 297\n",
      "18 formed\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "18 formed tens shape torch.Size([19, 768])\n",
      "tensor(6.8868)\n",
      "counter 298\n",
      "19 part\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "19 part tens shape torch.Size([20, 768])\n",
      "tensor(0.7660)\n",
      "counter 299\n",
      "20 of\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "20 of tens shape torch.Size([21, 768])\n",
      "tensor(0.6559)\n",
      "counter 300\n",
      "21 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "21 the tens shape torch.Size([22, 768])\n",
      "tensor(1.6205)\n",
      "counter 301\n",
      "22 surface\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([48, 768])\n",
      "22 surface tens shape torch.Size([23, 768])\n",
      "tensor(-4.4347)\n",
      "counter 302\n",
      "23 of\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "23 of tens shape torch.Size([24, 768])\n",
      "tensor(-4.6633)\n",
      "counter 303\n",
      "24 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "24 the tens shape torch.Size([25, 768])\n",
      "tensor(2.8957)\n",
      "counter 304\n",
      "25 right-hand\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "25 right-hand tens shape torch.Size([26, 768])\n",
      "tensor(-5.0853)\n",
      "counter 305\n",
      "26 wall\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "26 wall tens shape torch.Size([27, 768])\n",
      "tensor(-5.2932)\n",
      "counter 306\n",
      "27 .\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "27 . tens shape torch.Size([28, 768])\n",
      "tensor(-6.3553)\n",
      "counter 307\n",
      "28 Winston\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "28 Winston tens shape torch.Size([29, 768])\n",
      "tensor(-0.2202)\n",
      "counter 308\n",
      "29 turned\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([48, 768])\n",
      "29 turned tens shape torch.Size([30, 768])\n",
      "tensor(-2.1444)\n",
      "counter 309\n",
      "30 a\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "30 a tens shape torch.Size([31, 768])\n",
      "tensor(1.1534)\n",
      "counter 310\n",
      "31 switch\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "31 switch tens shape torch.Size([32, 768])\n",
      "tensor(0.0498)\n",
      "counter 311\n",
      "32 and\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "32 and tens shape torch.Size([33, 768])\n",
      "tensor(0.5624)\n",
      "counter 312\n",
      "33 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "33 the tens shape torch.Size([34, 768])\n",
      "tensor(1.0399)\n",
      "counter 313\n",
      "34 voice\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "34 voice tens shape torch.Size([35, 768])\n",
      "tensor(-3.0634)\n",
      "counter 314\n",
      "35 sank\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "35 sank tens shape torch.Size([36, 768])\n",
      "tensor(5.3566)\n",
      "counter 315\n",
      "36 somewhat\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([48, 768])\n",
      "36 somewhat tens shape torch.Size([37, 768])\n",
      "tensor(-2.4430)\n",
      "counter 316\n",
      "37 ,\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "37 , tens shape torch.Size([38, 768])\n",
      "tensor(-4.4420)\n",
      "counter 317\n",
      "38 though\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "38 though tens shape torch.Size([39, 768])\n",
      "tensor(1.5561)\n",
      "counter 318\n",
      "39 the\n",
      "encoded {'input_ids': tensor([[  101,  1996,  2537,  1997, 10369,  1011,  3707,  1012,  1996,  2376,\n",
      "          2234,  2013,  2019, 27885, 10052,  3384, 11952,  2066,  1037, 10634,\n",
      "          2098,  5259,  2029,  2719,  2112,  1997,  1996,  3302,  1997,  1996,\n",
      "          2157,  1011,  2192,  2813,  1012, 10180,  2357,  1037,  6942,  1998,\n",
      "          1996,  2376,  7569,  5399,  1010,  2295,  1996,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False]\n",
      "output torch.Size([48, 768])\n",
      "39 the tens shape torch.Size([40, 768])\n",
      "tensor(0.7127)\n",
      "counter 319\n",
      "q 8\n",
      "0 words\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "tensor([ 7.7250e-01,  1.8585e+00,  2.1307e+00, -8.4600e-01,  5.6176e-02,\n",
      "         2.1717e+00, -7.2834e-01,  5.4030e+00,  2.8360e+00, -2.2567e+00,\n",
      "         1.9372e-01, -1.4285e+00, -1.5689e-01,  2.8208e+00,  2.0325e+00,\n",
      "         2.9392e+00, -2.9987e+00,  1.4000e+00, -5.3413e+00, -3.3705e+00,\n",
      "         2.9970e+00,  8.4875e-01,  3.5452e+00, -1.7190e+00,  2.3713e+00,\n",
      "         3.0858e+00,  3.2670e+00,  1.4982e+00, -3.1411e+00, -3.2428e+00,\n",
      "         7.9491e+00,  3.0460e+00,  4.4968e+00,  7.3282e-01, -7.8847e-02,\n",
      "        -6.0159e+00, -1.2155e-01, -4.0232e+00,  3.0014e+00,  3.2907e+00,\n",
      "        -5.7039e-02, -5.7381e-01, -1.9861e+00, -2.3033e+00, -7.0042e-01,\n",
      "        -4.0183e-01,  4.0116e-02,  2.8920e+00,  3.4438e+00,  3.0628e+00,\n",
      "        -1.4604e-01, -1.4156e+00, -4.6457e+00,  1.5826e+00, -2.8949e+00,\n",
      "         2.0660e+00,  3.5555e+00, -2.0668e+00, -2.0976e+00, -1.4209e+00,\n",
      "        -1.8979e+00,  2.5205e+00,  1.6184e+00, -8.3550e-01,  5.2220e+00,\n",
      "         3.8221e+00, -1.1602e+00, -4.7206e-01, -2.5375e+00,  9.1687e-02,\n",
      "         2.5766e+00,  4.3768e+00, -2.2202e+00, -3.8533e+00,  3.9437e-01,\n",
      "         2.4301e+00,  2.4051e+00,  1.2831e+00, -5.0349e+00, -2.3169e+00,\n",
      "        -1.7618e+00,  8.4404e-01, -1.0226e+00,  1.2857e+00,  8.5164e-01,\n",
      "        -2.1878e+00,  3.1666e+00,  3.4046e-02, -1.8084e+00,  4.5888e+00,\n",
      "        -5.8723e-02, -3.9592e-01,  5.1967e+00,  1.6254e+00,  1.5176e+00,\n",
      "         9.9214e-01,  1.9740e+00,  5.8053e-01, -1.7517e+00,  9.4537e-01,\n",
      "         1.7713e+00, -4.9523e+00, -3.0495e+00,  2.8907e+00, -3.2934e+00,\n",
      "         1.5752e+00, -1.6222e+00,  6.0432e+00, -1.1377e+00,  5.1018e-01,\n",
      "        -8.0301e-01,  2.8052e-01, -2.8520e+00, -1.9714e+00,  2.2528e+00,\n",
      "        -1.1377e+00, -1.0270e+00, -3.2289e-01, -2.8028e+00,  1.0200e-01,\n",
      "        -4.7201e-01, -4.6199e-01,  2.1842e+00,  5.9646e-01,  1.7849e+00,\n",
      "        -9.8091e-01, -2.5598e+00,  1.6368e+00, -5.2715e+00, -6.3461e-02,\n",
      "        -1.4983e+00,  1.3566e+00, -1.0543e+00,  7.4825e-01,  2.8601e+00,\n",
      "        -3.2519e+00, -4.1380e+00, -4.9006e-01, -5.4196e+00, -4.5397e+00,\n",
      "         5.6578e+00,  1.1277e+00,  5.4667e-02,  4.3828e+00, -2.5259e+00,\n",
      "        -1.2853e+00, -5.3688e-01,  1.0863e+00,  2.6728e+00, -1.5067e-01,\n",
      "        -5.6311e-01, -1.8739e+00, -3.5161e-01,  6.4212e-01, -3.9037e+00,\n",
      "         1.8716e+00, -1.8292e+00,  1.8835e+00, -6.3699e-01,  1.9006e-01,\n",
      "         8.0138e-01,  3.1626e+00, -2.2063e-01, -9.7907e-02,  2.7142e+00,\n",
      "         6.8661e+00,  1.6760e+00,  3.6918e+00, -1.1594e+00, -3.1854e+00,\n",
      "         1.5462e+00, -8.9322e-02,  2.4801e+00, -3.4365e+00,  3.5820e+00,\n",
      "        -9.7617e-01,  2.5561e+00, -2.2037e+00,  1.6930e+00, -1.7007e+00,\n",
      "        -3.7487e-01,  3.0576e+00,  1.9290e+00,  3.9695e+00,  3.6054e-03,\n",
      "        -3.0590e+00,  2.7291e+00, -1.8311e-01, -3.2772e+00, -1.7055e+00,\n",
      "        -1.9040e+00, -9.8041e-01,  1.3293e+00, -3.5954e+00,  1.6427e+00,\n",
      "        -1.6003e+00, -3.8125e-01,  5.0641e-01, -6.9201e+00, -1.5557e+00,\n",
      "        -2.2289e+00, -2.5122e+00,  1.5770e+00, -2.9566e+00, -4.4026e-02,\n",
      "        -3.0933e-01,  1.1711e+00,  4.2890e+00, -4.6729e-01,  3.5920e+00,\n",
      "        -3.2580e+00, -1.8916e+00,  6.9071e-01, -3.1653e+00, -8.7450e-01,\n",
      "         7.7920e-01, -1.2137e+00, -8.5299e+00,  7.8278e-01, -5.1865e-01,\n",
      "        -1.2233e+00,  1.1548e+00, -1.7449e-01, -2.1107e+00, -4.9756e+00,\n",
      "         6.1893e-01,  5.2349e+00,  4.5208e+00,  4.4115e+00,  1.0297e+00,\n",
      "        -1.2422e+00, -1.8787e+00,  2.5312e+00,  1.5618e-01,  7.9410e-01,\n",
      "         2.2765e+00,  2.9758e-01, -1.5546e+00, -1.7017e+00,  3.2771e-02,\n",
      "         3.0663e-01,  4.8643e+00, -1.3124e+00, -7.0314e-02,  2.2047e+00,\n",
      "        -2.4618e+00, -7.1484e-01,  9.0168e-01,  9.9175e-01, -1.8683e+00,\n",
      "        -3.8557e+00,  2.0426e+00,  3.4242e+00,  2.3018e+00,  2.5238e+00,\n",
      "         2.8423e+00, -2.9582e+00, -1.7408e+00,  3.4509e+00,  3.7389e-01,\n",
      "        -1.2633e+00,  8.4921e-01,  3.3820e-01,  3.0010e+00, -1.0301e+00,\n",
      "        -2.9768e+00, -1.4083e+00, -2.2255e-01, -2.5562e+00, -6.7122e+00,\n",
      "        -1.8370e+00,  1.8883e+00,  3.8254e+00, -3.0090e+00, -9.9451e-01,\n",
      "         2.4283e-01, -1.9022e+00, -2.4481e+00, -7.1674e-01, -4.0600e+00,\n",
      "        -1.1431e-01, -3.9697e+00,  1.6884e+00, -2.7438e+00,  7.4528e-01,\n",
      "        -8.3444e-01,  5.7906e+00,  1.0286e+00, -8.9775e-01,  3.2606e+00,\n",
      "         1.1036e-01,  1.5764e+00, -4.0751e-01,  1.3826e+00,  2.1974e+00,\n",
      "        -1.2973e+00, -6.3680e-01,  1.0243e+00, -2.4172e+00, -1.8117e+00,\n",
      "        -8.1019e-01, -2.1421e+00,  3.2835e-01,  2.2492e-02, -2.2507e+00,\n",
      "         1.9724e+00,  4.7294e-01,  8.7772e-01, -1.2358e+01, -1.8091e+00,\n",
      "         1.4543e+00, -1.9417e+00,  2.7520e-01, -1.0678e+00, -3.3005e+00,\n",
      "         2.8759e-01, -2.2854e+00,  1.4433e+00, -9.0370e-01,  3.2608e+00,\n",
      "         3.0032e+00,  1.6669e+00,  2.2768e+00, -4.2191e+00, -8.0035e-01,\n",
      "        -3.1461e+00, -6.4478e-01,  2.5194e+00, -4.9969e+00,  4.7121e-01,\n",
      "        -3.3060e-01, -8.8105e-01, -2.3262e+00,  2.8266e-01,  4.6451e-01,\n",
      "        -2.6737e+00,  1.8024e+00,  3.9656e+00, -4.8532e+00,  1.1561e-01,\n",
      "         8.2731e-01, -6.3801e-01,  4.7232e+00, -2.6181e+00,  1.5914e+00,\n",
      "        -1.7621e+00, -9.5082e-01, -5.8736e+00,  2.4820e+00, -1.6224e+00,\n",
      "        -1.2014e+00,  1.1236e+00,  3.1706e-01, -3.1568e-01, -7.2815e+00,\n",
      "        -1.9170e+00, -1.6841e+00,  3.1340e+00,  2.8855e-01,  1.1931e+00,\n",
      "        -4.3510e+00,  2.6204e+00, -1.5566e+00, -4.0665e+00,  4.8104e+00,\n",
      "        -8.6347e-02,  1.6154e+00,  2.1902e-01, -2.5709e-01, -2.5677e+00,\n",
      "         1.2662e+00, -2.2991e+00,  4.1905e+00,  6.7763e-01, -5.3080e+00,\n",
      "        -3.9620e+00, -1.7515e-01, -3.2356e+00, -2.7244e+00, -1.7749e+00,\n",
      "        -1.0541e+00, -7.1837e+00,  1.7027e+00, -1.3631e-01, -2.3544e-01,\n",
      "         2.3549e+00, -8.9765e-01, -7.6540e-01, -1.7137e-01, -1.5637e+00,\n",
      "         7.6168e-01, -9.3970e-01,  3.3858e-01, -2.6585e-01, -3.7988e+00,\n",
      "         1.0232e-01,  9.5792e-01,  2.4572e+00,  2.0152e+00,  1.9424e+00,\n",
      "        -1.0669e-01,  2.1651e+00,  2.9060e+00,  4.3796e-01, -6.2488e+00,\n",
      "        -1.0232e+00,  1.7154e+00,  1.6227e+00,  4.5453e-01,  8.9098e-01,\n",
      "        -1.1178e+00,  1.9699e+00,  1.0447e+00, -2.4955e+00, -1.0514e-01,\n",
      "        -1.1876e+00, -1.0641e-01,  4.1629e-01, -1.8024e+00, -1.7820e+00,\n",
      "         2.5041e+00, -1.5923e+00,  1.3895e-01,  1.6851e+00,  1.0098e+00,\n",
      "         2.0865e+00, -1.4852e+00, -1.8766e+00, -8.1459e-01,  4.3202e+00,\n",
      "         2.7811e-01,  7.9703e-01, -2.2485e+00,  1.5186e+00, -1.7445e-01,\n",
      "         3.6503e+00, -2.8795e+00, -4.0409e+00, -4.3476e+00, -1.6060e+00,\n",
      "         4.9301e+00,  9.5792e-01,  6.2265e+00, -7.4037e-01, -2.1698e+00,\n",
      "        -4.5781e+00, -2.1533e+00, -3.4036e+00, -8.2172e-01,  1.0761e+00,\n",
      "        -3.5765e-01,  9.5278e-01,  5.1720e-01, -5.3152e-01, -1.3750e+00,\n",
      "         3.2766e-01, -2.9143e+00,  2.0354e+00,  6.4013e-01, -2.2123e+00,\n",
      "        -1.2387e+00,  2.3236e+00, -4.2149e+00,  1.1478e+00, -3.0844e+00,\n",
      "         1.4294e+00,  1.5073e+00, -2.3260e+00,  2.6935e+00,  7.5445e-01,\n",
      "        -1.9955e+00,  7.6361e-02,  3.5170e+00,  1.5888e-01, -2.8401e+00,\n",
      "         2.4909e+00,  1.1205e+00,  2.2708e+00, -4.4361e-01,  1.0071e+00,\n",
      "        -3.0749e+00,  9.5474e-01, -1.2790e+00,  4.3807e-01, -1.6572e+00,\n",
      "        -1.5679e+00,  1.1019e+00,  5.8439e+00,  6.0971e-01, -7.1368e-01,\n",
      "        -3.7261e+00,  5.4003e-01, -1.8100e+00, -1.0230e+00,  3.9105e+00,\n",
      "        -3.4015e+00,  1.2820e+00, -9.7270e-01,  1.9323e+00,  3.2938e+00,\n",
      "         6.3700e+00,  1.6107e+00,  1.1141e+00, -1.0277e+00,  4.7615e+00,\n",
      "        -4.1509e+00, -1.5757e+00, -8.3211e-01, -3.1508e-01,  3.1631e+00,\n",
      "         9.0004e-01, -2.3878e+00, -1.3157e+00,  3.7616e-01,  3.4656e+00,\n",
      "        -3.0986e+00,  6.0524e-01,  2.8558e-03,  4.7184e-01, -1.1392e+00,\n",
      "        -9.7650e-01, -4.3537e+00, -1.0720e-02,  1.6202e+00, -1.3889e+00,\n",
      "         8.6495e-01, -9.8804e-01,  1.7496e+00, -1.4537e+00,  1.4998e+00,\n",
      "         2.3650e+00, -5.6733e+00, -2.4021e+00,  1.5181e+00,  2.3092e-01,\n",
      "        -8.3324e-01, -1.5281e+00, -1.6611e+00,  3.3113e+00, -7.6584e+00,\n",
      "        -2.3677e+00, -4.5172e+00,  1.8344e+00, -3.2833e+00,  7.9772e-01,\n",
      "        -2.6524e+00,  5.5487e+00, -7.5973e-01, -1.4453e-01, -2.5018e+00,\n",
      "        -1.5301e-01, -4.3133e+00, -1.1749e+00,  6.2307e+00, -2.9630e+00,\n",
      "         2.8327e+00,  2.6273e-01,  1.6191e+00, -3.1941e+00, -1.1118e-01,\n",
      "        -1.2375e+00, -1.4431e+00,  9.3707e-01, -6.2610e-01, -9.7502e-01,\n",
      "         3.7780e+00, -7.9963e-01,  1.7990e+00, -1.0554e-01, -7.7191e-01,\n",
      "        -4.6447e+00,  4.1024e-01,  7.4449e-01, -1.8306e+00, -5.6909e-02,\n",
      "         1.9914e+00, -4.5377e+00, -4.7357e+00,  1.5192e+00, -2.1342e+00,\n",
      "         1.3910e+00, -3.8483e+00, -5.9129e+00,  2.7608e+00,  2.6317e+00,\n",
      "        -2.1657e+00,  3.1945e+00,  2.4866e+00, -2.8142e+00,  6.4787e-01,\n",
      "         1.0691e+00, -2.9147e+00,  7.2261e-01,  6.4704e-01,  5.1545e-01,\n",
      "         3.2936e+00, -2.9150e+00, -3.1745e+00,  1.1218e-01,  2.9710e+00,\n",
      "         2.8440e+00, -1.6524e+00,  1.2901e+00,  3.7021e-01, -9.3660e-01,\n",
      "         3.2628e+00, -2.0793e+00,  3.1504e+00,  2.6749e+00,  8.0246e-01,\n",
      "        -1.4175e+00, -3.8307e+00, -2.2397e+00,  2.4886e+00,  3.9866e+00,\n",
      "        -2.3995e+00, -1.1207e+00, -2.8645e+00, -8.9473e-01, -1.1440e+00,\n",
      "         1.4086e+00, -3.0389e+00, -1.8725e+00, -2.6351e+00,  2.6834e-01,\n",
      "        -1.2016e+00,  4.4489e+00, -1.1012e-01,  2.5095e-01,  2.4309e+00,\n",
      "         3.9857e+00,  3.4481e+00, -1.2502e+00, -6.5722e-01, -1.4442e+00,\n",
      "         9.4718e-01,  8.1771e-01,  8.3035e-01,  7.2451e-02,  7.8376e-01,\n",
      "        -2.9315e+00,  7.6180e-01,  1.7405e+00, -2.6893e+00, -1.5884e+00,\n",
      "         2.8579e-01,  1.3231e+00,  2.0857e+00,  1.0685e+00,  1.2585e+00,\n",
      "        -1.8313e+00,  8.4612e-01,  1.1742e+00,  8.0834e-01,  1.5579e+00,\n",
      "        -3.0375e+00,  2.2226e-01, -1.5953e+00,  2.8373e+00, -7.1592e-01,\n",
      "        -4.1822e+00, -4.9575e+00, -1.2847e+00,  3.1261e+00, -1.8744e+00,\n",
      "        -4.7450e-01,  1.2612e+00, -1.8149e-01,  2.0849e+00, -8.4401e-01,\n",
      "        -3.6520e-02, -5.3650e+00,  1.7947e+00, -3.8533e-01, -1.0022e+00,\n",
      "        -1.3788e+00,  1.4985e+00,  2.3701e+00,  6.5642e+00, -1.2496e+00,\n",
      "        -6.5945e+00,  3.2370e+00,  5.3058e-01,  1.3115e+00, -4.1329e+00,\n",
      "        -1.2746e+00, -8.0397e-01, -2.8075e+00,  4.2365e+00,  2.6075e+00,\n",
      "        -3.9642e+00, -2.9373e-01, -4.0793e+00, -3.4567e-01, -4.6269e-01,\n",
      "        -2.0709e+00,  1.2842e+00, -1.2928e+00, -7.5915e-02,  3.1019e+00,\n",
      "         7.1030e-01,  3.0870e+00, -2.3063e+00,  2.6056e+00, -3.3357e+00,\n",
      "         5.7835e-01, -4.5482e+00, -2.2855e-01,  3.0488e+00, -8.2266e-01,\n",
      "         1.1966e+00, -3.8638e+00,  1.2938e+00,  2.0376e+00,  4.1929e+00,\n",
      "         3.0869e+00, -2.8196e+00, -3.0738e-01, -9.0724e-01, -1.5432e+00,\n",
      "         1.1787e+00,  6.8525e-01, -1.8769e+00,  9.5582e-01,  2.1887e-01,\n",
      "         9.2644e-01, -1.4121e+00,  2.0034e-01,  2.9599e+00, -1.1694e-01,\n",
      "        -4.6772e-01, -5.8288e+00,  1.8616e+00, -3.2336e+00,  8.0889e-01,\n",
      "        -1.3963e-01, -9.2757e-01, -1.0337e+00, -3.3361e-01,  1.6921e+00,\n",
      "         3.9395e-01, -2.6252e+00,  8.3901e-01,  1.4275e+00, -2.5344e+00,\n",
      "         1.6210e+00,  1.9240e+00, -3.5026e+00,  4.4138e+00,  3.3436e+00,\n",
      "         2.9185e+00, -1.3339e+00, -4.0244e+00,  5.8837e-01,  1.7001e+00,\n",
      "         1.0881e-01,  3.3691e+00, -1.3626e+00,  4.0543e+00, -3.3459e+00,\n",
      "         3.1578e-01,  2.8326e+00, -9.0098e-01,  1.5374e+00, -2.5343e+00,\n",
      "        -1.3981e+00, -8.2933e-01, -3.5384e+00])\n",
      "1 were\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "1 were tens shape torch.Size([2, 768])\n",
      "tensor(2.4978)\n",
      "counter 321\n",
      "2 still\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "2 still tens shape torch.Size([3, 768])\n",
      "tensor(-0.8471)\n",
      "counter 322\n",
      "3 distinguishable\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "3 distinguishable tens shape torch.Size([4, 768])\n",
      "tensor(-1.3668)\n",
      "counter 323\n",
      "4 .\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "4 . tens shape torch.Size([5, 768])\n",
      "tensor(0.2321)\n",
      "counter 324\n",
      "5 The\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "5 The tens shape torch.Size([6, 768])\n",
      "tensor(-3.1766)\n",
      "counter 325\n",
      "6 instrument\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "6 instrument tens shape torch.Size([7, 768])\n",
      "tensor(1.3303)\n",
      "counter 326\n",
      "7 (\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "7 ( tens shape torch.Size([8, 768])\n",
      "tensor(-0.1504)\n",
      "counter 327\n",
      "8 the\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "8 the tens shape torch.Size([9, 768])\n",
      "tensor(-2.8035)\n",
      "counter 328\n",
      "9 telescreen\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "9 telescreen tens shape torch.Size([10, 768])\n",
      "tensor(2.8890)\n",
      "counter 329\n",
      "10 ,\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "10 , tens shape torch.Size([11, 768])\n",
      "tensor(0.8457)\n",
      "counter 330\n",
      "11 it\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "11 it tens shape torch.Size([12, 768])\n",
      "tensor(2.8583)\n",
      "counter 331\n",
      "12 was\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "12 was tens shape torch.Size([13, 768])\n",
      "tensor(1.1438)\n",
      "counter 332\n",
      "13 called\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "13 called tens shape torch.Size([14, 768])\n",
      "tensor(3.6134)\n",
      "counter 333\n",
      "14 )\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "14 ) tens shape torch.Size([15, 768])\n",
      "tensor(0.1493)\n",
      "counter 334\n",
      "15 could\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "15 could tens shape torch.Size([16, 768])\n",
      "tensor(3.2988)\n",
      "counter 335\n",
      "16 be\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "16 be tens shape torch.Size([17, 768])\n",
      "tensor(1.5173)\n",
      "counter 336\n",
      "17 dimmed\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "17 dimmed tens shape torch.Size([18, 768])\n",
      "tensor(2.6949)\n",
      "counter 337\n",
      "18 ,\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "18 , tens shape torch.Size([19, 768])\n",
      "tensor(0.5518)\n",
      "counter 338\n",
      "19 but\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "19 but tens shape torch.Size([20, 768])\n",
      "tensor(-0.6518)\n",
      "counter 339\n",
      "20 there\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "20 there tens shape torch.Size([21, 768])\n",
      "tensor(0.9358)\n",
      "counter 340\n",
      "21 was\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "21 was tens shape torch.Size([22, 768])\n",
      "tensor(-1.1659)\n",
      "counter 341\n",
      "22 no\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "22 no tens shape torch.Size([23, 768])\n",
      "tensor(-4.4405)\n",
      "counter 342\n",
      "23 way\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "23 way tens shape torch.Size([24, 768])\n",
      "tensor(-0.9106)\n",
      "counter 343\n",
      "24 of\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "24 of tens shape torch.Size([25, 768])\n",
      "tensor(-4.1626)\n",
      "counter 344\n",
      "25 shutting\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "25 shutting tens shape torch.Size([26, 768])\n",
      "tensor(0.6878)\n",
      "counter 345\n",
      "26 it\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "26 it tens shape torch.Size([27, 768])\n",
      "tensor(2.1757)\n",
      "counter 346\n",
      "27 off\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "27 off tens shape torch.Size([28, 768])\n",
      "tensor(-2.5163)\n",
      "counter 347\n",
      "28 completely\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "28 completely tens shape torch.Size([29, 768])\n",
      "tensor(0.6330)\n",
      "counter 348\n",
      "29 .\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "29 . tens shape torch.Size([30, 768])\n",
      "tensor(0.2531)\n",
      "counter 349\n",
      "30 He\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "30 He tens shape torch.Size([31, 768])\n",
      "tensor(4.2098)\n",
      "counter 350\n",
      "31 moved\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "31 moved tens shape torch.Size([32, 768])\n",
      "tensor(0.9421)\n",
      "counter 351\n",
      "32 over\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "32 over tens shape torch.Size([33, 768])\n",
      "tensor(-1.3886)\n",
      "counter 352\n",
      "33 to\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "33 to tens shape torch.Size([34, 768])\n",
      "tensor(-2.8120)\n",
      "counter 353\n",
      "34 the\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "34 the tens shape torch.Size([35, 768])\n",
      "tensor(-4.0335)\n",
      "counter 354\n",
      "35 window\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False]\n",
      "output torch.Size([47, 768])\n",
      "35 window tens shape torch.Size([36, 768])\n",
      "tensor(2.2755)\n",
      "counter 355\n",
      "36 :\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([47, 768])\n",
      "36 : tens shape torch.Size([37, 768])\n",
      "tensor(0.3582)\n",
      "counter 356\n",
      "37 a\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False]\n",
      "output torch.Size([47, 768])\n",
      "37 a tens shape torch.Size([38, 768])\n",
      "tensor(-2.9987)\n",
      "counter 357\n",
      "38 smallish\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True False False]\n",
      "output torch.Size([47, 768])\n",
      "38 smallish tens shape torch.Size([39, 768])\n",
      "tensor(-0.2430)\n",
      "counter 358\n",
      "39 ,\n",
      "encoded {'input_ids': tensor([[  101,  2616,  2020,  2145, 10782,  3085,  1012,  1996,  6602,  1006,\n",
      "          1996, 10093,  2229, 24410,  1010,  2009,  2001,  2170,  1007,  2071,\n",
      "          2022, 11737,  7583,  1010,  2021,  2045,  2001,  2053,  2126,  1997,\n",
      "         17521,  2009,  2125,  3294,  1012,  2002,  2333,  2058,  2000,  1996,\n",
      "          3332,  1024,  1037,  2235,  4509,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False]\n",
      "output torch.Size([47, 768])\n",
      "39 , tens shape torch.Size([40, 768])\n",
      "tensor(0.2469)\n",
      "counter 359\n",
      "40 \n",
      "q 9\n",
      "0 frail\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "tensor([ 2.6961e+00,  1.2176e-02,  3.9668e+00,  3.4050e+00, -1.5292e-01,\n",
      "         2.7440e+00, -1.5693e+00,  2.5454e-01, -7.9387e-01,  5.4535e-01,\n",
      "        -5.3410e-01, -2.9631e+00,  1.9018e-01,  1.0323e+00, -3.0085e+00,\n",
      "         2.5551e+00,  2.6384e+00,  1.7626e+00, -4.9883e+00, -2.3458e+00,\n",
      "        -2.9305e+00,  1.4504e+00,  4.0516e+00,  1.5332e+00, -2.1155e-01,\n",
      "         2.8999e+00,  2.7984e+00, -1.4328e-01, -3.5186e+00, -2.1488e+00,\n",
      "         2.2277e+00,  1.6575e+00,  2.4065e+00,  2.4039e-01, -9.0610e-01,\n",
      "        -4.1758e+00, -4.0006e-01, -7.4658e-01, -2.7450e+00, -1.8311e+00,\n",
      "         2.8374e+00, -7.8993e-01, -5.8013e-01,  6.0808e+00,  7.5630e-01,\n",
      "         9.2277e-01,  2.1200e-01,  1.4098e-01,  2.2233e+00, -5.5278e+00,\n",
      "        -2.9020e+00,  3.4486e-01,  3.8277e+00,  9.1324e-01, -6.9078e-01,\n",
      "         2.2968e+00,  1.9662e+00, -1.5406e+00, -9.1249e-02, -4.3658e+00,\n",
      "        -7.5518e-01,  5.9053e+00,  2.5417e+00, -1.1564e+00,  4.5958e+00,\n",
      "         1.1012e+00, -3.5991e-01, -7.4807e-01, -7.3835e+00,  2.5345e+00,\n",
      "         1.2395e+00, -3.0526e+00, -2.3420e+00, -1.4336e+00,  2.2554e+00,\n",
      "         3.8091e-01,  1.4020e+00, -3.4469e-01, -2.6012e+00,  8.4434e-01,\n",
      "         3.4846e+00,  2.3939e+00,  3.5208e-01, -1.1381e+00,  5.9004e-02,\n",
      "        -1.3868e+00,  3.2344e+00,  3.6567e+00, -2.8287e+00,  1.2902e+00,\n",
      "        -2.1341e-01, -4.5723e+00,  3.1689e+00,  1.3777e+00, -1.3377e+00,\n",
      "        -6.8309e-01,  1.4407e+00,  2.3940e+00,  2.6912e-01,  3.0400e+00,\n",
      "         3.1552e-02,  2.4945e+00, -7.5903e-01,  3.6781e-01, -1.5440e+00,\n",
      "         1.1370e+00,  2.2828e-01, -6.8465e-01, -1.3443e+00,  4.4661e+00,\n",
      "         5.8296e-01,  1.0648e+00, -3.9645e+00, -6.5611e+00,  3.2562e-01,\n",
      "         1.8578e+00, -1.3731e+00, -2.1097e+00, -2.5461e-01, -5.6610e+00,\n",
      "        -9.7898e-01,  5.6766e-01, -1.3162e+00, -1.0347e-01,  6.6444e-01,\n",
      "        -4.7869e-01, -3.9177e+00,  8.4487e-01,  1.2016e+00,  1.1740e+00,\n",
      "        -4.3487e-01,  2.5933e+00, -1.1017e+00,  3.8566e-01,  1.1061e+00,\n",
      "         1.5155e+00,  8.5962e-01, -8.4024e-01,  1.0081e-01, -5.5540e-01,\n",
      "         3.8488e+00,  3.5889e-01, -9.0459e-02,  3.6141e+00,  1.7257e+00,\n",
      "        -1.6573e+00, -1.3991e+00, -2.9574e+00,  3.4283e+00,  2.1239e+00,\n",
      "        -3.0636e-01,  1.6819e+00, -2.5035e+00,  3.4519e+00, -5.4293e+00,\n",
      "        -2.4582e-01, -6.3763e-01, -1.6836e+00,  3.4411e+00, -1.6065e-01,\n",
      "        -2.8787e+00,  7.1989e-01,  3.5519e+00,  1.2122e+00,  1.0931e+00,\n",
      "         1.6024e+00, -5.8900e+00,  1.4973e+00, -1.1430e+00,  2.8860e-01,\n",
      "        -1.0119e+00, -3.3891e+00,  3.3167e+00,  2.7223e-01, -8.3549e-01,\n",
      "         1.2769e+00,  5.2610e+00, -2.1404e+00, -2.5432e-01,  1.7709e+00,\n",
      "         9.6828e-01,  1.1765e+00,  3.2206e-02,  3.1835e+00,  8.4086e-01,\n",
      "        -2.2210e+00,  1.5999e+00,  1.7982e+00,  5.1219e-01,  1.3480e-01,\n",
      "         2.0218e+00,  2.4938e+00, -6.9646e-01, -1.3063e+00,  3.2951e+00,\n",
      "         2.9221e+00, -5.1554e+00,  2.7887e+00,  3.9673e-01, -3.0512e+00,\n",
      "        -9.3810e-01, -1.2892e+00,  1.4813e+00, -1.7215e+00, -2.5597e+00,\n",
      "         2.5900e+00,  1.1337e+00,  1.5159e+00, -3.2016e+00,  1.3849e+00,\n",
      "         6.1722e-02, -2.1127e+00,  1.5705e+00,  3.5652e+00, -1.9402e+00,\n",
      "         3.3777e-01, -3.9723e+00,  7.0913e-01,  1.6733e+00, -3.2066e-01,\n",
      "         4.6744e+00,  2.2807e+00, -1.9442e+00, -3.5552e-01, -2.1630e+00,\n",
      "         3.4983e+00,  5.2031e+00, -2.5430e+00,  3.8293e+00,  2.2686e-01,\n",
      "        -1.3827e+00, -3.8047e+00, -7.4766e-01,  5.3463e-01,  2.0563e+00,\n",
      "         1.4108e+00,  1.6588e-01,  2.1937e-01, -3.3384e+00, -1.8031e+00,\n",
      "        -4.6224e+00,  4.2248e+00,  1.3152e+00, -5.7417e-01, -3.4779e+00,\n",
      "        -2.4281e+00, -1.1105e+00,  2.9473e+00,  9.5385e-01,  1.5375e+00,\n",
      "        -2.5898e+00,  1.7150e+00,  4.2143e+00, -1.4105e+00, -1.2373e+00,\n",
      "         1.5363e+00,  1.8940e-01, -1.9387e+00,  2.4231e+00, -3.6670e+00,\n",
      "        -1.4979e+00, -5.4903e-01, -2.3783e+00, -4.1288e+00,  2.0305e+00,\n",
      "        -1.6657e+00,  3.4878e+00, -1.7369e+00, -1.8844e+00, -5.3973e+00,\n",
      "         2.5200e+00,  9.2989e-01,  1.3216e-01,  1.1591e+00,  1.2656e+00,\n",
      "        -5.1357e+00,  1.0243e+00, -2.5957e+00,  2.2531e+00, -2.5079e+00,\n",
      "        -1.6616e+00,  4.7947e+00,  1.4419e-01, -4.1977e-01, -2.9868e+00,\n",
      "        -1.4677e-01,  1.3198e+00,  2.2782e+00, -4.8154e-01, -5.5635e+00,\n",
      "         2.0588e+00,  1.5509e+00, -2.7557e+00, -4.1233e-01,  3.5397e+00,\n",
      "        -3.0111e-01,  1.1594e+00,  1.7614e+00, -2.0961e+00, -5.8869e+00,\n",
      "         4.3592e+00, -2.1775e+00, -4.1950e-01, -2.6609e-01,  4.1237e+00,\n",
      "         4.8215e+00, -1.1602e+00, -2.1427e+00, -1.4070e+01,  2.3408e-03,\n",
      "         1.0333e+00,  1.7868e+00, -1.1738e+00, -5.6324e-01, -9.6529e+00,\n",
      "        -2.3815e+00, -1.5915e+00, -8.3658e-01,  8.5311e-01,  1.8274e+00,\n",
      "        -2.0418e+00,  5.2451e-01,  1.6769e+00, -2.5059e+00, -2.3760e+00,\n",
      "         9.6106e-01,  6.4033e-01, -1.3487e+00,  1.9320e-01,  1.2062e-01,\n",
      "         7.8898e-01, -1.9234e-01, -2.3989e+00,  4.1441e+00, -1.4718e-01,\n",
      "        -3.6830e+00,  2.7300e-01, -9.4668e-01, -5.5686e+00, -3.1229e-01,\n",
      "         1.1225e+00, -2.2145e+00,  3.2696e-01, -3.8637e+00, -2.8065e-01,\n",
      "        -7.2810e-01, -5.0483e-01, -5.8677e-01, -2.9008e-01, -2.6412e+00,\n",
      "        -1.6906e+00,  1.3840e+00,  4.2591e+00, -2.9041e+00, -3.4109e+00,\n",
      "        -3.3605e+00,  1.7469e+00,  7.1152e-01, -4.1422e+00,  2.1820e+00,\n",
      "        -9.7486e-01, -2.6708e+00, -1.7983e+00, -9.3255e-02, -1.6011e+00,\n",
      "         1.2279e-01,  1.0848e-02, -9.9468e-01, -1.2356e+00, -4.8953e+00,\n",
      "        -3.5197e+00, -1.6097e+00, -2.8514e+00, -1.1223e+00, -7.4096e-01,\n",
      "        -5.5114e-01, -1.0088e+00, -3.6292e+00, -3.1529e+00, -4.6680e+00,\n",
      "         4.2604e+00, -6.5731e+00, -1.0655e+00,  9.3868e-01,  1.3686e+00,\n",
      "         1.0035e+00,  1.2973e-01, -1.7241e+00,  3.8373e+00, -3.4893e-01,\n",
      "        -7.0607e-02,  1.9301e+00, -9.4171e-01, -1.4141e+00, -1.6038e-01,\n",
      "        -3.1125e+00, -3.1988e+00,  2.3178e+00,  2.9007e+00, -1.2412e+00,\n",
      "         1.8095e+00,  3.4070e+00, -1.7813e+00, -8.1218e-01, -2.2380e+00,\n",
      "        -1.6352e+00,  4.4851e+00,  9.2870e-01,  1.0742e+00,  5.2355e+00,\n",
      "         2.2786e+00, -1.0856e+00,  1.2086e+00, -7.0719e-01,  4.3001e+00,\n",
      "        -1.1313e+00,  9.5457e-01,  1.9366e+00,  2.2263e+00, -4.6142e-01,\n",
      "         1.1453e+00,  3.4081e+00,  2.2953e+00, -3.0215e+00,  6.9475e-02,\n",
      "        -2.5465e-01, -6.1859e-01, -5.9538e-02,  3.7370e-01,  4.9657e+00,\n",
      "         7.5891e-01, -3.6610e+00, -4.3045e+00,  8.5795e-01, -1.4403e+00,\n",
      "        -3.6514e+00,  1.8802e+00, -9.3317e-01,  7.2400e-01, -3.4574e+00,\n",
      "         2.5909e+00, -2.8695e+00, -1.3218e+00, -2.3455e+00,  3.4061e+00,\n",
      "        -5.1336e+00,  3.4706e+00,  9.2521e-01,  1.5080e+00,  2.3536e+00,\n",
      "        -1.1073e+00,  2.3637e+00,  7.4497e-01,  1.0102e+00, -1.8567e-01,\n",
      "        -2.9122e+00, -1.3764e+00, -1.5219e+00, -1.9882e+00, -2.1468e+00,\n",
      "         9.6618e-01,  4.5995e+00, -5.3094e+00,  1.3511e+00,  1.0417e+00,\n",
      "        -1.1501e+00,  3.5883e-01, -1.0051e+00,  4.1333e-01,  3.2081e+00,\n",
      "        -1.3138e+00,  3.8102e+00,  3.3602e-01,  4.6539e+00, -2.1697e+00,\n",
      "        -1.0877e+00, -1.4231e-01,  1.0190e-01,  1.7887e+00,  2.4840e-01,\n",
      "         3.2282e+00,  2.8451e+00, -1.1947e+00, -1.2125e+00, -4.0421e-01,\n",
      "         1.2729e-01, -3.9102e+00,  3.3377e+00, -1.3830e+00, -6.0437e-01,\n",
      "        -1.7886e+00,  1.4913e+00, -2.9997e+00, -2.1938e-01,  4.1202e+00,\n",
      "         3.2739e-01, -4.6718e-01, -4.1082e-01,  9.0038e-01, -2.4381e+00,\n",
      "         2.9058e+00, -3.5037e+00, -2.1621e+00, -1.9753e+00,  3.5511e+00,\n",
      "        -3.0970e+00, -7.8644e-02,  1.1528e+00,  2.6313e+00,  1.2507e+00,\n",
      "        -2.5409e+00, -1.6603e+00, -8.7131e-01, -7.3717e-01,  1.9760e+00,\n",
      "         1.3989e+00,  1.2953e-01, -9.8057e-01,  4.8638e-01, -3.1115e-01,\n",
      "         7.0645e-02, -1.7289e+00,  1.9103e+00, -4.7436e-01, -2.1076e+00,\n",
      "         1.4162e+00, -6.1693e-01,  4.4774e+00, -2.8372e+00,  2.1663e+00,\n",
      "        -2.7473e-01, -4.1419e+00,  3.3089e+00,  9.1716e-01, -9.1214e-01,\n",
      "         1.3245e+00, -5.8970e-01,  9.2877e-01, -1.2693e+00, -9.8495e+00,\n",
      "        -1.8325e+00, -3.5198e+00,  1.8318e+00,  7.8366e-01,  3.0642e+00,\n",
      "        -2.4910e+00,  7.4513e-01,  1.9690e+00, -2.0091e-01,  3.4139e+00,\n",
      "        -1.5855e+00, -1.3711e+00,  5.3034e+00,  2.4293e+00, -4.7340e+00,\n",
      "         3.7809e+00,  3.3850e-01,  8.4706e-01, -3.4269e+00,  8.2182e-01,\n",
      "        -2.2690e+00, -2.6863e+00, -2.1524e+00, -2.2806e+00, -3.9766e+00,\n",
      "         3.4253e+00, -1.3147e-01,  5.6351e+00,  4.4869e-02,  2.5750e+00,\n",
      "        -4.0218e+00, -1.6552e+00, -3.3640e+00, -8.4657e-01,  6.9035e-01,\n",
      "        -8.9113e-01, -2.7932e+00, -4.3046e+00,  1.7269e+00,  1.7026e-01,\n",
      "         3.3529e+00, -3.2488e+00, -1.3378e+00,  1.1246e+00, -3.2829e+00,\n",
      "        -1.5871e+00,  8.5161e-01,  3.4760e+00, -1.7531e+00,  6.7727e+00,\n",
      "        -5.9446e+00, -4.2732e-01, -5.6905e+00, -6.9849e-01,  2.6664e-01,\n",
      "         1.3878e+00,  7.0145e-01, -9.6188e-01,  9.9985e-01,  3.3534e+00,\n",
      "        -2.6592e+00, -4.3063e+00, -1.0374e+00, -3.9760e+00, -1.6417e+00,\n",
      "        -1.3281e-01,  3.6796e-01,  1.9003e+00,  2.6875e+00, -2.5322e+00,\n",
      "        -1.7439e+00, -2.0003e+00,  1.0204e-01,  3.4234e-01,  4.8535e-02,\n",
      "         1.8158e+00, -3.5935e+00, -4.4443e-01,  8.2697e-01,  1.3814e+00,\n",
      "        -2.4149e+00,  4.9341e-01,  3.5622e-01, -8.0834e-01, -2.2284e+00,\n",
      "         5.7344e-01,  5.9172e+00,  3.2085e+00,  2.0079e+00,  1.5188e+00,\n",
      "        -4.0114e+00,  1.9916e+00,  1.6107e-01,  1.3607e+00, -3.6516e+00,\n",
      "         3.2909e+00,  2.4384e+00, -6.4555e-01,  1.8196e+00, -6.5168e-01,\n",
      "        -3.0735e+00,  1.9883e+00,  1.3391e+00, -1.4305e-01,  3.5277e+00,\n",
      "         2.9085e-01, -1.9817e+00,  1.2859e+00,  3.0753e+00, -1.3261e+00,\n",
      "        -3.9690e+00,  2.3215e+00, -1.1643e+00,  5.0250e+00,  3.9558e+00,\n",
      "        -2.6493e+00,  1.4509e+00, -6.5388e-01, -2.4745e+00,  2.1662e-01,\n",
      "        -3.2295e+00, -2.1285e+00, -8.4898e-01, -5.9538e+00, -4.7013e+00,\n",
      "        -1.9192e+00,  1.0686e+00,  7.0916e-01,  1.4968e+00, -7.0494e-01,\n",
      "         2.0167e-01, -3.3697e+00,  4.4721e+00, -2.4653e+00, -1.5080e+00,\n",
      "        -2.4559e+00,  1.7203e+00,  6.9423e-01,  3.2460e+00,  2.5632e+00,\n",
      "        -6.0808e+00,  2.9800e-01, -4.5236e-01,  4.6845e+00, -1.4733e+00,\n",
      "         3.2596e+00, -2.5524e+00, -4.5813e-01,  1.4793e-01,  4.4371e+00,\n",
      "         1.4806e+00, -6.4592e-01, -5.5791e+00,  3.2812e+00, -6.6752e-03,\n",
      "        -1.0558e+00,  1.3211e+00, -2.8222e+00,  2.6093e-01,  2.7572e+00,\n",
      "         3.3020e+00,  3.7790e+00, -5.9394e+00,  1.1316e+00, -1.2520e+00,\n",
      "        -2.5199e+00, -1.6197e-02, -1.9700e+00,  1.7967e+00, -1.6906e+00,\n",
      "        -4.1300e-01, -2.0576e+00, -1.7080e+00, -4.3328e-01,  1.8719e+00,\n",
      "        -5.2697e-01,  2.7524e+00,  2.8325e+00,  1.5010e+00, -4.5091e+00,\n",
      "         1.6200e-01,  2.7604e+00, -1.1920e+00, -2.0546e+00, -1.4975e+00,\n",
      "         8.6004e-01, -4.5720e-01, -3.8391e+00,  1.7625e+00,  2.0132e+00,\n",
      "         1.1493e+00, -1.3228e+00, -2.6493e+00, -1.8952e+00, -1.8475e+00,\n",
      "        -1.5617e+00, -2.3231e+00, -1.6115e+00, -4.3514e+00,  1.0231e+00,\n",
      "        -2.7034e+00, -5.0022e+00, -4.2310e+00, -2.3734e+00,  1.3447e+00,\n",
      "         1.2043e+00,  2.5987e+00, -3.5529e+00,  6.3137e-01,  5.8554e+00,\n",
      "         7.7419e+00, -8.3601e-01,  2.5533e+00,  8.0044e-01,  3.6869e+00,\n",
      "        -9.0838e-01,  2.2930e+00,  2.2146e+00,  3.5925e+00, -2.2821e+00,\n",
      "        -7.0014e-02, -2.1730e+00,  7.3183e-01,  3.3968e+00, -2.5008e+00,\n",
      "        -2.8522e+00, -5.7571e-01, -2.4453e+00])\n",
      "1 figure\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([49, 768])\n",
      "1 figure tens shape torch.Size([2, 768])\n",
      "tensor(5.1025)\n",
      "counter 361\n",
      "2 ,\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "2 , tens shape torch.Size([3, 768])\n",
      "tensor(-0.5253)\n",
      "counter 362\n",
      "3 the\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "3 the tens shape torch.Size([4, 768])\n",
      "tensor(-3.4498)\n",
      "counter 363\n",
      "4 meagreness\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False  True  True  True  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "4 meagreness tens shape torch.Size([5, 768])\n",
      "tensor(-2.0096)\n",
      "counter 364\n",
      "5 of\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "5 of tens shape torch.Size([6, 768])\n",
      "tensor(-1.4380)\n",
      "counter 365\n",
      "6 his\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "6 his tens shape torch.Size([7, 768])\n",
      "tensor(4.9051)\n",
      "counter 366\n",
      "7 body\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "7 body tens shape torch.Size([8, 768])\n",
      "tensor(4.5761)\n",
      "counter 367\n",
      "8 merely\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([49, 768])\n",
      "8 merely tens shape torch.Size([9, 768])\n",
      "tensor(0.6038)\n",
      "counter 368\n",
      "9 emphasized\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "9 emphasized tens shape torch.Size([10, 768])\n",
      "tensor(1.7042)\n",
      "counter 369\n",
      "10 by\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "10 by tens shape torch.Size([11, 768])\n",
      "tensor(-2.9632)\n",
      "counter 370\n",
      "11 the\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "11 the tens shape torch.Size([12, 768])\n",
      "tensor(-3.0051)\n",
      "counter 371\n",
      "12 blue\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "12 blue tens shape torch.Size([13, 768])\n",
      "tensor(-0.5645)\n",
      "counter 372\n",
      "13 overalls\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "13 overalls tens shape torch.Size([14, 768])\n",
      "tensor(3.4396)\n",
      "counter 373\n",
      "14 which\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "14 which tens shape torch.Size([15, 768])\n",
      "tensor(1.7137)\n",
      "counter 374\n",
      "15 were\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([49, 768])\n",
      "15 were tens shape torch.Size([16, 768])\n",
      "tensor(2.5366)\n",
      "counter 375\n",
      "16 the\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "16 the tens shape torch.Size([17, 768])\n",
      "tensor(-2.8004)\n",
      "counter 376\n",
      "17 uniform\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "17 uniform tens shape torch.Size([18, 768])\n",
      "tensor(2.0992)\n",
      "counter 377\n",
      "18 of\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "18 of tens shape torch.Size([19, 768])\n",
      "tensor(-3.8047)\n",
      "counter 378\n",
      "19 the\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "19 the tens shape torch.Size([20, 768])\n",
      "tensor(-3.6803)\n",
      "counter 379\n",
      "20 Party\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "20 Party tens shape torch.Size([21, 768])\n",
      "tensor(1.7873)\n",
      "counter 380\n",
      "21 .\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "21 . tens shape torch.Size([22, 768])\n",
      "tensor(0.0904)\n",
      "counter 381\n",
      "22 His\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([49, 768])\n",
      "22 His tens shape torch.Size([23, 768])\n",
      "tensor(3.8306)\n",
      "counter 382\n",
      "23 hair\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "23 hair tens shape torch.Size([24, 768])\n",
      "tensor(6.3657)\n",
      "counter 383\n",
      "24 was\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "24 was tens shape torch.Size([25, 768])\n",
      "tensor(1.7050)\n",
      "counter 384\n",
      "25 very\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "25 very tens shape torch.Size([26, 768])\n",
      "tensor(-0.3668)\n",
      "counter 385\n",
      "26 fair\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "26 fair tens shape torch.Size([27, 768])\n",
      "tensor(2.1601)\n",
      "counter 386\n",
      "27 ,\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "27 , tens shape torch.Size([28, 768])\n",
      "tensor(-0.3688)\n",
      "counter 387\n",
      "28 his\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "28 his tens shape torch.Size([29, 768])\n",
      "tensor(3.6636)\n",
      "counter 388\n",
      "29 face\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([49, 768])\n",
      "29 face tens shape torch.Size([30, 768])\n",
      "tensor(4.8590)\n",
      "counter 389\n",
      "30 naturally\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "30 naturally tens shape torch.Size([31, 768])\n",
      "tensor(1.6870)\n",
      "counter 390\n",
      "31 sanguine\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True False False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "31 sanguine tens shape torch.Size([32, 768])\n",
      "tensor(0.9601)\n",
      "counter 391\n",
      "32 ,\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "32 , tens shape torch.Size([33, 768])\n",
      "tensor(-0.2828)\n",
      "counter 392\n",
      "33 his\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "33 his tens shape torch.Size([34, 768])\n",
      "tensor(4.1696)\n",
      "counter 393\n",
      "34 skin\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "34 skin tens shape torch.Size([35, 768])\n",
      "tensor(5.3757)\n",
      "counter 394\n",
      "35 roughened\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True  True False False False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "35 roughened tens shape torch.Size([36, 768])\n",
      "tensor(0.2606)\n",
      "counter 395\n",
      "36 by\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([49, 768])\n",
      "36 by tens shape torch.Size([37, 768])\n",
      "tensor(-2.0391)\n",
      "counter 396\n",
      "37 coarse\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "37 coarse tens shape torch.Size([38, 768])\n",
      "tensor(2.6758)\n",
      "counter 397\n",
      "38 soap\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "38 soap tens shape torch.Size([39, 768])\n",
      "tensor(4.8607)\n",
      "counter 398\n",
      "39 and\n",
      "encoded {'input_ids': tensor([[  101, 25737,  3275,  1010,  1996,  2033,  8490,  7389,  7971,  1997,\n",
      "          2010,  2303,  6414, 13155,  2011,  1996,  2630,  3452,  2015,  2029,\n",
      "          2020,  1996,  6375,  1997,  1996,  2283,  1012,  2010,  2606,  2001,\n",
      "          2200,  4189,  1010,  2010,  2227,  8100,  6369, 20023,  2063,  1010,\n",
      "          2010,  3096,  5931,  6675,  2011, 20392,  7815,  1998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded.word_ids-idx [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False]\n",
      "output torch.Size([49, 768])\n",
      "39 and tens shape torch.Size([40, 768])\n",
      "tensor(-0.8871)\n",
      "counter 399\n"
     ]
    }
   ],
   "source": [
    "# Use last four layers by default\n",
    "counter=0\n",
    "layers = [-4, -3, -2, -1]\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "config = AutoConfig.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\", output_hidden_states=True)\n",
    "model = AutoModel.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\", output_hidden_states=True)\n",
    "tens = torch.empty((0), dtype=torch.int32)\n",
    "extra_set_list = []\n",
    "for q in range(0,10):\n",
    "    input_string = set_creator(q)\n",
    "    ww = input_string.split(\" \")\n",
    "    print('q',q)\n",
    "\n",
    "    for ix, i in enumerate(ww):\n",
    "        print(ix,i)\n",
    "        #print(list_labels[ix])\n",
    "        if i != '':\n",
    "            extra_set_list.append(i)\n",
    "            idx = ix\n",
    "            word_embedding = get_word_vector(input_string,idx,tokenizer,model,layers)\n",
    "            \n",
    "            if (ix == 0 & q == 0): # CHANGE THIS \n",
    "                tens = word_embedding[None,:]\n",
    "                print(word_embedding)\n",
    "            else:\n",
    "                tens = torch.cat((tens, word_embedding[None,:]),0)\n",
    "                print(ix,i, 'tens shape',np.shape(tens))\n",
    "                print(word_embedding[0])\n",
    "                print('counter',counter)\n",
    "            \n",
    "            counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-syndicate",
   "metadata": {},
   "source": [
    "This part deals with POS tags from NLTK corpus (data variable instantiated above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-custom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "owned-uniform",
   "metadata": {},
   "source": [
    "### Label creators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-instruction",
   "metadata": {},
   "source": [
    "The below creates the labels corresponding to contextual embeddings for tokens tensor above. Some parts are manual, as some parts are split differently above, as they are in the NLTK corpus. For example, '3,000' versus '3'  ','  '000'  splits differently for both. Same for '...' versus '.' ,'.', '.' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "id": "explicit-college",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('It', 'PRON')\n",
      "1 ('was', 'VERB')\n",
      "2 ('a', 'DET')\n",
      "3 ('bright', 'ADJ')\n",
      "4 ('cold', 'ADJ')\n",
      "5 ('day', 'NOUN')\n",
      "6 ('in', 'ADP')\n",
      "7 ('April', 'NOUN')\n",
      "8 (',', '')\n",
      "9 ('and', 'CONJ')\n",
      "10 ('the', 'DET')\n",
      "11 ('clocks', 'NOUN')\n",
      "12 ('were', 'VERB')\n",
      "13 ('striking', 'VERB')\n",
      "14 ('thirteen', 'NUM')\n",
      "15 ('.', '')\n",
      "16 ('Winston', 'NOUN')\n",
      "17 ('Smith', 'NOUN')\n",
      "18 (',', '')\n",
      "19 ('his', 'DET')\n",
      "20 ('chin', 'NOUN')\n",
      "21 ('nuzzled', 'VERB')\n",
      "22 ('into', 'ADP')\n",
      "23 ('his', 'DET')\n",
      "24 ('breast', 'NOUN')\n",
      "25 ('in', 'ADP')\n",
      "26 ('an', 'DET')\n",
      "27 ('effort', 'NOUN')\n",
      "28 ('to', 'ADP')\n",
      "29 ('escape', 'VERB')\n",
      "30 ('the', 'DET')\n",
      "31 ('vile', 'ADJ')\n",
      "32 ('wind', 'NOUN')\n",
      "33 (',', '')\n",
      "34 ('slipped', 'VERB')\n",
      "35 ('quickly', 'ADV')\n",
      "36 ('through', 'ADP')\n",
      "37 ('the', 'DET')\n",
      "38 ('glass', 'NOUN')\n",
      "39 ('doors', 'NOUN')\n",
      "40 ('of', 'ADP')\n",
      "41 ('Victory', 'NOUN')\n",
      "42 ('Mansions', 'NOUN')\n",
      "43 (',', '')\n",
      "44 ('though', 'CONJ')\n",
      "45 ('not', 'ADV')\n",
      "46 ('quickly', 'ADV')\n",
      "47 ('enough', 'ADV')\n",
      "48 ('to', 'ADP')\n",
      "49 ('prevent', 'VERB')\n",
      "50 ('a', 'DET')\n",
      "51 ('swirl', 'NOUN')\n",
      "52 ('of', 'ADP')\n",
      "53 ('gritty', 'ADJ')\n",
      "54 ('dust', 'NOUN')\n",
      "55 ('from', 'ADP')\n",
      "56 ('entering', 'VERB')\n",
      "57 ('along', 'ADV')\n",
      "58 ('with', 'ADP')\n",
      "59 ('him', 'PRON')\n",
      "60 ('.', '')\n",
      "61 ('The', 'DET')\n",
      "62 ('hallway', 'NOUN')\n",
      "63 ('smelt', 'VERB')\n",
      "64 ('of', 'ADP')\n",
      "65 ('boiled', 'ADJ')\n",
      "66 ('cabbage', 'NOUN')\n",
      "67 ('and', 'CONJ')\n",
      "68 ('old', 'ADJ')\n",
      "69 ('rag', 'NOUN')\n",
      "70 ('mats', 'NOUN')\n",
      "71 ('.', '')\n",
      "72 ('At', 'ADP')\n",
      "73 ('one', 'NUM')\n",
      "74 ('end', 'NOUN')\n",
      "75 ('of', 'ADP')\n",
      "76 ('it', 'PRON')\n",
      "77 ('a', 'DET')\n",
      "78 ('coloured', 'ADJ')\n",
      "79 ('poster', 'NOUN')\n",
      "80 (',', '')\n",
      "81 ('too', 'ADV')\n",
      "82 ('large', 'ADJ')\n",
      "83 ('for', 'ADP')\n",
      "84 ('indoor', 'ADJ')\n",
      "85 ('display', 'NOUN')\n",
      "86 (',', '')\n",
      "87 ('had', 'VERB')\n",
      "88 ('been', 'VERB')\n",
      "89 ('tacked', 'VERB')\n",
      "90 ('to', 'ADP')\n",
      "91 ('the', 'DET')\n",
      "92 ('wall', 'NOUN')\n",
      "93 ('.', '')\n",
      "94 ('It', 'PRON')\n",
      "95 ('depicted', 'VERB')\n",
      "96 ('simply', 'ADV')\n",
      "97 ('an', 'DET')\n",
      "98 ('enormous', 'ADJ')\n",
      "99 ('face', 'NOUN')\n",
      "100 (',', '')\n",
      "101 ('more', 'ADV')\n",
      "102 ('than', 'CONJ')\n",
      "103 ('a', 'DET')\n",
      "104 ('metre', 'NOUN')\n",
      "105 ('wide', 'ADJ')\n",
      "106 (':', '')\n",
      "107 ('the', 'DET')\n",
      "108 ('face', 'NOUN')\n",
      "109 ('of', 'ADP')\n",
      "110 ('a', 'DET')\n",
      "111 ('man', 'NOUN')\n",
      "112 ('of', 'ADP')\n",
      "113 ('about', 'ADV')\n",
      "114 ('forty-five', 'NUM')\n",
      "115 (',', '')\n",
      "116 ('with', 'ADP')\n",
      "117 ('a', 'DET')\n",
      "118 ('heavy', 'ADJ')\n",
      "119 ('black', 'ADJ')\n",
      "120 ('moustache', 'NOUN')\n",
      "121 ('and', 'CONJ')\n",
      "122 ('ruggedly', 'ADV')\n",
      "123 ('handsome', 'ADJ')\n",
      "124 ('features', 'NOUN')\n",
      "125 ('.', '')\n",
      "126 ('Winston', 'NOUN')\n",
      "127 ('made', 'VERB')\n",
      "128 ('for', 'ADP')\n",
      "129 ('the', 'DET')\n",
      "130 ('stairs', 'NOUN')\n",
      "131 ('.', '')\n",
      "132 ('It', 'PRON')\n",
      "133 ('was', 'VERB')\n",
      "134 ('no', 'DET')\n",
      "135 ('use', 'NOUN')\n",
      "136 ('trying', 'VERB')\n",
      "137 ('the', 'DET')\n",
      "138 ('lift', 'NOUN')\n",
      "139 ('.', '')\n",
      "140 ('Even', 'ADV')\n",
      "141 ('at', 'ADP')\n",
      "142 ('the', 'DET')\n",
      "143 ('best', 'NOUN')\n",
      "144 ('of', 'ADP')\n",
      "145 ('times', 'NOUN')\n",
      "146 ('it', 'PRON')\n",
      "147 ('was', 'VERB')\n",
      "148 ('seldom', 'ADV')\n",
      "149 ('working', 'VERB')\n",
      "150 (',', '')\n",
      "151 ('and', 'CONJ')\n",
      "152 ('at', 'ADP')\n",
      "153 ('present', 'NOUN')\n",
      "154 ('the', 'DET')\n",
      "155 ('electric', 'ADJ')\n",
      "156 ('current', 'NOUN')\n",
      "157 ('was', 'VERB')\n",
      "158 ('cut', 'VERB')\n",
      "159 ('off', 'ADV')\n",
      "160 ('during', 'ADP')\n",
      "161 ('daylight', 'NOUN')\n",
      "162 ('hours', 'NOUN')\n",
      "163 ('.', '')\n",
      "164 ('It', 'PRON')\n",
      "165 ('was', 'VERB')\n",
      "166 ('part', 'NOUN')\n",
      "167 ('of', 'ADP')\n",
      "168 ('the', 'DET')\n",
      "169 ('economy', 'NOUN')\n",
      "170 ('drive', 'NOUN')\n",
      "171 ('in', 'ADP')\n",
      "172 ('preparation', 'NOUN')\n",
      "173 ('for', 'ADP')\n",
      "174 ('Hate', 'NOUN')\n",
      "175 ('Week', 'NOUN')\n",
      "176 ('.', '')\n",
      "177 ('The', 'DET')\n",
      "178 ('flat', 'NOUN')\n",
      "179 ('was', 'VERB')\n",
      "180 ('seven', 'NUM')\n",
      "181 ('flights', 'NOUN')\n",
      "182 ('up', 'ADP')\n",
      "183 (',', '')\n",
      "184 ('and', 'CONJ')\n",
      "185 ('Winston', 'NOUN')\n",
      "186 (',', '')\n",
      "187 ('who', 'PRON')\n",
      "188 ('was', 'VERB')\n",
      "189 ('thirty-nine', 'NUM')\n",
      "190 ('and', 'CONJ')\n",
      "191 ('had', 'VERB')\n",
      "192 ('a', 'DET')\n",
      "193 ('varicose', 'ADJ')\n",
      "194 ('ulcer', 'NOUN')\n",
      "195 ('above', 'ADP')\n",
      "196 ('his', 'DET')\n",
      "197 ('right', 'ADJ')\n",
      "198 ('ankle', 'NOUN')\n",
      "199 (',', '')\n",
      "200 ('went', 'VERB')\n",
      "201 ('slowly', 'ADV')\n",
      "202 (',', '')\n",
      "203 ('resting', 'VERB')\n",
      "204 ('several', 'DET')\n",
      "205 ('times', 'NOUN')\n",
      "206 ('on', 'ADP')\n",
      "207 ('the', 'DET')\n",
      "208 ('way', 'NOUN')\n",
      "209 ('.', '')\n",
      "210 ('On', 'ADP')\n",
      "211 ('each', 'DET')\n",
      "212 ('landing', 'NOUN')\n",
      "213 (',', '')\n",
      "214 ('opposite', 'ADP')\n",
      "215 ('the', 'DET')\n",
      "216 ('lift-shaft', 'NOUN')\n",
      "217 (',', '')\n",
      "218 ('the', 'DET')\n",
      "219 ('poster', 'NOUN')\n",
      "220 ('with', 'ADP')\n",
      "221 ('the', 'DET')\n",
      "222 ('enormous', 'ADJ')\n",
      "223 ('face', 'NOUN')\n",
      "224 ('gazed', 'VERB')\n",
      "225 ('from', 'ADP')\n",
      "226 ('the', 'DET')\n",
      "227 ('wall', 'NOUN')\n",
      "228 ('.', '')\n",
      "229 ('It', 'PRON')\n",
      "230 ('was', 'VERB')\n",
      "231 ('one', 'PRON')\n",
      "232 ('of', 'ADP')\n",
      "233 ('those', 'DET')\n",
      "234 ('pictures', 'NOUN')\n",
      "235 ('which', 'PRON')\n",
      "236 ('are', 'VERB')\n",
      "237 ('so', 'CONJ')\n",
      "238 ('contrived', 'VERB')\n",
      "239 ('that', 'CONJ')\n",
      "240 ('the', 'DET')\n",
      "241 ('eyes', 'NOUN')\n",
      "242 ('follow', 'VERB')\n",
      "243 ('you', 'PRON')\n",
      "244 ('about', 'ADV')\n",
      "245 ('when', 'CONJ')\n",
      "246 ('you', 'PRON')\n",
      "247 ('move', 'VERB')\n",
      "248 ('.', '')\n",
      "249 ('Big', 'ADJ')\n",
      "250 ('Brother', 'NOUN')\n",
      "251 ('is', 'VERB')\n",
      "252 ('watching', 'VERB')\n",
      "253 ('you', 'PRON')\n",
      "254 (',', '')\n",
      "255 ('the', 'DET')\n",
      "256 ('caption', 'NOUN')\n",
      "257 ('beneath', 'ADP')\n",
      "258 ('it', 'PRON')\n",
      "259 ('ran', 'VERB')\n",
      "260 ('.', '')\n",
      "261 ('Inside', 'ADP')\n",
      "262 ('the', 'DET')\n",
      "263 ('flat', 'NOUN')\n",
      "264 ('a', 'DET')\n",
      "265 ('fruity', 'ADJ')\n",
      "266 ('voice', 'NOUN')\n",
      "267 ('was', 'VERB')\n",
      "268 ('reading', 'VERB')\n",
      "269 ('out', 'ADP')\n",
      "270 ('a', 'DET')\n",
      "271 ('list', 'NOUN')\n",
      "272 ('of', 'ADP')\n",
      "273 ('figures', 'NOUN')\n",
      "274 ('which', 'PRON')\n",
      "275 ('had', 'VERB')\n",
      "276 ('something', 'PRON')\n",
      "277 ('to', 'ADP')\n",
      "278 ('do', 'VERB')\n",
      "279 ('with', 'ADP')\n",
      "280 ('the', 'DET')\n",
      "281 ('production', 'NOUN')\n",
      "282 ('of', 'ADP')\n",
      "283 ('pig-iron', 'NOUN')\n",
      "284 ('.', '')\n",
      "285 ('The', 'DET')\n",
      "286 ('voice', 'NOUN')\n",
      "287 ('came', 'VERB')\n",
      "288 ('from', 'ADP')\n",
      "289 ('an', 'DET')\n",
      "290 ('oblong', 'ADJ')\n",
      "291 ('metal', 'NOUN')\n",
      "292 ('plaque', 'NOUN')\n",
      "293 ('like', 'ADP')\n",
      "294 ('a', 'DET')\n",
      "295 ('dulled', 'ADJ')\n",
      "296 ('mirror', 'NOUN')\n",
      "297 ('which', 'PRON')\n",
      "298 ('formed', 'VERB')\n",
      "299 ('part', 'NOUN')\n",
      "300 ('of', 'ADP')\n",
      "301 ('the', 'DET')\n",
      "302 ('surface', 'NOUN')\n",
      "303 ('of', 'ADP')\n",
      "304 ('the', 'DET')\n",
      "305 ('right-hand', 'ADJ')\n",
      "306 ('wall', 'NOUN')\n",
      "307 ('.', '')\n",
      "308 ('Winston', 'NOUN')\n",
      "309 ('turned', 'VERB')\n",
      "310 ('a', 'DET')\n",
      "311 ('switch', 'NOUN')\n",
      "312 ('and', 'CONJ')\n",
      "313 ('the', 'DET')\n",
      "314 ('voice', 'NOUN')\n",
      "315 ('sank', 'VERB')\n",
      "316 ('somewhat', 'ADV')\n",
      "317 (',', '')\n",
      "318 ('though', 'CONJ')\n",
      "319 ('the', 'DET')\n",
      "320 ('words', 'NOUN')\n",
      "321 ('were', 'VERB')\n",
      "322 ('still', 'ADV')\n",
      "323 ('distinguishable', 'ADJ')\n",
      "324 ('.', '')\n",
      "325 ('The', 'DET')\n",
      "326 ('instrument', 'NOUN')\n",
      "327 ('(', '')\n",
      "328 ('the', 'DET')\n",
      "329 ('telescreen', 'NOUN')\n",
      "330 (',', '')\n",
      "331 ('it', 'PRON')\n",
      "332 ('was', 'VERB')\n",
      "333 ('called', 'VERB')\n",
      "334 (')', '')\n",
      "335 ('could', 'VERB')\n",
      "336 ('be', 'VERB')\n",
      "337 ('dimmed', 'VERB')\n",
      "338 (',', '')\n",
      "339 ('but', 'CONJ')\n",
      "340 ('there', 'PRON')\n",
      "341 ('was', 'VERB')\n",
      "342 ('no', 'DET')\n",
      "343 ('way', 'NOUN')\n",
      "344 ('of', 'ADP')\n",
      "345 ('shutting', 'VERB')\n",
      "346 ('it', 'PRON')\n",
      "347 ('off', 'ADV')\n",
      "348 ('completely', 'ADV')\n",
      "349 ('.', '')\n",
      "350 ('He', 'PRON')\n",
      "351 ('moved', 'VERB')\n",
      "352 ('over', 'ADV')\n",
      "353 ('to', 'ADP')\n",
      "354 ('the', 'DET')\n",
      "355 ('window', 'NOUN')\n",
      "356 (':', '')\n",
      "357 ('a', 'DET')\n",
      "358 ('smallish', 'ADJ')\n",
      "359 (',', '')\n",
      "360 ('frail', 'ADJ')\n",
      "361 ('figure', 'NOUN')\n",
      "362 (',', '')\n",
      "363 ('the', 'DET')\n",
      "364 ('meagreness', 'NOUN')\n",
      "365 ('of', 'ADP')\n",
      "366 ('his', 'DET')\n",
      "367 ('body', 'NOUN')\n",
      "368 ('merely', 'ADV')\n",
      "369 ('emphasized', 'VERB')\n",
      "370 ('by', 'ADP')\n",
      "371 ('the', 'DET')\n",
      "372 ('blue', 'ADJ')\n",
      "373 ('overalls', 'NOUN')\n",
      "374 ('which', 'PRON')\n",
      "375 ('were', 'VERB')\n",
      "376 ('the', 'DET')\n",
      "377 ('uniform', 'NOUN')\n",
      "378 ('of', 'ADP')\n",
      "379 ('the', 'DET')\n",
      "380 ('Party', 'NOUN')\n",
      "381 ('.', '')\n",
      "382 ('His', 'DET')\n",
      "383 ('hair', 'NOUN')\n",
      "384 ('was', 'VERB')\n",
      "385 ('very', 'ADV')\n",
      "386 ('fair', 'ADJ')\n",
      "387 (',', '')\n",
      "388 ('his', 'DET')\n",
      "389 ('face', 'NOUN')\n",
      "390 ('naturally', 'ADV')\n",
      "391 ('sanguine', 'ADJ')\n",
      "392 (',', '')\n",
      "393 ('his', 'DET')\n",
      "394 ('skin', 'NOUN')\n",
      "395 ('roughened', 'VERB')\n",
      "396 ('by', 'ADP')\n",
      "397 ('coarse', 'ADJ')\n",
      "398 ('soap', 'NOUN')\n",
      "399 ('and', 'CONJ')\n",
      "400 ('blunt', 'ADJ')\n",
      "401 ('razor', 'NOUN')\n",
      "402 ('blades', 'NOUN')\n",
      "403 ('and', 'CONJ')\n",
      "404 ('the', 'DET')\n",
      "405 ('cold', 'NOUN')\n",
      "406 ('of', 'ADP')\n",
      "407 ('the', 'DET')\n",
      "408 ('winter', 'NOUN')\n",
      "409 ('that', 'PRON')\n",
      "410 ('had', 'VERB')\n",
      "411 ('just', 'ADV')\n",
      "412 ('ended', 'VERB')\n",
      "413 ('.', '')\n",
      "414 ('Outside', 'ADV')\n",
      "415 (',', '')\n",
      "416 ('even', 'ADV')\n",
      "417 ('through', 'ADP')\n",
      "418 ('the', 'DET')\n",
      "419 ('shut', 'ADJ')\n",
      "420 ('window-pane', 'NOUN')\n",
      "421 (',', '')\n",
      "422 ('the', 'DET')\n",
      "423 ('world', 'NOUN')\n",
      "424 ('looked', 'VERB')\n",
      "425 ('cold', 'ADJ')\n",
      "426 ('.', '')\n",
      "427 ('Down', 'ADV')\n",
      "428 ('in', 'ADP')\n",
      "429 ('the', 'DET')\n",
      "430 ('street', 'NOUN')\n",
      "431 ('little', 'ADJ')\n",
      "432 ('eddies', 'NOUN')\n",
      "433 ('of', 'ADP')\n",
      "434 ('wind', 'NOUN')\n",
      "435 ('were', 'VERB')\n",
      "436 ('whirling', 'VERB')\n",
      "437 ('dust', 'NOUN')\n",
      "438 ('and', 'CONJ')\n",
      "439 ('torn', 'ADJ')\n",
      "440 ('paper', 'NOUN')\n",
      "441 ('into', 'ADP')\n",
      "442 ('spirals', 'NOUN')\n",
      "443 (',', '')\n",
      "444 ('and', 'CONJ')\n",
      "445 ('though', 'CONJ')\n",
      "446 ('the', 'DET')\n",
      "447 ('sun', 'NOUN')\n",
      "448 ('was', 'VERB')\n",
      "449 ('shining', 'VERB')\n",
      "450 ('and', 'CONJ')\n",
      "451 ('the', 'DET')\n",
      "452 ('sky', 'NOUN')\n",
      "453 ('a', 'DET')\n",
      "454 ('harsh', 'ADJ')\n",
      "455 ('blue', 'NOUN')\n",
      "456 (',', '')\n",
      "457 ('there', 'PRON')\n",
      "458 ('seemed', 'VERB')\n",
      "459 ('to', 'ADP')\n",
      "460 ('be', 'VERB')\n",
      "461 ('no', 'DET')\n",
      "462 ('colour', 'NOUN')\n",
      "463 ('in', 'ADP')\n",
      "464 ('anything', 'PRON')\n",
      "465 (',', '')\n",
      "466 ('except', 'ADP')\n",
      "467 ('the', 'DET')\n",
      "468 ('posters', 'NOUN')\n",
      "469 ('that', 'PRON')\n",
      "470 ('were', 'VERB')\n",
      "471 ('plastered', 'VERB')\n",
      "472 ('everywhere', 'ADV')\n",
      "473 ('.', '')\n",
      "474 ('The', 'DET')\n",
      "475 (\"blackmoustachio'd\", 'ADJ')\n",
      "476 ('face', 'NOUN')\n",
      "477 ('gazed', 'VERB')\n",
      "478 ('down', 'ADV')\n",
      "479 ('from', 'ADP')\n",
      "480 ('every', 'DET')\n",
      "481 ('commanding', 'ADJ')\n",
      "482 ('corner', 'NOUN')\n",
      "483 ('.', '')\n",
      "484 ('There', 'PRON')\n",
      "485 ('was', 'VERB')\n",
      "486 ('one', 'PRON')\n",
      "487 ('on', 'ADP')\n",
      "488 ('the', 'DET')\n",
      "489 ('house-front', 'NOUN')\n",
      "490 ('immediately', 'ADV')\n",
      "491 ('opposite', 'ADV')\n",
      "492 ('.', '')\n",
      "493 ('Big', 'ADJ')\n",
      "494 ('Brother', 'NOUN')\n",
      "495 ('is', 'VERB')\n",
      "496 ('watching', 'VERB')\n",
      "497 ('you', 'PRON')\n",
      "498 (',', '')\n",
      "499 ('the', 'DET')\n",
      "500 ('caption', 'NOUN')\n",
      "501 ('said', 'VERB')\n",
      "502 (',', '')\n",
      "503 ('while', 'CONJ')\n",
      "504 ('the', 'DET')\n",
      "505 ('dark', 'ADJ')\n",
      "506 ('eyes', 'NOUN')\n",
      "507 ('looked', 'VERB')\n",
      "508 ('deep', 'ADV')\n",
      "509 ('into', 'ADP')\n",
      "510 ('Winston', 'NOUN')\n",
      "511 (\"'s\", 'ADP')\n",
      "512 ('own', 'PRON')\n",
      "513 ('.', '')\n",
      "514 ('Down', 'ADV')\n",
      "515 ('at', 'ADP')\n",
      "516 ('streetlevel', 'NOUN')\n",
      "517 ('another', 'DET')\n",
      "518 ('poster', 'NOUN')\n",
      "519 (',', '')\n",
      "520 ('torn', 'VERB')\n",
      "521 ('at', 'ADP')\n",
      "522 ('one', 'NUM')\n",
      "523 ('corner', 'NOUN')\n",
      "524 (',', '')\n",
      "525 ('flapped', 'VERB')\n",
      "526 ('fitfully', 'ADV')\n",
      "527 ('in', 'ADP')\n",
      "528 ('the', 'DET')\n",
      "529 ('wind', 'NOUN')\n",
      "530 (',', '')\n",
      "531 ('alternately', 'ADV')\n",
      "532 ('covering', 'VERB')\n",
      "533 ('and', 'CONJ')\n",
      "534 ('uncovering', 'VERB')\n",
      "535 ('the', 'DET')\n",
      "536 ('single', 'NOUN')\n",
      "537 ('word', 'NOUN')\n",
      "538 ('Ingsoc', 'NOUN')\n",
      "539 ('.', '')\n",
      "540 ('In', 'ADP')\n",
      "541 ('the', 'DET')\n",
      "542 ('far', 'ADJ')\n",
      "543 ('distance', 'NOUN')\n",
      "544 ('a', 'DET')\n",
      "545 ('helicopter', 'NOUN')\n",
      "546 ('skimmed', 'VERB')\n",
      "547 ('down', 'ADV')\n",
      "548 ('between', 'ADP')\n",
      "549 ('the', 'DET')\n",
      "550 ('roofs', 'NOUN')\n",
      "551 (',', '')\n",
      "552 ('hovered', 'VERB')\n",
      "553 ('for', 'ADP')\n",
      "554 ('an', 'DET')\n",
      "555 ('instant', 'NOUN')\n",
      "556 ('like', 'ADP')\n",
      "557 ('a', 'DET')\n",
      "558 ('bluebottle', 'NOUN')\n",
      "559 (',', '')\n",
      "560 ('and', 'CONJ')\n",
      "561 ('darted', 'VERB')\n",
      "562 ('away', 'ADV')\n",
      "563 ('again', 'ADV')\n",
      "564 ('with', 'ADP')\n",
      "565 ('a', 'DET')\n",
      "566 ('curving', 'ADJ')\n",
      "567 ('flight', 'NOUN')\n",
      "568 ('.', '')\n",
      "569 ('It', 'PRON')\n",
      "570 ('was', 'VERB')\n",
      "571 ('the', 'DET')\n",
      "572 ('police', 'NOUN')\n",
      "573 ('patrol', 'NOUN')\n",
      "574 (',', '')\n",
      "575 ('snooping', 'VERB')\n",
      "576 ('into', 'ADP')\n",
      "577 ('people', 'NOUN')\n",
      "578 (\"'s\", 'ADP')\n",
      "579 ('windows', 'NOUN')\n",
      "580 ('.', '')\n",
      "581 ('The', 'DET')\n",
      "582 ('patrols', 'NOUN')\n",
      "583 ('did', 'VERB')\n",
      "584 ('not', 'ADV')\n",
      "585 ('matter', 'VERB')\n",
      "586 (',', '')\n",
      "587 ('however', 'ADV')\n",
      "588 ('.', '')\n",
      "589 ('Only', 'ADV')\n",
      "590 ('the', 'DET')\n",
      "591 ('Thought', 'NOUN')\n",
      "592 ('Police', 'NOUN')\n",
      "593 ('mattered', 'VERB')\n",
      "594 ('.', '')\n",
      "595 ('Behind', 'ADP')\n",
      "596 ('Winston', 'NOUN')\n",
      "597 (\"'s\", 'ADP')\n",
      "598 ('back', 'NOUN')\n",
      "599 ('the', 'DET')\n",
      "600 ('voice', 'NOUN')\n",
      "601 ('from', 'ADP')\n",
      "602 ('the', 'DET')\n",
      "603 ('telescreen', 'NOUN')\n",
      "604 ('was', 'VERB')\n",
      "605 ('still', 'ADV')\n",
      "606 ('babbling', 'VERB')\n",
      "607 ('away', 'ADV')\n",
      "608 ('about', 'ADP')\n",
      "609 ('pig-iron', 'NOUN')\n",
      "610 ('and', 'CONJ')\n",
      "611 ('the', 'DET')\n",
      "612 ('overfulfillment', 'NOUN')\n",
      "613 ('of', 'ADP')\n",
      "614 ('the', 'DET')\n",
      "615 ('Ninth', 'ADJ')\n",
      "616 ('Three-Year', 'ADJ')\n",
      "617 ('Plan', 'NOUN')\n",
      "618 ('.', '')\n",
      "619 ('The', 'DET')\n",
      "620 ('telescreen', 'NOUN')\n",
      "621 ('received', 'VERB')\n",
      "622 ('and', 'CONJ')\n",
      "623 ('transmitted', 'VERB')\n",
      "624 ('simultaneously', 'ADV')\n",
      "625 ('.', '')\n",
      "626 ('Any', 'DET')\n",
      "627 ('sound', 'NOUN')\n",
      "628 ('that', 'PRON')\n",
      "629 ('Winston', 'NOUN')\n",
      "630 ('made', 'VERB')\n",
      "631 (',', '')\n",
      "632 ('above', 'ADP')\n",
      "633 ('the', 'DET')\n",
      "634 ('level', 'NOUN')\n",
      "635 ('of', 'ADP')\n",
      "636 ('a', 'DET')\n",
      "637 ('very', 'ADV')\n",
      "638 ('low', 'ADJ')\n",
      "639 ('whisper', 'NOUN')\n",
      "640 (',', '')\n",
      "641 ('would', 'VERB')\n",
      "642 ('be', 'VERB')\n",
      "643 ('picked', 'VERB')\n",
      "644 ('up', 'ADP')\n",
      "645 ('by', 'ADP')\n",
      "646 ('it', 'PRON')\n",
      "647 (',', '')\n",
      "648 ('moreover', 'ADV')\n",
      "649 (',', '')\n",
      "650 ('so', 'ADV')\n",
      "651 ('long', 'ADV')\n",
      "652 ('as', 'CONJ')\n",
      "653 ('he', 'PRON')\n",
      "654 ('remained', 'VERB')\n",
      "655 ('within', 'ADP')\n",
      "656 ('the', 'DET')\n",
      "657 ('field', 'NOUN')\n",
      "658 ('of', 'ADP')\n",
      "659 ('vision', 'NOUN')\n",
      "660 ('which', 'PRON')\n",
      "661 ('the', 'DET')\n",
      "662 ('metal', 'NOUN')\n",
      "663 ('plaque', 'NOUN')\n",
      "664 ('commanded', 'VERB')\n",
      "665 (',', '')\n",
      "666 ('he', 'PRON')\n",
      "667 ('could', 'VERB')\n",
      "668 ('be', 'VERB')\n",
      "669 ('seen', 'VERB')\n",
      "670 ('as', 'CONJ')\n",
      "671 ('well', 'ADV')\n",
      "672 ('as', 'CONJ')\n",
      "673 ('heard', 'VERB')\n",
      "674 ('.', '')\n",
      "675 ('There', 'PRON')\n",
      "676 ('was', 'VERB')\n",
      "677 ('of', 'ADP')\n",
      "678 ('course', 'NOUN')\n",
      "679 ('no', 'DET')\n",
      "680 ('way', 'NOUN')\n",
      "681 ('of', 'ADP')\n",
      "682 ('knowing', 'VERB')\n",
      "683 ('whether', 'CONJ')\n",
      "684 ('you', 'PRON')\n",
      "685 ('were', 'VERB')\n",
      "686 ('being', 'VERB')\n",
      "687 ('watched', 'VERB')\n",
      "688 ('at', 'ADP')\n",
      "689 ('any', 'DET')\n",
      "690 ('given', 'VERB')\n",
      "691 ('moment', 'NOUN')\n",
      "692 ('.', '')\n",
      "693 ('How', 'ADV')\n",
      "694 ('often', 'ADV')\n",
      "695 (',', '')\n",
      "696 ('or', 'CONJ')\n",
      "697 ('on', 'ADP')\n",
      "698 ('what', 'DET')\n",
      "699 ('system', 'NOUN')\n",
      "700 (',', '')\n",
      "701 ('the', 'DET')\n",
      "702 ('Thought', 'NOUN')\n",
      "703 ('Police', 'NOUN')\n",
      "704 ('plugged', 'VERB')\n",
      "705 ('in', 'ADP')\n",
      "706 ('on', 'ADP')\n",
      "707 ('any', 'DET')\n",
      "708 ('individual', 'ADJ')\n",
      "709 ('wire', 'NOUN')\n",
      "710 ('was', 'VERB')\n",
      "711 ('guesswork', 'NOUN')\n",
      "712 ('.', '')\n",
      "713 ('It', 'PRON')\n",
      "714 ('was', 'VERB')\n",
      "715 ('even', 'ADV')\n",
      "716 ('conceivable', 'ADJ')\n",
      "717 ('that', 'CONJ')\n",
      "718 ('they', 'PRON')\n",
      "719 ('watched', 'VERB')\n",
      "720 ('everybody', 'PRON')\n",
      "721 ('all', 'DET')\n",
      "722 ('the', 'DET')\n",
      "723 ('time', 'NOUN')\n",
      "724 ('.', '')\n",
      "725 ('But', 'CONJ')\n",
      "726 ('at', 'ADP')\n",
      "727 ('any', 'DET')\n",
      "728 ('rate', 'NOUN')\n",
      "729 ('they', 'PRON')\n",
      "730 ('could', 'VERB')\n",
      "731 ('plug', 'VERB')\n",
      "732 ('in', 'ADP')\n",
      "733 ('your', 'DET')\n",
      "734 ('wire', 'NOUN')\n",
      "735 ('whenever', 'CONJ')\n",
      "736 ('they', 'PRON')\n",
      "737 ('wanted', 'VERB')\n",
      "738 ('to', 'ADP')\n",
      "739 ('.', '')\n",
      "740 ('You', 'PRON')\n",
      "741 ('had', 'VERB')\n",
      "742 ('to', 'ADP')\n",
      "743 ('live', 'VERB')\n",
      "744 ('-', '')\n",
      "745 ('did', 'VERB')\n",
      "746 ('live', 'VERB')\n",
      "747 (',', '')\n",
      "748 ('from', 'ADP')\n",
      "749 ('habit', 'NOUN')\n",
      "750 ('that', 'PRON')\n",
      "751 ('became', 'VERB')\n",
      "752 ('instinct', 'NOUN')\n",
      "753 ('-', '')\n",
      "754 ('in', 'ADP')\n",
      "755 ('the', 'DET')\n",
      "756 ('assumption', 'NOUN')\n",
      "757 ('that', 'CONJ')\n",
      "758 ('every', 'DET')\n",
      "759 ('sound', 'NOUN')\n",
      "760 ('you', 'PRON')\n",
      "761 ('made', 'VERB')\n",
      "762 ('was', 'VERB')\n",
      "763 ('overheard', 'VERB')\n",
      "764 (',', '')\n",
      "765 ('and', 'CONJ')\n",
      "766 (',', '')\n",
      "767 ('except', 'CONJ')\n",
      "768 ('in', 'ADP')\n",
      "769 ('darkness', 'NOUN')\n",
      "770 (',', '')\n",
      "771 ('every', 'DET')\n",
      "772 ('movement', 'NOUN')\n",
      "773 ('scrutinized', 'VERB')\n",
      "774 ('.', '')\n",
      "775 ('Winston', 'NOUN')\n",
      "776 ('kept', 'VERB')\n",
      "777 ('his', 'DET')\n",
      "778 ('back', 'NOUN')\n",
      "779 ('turned', 'VERB')\n",
      "780 ('to', 'ADP')\n",
      "781 ('the', 'DET')\n",
      "782 ('telescreen', 'NOUN')\n",
      "783 ('.', '')\n",
      "784 ('It', 'PRON')\n",
      "785 ('was', 'VERB')\n",
      "786 ('safer', 'ADJ')\n",
      "787 (',', '')\n",
      "788 ('though', 'CONJ')\n",
      "789 (',', '')\n",
      "790 ('as', 'ADV')\n",
      "791 ('he', 'PRON')\n",
      "792 ('well', 'ADV')\n",
      "793 ('knew', 'VERB')\n",
      "794 (',', '')\n",
      "795 ('even', 'ADV')\n",
      "796 ('a', 'DET')\n",
      "797 ('back', 'NOUN')\n",
      "798 ('can', 'VERB')\n",
      "799 ('be', 'VERB')\n",
      "800 ('revealing', 'ADJ')\n",
      "801 ('.', '')\n",
      "802 ('A', 'DET')\n",
      "803 ('kilometre', 'NOUN')\n",
      "804 ('away', 'ADV')\n",
      "805 ('the', 'DET')\n",
      "806 ('Ministry', 'NOUN')\n",
      "807 ('of', 'ADP')\n",
      "808 ('Truth', 'NOUN')\n",
      "809 (',', '')\n",
      "810 ('his', 'DET')\n",
      "811 ('place', 'NOUN')\n",
      "812 ('of', 'ADP')\n",
      "813 ('work', 'NOUN')\n",
      "814 (',', '')\n",
      "815 ('towered', 'VERB')\n",
      "816 ('vast', 'ADJ')\n",
      "817 ('and', 'CONJ')\n",
      "818 ('white', 'ADJ')\n",
      "819 ('above', 'ADV')\n",
      "820 ('the', 'DET')\n",
      "821 ('grimy', 'ADJ')\n",
      "822 ('landscape', 'NOUN')\n",
      "823 ('.', '')\n",
      "824 ('This', 'PRON')\n",
      "825 (',', '')\n",
      "826 ('he', 'PRON')\n",
      "827 ('thought', 'VERB')\n",
      "828 ('with', 'ADP')\n",
      "829 ('a', 'DET')\n",
      "830 ('sort', 'NOUN')\n",
      "831 ('of', 'ADP')\n",
      "832 ('vague', 'ADJ')\n",
      "833 ('distaste', 'NOUN')\n",
      "834 ('-', '')\n",
      "835 ('this', 'PRON')\n",
      "836 ('was', 'VERB')\n",
      "837 ('London', 'NOUN')\n",
      "838 (',', '')\n",
      "839 ('chief', 'ADJ')\n",
      "840 ('city', 'NOUN')\n",
      "841 ('of', 'ADP')\n",
      "842 ('Airstrip', 'NOUN')\n",
      "843 ('One', 'NUM')\n",
      "844 (',', '')\n",
      "845 ('itself', 'PRON')\n",
      "846 ('the', 'DET')\n",
      "847 ('third', 'ADJ')\n",
      "848 ('most', 'ADV')\n",
      "849 ('populous', 'ADJ')\n",
      "850 ('of', 'ADP')\n",
      "851 ('the', 'DET')\n",
      "852 ('provinces', 'NOUN')\n",
      "853 ('of', 'ADP')\n",
      "854 ('Oceania', 'NOUN')\n",
      "855 ('.', '')\n",
      "856 ('He', 'PRON')\n",
      "857 ('tried', 'VERB')\n",
      "858 ('to', 'ADP')\n",
      "859 ('squeeze', 'VERB')\n",
      "860 ('out', 'ADP')\n",
      "861 ('some', 'DET')\n",
      "862 ('childhood', 'NOUN')\n",
      "863 ('memory', 'NOUN')\n",
      "864 ('that', 'PRON')\n",
      "865 ('should', 'VERB')\n",
      "866 ('tell', 'VERB')\n",
      "867 ('him', 'PRON')\n",
      "868 ('whether', 'CONJ')\n",
      "869 ('London', 'NOUN')\n",
      "870 ('had', 'VERB')\n",
      "871 ('always', 'ADV')\n",
      "872 ('been', 'VERB')\n",
      "873 ('quite', 'ADV')\n",
      "874 ('like', 'ADP')\n",
      "875 ('this', 'PRON')\n",
      "876 ('.', '')\n",
      "877 ('Were', 'VERB')\n",
      "878 ('there', 'PRON')\n",
      "879 ('always', 'ADV')\n",
      "880 ('these', 'DET')\n",
      "881 ('vistas', 'NOUN')\n",
      "882 ('of', 'ADP')\n",
      "883 ('rotting', 'ADJ')\n",
      "884 ('nineteenth-century', 'ADJ')\n",
      "885 ('houses', 'NOUN')\n",
      "886 (',', '')\n",
      "887 ('their', 'DET')\n",
      "888 ('sides', 'NOUN')\n",
      "889 ('shored', 'VERB')\n",
      "890 ('up', 'ADP')\n",
      "891 ('with', 'ADP')\n",
      "892 ('baulks', 'VERB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893 ('of', 'ADP')\n",
      "894 ('timber', 'NOUN')\n",
      "895 (',', '')\n",
      "896 ('their', 'DET')\n",
      "897 ('windows', 'NOUN')\n",
      "898 ('patched', 'VERB')\n",
      "899 ('with', 'ADP')\n",
      "900 ('cardboard', 'NOUN')\n",
      "901 ('and', 'CONJ')\n",
      "902 ('their', 'DET')\n",
      "903 ('roofs', 'NOUN')\n",
      "904 ('with', 'ADP')\n",
      "905 ('corrugated', 'ADJ')\n",
      "906 ('iron', 'NOUN')\n",
      "907 (',', '')\n",
      "908 ('their', 'DET')\n",
      "909 ('crazy', 'ADJ')\n",
      "910 ('garden', 'NOUN')\n",
      "911 ('walls', 'NOUN')\n",
      "912 ('sagging', 'VERB')\n",
      "913 ('in', 'ADP')\n",
      "914 ('all', 'DET')\n",
      "915 ('directions', 'NOUN')\n",
      "916 ('?', '')\n",
      "917 ('And', 'CONJ')\n",
      "918 ('the', 'DET')\n",
      "919 ('bombed', 'ADJ')\n",
      "920 ('sites', 'NOUN')\n",
      "921 ('where', 'ADV')\n",
      "922 ('the', 'DET')\n",
      "923 ('plaster', 'NOUN')\n",
      "924 ('dust', 'NOUN')\n",
      "925 ('swirled', 'VERB')\n",
      "926 ('in', 'ADP')\n",
      "927 ('the', 'DET')\n",
      "928 ('air', 'NOUN')\n",
      "929 ('and', 'CONJ')\n",
      "930 ('the', 'DET')\n",
      "931 ('willow-herb', 'NOUN')\n",
      "932 ('straggled', 'VERB')\n",
      "933 ('over', 'ADP')\n",
      "934 ('the', 'DET')\n",
      "935 ('heaps', 'NOUN')\n",
      "936 ('of', 'ADP')\n",
      "937 ('rubble', 'NOUN')\n",
      "938 (';', '')\n",
      "939 ('and', 'CONJ')\n",
      "940 ('the', 'DET')\n",
      "941 ('places', 'NOUN')\n",
      "942 ('where', 'CONJ')\n",
      "943 ('the', 'DET')\n",
      "944 ('bombs', 'NOUN')\n",
      "945 ('had', 'VERB')\n",
      "946 ('cleared', 'VERB')\n",
      "947 ('a', 'DET')\n",
      "948 ('larger', 'ADJ')\n",
      "949 ('patch', 'NOUN')\n",
      "950 ('and', 'CONJ')\n",
      "951 ('there', 'PRON')\n",
      "952 ('had', 'VERB')\n",
      "953 ('sprung', 'VERB')\n",
      "954 ('up', 'ADP')\n",
      "955 ('sordid', 'ADJ')\n",
      "956 ('colonies', 'NOUN')\n",
      "957 ('of', 'ADP')\n",
      "958 ('wooden', 'ADJ')\n",
      "959 ('dwellings', 'NOUN')\n",
      "960 ('like', 'ADP')\n",
      "961 ('chicken-houses', 'NOUN')\n",
      "962 ('?', '')\n",
      "963 ('But', 'CONJ')\n",
      "964 ('it', 'PRON')\n",
      "965 ('was', 'VERB')\n",
      "966 ('no', 'DET')\n",
      "967 ('use', 'NOUN')\n",
      "968 (',', '')\n",
      "969 ('he', 'PRON')\n",
      "970 ('could', 'VERB')\n",
      "971 ('not', 'ADV')\n",
      "972 ('remember', 'VERB')\n",
      "973 (':', '')\n",
      "974 ('nothing', 'PRON')\n",
      "975 ('remained', 'VERB')\n",
      "976 ('of', 'ADP')\n",
      "977 ('his', 'DET')\n",
      "978 ('childhood', 'NOUN')\n",
      "979 ('except', 'ADP')\n",
      "980 ('a', 'DET')\n",
      "981 ('series', 'NOUN')\n",
      "982 ('of', 'ADP')\n",
      "983 ('bright-lit', 'ADJ')\n",
      "984 ('tableaux', 'NOUN')\n",
      "985 ('occurring', 'VERB')\n",
      "986 ('against', 'ADP')\n",
      "987 ('no', 'DET')\n",
      "988 ('background', 'NOUN')\n",
      "989 ('and', 'CONJ')\n",
      "990 ('mostly', 'ADV')\n",
      "991 ('unintelligible', 'ADJ')\n",
      "992 ('.', '')\n",
      "993 ('Ministry', 'NOUN')\n",
      "994 ('of', 'ADP')\n",
      "995 ('Truth', 'NOUN')\n",
      "996 (',', '')\n",
      "997 ('-', '')\n",
      "998 ('Minitrue', 'NOUN')\n",
      "999 (',', '')\n",
      "1000 ('in', 'ADP')\n",
      "1001 ('Newspeak', 'NOUN')\n",
      "1002 ('-', '')\n",
      "1003 ('was', 'VERB')\n",
      "1004 ('startlingly', 'ADV')\n",
      "1005 ('different', 'ADJ')\n",
      "1006 ('from', 'ADP')\n",
      "1007 ('any', 'DET')\n",
      "1008 ('other', 'DET')\n",
      "1009 ('object', 'NOUN')\n",
      "1010 ('in', 'ADP')\n",
      "1011 ('sight', 'NOUN')\n",
      "1012 ('.', '')\n",
      "1013 ('It', 'PRON')\n",
      "1014 ('was', 'VERB')\n",
      "1015 ('an', 'DET')\n",
      "1016 ('enormous', 'ADJ')\n",
      "1017 ('pyramidal', 'ADJ')\n",
      "1018 ('structure', 'NOUN')\n",
      "1019 ('of', 'ADP')\n",
      "1020 ('glittering', 'ADJ')\n",
      "1021 ('white', 'ADJ')\n",
      "1022 ('concrete', 'NOUN')\n",
      "1023 (',', '')\n",
      "1024 ('soaring', 'VERB')\n",
      "1025 ('up', 'ADP')\n",
      "1026 (',', '')\n",
      "1027 ('terrace', 'NOUN')\n",
      "1028 ('after', 'ADP')\n",
      "1029 ('terrace', 'NOUN')\n",
      "1030 (',', '')\n",
      "1031 ('300', 'NUM')\n",
      "1032 ('metres', 'NOUN')\n",
      "1033 ('into', 'ADP')\n",
      "1034 ('the', 'DET')\n",
      "1035 ('air', 'NOUN')\n",
      "1036 ('.', '')\n",
      "1037 ('From', 'ADP')\n",
      "1038 ('where', 'ADV')\n",
      "1039 ('Winston', 'NOUN')\n",
      "1040 ('stood', 'VERB')\n",
      "1041 ('it', 'PRON')\n",
      "1042 ('was', 'VERB')\n",
      "1043 ('just', 'ADV')\n",
      "1044 ('possible', 'ADJ')\n",
      "1045 ('to', 'ADP')\n",
      "1046 ('read', 'VERB')\n",
      "1047 (',', '')\n",
      "1048 ('picked', 'VERB')\n",
      "1049 ('out', 'ADP')\n",
      "1050 ('on', 'ADP')\n",
      "1051 ('its', 'DET')\n",
      "1052 ('white', 'ADJ')\n",
      "1053 ('face', 'NOUN')\n",
      "1054 ('in', 'ADP')\n",
      "1055 ('elegant', 'ADJ')\n",
      "1056 ('lettering', 'NOUN')\n",
      "1057 (',', '')\n",
      "1058 ('the', 'DET')\n",
      "1059 ('three', 'NUM')\n",
      "1060 ('slogans', 'NOUN')\n",
      "1061 ('of', 'ADP')\n",
      "1062 ('the', 'DET')\n",
      "1063 ('Party', 'NOUN')\n",
      "1064 (':', '')\n",
      "1065 ('War', 'NOUN')\n",
      "1066 ('is', 'VERB')\n",
      "1067 ('peace', 'NOUN')\n",
      "1068 ('Freedom', 'NOUN')\n",
      "1069 ('is', 'VERB')\n",
      "1070 ('slavery', 'NOUN')\n",
      "1071 ('Ignorance', 'NOUN')\n",
      "1072 ('is', 'VERB')\n",
      "1073 ('strength', 'NOUN')\n",
      "1074 ('.', '')\n",
      "1075 ('Ministry', 'NOUN')\n",
      "1076 ('of', 'ADP')\n",
      "1077 ('Truth', 'NOUN')\n",
      "1078 (',', '')\n",
      "1079 ('contained', 'VERB')\n",
      "1080 (',', '')\n",
      "1081 ('it', 'PRON')\n",
      "1082 ('was', 'VERB')\n",
      "1083 ('said', 'VERB')\n",
      "1084 (',', '')\n",
      "1085 ('three', 'NUM')\n",
      "1086 ('thousand', 'NUM')\n",
      "1087 ('rooms', 'NOUN')\n",
      "1088 ('above', 'ADP')\n",
      "1089 ('ground', 'NOUN')\n",
      "1090 ('level', 'NOUN')\n",
      "1091 (',', '')\n",
      "1092 ('and', 'CONJ')\n",
      "1093 ('corresponding', 'ADJ')\n",
      "1094 ('ramifications', 'NOUN')\n",
      "1095 ('below', 'ADV')\n",
      "1096 ('.', '')\n",
      "1097 ('Scattered', 'VERB')\n",
      "1098 ('about', 'ADP')\n",
      "1099 ('London', 'NOUN')\n",
      "1100 ('there', 'PRON')\n",
      "1101 ('were', 'VERB')\n",
      "1102 ('just', 'ADV')\n",
      "1103 ('three', 'NUM')\n",
      "1104 ('other', 'DET')\n",
      "1105 ('buildings', 'NOUN')\n",
      "1106 ('of', 'ADP')\n",
      "1107 ('similar', 'ADJ')\n",
      "1108 ('appearance', 'NOUN')\n",
      "1109 ('and', 'CONJ')\n",
      "1110 ('size', 'NOUN')\n",
      "1111 ('.', '')\n",
      "1112 ('So', 'ADV')\n",
      "1113 ('completely', 'ADV')\n",
      "1114 ('did', 'VERB')\n",
      "1115 ('they', 'PRON')\n",
      "1116 ('dwarf', 'VERB')\n",
      "1117 ('the', 'DET')\n",
      "1118 ('surrounding', 'ADJ')\n",
      "1119 ('architecture', 'NOUN')\n",
      "1120 ('that', 'CONJ')\n",
      "1121 ('from', 'ADP')\n",
      "1122 ('the', 'DET')\n",
      "1123 ('roof', 'NOUN')\n",
      "1124 ('of', 'ADP')\n",
      "1125 ('Victory', 'NOUN')\n",
      "1126 ('Mansions', 'NOUN')\n",
      "1127 ('you', 'PRON')\n",
      "1128 ('could', 'VERB')\n",
      "1129 ('see', 'VERB')\n",
      "1130 ('all', 'DET')\n",
      "1131 ('four', 'NUM')\n",
      "1132 ('of', 'ADP')\n",
      "1133 ('them', 'PRON')\n",
      "1134 ('simultaneously', 'ADV')\n",
      "1135 ('.', '')\n",
      "1136 ('They', 'PRON')\n",
      "1137 ('were', 'VERB')\n",
      "1138 ('the', 'DET')\n",
      "1139 ('homes', 'NOUN')\n",
      "1140 ('of', 'ADP')\n",
      "1141 ('the', 'DET')\n",
      "1142 ('four', 'NUM')\n",
      "1143 ('Ministries', 'NOUN')\n",
      "1144 ('between', 'ADP')\n",
      "1145 ('which', 'PRON')\n",
      "1146 ('the', 'DET')\n",
      "1147 ('entire', 'ADJ')\n",
      "1148 ('apparatus', 'NOUN')\n",
      "1149 ('of', 'ADP')\n",
      "1150 ('government', 'NOUN')\n",
      "1151 ('was', 'VERB')\n",
      "1152 ('divided', 'VERB')\n",
      "1153 ('.', '')\n",
      "1154 ('The', 'DET')\n",
      "1155 ('Ministry', 'NOUN')\n",
      "1156 ('of', 'ADP')\n",
      "1157 ('Truth', 'NOUN')\n",
      "1158 (',', '')\n",
      "1159 ('which', 'PRON')\n",
      "1160 ('concerned', 'VERB')\n",
      "1161 ('itself', 'PRON')\n",
      "1162 ('with', 'ADP')\n",
      "1163 ('news', 'NOUN')\n",
      "1164 (',', '')\n",
      "1165 ('entertainment', 'NOUN')\n",
      "1166 (',', '')\n",
      "1167 ('education', 'NOUN')\n",
      "1168 (',', '')\n",
      "1169 ('and', 'CONJ')\n",
      "1170 ('the', 'DET')\n",
      "1171 ('fine', 'ADJ')\n",
      "1172 ('arts', 'NOUN')\n",
      "1173 ('.', '')\n",
      "1174 ('The', 'DET')\n",
      "1175 ('Ministry', 'NOUN')\n",
      "1176 ('of', 'ADP')\n",
      "1177 ('Peace', 'NOUN')\n",
      "1178 (',', '')\n",
      "1179 ('which', 'PRON')\n",
      "1180 ('concerned', 'VERB')\n",
      "1181 ('itself', 'PRON')\n",
      "1182 ('with', 'ADP')\n",
      "1183 ('war', 'NOUN')\n",
      "1184 ('.', '')\n",
      "1185 ('The', 'DET')\n",
      "1186 ('Ministry', 'NOUN')\n",
      "1187 ('of', 'ADP')\n",
      "1188 ('Love', 'NOUN')\n",
      "1189 (',', '')\n",
      "1190 ('which', 'PRON')\n",
      "1191 ('maintained', 'VERB')\n",
      "1192 ('law', 'NOUN')\n",
      "1193 ('and', 'CONJ')\n",
      "1194 ('order', 'NOUN')\n",
      "1195 ('.', '')\n",
      "1196 ('And', 'CONJ')\n",
      "1197 ('the', 'DET')\n",
      "1198 ('Ministry', 'NOUN')\n",
      "1199 ('of', 'ADP')\n",
      "1200 ('Plenty', 'NOUN')\n",
      "1201 (',', '')\n",
      "1202 ('which', 'PRON')\n",
      "1203 ('was', 'VERB')\n",
      "1204 ('responsible', 'ADJ')\n",
      "1205 ('for', 'ADP')\n",
      "1206 ('economic', 'ADJ')\n",
      "1207 ('affairs', 'NOUN')\n",
      "1208 ('.', '')\n",
      "1209 ('Their', 'DET')\n",
      "1210 ('names', 'NOUN')\n",
      "1211 (',', '')\n",
      "1212 ('in', 'ADP')\n",
      "1213 ('Newspeak', 'NOUN')\n",
      "1214 (':', '')\n",
      "1215 ('Minitrue', 'NOUN')\n",
      "1216 (',', '')\n",
      "1217 ('Minipax', 'NOUN')\n",
      "1218 (',', '')\n",
      "1219 ('Miniluv', 'NOUN')\n",
      "1220 (',', '')\n",
      "1221 ('and', 'CONJ')\n",
      "1222 ('Miniplenty', 'NOUN')\n",
      "1223 ('.', '')\n",
      "1224 ('The', 'DET')\n",
      "1225 ('Ministry', 'NOUN')\n",
      "1226 ('of', 'ADP')\n",
      "1227 ('Love', 'NOUN')\n",
      "1228 ('was', 'VERB')\n",
      "1229 ('the', 'DET')\n",
      "1230 ('really', 'ADV')\n",
      "1231 ('frightening', 'ADJ')\n",
      "1232 ('one', 'PRON')\n",
      "1233 ('.', '')\n",
      "1234 ('There', 'PRON')\n",
      "1235 ('were', 'VERB')\n",
      "1236 ('no', 'DET')\n",
      "1237 ('windows', 'NOUN')\n",
      "1238 ('in', 'ADP')\n",
      "1239 ('it', 'PRON')\n",
      "1240 ('at', 'ADP')\n",
      "1241 ('all', 'ADV')\n",
      "1242 ('.', '')\n",
      "1243 ('Winston', 'NOUN')\n",
      "1244 ('had', 'VERB')\n",
      "1245 ('never', 'ADV')\n",
      "1246 ('been', 'VERB')\n",
      "1247 ('inside', 'ADP')\n",
      "1248 ('the', 'DET')\n",
      "1249 ('Ministry', 'NOUN')\n",
      "1250 ('of', 'ADP')\n",
      "1251 ('Love', 'NOUN')\n",
      "1252 (',', '')\n",
      "1253 ('nor', 'CONJ')\n",
      "1254 ('within', 'ADP')\n",
      "1255 ('half', 'DET')\n",
      "1256 ('a', 'DET')\n",
      "1257 ('kilometre', 'NOUN')\n",
      "1258 ('of', 'ADP')\n",
      "1259 ('it', 'PRON')\n",
      "1260 ('.', '')\n",
      "1261 ('It', 'PRON')\n",
      "1262 ('was', 'VERB')\n",
      "1263 ('a', 'DET')\n",
      "1264 ('place', 'NOUN')\n",
      "1265 ('impossible', 'ADJ')\n",
      "1266 ('to', 'ADP')\n",
      "1267 ('enter', 'VERB')\n",
      "1268 ('except', 'CONJ')\n",
      "1269 ('on', 'ADP')\n",
      "1270 ('official', 'ADJ')\n",
      "1271 ('business', 'NOUN')\n",
      "1272 (',', '')\n",
      "1273 ('and', 'CONJ')\n",
      "1274 ('then', 'ADV')\n",
      "1275 ('only', 'ADV')\n",
      "1276 ('by', 'ADP')\n",
      "1277 ('penetrating', 'VERB')\n",
      "1278 ('through', 'ADP')\n",
      "1279 ('a', 'DET')\n",
      "1280 ('maze', 'NOUN')\n",
      "1281 ('of', 'ADP')\n",
      "1282 ('barbed-wire', 'NOUN')\n",
      "1283 ('entanglements', 'NOUN')\n",
      "1284 (',', '')\n",
      "1285 ('steel', 'NOUN')\n",
      "1286 ('doors', 'NOUN')\n",
      "1287 (',', '')\n",
      "1288 ('and', 'CONJ')\n",
      "1289 ('hidden', 'VERB')\n",
      "1290 ('machine-gun', 'NOUN')\n",
      "1291 ('nests', 'NOUN')\n",
      "1292 ('.', '')\n",
      "1293 ('Even', 'ADV')\n",
      "1294 ('the', 'DET')\n",
      "1295 ('streets', 'NOUN')\n",
      "1296 ('leading', 'VERB')\n",
      "1297 ('up', 'ADP')\n",
      "1298 ('to', 'ADP')\n",
      "1299 ('its', 'DET')\n",
      "1300 ('outer', 'ADJ')\n",
      "1301 ('barriers', 'NOUN')\n",
      "1302 ('were', 'VERB')\n",
      "1303 ('roamed', 'VERB')\n",
      "1304 ('by', 'ADP')\n",
      "1305 ('gorilla-faced', 'ADJ')\n",
      "1306 ('guards', 'NOUN')\n",
      "1307 ('in', 'ADP')\n",
      "1308 ('black', 'ADJ')\n",
      "1309 ('uniforms', 'NOUN')\n",
      "1310 (',', '')\n",
      "1311 ('armed', 'VERB')\n",
      "1312 ('with', 'ADP')\n",
      "1313 ('jointed', 'ADJ')\n",
      "1314 ('truncheons', 'NOUN')\n",
      "1315 ('.', '')\n",
      "1316 ('Winston', 'NOUN')\n",
      "1317 ('turned', 'VERB')\n",
      "1318 ('round', 'ADV')\n",
      "1319 ('abruptly', 'ADV')\n",
      "1320 ('.', '')\n",
      "1321 ('He', 'PRON')\n",
      "1322 ('had', 'VERB')\n",
      "1323 ('set', 'VERB')\n",
      "1324 ('his', 'DET')\n",
      "1325 ('features', 'NOUN')\n",
      "1326 ('into', 'ADP')\n",
      "1327 ('the', 'DET')\n",
      "1328 ('expression', 'NOUN')\n",
      "1329 ('of', 'ADP')\n",
      "1330 ('quiet', 'ADJ')\n",
      "1331 ('optimism', 'NOUN')\n",
      "1332 ('which', 'PRON')\n",
      "1333 ('it', 'PRON')\n",
      "1334 ('was', 'VERB')\n",
      "1335 ('advisable', 'ADJ')\n",
      "1336 ('to', 'ADP')\n",
      "1337 ('wear', 'VERB')\n",
      "1338 ('when', 'CONJ')\n",
      "1339 ('facing', 'VERB')\n",
      "1340 ('the', 'DET')\n",
      "1341 ('telescreen', 'NOUN')\n",
      "1342 ('.', '')\n",
      "1343 ('He', 'PRON')\n",
      "1344 ('crossed', 'VERB')\n",
      "1345 ('the', 'DET')\n",
      "1346 ('room', 'NOUN')\n",
      "1347 ('into', 'ADP')\n",
      "1348 ('the', 'DET')\n",
      "1349 ('tiny', 'ADJ')\n",
      "1350 ('kitchen', 'NOUN')\n",
      "1351 ('.', '')\n",
      "1352 ('By', 'ADP')\n",
      "1353 ('leaving', 'VERB')\n",
      "1354 ('the', 'DET')\n",
      "1355 ('Ministry', 'NOUN')\n",
      "1356 ('at', 'ADP')\n",
      "1357 ('this', 'DET')\n",
      "1358 ('time', 'NOUN')\n",
      "1359 ('of', 'ADP')\n",
      "1360 ('day', 'NOUN')\n",
      "1361 ('he', 'PRON')\n",
      "1362 ('had', 'VERB')\n",
      "1363 ('sacrificed', 'VERB')\n",
      "1364 ('his', 'DET')\n",
      "1365 ('lunch', 'NOUN')\n",
      "1366 ('in', 'ADP')\n",
      "1367 ('the', 'DET')\n",
      "1368 ('canteen', 'NOUN')\n",
      "1369 (',', '')\n",
      "1370 ('and', 'CONJ')\n",
      "1371 ('he', 'PRON')\n",
      "1372 ('was', 'VERB')\n",
      "1373 ('aware', 'ADJ')\n",
      "1374 ('that', 'CONJ')\n",
      "1375 ('there', 'PRON')\n",
      "1376 ('was', 'VERB')\n",
      "1377 ('no', 'DET')\n",
      "1378 ('food', 'NOUN')\n",
      "1379 ('in', 'ADP')\n",
      "1380 ('the', 'DET')\n",
      "1381 ('kitchen', 'NOUN')\n",
      "1382 ('except', 'ADP')\n",
      "1383 ('a', 'DET')\n",
      "1384 ('hunk', 'NOUN')\n",
      "1385 ('of', 'ADP')\n",
      "1386 ('dark-coloured', 'ADJ')\n",
      "1387 ('bread', 'NOUN')\n",
      "1388 ('which', 'PRON')\n",
      "1389 ('had', 'VERB')\n",
      "1390 ('got', 'VERB')\n",
      "1391 ('to', 'ADP')\n",
      "1392 ('be', 'VERB')\n",
      "1393 ('saved', 'VERB')\n",
      "1394 ('for', 'ADP')\n",
      "1395 ('tomorrow', 'ADV')\n",
      "1396 (\"'s\", 'ADP')\n",
      "1397 ('breakfast', 'NOUN')\n",
      "1398 ('.', '')\n",
      "1399 ('He', 'PRON')\n",
      "1400 ('took', 'VERB')\n",
      "1401 ('down', 'ADV')\n",
      "1402 ('from', 'ADP')\n",
      "1403 ('the', 'DET')\n",
      "1404 ('shelf', 'NOUN')\n",
      "1405 ('a', 'DET')\n",
      "1406 ('bottle', 'NOUN')\n",
      "1407 ('of', 'ADP')\n",
      "1408 ('colourless', 'ADJ')\n",
      "1409 ('liquid', 'NOUN')\n",
      "1410 ('with', 'ADP')\n",
      "1411 ('a', 'DET')\n",
      "1412 ('plain', 'ADJ')\n",
      "1413 ('white', 'ADJ')\n",
      "1414 ('label', 'NOUN')\n",
      "1415 ('marked', 'VERB')\n",
      "1416 ('Victory', 'NOUN')\n",
      "1417 ('Gin', 'NOUN')\n",
      "1418 ('.', '')\n",
      "1419 ('It', 'PRON')\n",
      "1420 ('gave', 'VERB')\n",
      "1421 ('off', 'ADV')\n",
      "1422 ('a', 'DET')\n",
      "1423 ('sickly', 'ADJ')\n",
      "1424 (',', '')\n",
      "1425 ('oily', 'ADJ')\n",
      "1426 ('smell', 'NOUN')\n",
      "1427 (',', '')\n",
      "1428 ('as', 'CONJ')\n",
      "1429 ('of', 'ADP')\n",
      "1430 ('Chinese', 'ADJ')\n",
      "1431 ('rice', 'NOUN')\n",
      "1432 ('spirit', 'NOUN')\n",
      "1433 ('.', '')\n",
      "1434 ('Winston', 'NOUN')\n",
      "1435 ('poured', 'VERB')\n",
      "1436 ('out', 'ADP')\n",
      "1437 ('nearly', 'ADV')\n",
      "1438 ('a', 'DET')\n",
      "1439 ('teacupful', 'NOUN')\n",
      "1440 (',', '')\n",
      "1441 ('nerved', 'VERB')\n",
      "1442 ('himself', 'PRON')\n",
      "1443 ('for', 'ADP')\n",
      "1444 ('a', 'DET')\n",
      "1445 ('shock', 'NOUN')\n",
      "1446 (',', '')\n",
      "1447 ('and', 'CONJ')\n",
      "1448 ('gulped', 'VERB')\n",
      "1449 ('it', 'PRON')\n",
      "1450 ('down', 'ADV')\n",
      "1451 ('like', 'ADP')\n",
      "1452 ('a', 'DET')\n",
      "1453 ('dose', 'NOUN')\n",
      "1454 ('of', 'ADP')\n",
      "1455 ('medicine', 'NOUN')\n",
      "1456 ('.', '')\n",
      "1457 ('Instantly', 'ADV')\n",
      "1458 ('his', 'DET')\n",
      "1459 ('face', 'NOUN')\n",
      "1460 ('turned', 'VERB')\n",
      "1461 ('scarlet', 'ADJ')\n",
      "1462 ('and', 'CONJ')\n",
      "1463 ('the', 'DET')\n",
      "1464 ('water', 'NOUN')\n",
      "1465 ('ran', 'VERB')\n",
      "1466 ('out', 'ADP')\n",
      "1467 ('of', 'ADP')\n",
      "1468 ('his', 'DET')\n",
      "1469 ('eyes', 'NOUN')\n",
      "1470 ('.', '')\n",
      "1471 ('The', 'DET')\n",
      "1472 ('stuff', 'NOUN')\n",
      "1473 ('was', 'VERB')\n",
      "1474 ('like', 'ADP')\n",
      "1475 ('nitric', 'ADJ')\n",
      "1476 ('acid', 'NOUN')\n",
      "1477 (',', '')\n",
      "1478 ('and', 'CONJ')\n",
      "1479 ('moreover', 'ADV')\n",
      "1480 (',', '')\n",
      "1481 ('in', 'ADP')\n",
      "1482 ('swallowing', 'VERB')\n",
      "1483 ('it', 'PRON')\n",
      "1484 ('one', 'PRON')\n",
      "1485 ('had', 'VERB')\n",
      "1486 ('the', 'DET')\n",
      "1487 ('sensation', 'NOUN')\n",
      "1488 ('of', 'ADP')\n",
      "1489 ('being', 'VERB')\n",
      "1490 ('hit', 'VERB')\n",
      "1491 ('on', 'ADP')\n",
      "1492 ('the', 'DET')\n",
      "1493 ('back', 'NOUN')\n",
      "1494 ('of', 'ADP')\n",
      "1495 ('the', 'DET')\n",
      "1496 ('head', 'NOUN')\n",
      "1497 ('with', 'ADP')\n",
      "1498 ('a', 'DET')\n",
      "1499 ('rubber', 'NOUN')\n",
      "1500 ('club', 'NOUN')\n",
      "1501 ('.', '')\n",
      "1502 ('The', 'DET')\n",
      "1503 ('next', 'ADJ')\n",
      "1504 ('moment', 'NOUN')\n",
      "1505 (',', '')\n",
      "1506 ('however', 'ADV')\n",
      "1507 (',', '')\n",
      "1508 ('the', 'DET')\n",
      "1509 ('burning', 'NOUN')\n",
      "1510 ('in', 'ADP')\n",
      "1511 ('his', 'DET')\n",
      "1512 ('belly', 'NOUN')\n",
      "1513 ('died', 'VERB')\n",
      "1514 ('down', 'ADV')\n",
      "1515 ('and', 'CONJ')\n",
      "1516 ('the', 'DET')\n",
      "1517 ('world', 'NOUN')\n",
      "1518 ('began', 'VERB')\n",
      "1519 ('to', 'ADP')\n",
      "1520 ('look', 'VERB')\n",
      "1521 ('more', 'ADV')\n",
      "1522 ('cheerful', 'ADJ')\n",
      "1523 ('.', '')\n",
      "1524 ('He', 'PRON')\n",
      "1525 ('took', 'VERB')\n",
      "1526 ('a', 'DET')\n",
      "1527 ('cigarette', 'NOUN')\n",
      "1528 ('from', 'ADP')\n",
      "1529 ('a', 'DET')\n",
      "1530 ('crumpled', 'ADJ')\n",
      "1531 ('packet', 'NOUN')\n",
      "1532 ('marked', 'VERB')\n",
      "1533 ('Victory', 'NOUN')\n",
      "1534 ('Cigarettes', 'NOUN')\n",
      "1535 ('and', 'CONJ')\n",
      "1536 ('incautiously', 'ADV')\n",
      "1537 ('held', 'VERB')\n",
      "1538 ('it', 'PRON')\n",
      "1539 ('upright', 'ADV')\n",
      "1540 (',', '')\n",
      "1541 ('whereupon', 'ADV')\n",
      "1542 ('the', 'DET')\n",
      "1543 ('tobacco', 'NOUN')\n",
      "1544 ('fell', 'VERB')\n",
      "1545 ('out', 'ADP')\n",
      "1546 ('on', 'ADP')\n",
      "1547 ('to', 'ADP')\n",
      "1548 ('the', 'DET')\n",
      "1549 ('floor', 'NOUN')\n",
      "1550 ('.', '')\n",
      "1551 ('With', 'ADP')\n",
      "1552 ('the', 'DET')\n",
      "1553 ('next', 'NOUN')\n",
      "1554 ('he', 'PRON')\n",
      "1555 ('was', 'VERB')\n",
      "1556 ('more', 'ADV')\n",
      "1557 ('successful', 'ADJ')\n",
      "1558 ('.', '')\n",
      "1559 ('He', 'PRON')\n",
      "1560 ('went', 'VERB')\n",
      "1561 ('back', 'ADV')\n",
      "1562 ('to', 'ADP')\n",
      "1563 ('the', 'DET')\n",
      "1564 ('living-room', 'NOUN')\n",
      "1565 ('and', 'CONJ')\n",
      "1566 ('sat', 'VERB')\n",
      "1567 ('down', 'ADV')\n",
      "1568 ('at', 'ADP')\n",
      "1569 ('a', 'DET')\n",
      "1570 ('small', 'ADJ')\n",
      "1571 ('table', 'NOUN')\n",
      "1572 ('that', 'PRON')\n",
      "1573 ('stood', 'VERB')\n",
      "1574 ('to', 'ADP')\n",
      "1575 ('the', 'DET')\n",
      "1576 ('left', 'NOUN')\n",
      "1577 ('of', 'ADP')\n",
      "1578 ('the', 'DET')\n",
      "1579 ('telescreen', 'NOUN')\n",
      "1580 ('.', '')\n",
      "1581 ('From', 'ADP')\n",
      "1582 ('the', 'DET')\n",
      "1583 ('table', 'NOUN')\n",
      "1584 ('drawer', 'NOUN')\n",
      "1585 ('he', 'PRON')\n",
      "1586 ('took', 'VERB')\n",
      "1587 ('out', 'ADP')\n",
      "1588 ('a', 'DET')\n",
      "1589 ('penholder', 'NOUN')\n",
      "1590 (',', '')\n",
      "1591 ('a', 'DET')\n",
      "1592 ('bottle', 'NOUN')\n",
      "1593 ('of', 'ADP')\n",
      "1594 ('ink', 'NOUN')\n",
      "1595 (',', '')\n",
      "1596 ('and', 'CONJ')\n",
      "1597 ('a', 'DET')\n",
      "1598 ('thick', 'ADJ')\n",
      "1599 (',', '')\n",
      "1600 ('quarto-sized', 'ADJ')\n",
      "1601 ('blank', 'ADJ')\n",
      "1602 ('book', 'NOUN')\n",
      "1603 ('with', 'ADP')\n",
      "1604 ('a', 'DET')\n",
      "1605 ('red', 'ADJ')\n",
      "1606 ('back', 'NOUN')\n",
      "1607 ('and', 'CONJ')\n",
      "1608 ('a', 'DET')\n",
      "1609 ('marbled', 'ADJ')\n",
      "1610 ('cover', 'NOUN')\n",
      "1611 ('.', '')\n",
      "1612 ('For', 'ADP')\n",
      "1613 ('some', 'DET')\n",
      "1614 ('reason', 'NOUN')\n",
      "1615 ('the', 'DET')\n",
      "1616 ('telescreen', 'NOUN')\n",
      "1617 ('in', 'ADP')\n",
      "1618 ('the', 'DET')\n",
      "1619 ('living-room', 'NOUN')\n",
      "1620 ('was', 'VERB')\n",
      "1621 ('in', 'ADP')\n",
      "1622 ('an', 'DET')\n",
      "1623 ('unusual', 'ADJ')\n",
      "1624 ('position', 'NOUN')\n",
      "1625 ('.', '')\n",
      "1626 ('Instead', 'ADV')\n",
      "1627 ('of', 'ADP')\n",
      "1628 ('being', 'VERB')\n",
      "1629 ('placed', 'VERB')\n",
      "1630 (',', '')\n",
      "1631 ('as', 'CONJ')\n",
      "1632 ('was', 'VERB')\n",
      "1633 ('normal', 'ADJ')\n",
      "1634 (',', '')\n",
      "1635 ('in', 'ADP')\n",
      "1636 ('the', 'DET')\n",
      "1637 ('end', 'NOUN')\n",
      "1638 ('wall', 'NOUN')\n",
      "1639 (',', '')\n",
      "1640 ('where', 'CONJ')\n",
      "1641 ('it', 'PRON')\n",
      "1642 ('could', 'VERB')\n",
      "1643 ('command', 'VERB')\n",
      "1644 ('the', 'DET')\n",
      "1645 ('whole', 'ADJ')\n",
      "1646 ('room', 'NOUN')\n",
      "1647 (',', '')\n",
      "1648 ('it', 'PRON')\n",
      "1649 ('was', 'VERB')\n",
      "1650 ('in', 'ADP')\n",
      "1651 ('the', 'DET')\n",
      "1652 ('longer', 'ADJ')\n",
      "1653 ('wall', 'NOUN')\n",
      "1654 (',', '')\n",
      "1655 ('opposite', 'ADP')\n",
      "1656 ('the', 'DET')\n",
      "1657 ('window', 'NOUN')\n",
      "1658 ('.', '')\n",
      "1659 ('To', 'ADP')\n",
      "1660 ('one', 'NUM')\n",
      "1661 ('side', 'NOUN')\n",
      "1662 ('of', 'ADP')\n",
      "1663 ('it', 'PRON')\n",
      "1664 ('there', 'PRON')\n",
      "1665 ('was', 'VERB')\n",
      "1666 ('a', 'DET')\n",
      "1667 ('shallow', 'ADJ')\n",
      "1668 ('alcove', 'NOUN')\n",
      "1669 ('in', 'ADP')\n",
      "1670 ('which', 'PRON')\n",
      "1671 ('Winston', 'NOUN')\n",
      "1672 ('was', 'VERB')\n",
      "1673 ('now', 'ADV')\n",
      "1674 ('sitting', 'VERB')\n",
      "1675 (',', '')\n",
      "1676 ('and', 'CONJ')\n",
      "1677 ('which', 'PRON')\n",
      "1678 (',', '')\n",
      "1679 ('when', 'CONJ')\n",
      "1680 ('the', 'DET')\n",
      "1681 ('flats', 'NOUN')\n",
      "1682 ('were', 'VERB')\n",
      "1683 ('built', 'VERB')\n",
      "1684 (',', '')\n",
      "1685 ('had', 'VERB')\n",
      "1686 ('probably', 'ADV')\n",
      "1687 ('been', 'VERB')\n",
      "1688 ('intended', 'VERB')\n",
      "1689 ('to', 'ADP')\n",
      "1690 ('hold', 'VERB')\n",
      "1691 ('bookshelves', 'NOUN')\n",
      "1692 ('.', '')\n",
      "1693 ('By', 'ADP')\n",
      "1694 ('sitting', 'VERB')\n",
      "1695 ('in', 'ADP')\n",
      "1696 ('the', 'DET')\n",
      "1697 ('alcove', 'NOUN')\n",
      "1698 (',', '')\n",
      "1699 ('and', 'CONJ')\n",
      "1700 ('keeping', 'VERB')\n",
      "1701 ('well', 'ADV')\n",
      "1702 ('back', 'ADV')\n",
      "1703 (',', '')\n",
      "1704 ('Winston', 'NOUN')\n",
      "1705 ('was', 'VERB')\n",
      "1706 ('able', 'ADJ')\n",
      "1707 ('to', 'ADP')\n",
      "1708 ('remain', 'VERB')\n",
      "1709 ('outside', 'ADP')\n",
      "1710 ('the', 'DET')\n",
      "1711 ('range', 'NOUN')\n",
      "1712 ('of', 'ADP')\n",
      "1713 ('the', 'DET')\n",
      "1714 ('telescreen', 'NOUN')\n",
      "1715 (',', '')\n",
      "1716 ('so', 'ADV')\n",
      "1717 ('far', 'ADV')\n",
      "1718 ('as', 'CONJ')\n",
      "1719 ('sight', 'NOUN')\n",
      "1720 ('went', 'VERB')\n",
      "1721 ('.', '')\n",
      "1722 ('He', 'PRON')\n",
      "1723 ('could', 'VERB')\n",
      "1724 ('be', 'VERB')\n",
      "1725 ('heard', 'VERB')\n",
      "1726 (',', '')\n",
      "1727 ('of', 'ADP')\n",
      "1728 ('course', 'NOUN')\n",
      "1729 (',', '')\n",
      "1730 ('but', 'CONJ')\n",
      "1731 ('so', 'ADV')\n",
      "1732 ('long', 'ADV')\n",
      "1733 ('as', 'CONJ')\n",
      "1734 ('he', 'PRON')\n",
      "1735 ('stayed', 'VERB')\n",
      "1736 ('in', 'ADP')\n",
      "1737 ('his', 'DET')\n",
      "1738 ('present', 'ADJ')\n",
      "1739 ('position', 'NOUN')\n",
      "1740 ('he', 'PRON')\n",
      "1741 ('could', 'VERB')\n",
      "1742 ('not', 'ADV')\n",
      "1743 ('be', 'VERB')\n",
      "1744 ('seen', 'VERB')\n",
      "1745 ('.', '')\n",
      "1746 ('It', 'PRON')\n",
      "1747 ('was', 'VERB')\n",
      "1748 ('partly', 'ADV')\n",
      "1749 ('the', 'DET')\n",
      "1750 ('unusual', 'ADJ')\n",
      "1751 ('geography', 'NOUN')\n",
      "1752 ('of', 'ADP')\n",
      "1753 ('the', 'DET')\n",
      "1754 ('room', 'NOUN')\n",
      "1755 ('that', 'PRON')\n",
      "1756 ('had', 'VERB')\n",
      "1757 ('suggested', 'VERB')\n",
      "1758 ('to', 'ADP')\n",
      "1759 ('him', 'PRON')\n",
      "1760 ('the', 'DET')\n",
      "1761 ('thing', 'NOUN')\n",
      "1762 ('that', 'PRON')\n",
      "1763 ('he', 'PRON')\n",
      "1764 ('was', 'VERB')\n",
      "1765 ('now', 'ADV')\n",
      "1766 ('about', 'ADV')\n",
      "1767 ('to', 'ADP')\n",
      "1768 ('do', 'VERB')\n",
      "1769 ('.', '')\n",
      "1770 ('But', 'CONJ')\n",
      "1771 ('it', 'PRON')\n",
      "1772 ('had', 'VERB')\n",
      "1773 ('also', 'ADV')\n",
      "1774 ('been', 'VERB')\n",
      "1775 ('suggested', 'VERB')\n",
      "1776 ('by', 'ADP')\n",
      "1777 ('the', 'DET')\n",
      "1778 ('book', 'NOUN')\n",
      "1779 ('that', 'PRON')\n",
      "1780 ('he', 'PRON')\n",
      "1781 ('had', 'VERB')\n",
      "1782 ('just', 'ADV')\n",
      "1783 ('taken', 'VERB')\n",
      "1784 ('out', 'ADP')\n",
      "1785 ('of', 'ADP')\n",
      "1786 ('the', 'DET')\n",
      "1787 ('drawer', 'NOUN')\n",
      "1788 ('.', '')\n",
      "1789 ('It', 'PRON')\n",
      "1790 ('was', 'VERB')\n",
      "1791 ('a', 'DET')\n",
      "1792 ('peculiarly', 'ADV')\n",
      "1793 ('beautiful', 'ADJ')\n",
      "1794 ('book', 'NOUN')\n",
      "1795 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796 ('Its', 'DET')\n",
      "1797 ('smooth', 'ADJ')\n",
      "1798 ('creamy', 'ADJ')\n",
      "1799 ('paper', 'NOUN')\n",
      "1800 (',', '')\n",
      "1801 ('a', 'DET')\n",
      "1802 ('little', 'ADV')\n",
      "1803 ('yellowed', 'VERB')\n",
      "1804 ('by', 'ADP')\n",
      "1805 ('age', 'NOUN')\n",
      "1806 (',', '')\n",
      "1807 ('was', 'VERB')\n",
      "1808 ('of', 'ADP')\n",
      "1809 ('a', 'DET')\n",
      "1810 ('kind', 'NOUN')\n",
      "1811 ('that', 'PRON')\n",
      "1812 ('had', 'VERB')\n",
      "1813 ('not', 'ADV')\n",
      "1814 ('been', 'VERB')\n",
      "1815 ('manufactured', 'VERB')\n",
      "1816 ('for', 'ADP')\n",
      "1817 ('at', 'ADP')\n",
      "1818 ('least', 'ADJ')\n",
      "1819 ('forty', 'NUM')\n",
      "1820 ('years', 'NOUN')\n",
      "1821 ('past', 'ADV')\n",
      "1822 ('.', '')\n",
      "1823 ('He', 'PRON')\n",
      "1824 ('could', 'VERB')\n",
      "1825 ('guess', 'VERB')\n",
      "1826 (',', '')\n",
      "1827 ('however', 'ADV')\n",
      "1828 (',', '')\n",
      "1829 ('that', 'CONJ')\n",
      "1830 ('the', 'DET')\n",
      "1831 ('book', 'NOUN')\n",
      "1832 ('was', 'VERB')\n",
      "1833 ('much', 'ADV')\n",
      "1834 ('older', 'ADJ')\n",
      "1835 ('than', 'ADP')\n",
      "1836 ('that', 'PRON')\n",
      "1837 ('.', '')\n",
      "1838 ('He', 'PRON')\n",
      "1839 ('had', 'VERB')\n",
      "1840 ('seen', 'VERB')\n",
      "1841 ('it', 'PRON')\n",
      "1842 ('lying', 'VERB')\n",
      "1843 ('in', 'ADP')\n",
      "1844 ('the', 'DET')\n",
      "1845 ('window', 'NOUN')\n",
      "1846 ('of', 'ADP')\n",
      "1847 ('a', 'DET')\n",
      "1848 ('frowsy', 'ADJ')\n",
      "1849 ('little', 'ADJ')\n",
      "1850 ('junk-shop', 'NOUN')\n",
      "1851 ('in', 'ADP')\n",
      "1852 ('a', 'DET')\n",
      "1853 ('slummy', 'ADJ')\n",
      "1854 ('quarter', 'NOUN')\n",
      "1855 ('of', 'ADP')\n",
      "1856 ('the', 'DET')\n",
      "1857 ('town', 'NOUN')\n",
      "1858 ('(', '')\n",
      "1859 ('just', 'ADV')\n",
      "1860 ('what', 'DET')\n",
      "1861 ('quarter', 'NOUN')\n",
      "1862 ('he', 'PRON')\n",
      "1863 ('did', 'VERB')\n",
      "1864 ('not', 'ADV')\n",
      "1865 ('now', 'ADV')\n",
      "1866 ('remember', 'VERB')\n",
      "1867 (')', '')\n",
      "1868 ('and', 'CONJ')\n",
      "1869 ('had', 'VERB')\n",
      "1870 ('been', 'VERB')\n",
      "1871 ('stricken', 'VERB')\n",
      "1872 ('immediately', 'ADV')\n",
      "1873 ('by', 'ADP')\n",
      "1874 ('an', 'DET')\n",
      "1875 ('overwhelming', 'ADJ')\n",
      "1876 ('desire', 'NOUN')\n",
      "1877 ('to', 'ADP')\n",
      "1878 ('possess', 'VERB')\n",
      "1879 ('it', 'PRON')\n",
      "1880 ('.', '')\n",
      "1881 ('Party', 'NOUN')\n",
      "1882 ('members', 'NOUN')\n",
      "1883 ('were', 'VERB')\n",
      "1884 ('supposed', 'VERB')\n",
      "1885 ('not', 'ADV')\n",
      "1886 ('to', 'ADP')\n",
      "1887 ('go', 'VERB')\n",
      "1888 ('into', 'ADP')\n",
      "1889 ('ordinary', 'ADJ')\n",
      "1890 ('shops', 'NOUN')\n",
      "1891 ('(', '')\n",
      "1892 ('dealing', 'VERB')\n",
      "1893 ('on', 'ADP')\n",
      "1894 ('the', 'DET')\n",
      "1895 ('free', 'ADJ')\n",
      "1896 ('market', 'NOUN')\n",
      "1897 (',', '')\n",
      "1898 ('it', 'PRON')\n",
      "1899 ('was', 'VERB')\n",
      "1900 ('called', 'VERB')\n",
      "1901 (')', '')\n",
      "1902 (',', '')\n",
      "1903 ('but', 'CONJ')\n",
      "1904 ('the', 'DET')\n",
      "1905 ('rule', 'NOUN')\n",
      "1906 ('was', 'VERB')\n",
      "1907 ('not', 'ADV')\n",
      "1908 ('strictly', 'ADV')\n",
      "1909 ('kept', 'VERB')\n",
      "1910 (',', '')\n",
      "1911 ('because', 'CONJ')\n",
      "1912 ('there', 'PRON')\n",
      "1913 ('were', 'VERB')\n",
      "1914 ('various', 'ADJ')\n",
      "1915 ('things', 'NOUN')\n",
      "1916 (',', '')\n",
      "1917 ('such', 'ADJ')\n",
      "1918 ('as', 'CONJ')\n",
      "1919 ('shoelaces', 'NOUN')\n",
      "1920 ('and', 'CONJ')\n",
      "1921 ('razor', 'NOUN')\n",
      "1922 ('blades', 'NOUN')\n",
      "1923 (',', '')\n",
      "1924 ('which', 'PRON')\n",
      "1925 ('it', 'PRON')\n",
      "1926 ('was', 'VERB')\n",
      "1927 ('impossible', 'ADJ')\n",
      "1928 ('to', 'ADP')\n",
      "1929 ('get', 'VERB')\n",
      "1930 ('hold', 'NOUN')\n",
      "1931 ('of', 'ADP')\n",
      "1932 ('in', 'ADP')\n",
      "1933 ('any', 'DET')\n",
      "1934 ('other', 'ADJ')\n",
      "1935 ('way', 'NOUN')\n",
      "1936 ('.', '')\n",
      "1937 ('He', 'PRON')\n",
      "1938 ('had', 'VERB')\n",
      "1939 ('given', 'VERB')\n",
      "1940 ('a', 'DET')\n",
      "1941 ('quick', 'ADJ')\n",
      "1942 ('glance', 'NOUN')\n",
      "1943 ('up', 'ADP')\n",
      "1944 ('and', 'CONJ')\n",
      "1945 ('down', 'ADP')\n",
      "1946 ('the', 'DET')\n",
      "1947 ('street', 'NOUN')\n",
      "1948 ('and', 'CONJ')\n",
      "1949 ('then', 'ADV')\n",
      "1950 ('had', 'VERB')\n",
      "1951 ('slipped', 'VERB')\n",
      "1952 ('inside', 'ADV')\n",
      "1953 ('and', 'CONJ')\n",
      "1954 ('bought', 'VERB')\n",
      "1955 ('the', 'DET')\n",
      "1956 ('book', 'NOUN')\n",
      "1957 ('for', 'ADP')\n",
      "1958 ('two', 'NUM')\n",
      "1959 ('dollars', 'NOUN')\n",
      "1960 ('fifty', 'NUM')\n",
      "1961 ('.', '')\n",
      "1962 ('At', 'ADP')\n",
      "1963 ('the', 'DET')\n",
      "1964 ('time', 'NOUN')\n",
      "1965 ('he', 'PRON')\n",
      "1966 ('was', 'VERB')\n",
      "1967 ('not', 'ADV')\n",
      "1968 ('conscious', 'ADJ')\n",
      "1969 ('of', 'ADP')\n",
      "1970 ('wanting', 'VERB')\n",
      "1971 ('it', 'PRON')\n",
      "1972 ('for', 'ADP')\n",
      "1973 ('any', 'DET')\n",
      "1974 ('particular', 'ADJ')\n",
      "1975 ('purpose', 'NOUN')\n",
      "1976 ('.', '')\n",
      "1977 ('He', 'PRON')\n",
      "1978 ('had', 'VERB')\n",
      "1979 ('carried', 'VERB')\n",
      "1980 ('it', 'PRON')\n",
      "1981 ('guiltily', 'ADV')\n",
      "1982 ('home', 'ADV')\n",
      "1983 ('in', 'ADP')\n",
      "1984 ('his', 'DET')\n",
      "1985 ('briefcase', 'NOUN')\n",
      "1986 ('.', '')\n",
      "1987 ('Even', 'ADV')\n",
      "1988 ('with', 'ADP')\n",
      "1989 ('nothing', 'PRON')\n",
      "1990 ('written', 'VERB')\n",
      "1991 ('in', 'ADP')\n",
      "1992 ('it', 'PRON')\n",
      "1993 (',', '')\n",
      "1994 ('it', 'PRON')\n",
      "1995 ('was', 'VERB')\n",
      "1996 ('a', 'DET')\n",
      "1997 ('compromising', 'ADJ')\n",
      "1998 ('possession', 'NOUN')\n",
      "1999 ('.', '')\n",
      "2000 ('The', 'DET')\n",
      "2001 ('thing', 'NOUN')\n",
      "2002 ('that', 'PRON')\n",
      "2003 ('he', 'PRON')\n",
      "2004 ('was', 'VERB')\n",
      "2005 ('about', 'ADV')\n",
      "2006 ('to', 'ADP')\n",
      "2007 ('do', 'VERB')\n",
      "2008 ('was', 'VERB')\n",
      "2009 ('to', 'ADP')\n",
      "2010 ('open', 'VERB')\n",
      "2011 ('a', 'DET')\n",
      "2012 ('diary', 'NOUN')\n",
      "2013 ('.', '')\n",
      "2014 ('This', 'PRON')\n",
      "2015 ('was', 'VERB')\n",
      "2016 ('not', 'ADV')\n",
      "2017 ('illegal', 'ADJ')\n",
      "2018 ('(', '')\n",
      "2019 ('nothing', 'PRON')\n",
      "2020 ('was', 'VERB')\n",
      "2021 ('illegal', 'ADJ')\n",
      "2022 (',', '')\n",
      "2023 ('since', 'CONJ')\n",
      "2024 ('there', 'PRON')\n",
      "2025 ('were', 'VERB')\n",
      "2026 ('no', 'ADV')\n",
      "2027 ('longer', 'ADV')\n",
      "2028 ('any', 'DET')\n",
      "2029 ('laws', 'NOUN')\n",
      "2030 (')', '')\n",
      "2031 (',', '')\n",
      "2032 ('but', 'CONJ')\n",
      "2033 ('if', 'CONJ')\n",
      "2034 ('detected', 'VERB')\n",
      "2035 ('it', 'PRON')\n",
      "2036 ('was', 'VERB')\n",
      "2037 ('reasonably', 'ADV')\n",
      "2038 ('certain', 'ADJ')\n",
      "2039 ('that', 'CONJ')\n",
      "2040 ('it', 'PRON')\n",
      "2041 ('would', 'VERB')\n",
      "2042 ('be', 'VERB')\n",
      "2043 ('punished', 'VERB')\n",
      "2044 ('by', 'ADP')\n",
      "2045 ('death', 'NOUN')\n",
      "2046 (',', '')\n",
      "2047 ('or', 'CONJ')\n",
      "2048 ('at', 'ADP')\n",
      "2049 ('least', 'ADJ')\n",
      "2050 ('by', 'ADP')\n",
      "2051 ('twenty-five', 'NUM')\n",
      "2052 ('years', 'NOUN')\n",
      "2053 ('in', 'ADP')\n",
      "2054 ('a', 'DET')\n",
      "2055 ('forced', 'ADJ')\n",
      "2056 ('labour', 'NOUN')\n",
      "2057 ('camp', 'ADJ')\n",
      "2058 ('.', '')\n",
      "2059 ('Winston', 'NOUN')\n",
      "2060 ('fitted', 'VERB')\n",
      "2061 ('a', 'DET')\n",
      "2062 ('nib', 'NOUN')\n",
      "2063 ('into', 'ADP')\n",
      "2064 ('the', 'DET')\n",
      "2065 ('penholder', 'NOUN')\n",
      "2066 ('and', 'CONJ')\n",
      "2067 ('sucked', 'VERB')\n",
      "2068 ('it', 'PRON')\n",
      "2069 ('to', 'ADP')\n",
      "2070 ('get', 'VERB')\n",
      "2071 ('the', 'DET')\n",
      "2072 ('grease', 'NOUN')\n",
      "2073 ('off', 'ADV')\n",
      "2074 ('.', '')\n",
      "2075 ('The', 'DET')\n",
      "2076 ('pen', 'NOUN')\n",
      "2077 ('was', 'VERB')\n",
      "2078 ('an', 'DET')\n",
      "2079 ('archaic', 'ADJ')\n",
      "2080 ('instrument', 'NOUN')\n",
      "2081 (',', '')\n",
      "2082 ('seldom', 'ADV')\n",
      "2083 ('used', 'VERB')\n",
      "2084 ('even', 'ADV')\n",
      "2085 ('for', 'ADP')\n",
      "2086 ('signatures', 'NOUN')\n",
      "2087 (',', '')\n",
      "2088 ('and', 'CONJ')\n",
      "2089 ('he', 'PRON')\n",
      "2090 ('had', 'VERB')\n",
      "2091 ('procured', 'VERB')\n",
      "2092 ('one', 'PRON')\n",
      "2093 (',', '')\n",
      "2094 ('furtively', 'ADV')\n",
      "2095 ('and', 'CONJ')\n",
      "2096 ('with', 'ADP')\n",
      "2097 ('some', 'DET')\n",
      "2098 ('difficulty', 'NOUN')\n",
      "2099 (',', '')\n",
      "2100 ('simply', 'ADV')\n",
      "2101 ('because', 'CONJ')\n",
      "2102 ('of', 'ADP')\n",
      "2103 ('a', 'DET')\n",
      "2104 ('feeling', 'NOUN')\n",
      "2105 ('that', 'CONJ')\n",
      "2106 ('the', 'DET')\n",
      "2107 ('beautiful', 'ADJ')\n",
      "2108 ('creamy', 'ADJ')\n",
      "2109 ('paper', 'NOUN')\n",
      "2110 ('deserved', 'VERB')\n",
      "2111 ('to', 'ADP')\n",
      "2112 ('be', 'VERB')\n",
      "2113 ('written', 'VERB')\n",
      "2114 ('on', 'ADP')\n",
      "2115 ('with', 'ADP')\n",
      "2116 ('a', 'DET')\n",
      "2117 ('real', 'ADJ')\n",
      "2118 ('nib', 'NOUN')\n",
      "2119 ('instead', 'ADV')\n",
      "2120 ('of', 'ADP')\n",
      "2121 ('being', 'VERB')\n",
      "2122 ('scratched', 'VERB')\n",
      "2123 ('with', 'ADP')\n",
      "2124 ('an', 'DET')\n",
      "2125 ('ink-pencil', 'NOUN')\n",
      "2126 ('.', '')\n",
      "2127 ('Actually', 'ADV')\n",
      "2128 ('he', 'PRON')\n",
      "2129 ('was', 'VERB')\n",
      "2130 ('not', 'ADJ')\n",
      "2131 ('used', 'VERB')\n",
      "2132 ('to', 'ADP')\n",
      "2133 ('writing', 'VERB')\n",
      "2134 ('by', 'ADP')\n",
      "2135 ('hand', 'NOUN')\n",
      "2136 ('.', '')\n",
      "2137 ('Apart', 'ADV')\n",
      "2138 ('from', 'ADP')\n",
      "2139 ('very', 'ADV')\n",
      "2140 ('short', 'ADJ')\n",
      "2141 ('notes', 'NOUN')\n",
      "2142 (',', '')\n",
      "2143 ('it', 'PRON')\n",
      "2144 ('was', 'VERB')\n",
      "2145 ('usual', 'ADJ')\n",
      "2146 ('to', 'ADP')\n",
      "2147 ('dictate', 'VERB')\n",
      "2148 ('everything', 'PRON')\n",
      "2149 ('into', 'ADP')\n",
      "2150 ('the', 'DET')\n",
      "2151 ('speakwrite', 'NOUN')\n",
      "2152 ('which', 'PRON')\n",
      "2153 ('was', 'VERB')\n",
      "2154 ('of', 'ADP')\n",
      "2155 ('course', 'NOUN')\n",
      "2156 ('impossible', 'ADJ')\n",
      "2157 ('for', 'ADP')\n",
      "2158 ('his', 'DET')\n",
      "2159 ('present', 'ADJ')\n",
      "2160 ('purpose', 'NOUN')\n",
      "2161 ('.', '')\n",
      "2162 ('He', 'PRON')\n",
      "2163 ('dipped', 'VERB')\n",
      "2164 ('the', 'DET')\n",
      "2165 ('pen', 'NOUN')\n",
      "2166 ('into', 'ADP')\n",
      "2167 ('the', 'DET')\n",
      "2168 ('ink', 'NOUN')\n",
      "2169 ('and', 'CONJ')\n",
      "2170 ('then', 'ADV')\n",
      "2171 ('faltered', 'VERB')\n",
      "2172 ('for', 'ADP')\n",
      "2173 ('just', 'ADV')\n",
      "2174 ('a', 'DET')\n",
      "2175 ('second', 'NOUN')\n",
      "2176 ('.', '')\n",
      "2177 ('A', 'DET')\n",
      "2178 ('tremor', 'NOUN')\n",
      "2179 ('had', 'VERB')\n",
      "2180 ('gone', 'VERB')\n",
      "2181 ('through', 'ADP')\n",
      "2182 ('his', 'DET')\n",
      "2183 ('bowels', 'NOUN')\n",
      "2184 ('.', '')\n",
      "2185 ('To', 'ADP')\n",
      "2186 ('mark', 'VERB')\n",
      "2187 ('the', 'DET')\n",
      "2188 ('paper', 'NOUN')\n",
      "2189 ('was', 'VERB')\n",
      "2190 ('the', 'DET')\n",
      "2191 ('decisive', 'ADJ')\n",
      "2192 ('act', 'NOUN')\n",
      "2193 ('.', '')\n",
      "2194 ('In', 'ADP')\n",
      "2195 ('small', 'ADJ')\n",
      "2196 ('clumsy', 'ADJ')\n",
      "2197 ('letters', 'NOUN')\n",
      "2198 ('he', 'PRON')\n",
      "2199 ('wrote', 'VERB')\n",
      "2200 (':', '')\n",
      "2201 ('April', 'NOUN')\n",
      "2202 ('4th', 'NUM')\n",
      "2203 (',', '')\n",
      "2204 ('1984', 'NUM')\n",
      "2205 ('.', '')\n",
      "2206 ('He', 'PRON')\n",
      "2207 ('sat', 'VERB')\n",
      "2208 ('back', 'ADV')\n",
      "2209 ('.', '')\n",
      "2210 ('A', 'DET')\n",
      "2211 ('sense', 'NOUN')\n",
      "2212 ('of', 'ADP')\n",
      "2213 ('complete', 'ADJ')\n",
      "2214 ('helplessness', 'NOUN')\n",
      "2215 ('had', 'VERB')\n",
      "2216 ('descended', 'VERB')\n",
      "2217 ('upon', 'ADP')\n",
      "2218 ('him', 'PRON')\n",
      "2219 ('.', '')\n",
      "2220 ('To', 'ADP')\n",
      "2221 ('begin', 'VERB')\n",
      "2222 ('with', 'ADP')\n",
      "2223 (',', '')\n",
      "2224 ('he', 'PRON')\n",
      "2225 ('did', 'VERB')\n",
      "2226 ('not', 'ADV')\n",
      "2227 ('know', 'VERB')\n",
      "2228 ('with', 'ADP')\n",
      "2229 ('any', 'DET')\n",
      "2230 ('certainty', 'NOUN')\n",
      "2231 ('that', 'CONJ')\n",
      "2232 ('this', 'PRON')\n",
      "2233 ('was', 'VERB')\n",
      "2234 ('1984', 'NUM')\n",
      "2235 ('.', '')\n",
      "2236 ('It', 'PRON')\n",
      "2237 ('must', 'VERB')\n",
      "2238 ('be', 'VERB')\n",
      "2239 ('round', 'ADV')\n",
      "2240 ('about', 'ADV')\n",
      "2241 ('that', 'DET')\n",
      "2242 ('date', 'NOUN')\n",
      "2243 (',', '')\n",
      "2244 ('since', 'CONJ')\n",
      "2245 ('he', 'PRON')\n",
      "2246 ('was', 'VERB')\n",
      "2247 ('fairly', 'ADV')\n",
      "2248 ('sure', 'ADJ')\n",
      "2249 ('that', 'CONJ')\n",
      "2250 ('his', 'DET')\n",
      "2251 ('age', 'NOUN')\n",
      "2252 ('was', 'VERB')\n",
      "2253 ('thirty-nine', 'NUM')\n",
      "2254 (',', '')\n",
      "2255 ('and', 'CONJ')\n",
      "2256 ('he', 'PRON')\n",
      "2257 ('believed', 'VERB')\n",
      "2258 ('that', 'CONJ')\n",
      "2259 ('he', 'PRON')\n",
      "2260 ('had', 'VERB')\n",
      "2261 ('been', 'VERB')\n",
      "2262 ('born', 'ADJ')\n",
      "2263 ('in', 'ADP')\n",
      "2264 ('1944', 'NUM')\n",
      "2265 ('or', 'CONJ')\n",
      "2266 ('1945', 'NUM')\n",
      "2267 (';', '')\n",
      "2268 ('but', 'CONJ')\n",
      "2269 ('it', 'PRON')\n",
      "2270 ('was', 'VERB')\n",
      "2271 ('never', 'ADV')\n",
      "2272 ('possible', 'ADJ')\n",
      "2273 ('nowadays', 'ADV')\n",
      "2274 ('to', 'ADP')\n",
      "2275 ('pin', 'VERB')\n",
      "2276 ('down', 'ADV')\n",
      "2277 ('any', 'DET')\n",
      "2278 ('date', 'NOUN')\n",
      "2279 ('within', 'ADP')\n",
      "2280 ('a', 'DET')\n",
      "2281 ('year', 'NOUN')\n",
      "2282 ('or', 'CONJ')\n",
      "2283 ('two', 'NUM')\n",
      "2284 ('.', '')\n",
      "2285 ('For', 'ADP')\n",
      "2286 ('whom', 'PRON')\n",
      "2287 (',', '')\n",
      "2288 ('it', 'PRON')\n",
      "2289 ('suddenly', 'ADV')\n",
      "2290 ('occurred', 'VERB')\n",
      "2291 ('to', 'ADP')\n",
      "2292 ('him', 'PRON')\n",
      "2293 ('to', 'ADP')\n",
      "2294 ('wonder', 'VERB')\n",
      "2295 (',', '')\n",
      "2296 ('was', 'VERB')\n",
      "2297 ('he', 'PRON')\n",
      "2298 ('writing', 'VERB')\n",
      "2299 ('this', 'DET')\n",
      "2300 ('diary', 'NOUN')\n",
      "2301 ('?', '')\n",
      "2302 ('For', 'ADP')\n",
      "2303 ('the', 'DET')\n",
      "2304 ('future', 'NOUN')\n",
      "2305 (',', '')\n",
      "2306 ('for', 'ADP')\n",
      "2307 ('the', 'DET')\n",
      "2308 ('unborn', 'ADJ')\n",
      "2309 ('.', '')\n",
      "2310 ('His', 'DET')\n",
      "2311 ('mind', 'NOUN')\n",
      "2312 ('hovered', 'VERB')\n",
      "2313 ('for', 'ADP')\n",
      "2314 ('a', 'DET')\n",
      "2315 ('moment', 'NOUN')\n",
      "2316 ('round', 'ADP')\n",
      "2317 ('the', 'DET')\n",
      "2318 ('doubtful', 'ADJ')\n",
      "2319 ('date', 'NOUN')\n",
      "2320 ('on', 'ADP')\n",
      "2321 ('the', 'DET')\n",
      "2322 ('page', 'NOUN')\n",
      "2323 (',', '')\n",
      "2324 ('and', 'CONJ')\n",
      "2325 ('then', 'ADV')\n",
      "2326 ('fetched', 'VERB')\n",
      "2327 ('up', 'ADP')\n",
      "2328 ('with', 'ADP')\n",
      "2329 ('a', 'DET')\n",
      "2330 ('bump', 'NOUN')\n",
      "2331 ('against', 'ADP')\n",
      "2332 ('the', 'DET')\n",
      "2333 ('Newspeak', 'NOUN')\n",
      "2334 ('word', 'NOUN')\n",
      "2335 ('doublethink', 'NOUN')\n",
      "2336 ('.', '')\n",
      "2337 ('For', 'ADP')\n",
      "2338 ('the', 'DET')\n",
      "2339 ('first', 'NUM')\n",
      "2340 ('time', 'NOUN')\n",
      "2341 ('the', 'DET')\n",
      "2342 ('magnitude', 'NOUN')\n",
      "2343 ('of', 'ADP')\n",
      "2344 ('what', 'PRON')\n",
      "2345 ('he', 'PRON')\n",
      "2346 ('had', 'VERB')\n",
      "2347 ('undertaken', 'VERB')\n",
      "2348 ('came', 'VERB')\n",
      "2349 ('home', 'ADV')\n",
      "2350 ('to', 'ADP')\n",
      "2351 ('him', 'PRON')\n",
      "2352 ('.', '')\n",
      "2353 ('How', 'ADV')\n",
      "2354 ('could', 'VERB')\n",
      "2355 ('you', 'PRON')\n",
      "2356 ('communicate', 'VERB')\n",
      "2357 ('with', 'ADP')\n",
      "2358 ('the', 'DET')\n",
      "2359 ('future', 'NOUN')\n",
      "2360 ('?', '')\n",
      "2361 ('It', 'PRON')\n",
      "2362 ('was', 'VERB')\n",
      "2363 ('of', 'ADP')\n",
      "2364 ('its', 'DET')\n",
      "2365 ('nature', 'NOUN')\n",
      "2366 ('impossible', 'ADJ')\n",
      "2367 ('.', '')\n",
      "2368 ('Either', 'CONJ')\n",
      "2369 ('the', 'DET')\n",
      "2370 ('future', 'NOUN')\n",
      "2371 ('would', 'VERB')\n",
      "2372 ('resemble', 'VERB')\n",
      "2373 ('the', 'DET')\n",
      "2374 ('present', 'NOUN')\n",
      "2375 (',', '')\n",
      "2376 ('in', 'ADP')\n",
      "2377 ('which', 'DET')\n",
      "2378 ('case', 'NOUN')\n",
      "2379 ('it', 'PRON')\n",
      "2380 ('would', 'VERB')\n",
      "2381 ('not', 'ADV')\n",
      "2382 ('listen', 'VERB')\n",
      "2383 ('to', 'ADP')\n",
      "2384 ('him', 'PRON')\n",
      "2385 (':', '')\n",
      "2386 ('or', 'CONJ')\n",
      "2387 ('it', 'PRON')\n",
      "2388 ('would', 'VERB')\n",
      "2389 ('be', 'VERB')\n",
      "2390 ('different', 'ADJ')\n",
      "2391 ('from', 'ADP')\n",
      "2392 ('it', 'PRON')\n",
      "2393 (',', '')\n",
      "2394 ('and', 'CONJ')\n",
      "2395 ('his', 'DET')\n",
      "2396 ('predicament', 'NOUN')\n",
      "2397 ('would', 'VERB')\n",
      "2398 ('be', 'VERB')\n",
      "2399 ('meaningless', 'ADJ')\n",
      "2400 ('.', '')\n",
      "2401 ('For', 'ADP')\n",
      "2402 ('some', 'DET')\n",
      "2403 ('time', 'NOUN')\n",
      "2404 ('he', 'PRON')\n",
      "2405 ('sat', 'VERB')\n",
      "2406 ('gazing', 'VERB')\n",
      "2407 ('stupidly', 'ADV')\n",
      "2408 ('at', 'ADP')\n",
      "2409 ('the', 'DET')\n",
      "2410 ('paper', 'NOUN')\n",
      "2411 ('.', '')\n",
      "2412 ('The', 'DET')\n",
      "2413 ('telescreen', 'NOUN')\n",
      "2414 ('had', 'VERB')\n",
      "2415 ('changed', 'VERB')\n",
      "2416 ('over', 'ADV')\n",
      "2417 ('to', 'ADP')\n",
      "2418 ('strident', 'ADJ')\n",
      "2419 ('military', 'NOUN')\n",
      "2420 ('music', 'NOUN')\n",
      "2421 ('.', '')\n",
      "2422 ('It', 'PRON')\n",
      "2423 ('was', 'VERB')\n",
      "2424 ('curious', 'ADJ')\n",
      "2425 ('that', 'CONJ')\n",
      "2426 ('he', 'PRON')\n",
      "2427 ('seemed', 'VERB')\n",
      "2428 ('not', 'ADV')\n",
      "2429 ('merely', 'ADV')\n",
      "2430 ('to', 'ADP')\n",
      "2431 ('have', 'VERB')\n",
      "2432 ('lost', 'VERB')\n",
      "2433 ('the', 'DET')\n",
      "2434 ('power', 'NOUN')\n",
      "2435 ('of', 'ADP')\n",
      "2436 ('expressing', 'VERB')\n",
      "2437 ('himself', 'PRON')\n",
      "2438 (',', '')\n",
      "2439 ('but', 'CONJ')\n",
      "2440 ('even', 'ADV')\n",
      "2441 ('to', 'ADP')\n",
      "2442 ('have', 'VERB')\n",
      "2443 ('forgotten', 'VERB')\n",
      "2444 ('what', 'PRON')\n",
      "2445 ('it', 'PRON')\n",
      "2446 ('was', 'VERB')\n",
      "2447 ('that', 'PRON')\n",
      "2448 ('he', 'PRON')\n",
      "2449 ('had', 'VERB')\n",
      "2450 ('originally', 'ADV')\n",
      "2451 ('intended', 'VERB')\n",
      "2452 ('to', 'ADP')\n",
      "2453 ('say', 'VERB')\n",
      "2454 ('.', '')\n",
      "2455 ('For', 'ADP')\n",
      "2456 ('weeks', 'NOUN')\n",
      "2457 ('past', 'ADJ')\n",
      "2458 ('he', 'PRON')\n",
      "2459 ('had', 'VERB')\n",
      "2460 ('been', 'VERB')\n",
      "2461 ('making', 'VERB')\n",
      "2462 ('ready', 'ADJ')\n",
      "2463 ('for', 'ADP')\n",
      "2464 ('this', 'DET')\n",
      "2465 ('moment', 'NOUN')\n",
      "2466 (',', '')\n",
      "2467 ('and', 'CONJ')\n",
      "2468 ('it', 'PRON')\n",
      "2469 ('had', 'VERB')\n",
      "2470 ('never', 'ADV')\n",
      "2471 ('crossed', 'VERB')\n",
      "2472 ('his', 'DET')\n",
      "2473 ('mind', 'NOUN')\n",
      "2474 ('that', 'CONJ')\n",
      "2475 ('anything', 'PRON')\n",
      "2476 ('would', 'VERB')\n",
      "2477 ('be', 'VERB')\n",
      "2478 ('needed', 'VERB')\n",
      "2479 ('except', 'ADP')\n",
      "2480 ('courage', 'NOUN')\n",
      "2481 ('.', '')\n",
      "2482 ('The', 'DET')\n",
      "2483 ('actual', 'ADJ')\n",
      "2484 ('writing', 'VERB')\n",
      "2485 ('would', 'VERB')\n",
      "2486 ('be', 'VERB')\n",
      "2487 ('easy', 'ADJ')\n",
      "2488 ('.', '')\n",
      "2489 ('All', 'DET')\n",
      "2490 ('he', 'PRON')\n",
      "2491 ('had', 'VERB')\n",
      "2492 ('to', 'ADP')\n",
      "2493 ('do', 'VERB')\n",
      "2494 ('was', 'VERB')\n",
      "2495 ('to', 'ADP')\n",
      "2496 ('transfer', 'VERB')\n",
      "2497 ('to', 'ADP')\n",
      "2498 ('paper', 'NOUN')\n",
      "2499 ('the', 'DET')\n",
      "2500 ('interminable', 'ADJ')\n",
      "2501 ('restless', 'ADJ')\n",
      "2502 ('monologue', 'NOUN')\n",
      "2503 ('that', 'PRON')\n",
      "2504 ('had', 'VERB')\n",
      "2505 ('been', 'VERB')\n",
      "2506 ('running', 'VERB')\n",
      "2507 ('inside', 'ADP')\n",
      "2508 ('his', 'DET')\n",
      "2509 ('head', 'NOUN')\n",
      "2510 (',', '')\n",
      "2511 ('literally', 'ADV')\n",
      "2512 ('for', 'ADP')\n",
      "2513 ('years', 'NOUN')\n",
      "2514 ('.', '')\n",
      "2515 ('At', 'ADP')\n",
      "2516 ('this', 'DET')\n",
      "2517 ('moment', 'NOUN')\n",
      "2518 (',', '')\n",
      "2519 ('however', 'ADV')\n",
      "2520 (',', '')\n",
      "2521 ('even', 'ADV')\n",
      "2522 ('the', 'DET')\n",
      "2523 ('monologue', 'NOUN')\n",
      "2524 ('had', 'VERB')\n",
      "2525 ('dried', 'VERB')\n",
      "2526 ('up', 'ADP')\n",
      "2527 ('.', '')\n",
      "2528 ('Moreover', 'ADV')\n",
      "2529 ('his', 'DET')\n",
      "2530 ('varicose', 'ADJ')\n",
      "2531 ('ulcer', 'NOUN')\n",
      "2532 ('had', 'VERB')\n",
      "2533 ('begun', 'VERB')\n",
      "2534 ('itching', 'VERB')\n",
      "2535 ('unbearably', 'ADV')\n",
      "2536 ('.', '')\n",
      "2537 ('He', 'PRON')\n",
      "2538 ('dared', 'VERB')\n",
      "2539 ('not', 'ADV')\n",
      "2540 ('scratch', 'VERB')\n",
      "2541 ('it', 'PRON')\n",
      "2542 (',', '')\n",
      "2543 ('because', 'CONJ')\n",
      "2544 ('if', 'CONJ')\n",
      "2545 ('he', 'PRON')\n",
      "2546 ('did', 'VERB')\n",
      "2547 ('so', 'ADV')\n",
      "2548 ('it', 'PRON')\n",
      "2549 ('always', 'ADV')\n",
      "2550 ('became', 'VERB')\n",
      "2551 ('inflamed', 'ADJ')\n",
      "2552 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553 ('The', 'DET')\n",
      "2554 ('seconds', 'NOUN')\n",
      "2555 ('were', 'VERB')\n",
      "2556 ('ticking', 'VERB')\n",
      "2557 ('by', 'ADV')\n",
      "2558 ('.', '')\n",
      "2559 ('He', 'PRON')\n",
      "2560 ('was', 'VERB')\n",
      "2561 ('conscious', 'ADJ')\n",
      "2562 ('of', 'ADP')\n",
      "2563 ('nothing', 'PRON')\n",
      "2564 ('except', 'ADP')\n",
      "2565 ('the', 'DET')\n",
      "2566 ('blankness', 'NOUN')\n",
      "2567 ('of', 'ADP')\n",
      "2568 ('the', 'DET')\n",
      "2569 ('page', 'NOUN')\n",
      "2570 ('in', 'ADP')\n",
      "2571 ('front', 'NOUN')\n",
      "2572 ('of', 'ADP')\n",
      "2573 ('him', 'PRON')\n",
      "2574 (',', '')\n",
      "2575 ('the', 'DET')\n",
      "2576 ('itching', 'NOUN')\n",
      "2577 ('of', 'ADP')\n",
      "2578 ('the', 'DET')\n",
      "2579 ('skin', 'NOUN')\n",
      "2580 ('above', 'ADP')\n",
      "2581 ('his', 'DET')\n",
      "2582 ('ankle', 'NOUN')\n",
      "2583 (',', '')\n",
      "2584 ('the', 'DET')\n",
      "2585 ('blaring', 'NOUN')\n",
      "2586 ('of', 'ADP')\n",
      "2587 ('the', 'DET')\n",
      "2588 ('music', 'NOUN')\n",
      "2589 (',', '')\n",
      "2590 ('and', 'CONJ')\n",
      "2591 ('a', 'DET')\n",
      "2592 ('slight', 'ADJ')\n",
      "2593 ('booziness', 'NOUN')\n",
      "2594 ('caused', 'VERB')\n",
      "2595 ('by', 'ADP')\n",
      "2596 ('the', 'DET')\n",
      "2597 ('gin', 'NOUN')\n",
      "2598 ('.', '')\n",
      "2599 ('Suddenly', 'ADV')\n",
      "2600 ('he', 'PRON')\n",
      "2601 ('began', 'VERB')\n",
      "2602 ('writing', 'VERB')\n",
      "2603 ('in', 'ADP')\n",
      "2604 ('sheer', 'ADJ')\n",
      "2605 ('panic', 'NOUN')\n",
      "2606 (',', '')\n",
      "2607 ('only', 'ADV')\n",
      "2608 ('imperfectly', 'ADV')\n",
      "2609 ('aware', 'ADJ')\n",
      "2610 ('of', 'ADP')\n",
      "2611 ('what', 'PRON')\n",
      "2612 ('he', 'PRON')\n",
      "2613 ('was', 'VERB')\n",
      "2614 ('setting', 'VERB')\n",
      "2615 ('down', 'ADV')\n",
      "2616 ('.', '')\n",
      "2617 ('His', 'DET')\n",
      "2618 ('small', 'ADJ')\n",
      "2619 ('but', 'CONJ')\n",
      "2620 ('childish', 'ADJ')\n",
      "2621 ('handwriting', 'NOUN')\n",
      "2622 ('straggled', 'VERB')\n",
      "2623 ('up', 'ADP')\n",
      "2624 ('and', 'CONJ')\n",
      "2625 ('down', 'ADP')\n",
      "2626 ('the', 'DET')\n",
      "2627 ('page', 'NOUN')\n",
      "2628 (',', '')\n",
      "2629 ('shedding', 'VERB')\n",
      "2630 ('first', 'ADV')\n",
      "2631 ('its', 'DET')\n",
      "2632 ('capital', 'ADJ')\n",
      "2633 ('letters', 'NOUN')\n",
      "2634 ('and', 'CONJ')\n",
      "2635 ('finally', 'ADV')\n",
      "2636 ('even', 'ADV')\n",
      "2637 ('its', 'DET')\n",
      "2638 ('full', 'ADJ')\n",
      "2639 ('stops', 'NOUN')\n",
      "2640 (':', '')\n",
      "2641 ('April', 'NOUN')\n",
      "2642 ('4th', 'NUM')\n",
      "2643 (',', '')\n",
      "2644 ('1984', 'NUM')\n",
      "2645 ('.', '')\n",
      "2646 ('Last', 'ADJ')\n",
      "2647 ('night', 'NOUN')\n",
      "2648 ('to', 'ADP')\n",
      "2649 ('the', 'DET')\n",
      "2650 ('flicks', 'NOUN')\n",
      "2651 ('.', '')\n",
      "2652 ('All', 'DET')\n",
      "2653 ('war', 'NOUN')\n",
      "2654 ('films', 'NOUN')\n",
      "2655 ('.', '')\n",
      "2656 ('One', 'NUM')\n",
      "2657 ('very', 'ADV')\n",
      "2658 ('good', 'ADJ')\n",
      "2659 ('one', 'PRON')\n",
      "2660 ('of', 'ADP')\n",
      "2661 ('a', 'DET')\n",
      "2662 ('ship', 'NOUN')\n",
      "2663 ('full', 'ADJ')\n",
      "2664 ('of', 'ADP')\n",
      "2665 ('refugees', 'NOUN')\n",
      "2666 ('being', 'VERB')\n",
      "2667 ('bombed', 'VERB')\n",
      "2668 ('somewhere', 'ADV')\n",
      "2669 ('in', 'ADP')\n",
      "2670 ('the', 'DET')\n",
      "2671 ('Mediterranean', 'NOUN')\n",
      "2672 ('.', '')\n",
      "2673 ('Audience', 'NOUN')\n",
      "2674 ('much', 'ADV')\n",
      "2675 ('amused', 'ADJ')\n",
      "2676 ('by', 'ADP')\n",
      "2677 ('shots', 'NOUN')\n",
      "2678 ('of', 'ADP')\n",
      "2679 ('a', 'DET')\n",
      "2680 ('great', 'ADJ')\n",
      "2681 ('huge', 'ADJ')\n",
      "2682 ('fat', 'ADJ')\n",
      "2683 ('man', 'NOUN')\n",
      "2684 ('trying', 'VERB')\n",
      "2685 ('to', 'ADP')\n",
      "2686 ('swim', 'VERB')\n",
      "2687 ('away', 'ADV')\n",
      "2688 ('with', 'ADP')\n",
      "2689 ('a', 'DET')\n",
      "2690 ('helicopter', 'NOUN')\n",
      "2691 ('after', 'ADP')\n",
      "2692 ('him', 'PRON')\n",
      "2693 (',', '')\n",
      "2694 ('first', 'ADV')\n",
      "2695 ('you', 'PRON')\n",
      "2696 ('saw', 'VERB')\n",
      "2697 ('him', 'PRON')\n",
      "2698 ('wallowing', 'VERB')\n",
      "2699 ('along', 'ADV')\n",
      "2700 ('in', 'ADP')\n",
      "2701 ('the', 'DET')\n",
      "2702 ('water', 'NOUN')\n",
      "2703 ('like', 'ADP')\n",
      "2704 ('a', 'DET')\n",
      "2705 ('porpoise', 'NOUN')\n",
      "2706 (',', '')\n",
      "2707 ('then', 'ADV')\n",
      "2708 ('you', 'PRON')\n",
      "2709 ('saw', 'VERB')\n",
      "2710 ('him', 'PRON')\n",
      "2711 ('through', 'ADP')\n",
      "2712 ('the', 'DET')\n",
      "2713 ('helicopters', 'NOUN')\n",
      "2714 ('gunsights', 'NOUN')\n",
      "2715 (',', '')\n",
      "2716 ('then', 'ADV')\n",
      "2717 ('he', 'PRON')\n",
      "2718 ('was', 'VERB')\n",
      "2719 ('full', 'ADJ')\n",
      "2720 ('of', 'ADP')\n",
      "2721 ('holes', 'NOUN')\n",
      "2722 ('and', 'CONJ')\n",
      "2723 ('the', 'DET')\n",
      "2724 ('sea', 'NOUN')\n",
      "2725 ('round', 'ADP')\n",
      "2726 ('him', 'PRON')\n",
      "2727 ('turned', 'VERB')\n",
      "2728 ('pink', 'ADJ')\n",
      "2729 ('and', 'CONJ')\n",
      "2730 ('he', 'PRON')\n",
      "2731 ('sank', 'VERB')\n",
      "2732 ('as', 'ADV')\n",
      "2733 ('suddenly', 'ADV')\n",
      "2734 ('as', 'CONJ')\n",
      "2735 ('though', 'CONJ')\n",
      "2736 ('the', 'DET')\n",
      "2737 ('holes', 'NOUN')\n",
      "2738 ('had', 'VERB')\n",
      "2739 ('let', 'VERB')\n",
      "2740 ('in', 'ADP')\n",
      "2741 ('the', 'DET')\n",
      "2742 ('water', 'NOUN')\n",
      "2743 (',', '')\n",
      "2744 ('audience', 'NOUN')\n",
      "2745 ('shouting', 'VERB')\n",
      "2746 ('with', 'ADP')\n",
      "2747 ('laughter', 'NOUN')\n",
      "2748 ('when', 'CONJ')\n",
      "2749 ('he', 'PRON')\n",
      "2750 ('sank', 'VERB')\n",
      "2751 ('.', '')\n",
      "2752 ('then', 'ADV')\n",
      "2753 ('you', 'PRON')\n",
      "2754 ('saw', 'VERB')\n",
      "2755 ('a', 'DET')\n",
      "2756 ('lifeboat', 'NOUN')\n",
      "2757 ('full', 'ADJ')\n",
      "2758 ('of', 'ADP')\n",
      "2759 ('children', 'NOUN')\n",
      "2760 ('with', 'ADP')\n",
      "2761 ('a', 'DET')\n",
      "2762 ('helicopter', 'NOUN')\n",
      "2763 ('hovering', 'VERB')\n",
      "2764 ('over', 'ADP')\n",
      "2765 ('it', 'PRON')\n",
      "2766 ('.', '')\n",
      "2767 ('there', 'PRON')\n",
      "2768 ('was', 'VERB')\n",
      "2769 ('a', 'DET')\n",
      "2770 ('middle-aged', 'ADJ')\n",
      "2771 ('woman', 'NOUN')\n",
      "2772 ('might', 'VERB')\n",
      "2773 ('have', 'VERB')\n",
      "2774 ('been', 'VERB')\n",
      "2775 ('a', 'DET')\n",
      "2776 ('jewess', 'NOUN')\n",
      "2777 ('sitting', 'VERB')\n",
      "2778 ('up', 'ADP')\n",
      "2779 ('in', 'ADP')\n",
      "2780 ('the', 'DET')\n",
      "2781 ('bow', 'NOUN')\n",
      "2782 ('with', 'ADP')\n",
      "2783 ('a', 'DET')\n",
      "2784 ('little', 'ADJ')\n",
      "2785 ('boy', 'NOUN')\n",
      "2786 ('about', 'ADV')\n",
      "2787 ('three', 'NUM')\n",
      "2788 ('years', 'NOUN')\n",
      "2789 ('old', 'ADJ')\n",
      "2790 ('in', 'ADP')\n",
      "2791 ('her', 'DET')\n",
      "2792 ('arms', 'NOUN')\n",
      "2793 ('.', '')\n",
      "2794 ('little', 'ADJ')\n",
      "2795 ('boy', 'NOUN')\n",
      "2796 ('screaming', 'VERB')\n",
      "2797 ('with', 'ADP')\n",
      "2798 ('fright', 'NOUN')\n",
      "2799 ('and', 'CONJ')\n",
      "2800 ('hiding', 'VERB')\n",
      "2801 ('his', 'DET')\n",
      "2802 ('head', 'NOUN')\n",
      "2803 ('between', 'ADP')\n",
      "2804 ('her', 'DET')\n",
      "2805 ('breasts', 'NOUN')\n",
      "2806 ('as', 'CONJ')\n",
      "2807 ('if', 'CONJ')\n",
      "2808 ('he', 'PRON')\n",
      "2809 ('was', 'VERB')\n",
      "2810 ('trying', 'VERB')\n",
      "2811 ('to', 'ADP')\n",
      "2812 ('burrow', 'VERB')\n",
      "2813 ('right', 'ADV')\n",
      "2814 ('into', 'ADP')\n",
      "2815 ('her', 'PRON')\n",
      "2816 ('and', 'CONJ')\n",
      "2817 ('the', 'DET')\n",
      "2818 ('woman', 'NOUN')\n",
      "2819 ('putting', 'VERB')\n",
      "2820 ('her', 'DET')\n",
      "2821 ('arms', 'NOUN')\n",
      "2822 ('round', 'ADP')\n",
      "2823 ('him', 'PRON')\n",
      "2824 ('and', 'CONJ')\n",
      "2825 ('comforting', 'VERB')\n",
      "2826 ('him', 'PRON')\n",
      "2827 ('although', 'CONJ')\n",
      "2828 ('she', 'PRON')\n",
      "2829 ('was', 'VERB')\n",
      "2830 ('blue', 'ADJ')\n",
      "2831 ('with', 'ADP')\n",
      "2832 ('fright', 'NOUN')\n",
      "2833 ('herself', 'PRON')\n",
      "2834 (',', '')\n",
      "2835 ('all', 'DET')\n",
      "2836 ('the', 'DET')\n",
      "2837 ('time', 'NOUN')\n",
      "2838 ('covering', 'VERB')\n",
      "2839 ('him', 'PRON')\n",
      "2840 ('up', 'ADP')\n",
      "2841 ('as', 'ADV')\n",
      "2842 ('much', 'ADV')\n",
      "2843 ('as', 'CONJ')\n",
      "2844 ('possible', 'ADJ')\n",
      "2845 ('as', 'CONJ')\n",
      "2846 ('if', 'CONJ')\n",
      "2847 ('she', 'PRON')\n",
      "2848 ('thought', 'VERB')\n",
      "2849 ('her', 'DET')\n",
      "2850 ('arms', 'NOUN')\n",
      "2851 ('could', 'VERB')\n",
      "2852 ('keep', 'VERB')\n",
      "2853 ('the', 'DET')\n",
      "2854 ('bullets', 'NOUN')\n",
      "2855 ('off', 'ADP')\n",
      "2856 ('him', 'PRON')\n",
      "2857 ('.', '')\n",
      "2858 ('then', 'ADV')\n",
      "2859 ('the', 'DET')\n",
      "2860 ('helicopter', 'NOUN')\n",
      "2861 ('planted', 'VERB')\n",
      "2862 ('a', 'DET')\n",
      "2863 ('20', 'NUM')\n",
      "2864 ('kilo', 'NOUN')\n",
      "2865 ('bomb', 'NOUN')\n",
      "2866 ('in', 'ADP')\n",
      "2867 ('among', 'ADP')\n",
      "2868 ('them', 'PRON')\n",
      "2869 ('terrific', 'ADJ')\n",
      "2870 ('flash', 'NOUN')\n",
      "2871 ('and', 'CONJ')\n",
      "2872 ('the', 'DET')\n",
      "2873 ('boat', 'NOUN')\n",
      "2874 ('went', 'VERB')\n",
      "2875 ('all', 'ADV')\n",
      "2876 ('to', 'ADP')\n",
      "2877 ('matchwood', 'NOUN')\n",
      "2878 ('.', '')\n",
      "2879 ('then', 'ADV')\n",
      "2880 ('there', 'PRON')\n",
      "2881 ('was', 'VERB')\n",
      "2882 ('a', 'DET')\n",
      "2883 ('wonderful', 'ADJ')\n",
      "2884 ('shot', 'NOUN')\n",
      "2885 ('of', 'ADP')\n",
      "2886 ('a', 'DET')\n",
      "2887 ('child', 'NOUN')\n",
      "2888 (\"'s\", 'ADP')\n",
      "2889 ('arm', 'NOUN')\n",
      "2890 ('going', 'VERB')\n",
      "2891 ('up', 'ADP')\n",
      "2892 ('up', 'ADP')\n",
      "2893 ('up', 'ADP')\n",
      "2894 ('right', 'ADV')\n",
      "2895 ('up', 'ADP')\n",
      "2896 ('into', 'ADP')\n",
      "2897 ('the', 'DET')\n",
      "2898 ('air', 'NOUN')\n",
      "2899 ('a', 'DET')\n",
      "2900 ('helicopter', 'NOUN')\n",
      "2901 ('with', 'ADP')\n",
      "2902 ('a', 'DET')\n",
      "2903 ('camera', 'NOUN')\n",
      "2904 ('in', 'ADP')\n",
      "2905 ('its', 'DET')\n",
      "2906 ('nose', 'NOUN')\n",
      "2907 ('must', 'VERB')\n",
      "2908 ('have', 'VERB')\n",
      "2909 ('followed', 'VERB')\n",
      "2910 ('it', 'PRON')\n",
      "2911 ('up', 'ADP')\n",
      "2912 ('and', 'CONJ')\n",
      "2913 ('there', 'PRON')\n",
      "2914 ('was', 'VERB')\n",
      "2915 ('a', 'DET')\n",
      "2916 ('lot', 'NOUN')\n",
      "2917 ('of', 'ADP')\n",
      "2918 ('applause', 'NOUN')\n",
      "2919 ('from', 'ADP')\n",
      "2920 ('the', 'DET')\n",
      "2921 ('party', 'NOUN')\n",
      "2922 ('seats', 'NOUN')\n",
      "2923 ('but', 'CONJ')\n",
      "2924 ('a', 'DET')\n",
      "2925 ('woman', 'NOUN')\n",
      "2926 ('down', 'ADV')\n",
      "2927 ('in', 'ADP')\n",
      "2928 ('the', 'DET')\n",
      "2929 ('prole', 'NOUN')\n",
      "2930 ('part', 'NOUN')\n",
      "2931 ('of', 'ADP')\n",
      "2932 ('the', 'DET')\n",
      "2933 ('house', 'NOUN')\n",
      "2934 ('suddenly', 'ADV')\n",
      "2935 ('started', 'VERB')\n",
      "2936 ('kicking', 'VERB')\n",
      "2937 ('up', 'ADP')\n",
      "2938 ('a', 'DET')\n",
      "2939 ('fuss', 'NOUN')\n",
      "2940 ('and', 'CONJ')\n",
      "2941 ('shouting', 'VERB')\n",
      "2942 ('they', 'PRON')\n",
      "2943 ('didnt', 'VERB')\n",
      "2944 ('oughter', 'ADJ')\n",
      "2945 ('of', 'ADP')\n",
      "2946 ('showed', 'VERB')\n",
      "2947 ('it', 'PRON')\n",
      "2948 ('not', 'ADV')\n",
      "2949 ('in', 'ADP')\n",
      "2950 ('front', 'NOUN')\n",
      "2951 ('of', 'ADP')\n",
      "2952 ('kids', 'NOUN')\n",
      "2953 ('they', 'PRON')\n",
      "2954 ('didnt', 'VERB')\n",
      "2955 ('it', 'PRON')\n",
      "2956 ('aint', 'VERB')\n",
      "2957 ('right', 'ADJ')\n",
      "2958 ('not', 'ADV')\n",
      "2959 ('in', 'ADP')\n",
      "2960 ('front', 'NOUN')\n",
      "2961 ('of', 'ADP')\n",
      "2962 ('kids', 'NOUN')\n",
      "2963 ('it', 'PRON')\n",
      "2964 ('aint', 'VERB')\n",
      "2965 ('until', 'CONJ')\n",
      "2966 ('the', 'DET')\n",
      "2967 ('police', 'NOUN')\n",
      "2968 ('turned', 'VERB')\n",
      "2969 ('her', 'PRON')\n",
      "2970 ('out', 'ADP')\n",
      "2971 ('i', 'NOUN')\n",
      "2972 ('dont', 'VERB')\n",
      "2973 ('suppose', 'VERB')\n",
      "2974 ('anything', 'PRON')\n",
      "2975 ('happened', 'VERB')\n",
      "2976 ('to', 'ADP')\n",
      "2977 ('her', 'PRON')\n",
      "2978 ('nobody', 'PRON')\n",
      "2979 ('cares', 'VERB')\n",
      "2980 ('what', 'PRON')\n",
      "2981 ('the', 'DET')\n",
      "2982 ('proles', 'NOUN')\n",
      "2983 ('say', 'VERB')\n",
      "2984 ('typical', 'ADJ')\n",
      "2985 ('prole', 'NOUN')\n",
      "2986 ('reaction', 'NOUN')\n",
      "2987 ('they', 'PRON')\n",
      "2988 ('never', 'ADV')\n",
      "2989 ('-', '')\n",
      "2990 ('Winston', 'NOUN')\n",
      "2991 ('stopped', 'VERB')\n",
      "2992 ('writing', 'VERB')\n",
      "2993 (',', '')\n",
      "2994 ('partly', 'ADV')\n",
      "2995 ('because', 'CONJ')\n",
      "2996 ('he', 'PRON')\n",
      "2997 ('was', 'VERB')\n",
      "2998 ('suffering', 'VERB')\n",
      "2999 ('from', 'ADP')\n",
      "3000 ('cramp', 'NOUN')\n",
      "3001 ('.', '')\n",
      "3002 ('He', 'PRON')\n",
      "3003 ('did', 'VERB')\n",
      "3004 ('not', 'ADV')\n",
      "3005 ('know', 'VERB')\n",
      "3006 ('what', 'PRON')\n",
      "3007 ('had', 'VERB')\n",
      "3008 ('made', 'VERB')\n",
      "3009 ('him', 'PRON')\n",
      "3010 ('pour', 'VERB')\n",
      "3011 ('out', 'ADP')\n",
      "3012 ('this', 'DET')\n",
      "3013 ('stream', 'NOUN')\n",
      "3014 ('of', 'ADP')\n",
      "3015 ('rubbish', 'NOUN')\n",
      "3016 ('.', '')\n",
      "3017 ('But', 'CONJ')\n",
      "3018 ('the', 'DET')\n",
      "3019 ('curious', 'ADJ')\n",
      "3020 ('thing', 'NOUN')\n",
      "3021 ('was', 'VERB')\n",
      "3022 ('that', 'CONJ')\n",
      "3023 ('while', 'CONJ')\n",
      "3024 ('he', 'PRON')\n",
      "3025 ('was', 'VERB')\n",
      "3026 ('doing', 'VERB')\n",
      "3027 ('so', 'ADV')\n",
      "3028 ('a', 'DET')\n",
      "3029 ('totally', 'ADV')\n",
      "3030 ('different', 'ADJ')\n",
      "3031 ('memory', 'NOUN')\n",
      "3032 ('had', 'VERB')\n",
      "3033 ('clarified', 'VERB')\n",
      "3034 ('itself', 'PRON')\n",
      "3035 ('in', 'ADP')\n",
      "3036 ('his', 'DET')\n",
      "3037 ('mind', 'NOUN')\n",
      "3038 (',', '')\n",
      "3039 ('to', 'ADP')\n",
      "3040 ('the', 'DET')\n",
      "3041 ('point', 'NOUN')\n",
      "3042 ('where', 'CONJ')\n",
      "3043 ('he', 'PRON')\n",
      "3044 ('almost', 'ADV')\n",
      "3045 ('felt', 'VERB')\n",
      "3046 ('equal', 'ADJ')\n",
      "3047 ('to', 'ADP')\n",
      "3048 ('writing', 'VERB')\n",
      "3049 ('it', 'PRON')\n",
      "3050 ('down', 'ADV')\n",
      "3051 ('.', '')\n",
      "3052 ('It', 'PRON')\n",
      "3053 ('was', 'VERB')\n",
      "3054 (',', '')\n",
      "3055 ('he', 'PRON')\n",
      "3056 ('now', 'ADV')\n",
      "3057 ('realized', 'VERB')\n",
      "3058 (',', '')\n",
      "3059 ('because', 'CONJ')\n",
      "3060 ('of', 'ADP')\n",
      "3061 ('this', 'DET')\n",
      "3062 ('other', 'DET')\n",
      "3063 ('incident', 'NOUN')\n",
      "3064 ('that', 'CONJ')\n",
      "3065 ('he', 'PRON')\n",
      "3066 ('had', 'VERB')\n",
      "3067 ('suddenly', 'ADV')\n",
      "3068 ('decided', 'VERB')\n",
      "3069 ('to', 'ADP')\n",
      "3070 ('come', 'VERB')\n",
      "3071 ('home', 'ADV')\n",
      "3072 ('and', 'CONJ')\n",
      "3073 ('begin', 'VERB')\n",
      "3074 ('the', 'DET')\n",
      "3075 ('diary', 'NOUN')\n",
      "3076 ('today', 'ADV')\n",
      "3077 ('.', '')\n",
      "3078 ('It', 'PRON')\n",
      "3079 ('had', 'VERB')\n",
      "3080 ('happened', 'VERB')\n",
      "3081 ('that', 'DET')\n",
      "3082 ('morning', 'NOUN')\n",
      "3083 ('at', 'ADP')\n",
      "3084 ('the', 'DET')\n",
      "3085 ('Ministry', 'NOUN')\n",
      "3086 (',', '')\n",
      "3087 ('if', 'CONJ')\n",
      "3088 ('anything', 'PRON')\n",
      "3089 ('so', 'ADV')\n",
      "3090 ('nebulous', 'ADJ')\n",
      "3091 ('could', 'VERB')\n",
      "3092 ('be', 'VERB')\n",
      "3093 ('said', 'VERB')\n",
      "3094 ('to', 'ADP')\n",
      "3095 ('happen', 'VERB')\n",
      "3096 ('.', '')\n",
      "3097 ('It', 'PRON')\n",
      "3098 ('was', 'VERB')\n",
      "3099 ('nearly', 'ADV')\n",
      "3100 ('eleven', 'NUM')\n",
      "3101 ('hundred', 'NUM')\n",
      "3102 (',', '')\n",
      "3103 ('and', 'CONJ')\n",
      "3104 ('in', 'ADP')\n",
      "3105 ('the', 'DET')\n",
      "3106 ('Records', 'NOUN')\n",
      "3107 ('Department', 'NOUN')\n",
      "3108 (',', '')\n",
      "3109 ('where', 'CONJ')\n",
      "3110 ('Winston', 'NOUN')\n",
      "3111 ('worked', 'VERB')\n",
      "3112 (',', '')\n",
      "3113 ('they', 'PRON')\n",
      "3114 ('were', 'VERB')\n",
      "3115 ('dragging', 'VERB')\n",
      "3116 ('the', 'DET')\n",
      "3117 ('chairs', 'NOUN')\n",
      "3118 ('out', 'ADP')\n",
      "3119 ('of', 'ADP')\n",
      "3120 ('the', 'DET')\n",
      "3121 ('cubicles', 'NOUN')\n",
      "3122 ('and', 'CONJ')\n",
      "3123 ('grouping', 'VERB')\n",
      "3124 ('them', 'PRON')\n",
      "3125 ('in', 'ADP')\n",
      "3126 ('the', 'DET')\n",
      "3127 ('centre', 'NOUN')\n",
      "3128 ('of', 'ADP')\n",
      "3129 ('the', 'DET')\n",
      "3130 ('hall', 'NOUN')\n",
      "3131 ('opposite', 'ADP')\n",
      "3132 ('the', 'DET')\n",
      "3133 ('big', 'ADJ')\n",
      "3134 ('telescreen', 'NOUN')\n",
      "3135 (',', '')\n",
      "3136 ('in', 'ADP')\n",
      "3137 ('preparation', 'NOUN')\n",
      "3138 ('for', 'ADP')\n",
      "3139 ('the', 'DET')\n",
      "3140 ('Two', 'NUM')\n",
      "3141 ('Minutes', 'NOUN')\n",
      "3142 ('Hate', 'NOUN')\n",
      "3143 ('.', '')\n",
      "3144 ('Winston', 'NOUN')\n",
      "3145 ('was', 'VERB')\n",
      "3146 ('just', 'ADV')\n",
      "3147 ('taking', 'VERB')\n",
      "3148 ('his', 'DET')\n",
      "3149 ('place', 'NOUN')\n",
      "3150 ('in', 'ADP')\n",
      "3151 ('one', 'PRON')\n",
      "3152 ('of', 'ADP')\n",
      "3153 ('the', 'DET')\n",
      "3154 ('middle', 'ADJ')\n",
      "3155 ('rows', 'NOUN')\n",
      "3156 ('when', 'CONJ')\n",
      "3157 ('two', 'NUM')\n",
      "3158 ('people', 'NOUN')\n",
      "3159 ('whom', 'PRON')\n",
      "3160 ('he', 'PRON')\n",
      "3161 ('knew', 'VERB')\n",
      "3162 ('by', 'ADP')\n",
      "3163 ('sight', 'NOUN')\n",
      "3164 (',', '')\n",
      "3165 ('but', 'CONJ')\n",
      "3166 ('had', 'VERB')\n",
      "3167 ('never', 'ADV')\n",
      "3168 ('spoken', 'VERB')\n",
      "3169 ('to', 'ADP')\n",
      "3170 (',', '')\n",
      "3171 ('came', 'VERB')\n",
      "3172 ('unexpectedly', 'ADV')\n",
      "3173 ('into', 'ADP')\n",
      "3174 ('the', 'DET')\n",
      "3175 ('room', 'NOUN')\n",
      "3176 ('.', '')\n",
      "3177 ('One', 'PRON')\n",
      "3178 ('of', 'ADP')\n",
      "3179 ('them', 'PRON')\n",
      "3180 ('was', 'VERB')\n",
      "3181 ('a', 'DET')\n",
      "3182 ('girl', 'NOUN')\n",
      "3183 ('whom', 'PRON')\n",
      "3184 ('he', 'PRON')\n",
      "3185 ('often', 'ADV')\n",
      "3186 ('passed', 'VERB')\n",
      "3187 ('in', 'ADP')\n",
      "3188 ('the', 'DET')\n",
      "3189 ('corridors', 'NOUN')\n",
      "3190 ('.', '')\n",
      "3191 ('He', 'PRON')\n",
      "3192 ('did', 'VERB')\n",
      "3193 ('not', 'ADV')\n",
      "3194 ('know', 'VERB')\n",
      "3195 ('her', 'DET')\n",
      "3196 ('name', 'NOUN')\n",
      "3197 (',', '')\n",
      "3198 ('but', 'CONJ')\n",
      "3199 ('he', 'PRON')\n",
      "3200 ('knew', 'VERB')\n",
      "3201 ('that', 'CONJ')\n",
      "3202 ('she', 'PRON')\n",
      "3203 ('worked', 'VERB')\n",
      "3204 ('in', 'ADP')\n",
      "3205 ('the', 'DET')\n",
      "3206 ('Fiction', 'NOUN')\n",
      "3207 ('Department', 'NOUN')\n",
      "3208 ('.', '')\n",
      "3209 ('Presumably', 'ADV')\n",
      "3210 ('-', '')\n",
      "3211 ('since', 'CONJ')\n",
      "3212 ('he', 'PRON')\n",
      "3213 ('had', 'VERB')\n",
      "3214 ('sometimes', 'ADV')\n",
      "3215 ('seen', 'VERB')\n",
      "3216 ('her', 'PRON')\n",
      "3217 ('with', 'ADP')\n",
      "3218 ('oily', 'ADJ')\n",
      "3219 ('hands', 'NOUN')\n",
      "3220 ('and', 'CONJ')\n",
      "3221 ('carrying', 'VERB')\n",
      "3222 ('a', 'DET')\n",
      "3223 ('spanner', 'NOUN')\n",
      "3224 ('she', 'PRON')\n",
      "3225 ('had', 'VERB')\n",
      "3226 ('some', 'DET')\n",
      "3227 ('mechanical', 'ADJ')\n",
      "3228 ('job', 'NOUN')\n",
      "3229 ('on', 'ADP')\n",
      "3230 ('one', 'PRON')\n",
      "3231 ('of', 'ADP')\n",
      "3232 ('the', 'DET')\n",
      "3233 ('novel-writing', 'ADJ')\n",
      "3234 ('machines', 'NOUN')\n",
      "3235 ('.', '')\n",
      "3236 ('She', 'PRON')\n",
      "3237 ('was', 'VERB')\n",
      "3238 ('a', 'DET')\n",
      "3239 ('bold-looking', 'ADJ')\n",
      "3240 ('girl', 'NOUN')\n",
      "3241 (',', '')\n",
      "3242 ('of', 'ADP')\n",
      "3243 ('about', 'ADV')\n",
      "3244 ('twenty-seven', 'NUM')\n",
      "3245 (',', '')\n",
      "3246 ('with', 'ADP')\n",
      "3247 ('thick', 'ADJ')\n",
      "3248 ('hair', 'NOUN')\n",
      "3249 (',', '')\n",
      "3250 ('a', 'DET')\n",
      "3251 ('freckled', 'ADJ')\n",
      "3252 ('face', 'NOUN')\n",
      "3253 (',', '')\n",
      "3254 ('and', 'CONJ')\n",
      "3255 ('swift', 'ADJ')\n",
      "3256 (',', '')\n",
      "3257 ('athletic', 'ADJ')\n",
      "3258 ('movements', 'NOUN')\n",
      "3259 ('.', '')\n",
      "3260 ('A', 'DET')\n",
      "3261 ('narrow', 'ADJ')\n",
      "3262 ('scarlet', 'ADJ')\n",
      "3263 ('sash', 'NOUN')\n",
      "3264 (',', '')\n",
      "3265 ('emblem', 'NOUN')\n",
      "3266 ('of', 'ADP')\n",
      "3267 ('the', 'DET')\n",
      "3268 ('Junior', 'ADJ')\n",
      "3269 ('Anti-Sex', 'ADJ')\n",
      "3270 ('League', 'NOUN')\n",
      "3271 (',', '')\n",
      "3272 ('was', 'VERB')\n",
      "3273 ('wound', 'VERB')\n",
      "3274 ('several', 'ADJ')\n",
      "3275 ('times', 'NOUN')\n",
      "3276 ('round', 'ADP')\n",
      "3277 ('the', 'DET')\n",
      "3278 ('waist', 'NOUN')\n",
      "3279 ('of', 'ADP')\n",
      "3280 ('her', 'DET')\n",
      "3281 ('overalls', 'NOUN')\n",
      "3282 (',', '')\n",
      "3283 ('just', 'ADV')\n",
      "3284 ('tightly', 'ADV')\n",
      "3285 ('enough', 'ADV')\n",
      "3286 ('to', 'ADP')\n",
      "3287 ('bring', 'VERB')\n",
      "3288 ('out', 'ADP')\n",
      "3289 ('the', 'DET')\n",
      "3290 ('shapeliness', 'NOUN')\n",
      "3291 ('of', 'ADP')\n",
      "3292 ('her', 'DET')\n",
      "3293 ('hips', 'NOUN')\n",
      "3294 ('.', '')\n",
      "3295 ('Winston', 'NOUN')\n",
      "3296 ('had', 'VERB')\n",
      "3297 ('disliked', 'VERB')\n",
      "3298 ('her', 'PRON')\n",
      "3299 ('from', 'ADP')\n",
      "3300 ('the', 'DET')\n",
      "3301 ('very', 'ADV')\n",
      "3302 ('first', 'NUM')\n",
      "3303 ('moment', 'NOUN')\n",
      "3304 ('of', 'ADP')\n",
      "3305 ('seeing', 'VERB')\n",
      "3306 ('her', 'PRON')\n",
      "3307 ('.', '')\n",
      "3308 ('He', 'PRON')\n",
      "3309 ('knew', 'VERB')\n",
      "3310 ('the', 'DET')\n",
      "3311 ('reason', 'NOUN')\n",
      "3312 ('.', '')\n",
      "3313 ('It', 'PRON')\n",
      "3314 ('was', 'VERB')\n",
      "3315 ('because', 'CONJ')\n",
      "3316 ('of', 'ADP')\n",
      "3317 ('the', 'DET')\n",
      "3318 ('atmosphere', 'NOUN')\n",
      "3319 ('of', 'ADP')\n",
      "3320 ('hockey-fields', 'NOUN')\n",
      "3321 ('and', 'CONJ')\n",
      "3322 ('cold', 'ADJ')\n",
      "3323 ('baths', 'NOUN')\n",
      "3324 ('and', 'CONJ')\n",
      "3325 ('community', 'NOUN')\n",
      "3326 ('hikes', 'NOUN')\n",
      "3327 ('and', 'CONJ')\n",
      "3328 ('general', 'ADJ')\n",
      "3329 ('clean-mindedness', 'NOUN')\n",
      "3330 ('which', 'PRON')\n",
      "3331 ('she', 'PRON')\n",
      "3332 ('managed', 'VERB')\n",
      "3333 ('to', 'ADP')\n",
      "3334 ('carry', 'VERB')\n",
      "3335 ('about', 'ADV')\n",
      "3336 ('with', 'ADP')\n",
      "3337 ('her', 'PRON')\n",
      "3338 ('.', '')\n",
      "3339 ('He', 'PRON')\n",
      "3340 ('disliked', 'VERB')\n",
      "3341 ('nearly', 'ADV')\n",
      "3342 ('all', 'DET')\n",
      "3343 ('women', 'NOUN')\n",
      "3344 (',', '')\n",
      "3345 ('and', 'CONJ')\n",
      "3346 ('especially', 'ADV')\n",
      "3347 ('the', 'DET')\n",
      "3348 ('young', 'ADJ')\n",
      "3349 ('and', 'CONJ')\n",
      "3350 ('pretty', 'ADJ')\n",
      "3351 ('ones', 'NOUN')\n",
      "3352 ('.', '')\n",
      "3353 ('It', 'PRON')\n",
      "3354 ('was', 'VERB')\n",
      "3355 ('always', 'ADV')\n",
      "3356 ('the', 'DET')\n",
      "3357 ('women', 'NOUN')\n",
      "3358 (',', '')\n",
      "3359 ('and', 'CONJ')\n",
      "3360 ('above', 'ADP')\n",
      "3361 ('all', 'PRON')\n",
      "3362 ('the', 'DET')\n",
      "3363 ('young', 'ADJ')\n",
      "3364 ('ones', 'NOUN')\n",
      "3365 (',', '')\n",
      "3366 ('who', 'PRON')\n",
      "3367 ('were', 'VERB')\n",
      "3368 ('the', 'DET')\n",
      "3369 ('most', 'ADV')\n",
      "3370 ('bigoted', 'ADJ')\n",
      "3371 ('adherents', 'NOUN')\n",
      "3372 ('of', 'ADP')\n",
      "3373 ('the', 'DET')\n",
      "3374 ('Party', 'NOUN')\n",
      "3375 (',', '')\n",
      "3376 ('the', 'DET')\n",
      "3377 ('swallowers', 'NOUN')\n",
      "3378 ('of', 'ADP')\n",
      "3379 ('slogans', 'NOUN')\n",
      "3380 (',', '')\n",
      "3381 ('the', 'DET')\n",
      "3382 ('amateur', 'ADJ')\n",
      "3383 ('spies', 'NOUN')\n",
      "3384 ('and', 'CONJ')\n",
      "3385 ('nosers-out', 'NOUN')\n",
      "3386 ('of', 'ADP')\n",
      "3387 ('unorthodoxy', 'NOUN')\n",
      "3388 ('.', '')\n",
      "3389 ('But', 'CONJ')\n",
      "3390 ('this', 'DET')\n",
      "3391 ('particular', 'ADJ')\n",
      "3392 ('girl', 'NOUN')\n",
      "3393 ('gave', 'VERB')\n",
      "3394 ('him', 'PRON')\n",
      "3395 ('the', 'DET')\n",
      "3396 ('impression', 'NOUN')\n",
      "3397 ('of', 'ADP')\n",
      "3398 ('being', 'VERB')\n",
      "3399 ('more', 'ADV')\n",
      "3400 ('dangerous', 'ADJ')\n",
      "3401 ('than', 'ADP')\n",
      "3402 ('most', 'PRON')\n",
      "3403 ('.', '')\n",
      "3404 ('Once', 'ADV')\n",
      "3405 ('when', 'CONJ')\n",
      "3406 ('they', 'PRON')\n",
      "3407 ('passed', 'VERB')\n",
      "3408 ('in', 'ADP')\n",
      "3409 ('the', 'DET')\n",
      "3410 ('corridor', 'NOUN')\n",
      "3411 ('she', 'PRON')\n",
      "3412 ('gave', 'VERB')\n",
      "3413 ('him', 'PRON')\n",
      "3414 ('a', 'DET')\n",
      "3415 ('quick', 'ADJ')\n",
      "3416 ('sidelong', 'ADJ')\n",
      "3417 ('glance', 'NOUN')\n",
      "3418 ('which', 'PRON')\n",
      "3419 ('seemed', 'VERB')\n",
      "3420 ('to', 'ADP')\n",
      "3421 ('pierce', 'VERB')\n",
      "3422 ('right', 'ADV')\n",
      "3423 ('into', 'ADP')\n",
      "3424 ('him', 'PRON')\n",
      "3425 ('and', 'CONJ')\n",
      "3426 ('for', 'ADP')\n",
      "3427 ('a', 'DET')\n",
      "3428 ('moment', 'NOUN')\n",
      "3429 ('had', 'VERB')\n",
      "3430 ('filled', 'VERB')\n",
      "3431 ('him', 'PRON')\n",
      "3432 ('with', 'ADP')\n",
      "3433 ('black', 'ADJ')\n",
      "3434 ('terror', 'NOUN')\n",
      "3435 ('.', '')\n",
      "3436 ('The', 'DET')\n",
      "3437 ('idea', 'NOUN')\n",
      "3438 ('had', 'VERB')\n",
      "3439 ('even', 'ADV')\n",
      "3440 ('crossed', 'VERB')\n",
      "3441 ('his', 'DET')\n",
      "3442 ('mind', 'NOUN')\n",
      "3443 ('that', 'CONJ')\n",
      "3444 ('she', 'PRON')\n",
      "3445 ('might', 'VERB')\n",
      "3446 ('be', 'VERB')\n",
      "3447 ('an', 'DET')\n",
      "3448 ('agent', 'NOUN')\n",
      "3449 ('of', 'ADP')\n",
      "3450 ('the', 'DET')\n",
      "3451 ('Thought', 'NOUN')\n",
      "3452 ('Police', 'NOUN')\n",
      "3453 ('.', '')\n",
      "3454 ('That', 'PRON')\n",
      "3455 (',', '')\n",
      "3456 ('it', 'PRON')\n",
      "3457 ('was', 'VERB')\n",
      "3458 ('true', 'ADJ')\n",
      "3459 (',', '')\n",
      "3460 ('was', 'VERB')\n",
      "3461 ('very', 'ADV')\n",
      "3462 ('unlikely', 'ADJ')\n",
      "3463 ('.', '')\n",
      "3464 ('Still', 'ADV')\n",
      "3465 (',', '')\n",
      "3466 ('he', 'PRON')\n",
      "3467 ('continued', 'VERB')\n",
      "3468 ('to', 'ADP')\n",
      "3469 ('feel', 'VERB')\n",
      "3470 ('a', 'DET')\n",
      "3471 ('peculiar', 'ADJ')\n",
      "3472 ('uneasiness', 'NOUN')\n",
      "3473 (',', '')\n",
      "3474 ('which', 'PRON')\n",
      "3475 ('had', 'VERB')\n",
      "3476 ('fear', 'NOUN')\n",
      "3477 ('mixed', 'VERB')\n",
      "3478 ('up', 'ADP')\n",
      "3479 ('in', 'ADP')\n",
      "3480 ('it', 'PRON')\n",
      "3481 ('as', 'ADV')\n",
      "3482 ('well', 'ADV')\n",
      "3483 ('as', 'CONJ')\n",
      "3484 ('hostility', 'NOUN')\n",
      "3485 (',', '')\n",
      "3486 ('whenever', 'CONJ')\n",
      "3487 ('she', 'PRON')\n",
      "3488 ('was', 'VERB')\n",
      "3489 ('anywhere', 'ADV')\n",
      "3490 ('near', 'ADP')\n",
      "3491 ('him', 'PRON')\n",
      "3492 ('.', '')\n",
      "3493 ('The', 'DET')\n",
      "3494 ('other', 'DET')\n",
      "3495 ('person', 'NOUN')\n",
      "3496 ('was', 'VERB')\n",
      "3497 ('a', 'DET')\n",
      "3498 ('man', 'NOUN')\n",
      "3499 ('named', 'VERB')\n",
      "3500 (\"O'Brien\", 'NOUN')\n",
      "3501 (',', '')\n",
      "3502 ('a', 'DET')\n",
      "3503 ('member', 'NOUN')\n",
      "3504 ('of', 'ADP')\n",
      "3505 ('the', 'DET')\n",
      "3506 ('Inner', 'ADJ')\n",
      "3507 ('Party', 'NOUN')\n",
      "3508 ('and', 'CONJ')\n",
      "3509 ('holder', 'NOUN')\n",
      "3510 ('of', 'ADP')\n",
      "3511 ('some', 'DET')\n",
      "3512 ('post', 'NOUN')\n",
      "3513 ('so', 'ADV')\n",
      "3514 ('important', 'ADJ')\n",
      "3515 ('and', 'CONJ')\n",
      "3516 ('remote', 'ADJ')\n",
      "3517 ('that', 'CONJ')\n",
      "3518 ('Winston', 'NOUN')\n",
      "3519 ('had', 'VERB')\n",
      "3520 ('only', 'ADV')\n",
      "3521 ('a', 'DET')\n",
      "3522 ('dim', 'ADJ')\n",
      "3523 ('idea', 'NOUN')\n",
      "3524 ('of', 'ADP')\n",
      "3525 ('its', 'DET')\n",
      "3526 ('nature', 'NOUN')\n",
      "3527 ('.', '')\n",
      "3528 ('A', 'DET')\n",
      "3529 ('momentary', 'ADJ')\n",
      "3530 ('hush', 'NOUN')\n",
      "3531 ('passed', 'VERB')\n",
      "3532 ('over', 'ADP')\n",
      "3533 ('the', 'DET')\n",
      "3534 ('group', 'NOUN')\n",
      "3535 ('of', 'ADP')\n",
      "3536 ('people', 'NOUN')\n",
      "3537 ('round', 'ADP')\n",
      "3538 ('the', 'DET')\n",
      "3539 ('chairs', 'NOUN')\n",
      "3540 ('as', 'CONJ')\n",
      "3541 ('they', 'PRON')\n",
      "3542 ('saw', 'VERB')\n",
      "3543 ('the', 'DET')\n",
      "3544 ('black', 'ADJ')\n",
      "3545 ('overalls', 'NOUN')\n",
      "3546 ('of', 'ADP')\n",
      "3547 ('an', 'DET')\n",
      "3548 ('Inner', 'ADJ')\n",
      "3549 ('Party', 'NOUN')\n",
      "3550 ('member', 'NOUN')\n",
      "3551 ('approaching', 'VERB')\n",
      "3552 ('.', '')\n",
      "3553 (\"O'Brien\", 'NOUN')\n",
      "3554 ('was', 'VERB')\n",
      "3555 ('a', 'DET')\n",
      "3556 ('large', 'ADJ')\n",
      "3557 (',', '')\n",
      "3558 ('burly', 'ADJ')\n",
      "3559 ('man', 'NOUN')\n",
      "3560 ('with', 'ADP')\n",
      "3561 ('a', 'DET')\n",
      "3562 ('thick', 'ADJ')\n",
      "3563 ('neck', 'NOUN')\n",
      "3564 ('and', 'CONJ')\n",
      "3565 ('a', 'DET')\n",
      "3566 ('coarse', 'ADJ')\n",
      "3567 (',', '')\n",
      "3568 ('humorous', 'ADJ')\n",
      "3569 (',', '')\n",
      "3570 ('brutal', 'ADJ')\n",
      "3571 ('face', 'NOUN')\n",
      "3572 ('.', '')\n",
      "3573 ('In', 'ADP')\n",
      "3574 ('spite', 'NOUN')\n",
      "3575 ('of', 'ADP')\n",
      "3576 ('his', 'DET')\n",
      "3577 ('formidable', 'ADJ')\n",
      "3578 ('appearance', 'NOUN')\n",
      "3579 ('he', 'PRON')\n",
      "3580 ('had', 'VERB')\n",
      "3581 ('a', 'DET')\n",
      "3582 ('certain', 'DET')\n",
      "3583 ('charm', 'NOUN')\n",
      "3584 ('of', 'ADP')\n",
      "3585 ('manner', 'NOUN')\n",
      "3586 ('.', '')\n",
      "3587 ('He', 'PRON')\n",
      "3588 ('had', 'VERB')\n",
      "3589 ('a', 'DET')\n",
      "3590 ('trick', 'NOUN')\n",
      "3591 ('of', 'ADP')\n",
      "3592 ('resettling', 'VERB')\n",
      "3593 ('his', 'DET')\n",
      "3594 ('spectacles', 'NOUN')\n",
      "3595 ('on', 'ADP')\n",
      "3596 ('his', 'DET')\n",
      "3597 ('nose', 'NOUN')\n",
      "3598 ('which', 'PRON')\n",
      "3599 ('was', 'VERB')\n",
      "3600 ('curiously', 'ADV')\n",
      "3601 ('disarming', 'ADJ')\n",
      "3602 ('-', '')\n",
      "3603 ('in', 'ADP')\n",
      "3604 ('some', 'DET')\n",
      "3605 ('indefinable', 'ADJ')\n",
      "3606 ('way', 'NOUN')\n",
      "3607 (',', '')\n",
      "3608 ('curiously', 'ADV')\n",
      "3609 ('civilized', 'ADJ')\n",
      "3610 ('.', '')\n",
      "3611 ('It', 'PRON')\n",
      "3612 ('was', 'VERB')\n",
      "3613 ('a', 'DET')\n",
      "3614 ('gesture', 'NOUN')\n",
      "3615 ('which', 'PRON')\n",
      "3616 (',', '')\n",
      "3617 ('if', 'CONJ')\n",
      "3618 ('anyone', 'PRON')\n",
      "3619 ('had', 'VERB')\n",
      "3620 ('still', 'ADV')\n",
      "3621 ('thought', 'VERB')\n",
      "3622 ('in', 'ADP')\n",
      "3623 ('such', 'DET')\n",
      "3624 ('terms', 'NOUN')\n",
      "3625 (',', '')\n",
      "3626 ('might', 'VERB')\n",
      "3627 ('have', 'VERB')\n",
      "3628 ('recalled', 'VERB')\n",
      "3629 ('an', 'DET')\n",
      "3630 ('eighteenth-century', 'ADJ')\n",
      "3631 ('nobleman', 'NOUN')\n",
      "3632 ('offering', 'VERB')\n",
      "3633 ('his', 'DET')\n",
      "3634 ('snuffbox', 'NOUN')\n",
      "3635 ('.', '')\n",
      "3636 ('Winston', 'NOUN')\n",
      "3637 ('had', 'VERB')\n",
      "3638 ('seen', 'VERB')\n",
      "3639 (\"O'Brien\", 'NOUN')\n",
      "3640 ('perhaps', 'ADV')\n",
      "3641 ('a', 'DET')\n",
      "3642 ('dozen', 'NOUN')\n",
      "3643 ('times', 'NOUN')\n",
      "3644 ('in', 'ADP')\n",
      "3645 ('almost', 'ADV')\n",
      "3646 ('as', 'CONJ')\n",
      "3647 ('many', 'DET')\n",
      "3648 ('years', 'NOUN')\n",
      "3649 ('.', '')\n",
      "3650 ('He', 'PRON')\n",
      "3651 ('felt', 'VERB')\n",
      "3652 ('deeply', 'ADV')\n",
      "3653 ('drawn', 'VERB')\n",
      "3654 ('to', 'ADP')\n",
      "3655 ('him', 'PRON')\n",
      "3656 (',', '')\n",
      "3657 ('and', 'CONJ')\n",
      "3658 ('not', 'ADV')\n",
      "3659 ('solely', 'ADV')\n",
      "3660 ('because', 'CONJ')\n",
      "3661 ('he', 'PRON')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3662 ('was', 'VERB')\n",
      "3663 ('intrigued', 'VERB')\n",
      "3664 ('by', 'ADP')\n",
      "3665 ('the', 'DET')\n",
      "3666 ('contrast', 'NOUN')\n",
      "3667 ('between', 'ADP')\n",
      "3668 (\"O'Brien\", 'NOUN')\n",
      "3669 (\"'s\", 'ADP')\n",
      "3670 ('urbane', 'ADJ')\n",
      "3671 ('manner', 'NOUN')\n",
      "3672 ('and', 'CONJ')\n",
      "3673 ('his', 'DET')\n",
      "3674 ('prize-fighter', 'NOUN')\n",
      "3675 (\"'s\", 'ADP')\n",
      "3676 ('physique', 'NOUN')\n",
      "3677 ('.', '')\n",
      "3678 ('Much', 'ADV')\n",
      "3679 ('more', 'ADV')\n",
      "3680 ('it', 'PRON')\n",
      "3681 ('was', 'VERB')\n",
      "3682 ('because', 'CONJ')\n",
      "3683 ('of', 'ADP')\n",
      "3684 ('a', 'DET')\n",
      "3685 ('secretly', 'ADV')\n",
      "3686 ('held', 'ADJ')\n",
      "3687 ('belief', 'NOUN')\n",
      "3688 ('-', '')\n",
      "3689 ('or', 'CONJ')\n",
      "3690 ('perhaps', 'ADV')\n",
      "3691 ('not', 'ADV')\n",
      "3692 ('even', 'ADV')\n",
      "3693 ('a', 'DET')\n",
      "3694 ('belief', 'NOUN')\n",
      "3695 (',', '')\n",
      "3696 ('merely', 'ADV')\n",
      "3697 ('a', 'DET')\n",
      "3698 ('hope', 'NOUN')\n",
      "3699 ('-', '')\n",
      "3700 ('that', 'CONJ')\n",
      "3701 (\"O'Brien\", 'NOUN')\n",
      "3702 (\"'s\", 'ADP')\n",
      "3703 ('political', 'ADJ')\n",
      "3704 ('orthodoxy', 'NOUN')\n",
      "3705 ('was', 'VERB')\n",
      "3706 ('not', 'ADV')\n",
      "3707 ('perfect', 'ADJ')\n",
      "3708 ('.', '')\n",
      "3709 ('Something', 'PRON')\n",
      "3710 ('in', 'ADP')\n",
      "3711 ('his', 'DET')\n",
      "3712 ('face', 'NOUN')\n",
      "3713 ('suggested', 'VERB')\n",
      "3714 ('it', 'PRON')\n",
      "3715 ('irresistibly', 'ADV')\n",
      "3716 ('.', '')\n",
      "3717 ('And', 'CONJ')\n",
      "3718 ('again', 'ADV')\n",
      "3719 (',', '')\n",
      "3720 ('perhaps', 'ADV')\n",
      "3721 ('it', 'PRON')\n",
      "3722 ('was', 'VERB')\n",
      "3723 ('not', 'ADV')\n",
      "3724 ('even', 'ADV')\n",
      "3725 ('unorthodoxy', 'NOUN')\n",
      "3726 ('that', 'PRON')\n",
      "3727 ('was', 'VERB')\n",
      "3728 ('written', 'VERB')\n",
      "3729 ('in', 'ADP')\n",
      "3730 ('his', 'DET')\n",
      "3731 ('face', 'NOUN')\n",
      "3732 (',', '')\n",
      "3733 ('but', 'CONJ')\n",
      "3734 ('simply', 'ADV')\n",
      "3735 ('intelligence', 'NOUN')\n",
      "3736 ('.', '')\n",
      "3737 ('But', 'CONJ')\n",
      "3738 ('at', 'ADP')\n",
      "3739 ('any', 'DET')\n",
      "3740 ('rate', 'NOUN')\n",
      "3741 ('he', 'PRON')\n",
      "3742 ('had', 'VERB')\n",
      "3743 ('the', 'DET')\n",
      "3744 ('appearance', 'NOUN')\n",
      "3745 ('of', 'ADP')\n",
      "3746 ('being', 'VERB')\n",
      "3747 ('a', 'DET')\n",
      "3748 ('person', 'NOUN')\n",
      "3749 ('that', 'PRON')\n",
      "3750 ('you', 'PRON')\n",
      "3751 ('could', 'VERB')\n",
      "3752 ('talk', 'VERB')\n",
      "3753 ('to', 'ADP')\n",
      "3754 ('if', 'CONJ')\n",
      "3755 ('somehow', 'ADV')\n",
      "3756 ('you', 'PRON')\n",
      "3757 ('could', 'VERB')\n",
      "3758 ('cheat', 'VERB')\n",
      "3759 ('the', 'DET')\n",
      "3760 ('telescreen', 'NOUN')\n",
      "3761 ('and', 'CONJ')\n",
      "3762 ('get', 'VERB')\n",
      "3763 ('him', 'PRON')\n",
      "3764 ('alone', 'ADJ')\n",
      "3765 ('.', '')\n",
      "3766 ('Winston', 'NOUN')\n",
      "3767 ('had', 'VERB')\n",
      "3768 ('never', 'ADV')\n",
      "3769 ('made', 'VERB')\n",
      "3770 ('the', 'DET')\n",
      "3771 ('smallest', 'ADJ')\n",
      "3772 ('effort', 'NOUN')\n",
      "3773 ('to', 'ADP')\n",
      "3774 ('verify', 'VERB')\n",
      "3775 ('this', 'DET')\n",
      "3776 ('guess', 'NOUN')\n",
      "3777 (':', '')\n",
      "3778 ('indeed', 'ADV')\n",
      "3779 (',', '')\n",
      "3780 ('there', 'PRON')\n",
      "3781 ('was', 'VERB')\n",
      "3782 ('no', 'DET')\n",
      "3783 ('way', 'NOUN')\n",
      "3784 ('of', 'ADP')\n",
      "3785 ('doing', 'VERB')\n",
      "3786 ('so', 'ADV')\n",
      "3787 ('.', '')\n",
      "3788 ('At', 'ADP')\n",
      "3789 ('this', 'DET')\n",
      "3790 ('moment', 'NOUN')\n",
      "3791 (\"O'Brien\", 'NOUN')\n",
      "3792 ('glanced', 'VERB')\n",
      "3793 ('at', 'ADP')\n",
      "3794 ('his', 'DET')\n",
      "3795 ('wrist-watch', 'NOUN')\n",
      "3796 (',', '')\n",
      "3797 ('saw', 'VERB')\n",
      "3798 ('that', 'CONJ')\n",
      "3799 ('it', 'PRON')\n",
      "3800 ('was', 'VERB')\n",
      "3801 ('nearly', 'ADV')\n",
      "3802 ('eleven', 'NUM')\n",
      "3803 ('hundred', 'NUM')\n",
      "3804 (',', '')\n",
      "3805 ('and', 'CONJ')\n",
      "3806 ('evidently', 'ADV')\n",
      "3807 ('decided', 'VERB')\n",
      "3808 ('to', 'ADP')\n",
      "3809 ('stay', 'VERB')\n",
      "3810 ('in', 'ADP')\n",
      "3811 ('the', 'DET')\n",
      "3812 ('Records', 'NOUN')\n",
      "3813 ('Department', 'NOUN')\n",
      "3814 ('until', 'CONJ')\n",
      "3815 ('the', 'DET')\n",
      "3816 ('Two', 'NUM')\n",
      "3817 ('Minutes', 'NOUN')\n",
      "3818 ('Hate', 'NOUN')\n",
      "3819 ('was', 'VERB')\n",
      "3820 ('over', 'ADJ')\n",
      "3821 ('.', '')\n",
      "3822 ('He', 'PRON')\n",
      "3823 ('took', 'VERB')\n",
      "3824 ('a', 'DET')\n",
      "3825 ('chair', 'NOUN')\n",
      "3826 ('in', 'ADP')\n",
      "3827 ('the', 'DET')\n",
      "3828 ('same', 'ADJ')\n",
      "3829 ('row', 'NOUN')\n",
      "3830 ('as', 'ADP')\n",
      "3831 ('Winston', 'NOUN')\n",
      "3832 (',', '')\n",
      "3833 ('a', 'DET')\n",
      "3834 ('couple', 'NOUN')\n",
      "3835 ('of', 'ADP')\n",
      "3836 ('places', 'NOUN')\n",
      "3837 ('away', 'ADV')\n",
      "3838 ('.', '')\n",
      "3839 ('A', 'DET')\n",
      "3840 ('small', 'ADJ')\n",
      "3841 (',', '')\n",
      "3842 ('sandy-haired', 'ADJ')\n",
      "3843 ('woman', 'NOUN')\n",
      "3844 ('who', 'PRON')\n",
      "3845 ('worked', 'VERB')\n",
      "3846 ('in', 'ADP')\n",
      "3847 ('the', 'DET')\n",
      "3848 ('next', 'ADJ')\n",
      "3849 ('cubicle', 'NOUN')\n",
      "3850 ('to', 'ADP')\n",
      "3851 ('Winston', 'NOUN')\n",
      "3852 ('was', 'VERB')\n",
      "3853 ('between', 'ADP')\n",
      "3854 ('them', 'PRON')\n",
      "3855 ('.', '')\n",
      "3856 ('The', 'DET')\n",
      "3857 ('girl', 'NOUN')\n",
      "3858 ('with', 'ADP')\n",
      "3859 ('dark', 'ADJ')\n",
      "3860 ('hair', 'NOUN')\n",
      "3861 ('was', 'VERB')\n",
      "3862 ('sitting', 'VERB')\n",
      "3863 ('immediately', 'ADV')\n",
      "3864 ('behind', 'ADV')\n",
      "3865 ('.', '')\n",
      "3866 ('The', 'DET')\n",
      "3867 ('next', 'ADJ')\n",
      "3868 ('moment', 'NOUN')\n",
      "3869 ('a', 'DET')\n",
      "3870 ('hideous', 'ADJ')\n",
      "3871 (',', '')\n",
      "3872 ('grinding', 'VERB')\n",
      "3873 ('speech', 'NOUN')\n",
      "3874 (',', '')\n",
      "3875 ('as', 'CONJ')\n",
      "3876 ('of', 'ADP')\n",
      "3877 ('some', 'DET')\n",
      "3878 ('monstrous', 'ADJ')\n",
      "3879 ('machine', 'NOUN')\n",
      "3880 ('running', 'VERB')\n",
      "3881 ('without', 'ADP')\n",
      "3882 ('oil', 'NOUN')\n",
      "3883 (',', '')\n",
      "3884 ('burst', 'VERB')\n",
      "3885 ('from', 'ADP')\n",
      "3886 ('the', 'DET')\n",
      "3887 ('big', 'ADJ')\n",
      "3888 ('telescreen', 'NOUN')\n",
      "3889 ('at', 'ADP')\n",
      "3890 ('the', 'DET')\n",
      "3891 ('end', 'NOUN')\n",
      "3892 ('of', 'ADP')\n",
      "3893 ('the', 'DET')\n",
      "3894 ('room', 'NOUN')\n",
      "3895 ('.', '')\n",
      "3896 ('It', 'PRON')\n",
      "3897 ('was', 'VERB')\n",
      "3898 ('a', 'DET')\n",
      "3899 ('noise', 'NOUN')\n",
      "3900 ('that', 'PRON')\n",
      "3901 ('set', 'VERB')\n",
      "3902 ('one', 'PRON')\n",
      "3903 (\"'s\", 'ADP')\n",
      "3904 ('teeth', 'NOUN')\n",
      "3905 ('on', 'ADP')\n",
      "3906 ('edge', 'NOUN')\n",
      "3907 ('and', 'CONJ')\n",
      "3908 ('bristled', 'VERB')\n",
      "3909 ('the', 'DET')\n",
      "3910 ('hair', 'NOUN')\n",
      "3911 ('at', 'ADP')\n",
      "3912 ('the', 'DET')\n",
      "3913 ('back', 'NOUN')\n",
      "3914 ('of', 'ADP')\n",
      "3915 ('one', 'PRON')\n",
      "3916 (\"'s\", 'ADP')\n",
      "3917 ('neck', 'NOUN')\n",
      "3918 ('.', '')\n",
      "3919 ('The', 'DET')\n",
      "3920 ('Hate', 'NOUN')\n",
      "3921 ('had', 'VERB')\n",
      "3922 ('started', 'VERB')\n",
      "3923 ('.', '')\n",
      "3924 ('As', 'CONJ')\n",
      "3925 ('usual', 'ADJ')\n",
      "3926 (',', '')\n",
      "3927 ('the', 'DET')\n",
      "3928 ('face', 'NOUN')\n",
      "3929 ('of', 'ADP')\n",
      "3930 ('Emmanuel', 'NOUN')\n",
      "3931 ('Goldstein', 'NOUN')\n",
      "3932 (',', '')\n",
      "3933 ('the', 'DET')\n",
      "3934 ('Enemy', 'NOUN')\n",
      "3935 ('of', 'ADP')\n",
      "3936 ('the', 'DET')\n",
      "3937 ('People', 'NOUN')\n",
      "3938 (',', '')\n",
      "3939 ('had', 'VERB')\n",
      "3940 ('flashed', 'VERB')\n",
      "3941 ('on', 'ADP')\n",
      "3942 ('to', 'ADP')\n",
      "3943 ('the', 'DET')\n",
      "3944 ('screen', 'NOUN')\n",
      "3945 ('.', '')\n",
      "3946 ('There', 'PRON')\n",
      "3947 ('were', 'VERB')\n",
      "3948 ('hisses', 'NOUN')\n",
      "3949 ('here', 'ADV')\n",
      "3950 ('and', 'CONJ')\n",
      "3951 ('there', 'ADV')\n",
      "3952 ('among', 'ADP')\n",
      "3953 ('the', 'DET')\n",
      "3954 ('audience', 'NOUN')\n",
      "3955 ('.', '')\n",
      "3956 ('The', 'DET')\n",
      "3957 ('little', 'ADJ')\n",
      "3958 ('sandy-haired', 'ADJ')\n",
      "3959 ('woman', 'NOUN')\n",
      "3960 ('gave', 'VERB')\n",
      "3961 ('a', 'DET')\n",
      "3962 ('squeak', 'NOUN')\n",
      "3963 ('of', 'ADP')\n",
      "3964 ('mingled', 'ADJ')\n",
      "3965 ('fear', 'NOUN')\n",
      "3966 ('and', 'CONJ')\n",
      "3967 ('disgust', 'NOUN')\n",
      "3968 ('.', '')\n",
      "3969 ('Goldstein', 'NOUN')\n",
      "3970 ('was', 'VERB')\n",
      "3971 ('the', 'DET')\n",
      "3972 ('renegade', 'NOUN')\n",
      "3973 ('and', 'CONJ')\n",
      "3974 ('backslider', 'NOUN')\n",
      "3975 ('who', 'PRON')\n",
      "3976 ('once', 'ADV')\n",
      "3977 (',', '')\n",
      "3978 ('long', 'ADV')\n",
      "3979 ('ago', 'ADP')\n",
      "3980 ('(', '')\n",
      "3981 ('how', 'ADV')\n",
      "3982 ('long', 'ADV')\n",
      "3983 ('ago', 'ADP')\n",
      "3984 (',', '')\n",
      "3985 ('nobody', 'PRON')\n",
      "3986 ('quite', 'ADV')\n",
      "3987 ('remembered', 'VERB')\n",
      "3988 (')', '')\n",
      "3989 (',', '')\n",
      "3990 ('had', 'VERB')\n",
      "3991 ('been', 'VERB')\n",
      "3992 ('one', 'PRON')\n",
      "3993 ('of', 'ADP')\n",
      "3994 ('the', 'DET')\n",
      "3995 ('leading', 'ADJ')\n",
      "3996 ('figures', 'NOUN')\n",
      "3997 ('of', 'ADP')\n",
      "3998 ('the', 'DET')\n",
      "3999 ('Party', 'NOUN')\n",
      "4000 (',', '')\n",
      "4001 ('almost', 'ADV')\n",
      "4002 ('on', 'ADP')\n",
      "4003 ('a', 'DET')\n",
      "4004 ('level', 'NOUN')\n",
      "4005 ('with', 'ADP')\n",
      "4006 ('Big', 'ADJ')\n",
      "4007 ('Brother', 'NOUN')\n",
      "4008 ('himself', 'PRON')\n",
      "4009 (',', '')\n",
      "4010 ('and', 'CONJ')\n",
      "4011 ('then', 'ADV')\n",
      "4012 ('had', 'VERB')\n",
      "4013 ('engaged', 'VERB')\n",
      "4014 ('in', 'ADP')\n",
      "4015 ('counter-revolutionary', 'ADJ')\n",
      "4016 ('activities', 'NOUN')\n",
      "4017 (',', '')\n",
      "4018 ('had', 'VERB')\n",
      "4019 ('been', 'VERB')\n",
      "4020 ('condemned', 'VERB')\n",
      "4021 ('to', 'ADP')\n",
      "4022 ('death', 'NOUN')\n",
      "4023 (',', '')\n",
      "4024 ('and', 'CONJ')\n",
      "4025 ('had', 'VERB')\n",
      "4026 ('mysteriously', 'ADV')\n",
      "4027 ('escaped', 'VERB')\n",
      "4028 ('and', 'CONJ')\n",
      "4029 ('disappeared', 'VERB')\n",
      "4030 ('.', '')\n",
      "4031 ('The', 'DET')\n",
      "4032 ('programmes', 'NOUN')\n",
      "4033 ('of', 'ADP')\n",
      "4034 ('the', 'DET')\n",
      "4035 ('Two', 'NUM')\n",
      "4036 ('Minutes', 'NOUN')\n",
      "4037 ('Hate', 'NOUN')\n",
      "4038 ('varied', 'VERB')\n",
      "4039 ('from', 'ADP')\n",
      "4040 ('day', 'NOUN')\n",
      "4041 ('to', 'ADP')\n",
      "4042 ('day', 'NOUN')\n",
      "4043 (',', '')\n",
      "4044 ('but', 'CONJ')\n",
      "4045 ('there', 'PRON')\n",
      "4046 ('was', 'VERB')\n",
      "4047 ('none', 'PRON')\n",
      "4048 ('in', 'ADP')\n",
      "4049 ('which', 'PRON')\n",
      "4050 ('Goldstein', 'NOUN')\n",
      "4051 ('was', 'VERB')\n",
      "4052 ('not', 'ADV')\n",
      "4053 ('the', 'DET')\n",
      "4054 ('principal', 'ADJ')\n",
      "4055 ('figure', 'NOUN')\n",
      "4056 ('.', '')\n",
      "4057 ('He', 'PRON')\n",
      "4058 ('was', 'VERB')\n",
      "4059 ('the', 'DET')\n",
      "4060 ('primal', 'ADJ')\n",
      "4061 ('traitor', 'NOUN')\n",
      "4062 (',', '')\n",
      "4063 ('the', 'DET')\n",
      "4064 ('earliest', 'ADJ')\n",
      "4065 ('defiler', 'NOUN')\n",
      "4066 ('of', 'ADP')\n",
      "4067 ('the', 'DET')\n",
      "4068 ('Party', 'NOUN')\n",
      "4069 (\"'s\", 'ADP')\n",
      "4070 ('purity', 'NOUN')\n",
      "4071 ('.', '')\n",
      "4072 ('All', 'DET')\n",
      "4073 ('subsequent', 'ADJ')\n",
      "4074 ('crimes', 'NOUN')\n",
      "4075 ('against', 'ADP')\n",
      "4076 ('the', 'DET')\n",
      "4077 ('Party', 'NOUN')\n",
      "4078 (',', '')\n",
      "4079 ('all', 'DET')\n",
      "4080 ('treacheries', 'NOUN')\n",
      "4081 (',', '')\n",
      "4082 ('acts', 'NOUN')\n",
      "4083 ('of', 'ADP')\n",
      "4084 ('sabotage', 'NOUN')\n",
      "4085 (',', '')\n",
      "4086 ('heresies', 'NOUN')\n",
      "4087 (',', '')\n",
      "4088 ('deviations', 'NOUN')\n",
      "4089 (',', '')\n",
      "4090 ('sprang', 'VERB')\n",
      "4091 ('directly', 'ADV')\n",
      "4092 ('out', 'ADP')\n",
      "4093 ('of', 'ADP')\n",
      "4094 ('his', 'DET')\n",
      "4095 ('teaching', 'NOUN')\n",
      "4096 ('.', '')\n",
      "4097 ('Somewhere', 'ADV')\n",
      "4098 ('or', 'CONJ')\n",
      "4099 ('other', 'DET')\n",
      "4100 ('he', 'PRON')\n",
      "4101 ('was', 'VERB')\n",
      "4102 ('still', 'ADV')\n",
      "4103 ('alive', 'ADJ')\n",
      "4104 ('and', 'CONJ')\n",
      "4105 ('hatching', 'VERB')\n",
      "4106 ('his', 'DET')\n",
      "4107 ('conspiracies', 'NOUN')\n",
      "4108 (':', '')\n",
      "4109 ('perhaps', 'ADV')\n",
      "4110 ('somewhere', 'ADV')\n",
      "4111 ('beyond', 'ADP')\n",
      "4112 ('the', 'DET')\n",
      "4113 ('sea', 'NOUN')\n",
      "4114 (',', '')\n",
      "4115 ('under', 'ADP')\n",
      "4116 ('the', 'DET')\n",
      "4117 ('protection', 'NOUN')\n",
      "4118 ('of', 'ADP')\n",
      "4119 ('his', 'DET')\n",
      "4120 ('foreign', 'ADJ')\n",
      "4121 ('paymasters', 'NOUN')\n",
      "4122 (',', '')\n",
      "4123 ('perhaps', 'ADV')\n",
      "4124 ('even', 'ADV')\n",
      "4125 ('-', '')\n",
      "4126 ('so', 'CONJ')\n",
      "4127 ('it', 'PRON')\n",
      "4128 ('was', 'VERB')\n",
      "4129 ('occasionally', 'ADV')\n",
      "4130 ('rumoured', 'VERB')\n",
      "4131 ('-', '')\n",
      "4132 ('in', 'ADP')\n",
      "4133 ('some', 'DET')\n",
      "4134 ('hiding-place', 'NOUN')\n",
      "4135 ('in', 'ADP')\n",
      "4136 ('Oceania', 'NOUN')\n",
      "4137 ('itself', 'PRON')\n",
      "4138 ('.', '')\n",
      "4139 ('Winston', 'NOUN')\n",
      "4140 (\"'s\", 'ADP')\n",
      "4141 ('diaphragm', 'NOUN')\n",
      "4142 ('was', 'VERB')\n",
      "4143 ('constricted', 'VERB')\n",
      "4144 ('.', '')\n",
      "4145 ('He', 'PRON')\n",
      "4146 ('could', 'VERB')\n",
      "4147 ('never', 'ADV')\n",
      "4148 ('see', 'VERB')\n",
      "4149 ('the', 'DET')\n",
      "4150 ('face', 'NOUN')\n",
      "4151 ('of', 'ADP')\n",
      "4152 ('Goldstein', 'NOUN')\n",
      "4153 ('without', 'ADP')\n",
      "4154 ('a', 'DET')\n",
      "4155 ('painful', 'ADJ')\n",
      "4156 ('mixture', 'NOUN')\n",
      "4157 ('of', 'ADP')\n",
      "4158 ('emotions', 'NOUN')\n",
      "4159 ('.', '')\n",
      "4160 ('It', 'PRON')\n",
      "4161 ('was', 'VERB')\n",
      "4162 ('a', 'DET')\n",
      "4163 ('lean', 'ADJ')\n",
      "4164 ('Jewish', 'ADJ')\n",
      "4165 ('face', 'NOUN')\n",
      "4166 (',', '')\n",
      "4167 ('with', 'ADP')\n",
      "4168 ('a', 'DET')\n",
      "4169 ('great', 'ADJ')\n",
      "4170 ('fuzzy', 'ADJ')\n",
      "4171 ('aureole', 'NOUN')\n",
      "4172 ('of', 'ADP')\n",
      "4173 ('white', 'ADJ')\n",
      "4174 ('hair', 'NOUN')\n",
      "4175 ('and', 'CONJ')\n",
      "4176 ('a', 'DET')\n",
      "4177 ('small', 'ADJ')\n",
      "4178 ('goatee', 'NOUN')\n",
      "4179 ('beard', 'NOUN')\n",
      "4180 ('-', '')\n",
      "4181 ('a', 'DET')\n",
      "4182 ('clever', 'ADJ')\n",
      "4183 ('face', 'NOUN')\n",
      "4184 (',', '')\n",
      "4185 ('and', 'CONJ')\n",
      "4186 ('yet', 'CONJ')\n",
      "4187 ('somehow', 'ADV')\n",
      "4188 ('inherently', 'ADV')\n",
      "4189 ('despicable', 'ADJ')\n",
      "4190 (',', '')\n",
      "4191 ('with', 'ADP')\n",
      "4192 ('a', 'DET')\n",
      "4193 ('kind', 'NOUN')\n",
      "4194 ('of', 'ADP')\n",
      "4195 ('senile', 'ADJ')\n",
      "4196 ('silliness', 'NOUN')\n",
      "4197 ('in', 'ADP')\n",
      "4198 ('the', 'DET')\n",
      "4199 ('long', 'ADJ')\n",
      "4200 ('thin', 'ADJ')\n",
      "4201 ('nose', 'NOUN')\n",
      "4202 (',', '')\n",
      "4203 ('near', 'ADP')\n",
      "4204 ('the', 'DET')\n",
      "4205 ('end', 'NOUN')\n",
      "4206 ('of', 'ADP')\n",
      "4207 ('which', 'PRON')\n",
      "4208 ('a', 'DET')\n",
      "4209 ('pair', 'NOUN')\n",
      "4210 ('of', 'ADP')\n",
      "4211 ('spectacles', 'NOUN')\n",
      "4212 ('was', 'VERB')\n",
      "4213 ('perched', 'VERB')\n",
      "4214 ('.', '')\n",
      "4215 ('It', 'PRON')\n",
      "4216 ('resembled', 'VERB')\n",
      "4217 ('the', 'DET')\n",
      "4218 ('face', 'NOUN')\n",
      "4219 ('of', 'ADP')\n",
      "4220 ('a', 'DET')\n",
      "4221 ('sheep', 'NOUN')\n",
      "4222 (',', '')\n",
      "4223 ('and', 'CONJ')\n",
      "4224 ('the', 'DET')\n",
      "4225 ('voice', 'NOUN')\n",
      "4226 (',', '')\n",
      "4227 ('too', 'ADV')\n",
      "4228 (',', '')\n",
      "4229 ('had', 'VERB')\n",
      "4230 ('a', 'DET')\n",
      "4231 ('sheep-like', 'ADJ')\n",
      "4232 ('quality', 'NOUN')\n",
      "4233 ('.', '')\n",
      "4234 ('Goldstein', 'NOUN')\n",
      "4235 ('was', 'VERB')\n",
      "4236 ('delivering', 'VERB')\n",
      "4237 ('his', 'DET')\n",
      "4238 ('usual', 'ADJ')\n",
      "4239 ('venomous', 'ADJ')\n",
      "4240 ('attack', 'NOUN')\n",
      "4241 ('upon', 'ADP')\n",
      "4242 ('the', 'DET')\n",
      "4243 ('doctrines', 'NOUN')\n",
      "4244 ('of', 'ADP')\n",
      "4245 ('the', 'DET')\n",
      "4246 ('Party', 'NOUN')\n",
      "4247 ('-', '')\n",
      "4248 ('an', 'DET')\n",
      "4249 ('attack', 'NOUN')\n",
      "4250 ('so', 'ADV')\n",
      "4251 ('exaggerated', 'ADJ')\n",
      "4252 ('and', 'CONJ')\n",
      "4253 ('perverse', 'ADJ')\n",
      "4254 ('that', 'CONJ')\n",
      "4255 ('a', 'DET')\n",
      "4256 ('child', 'NOUN')\n",
      "4257 ('should', 'VERB')\n",
      "4258 ('have', 'VERB')\n",
      "4259 ('been', 'VERB')\n",
      "4260 ('able', 'ADJ')\n",
      "4261 ('to', 'ADP')\n",
      "4262 ('see', 'VERB')\n",
      "4263 ('through', 'ADP')\n",
      "4264 ('it', 'PRON')\n",
      "4265 (',', '')\n",
      "4266 ('and', 'CONJ')\n",
      "4267 ('yet', 'CONJ')\n",
      "4268 ('just', 'ADV')\n",
      "4269 ('plausible', 'ADJ')\n",
      "4270 ('enough', 'ADV')\n",
      "4271 ('to', 'ADP')\n",
      "4272 ('fill', 'VERB')\n",
      "4273 ('one', 'PRON')\n",
      "4274 ('with', 'ADP')\n",
      "4275 ('an', 'DET')\n",
      "4276 ('alarmed', 'ADJ')\n",
      "4277 ('feeling', 'NOUN')\n",
      "4278 ('that', 'CONJ')\n",
      "4279 ('other', 'DET')\n",
      "4280 ('people', 'NOUN')\n",
      "4281 (',', '')\n",
      "4282 ('less', 'ADV')\n",
      "4283 ('level-headed', 'ADJ')\n",
      "4284 ('than', 'ADP')\n",
      "4285 ('oneself', 'PRON')\n",
      "4286 (',', '')\n",
      "4287 ('might', 'VERB')\n",
      "4288 ('be', 'VERB')\n",
      "4289 ('taken', 'VERB')\n",
      "4290 ('in', 'ADP')\n",
      "4291 ('by', 'ADP')\n",
      "4292 ('it', 'PRON')\n",
      "4293 ('.', '')\n",
      "4294 ('He', 'PRON')\n",
      "4295 ('was', 'VERB')\n",
      "4296 ('abusing', 'VERB')\n",
      "4297 ('Big', 'ADJ')\n",
      "4298 ('Brother', 'NOUN')\n",
      "4299 (',', '')\n",
      "4300 ('he', 'PRON')\n",
      "4301 ('was', 'VERB')\n",
      "4302 ('denouncing', 'VERB')\n",
      "4303 ('the', 'DET')\n",
      "4304 ('dictatorship', 'NOUN')\n",
      "4305 ('of', 'ADP')\n",
      "4306 ('the', 'DET')\n",
      "4307 ('Party', 'NOUN')\n",
      "4308 (',', '')\n",
      "4309 ('he', 'PRON')\n",
      "4310 ('was', 'VERB')\n",
      "4311 ('demanding', 'VERB')\n",
      "4312 ('the', 'DET')\n",
      "4313 ('immediate', 'ADJ')\n",
      "4314 ('conclusion', 'NOUN')\n",
      "4315 ('of', 'ADP')\n",
      "4316 ('peace', 'NOUN')\n",
      "4317 ('with', 'ADP')\n",
      "4318 ('Eurasia', 'NOUN')\n",
      "4319 (',', '')\n",
      "4320 ('he', 'PRON')\n",
      "4321 ('was', 'VERB')\n",
      "4322 ('advocating', 'VERB')\n",
      "4323 ('freedom', 'NOUN')\n",
      "4324 ('of', 'ADP')\n",
      "4325 ('speech', 'NOUN')\n",
      "4326 (',', '')\n",
      "4327 ('freedom', 'NOUN')\n",
      "4328 ('of', 'ADP')\n",
      "4329 ('the', 'DET')\n",
      "4330 ('Press', 'NOUN')\n",
      "4331 (',', '')\n",
      "4332 ('freedom', 'NOUN')\n",
      "4333 ('of', 'ADP')\n",
      "4334 ('assembly', 'NOUN')\n",
      "4335 (',', '')\n",
      "4336 ('freedom', 'NOUN')\n",
      "4337 ('of', 'ADP')\n",
      "4338 ('thought', 'NOUN')\n",
      "4339 (',', '')\n",
      "4340 ('he', 'PRON')\n",
      "4341 ('was', 'VERB')\n",
      "4342 ('crying', 'VERB')\n",
      "4343 ('hysterically', 'ADV')\n",
      "4344 ('that', 'CONJ')\n",
      "4345 ('the', 'DET')\n",
      "4346 ('revolution', 'NOUN')\n",
      "4347 ('had', 'VERB')\n",
      "4348 ('been', 'VERB')\n",
      "4349 ('betrayed', 'VERB')\n",
      "4350 ('-', '')\n",
      "4351 ('and', 'CONJ')\n",
      "4352 ('all', 'DET')\n",
      "4353 ('this', 'PRON')\n",
      "4354 ('in', 'ADP')\n",
      "4355 ('rapid', 'ADJ')\n",
      "4356 ('polysyllabic', 'ADJ')\n",
      "4357 ('speech', 'NOUN')\n",
      "4358 ('which', 'PRON')\n",
      "4359 ('was', 'VERB')\n",
      "4360 ('a', 'DET')\n",
      "4361 ('sort', 'NOUN')\n",
      "4362 ('of', 'ADP')\n",
      "4363 ('parody', 'NOUN')\n",
      "4364 ('of', 'ADP')\n",
      "4365 ('the', 'DET')\n",
      "4366 ('habitual', 'ADJ')\n",
      "4367 ('style', 'NOUN')\n",
      "4368 ('of', 'ADP')\n",
      "4369 ('the', 'DET')\n",
      "4370 ('orators', 'NOUN')\n",
      "4371 ('of', 'ADP')\n",
      "4372 ('the', 'DET')\n",
      "4373 ('Party', 'NOUN')\n",
      "4374 (',', '')\n",
      "4375 ('and', 'CONJ')\n",
      "4376 ('even', 'ADV')\n",
      "4377 ('contained', 'VERB')\n",
      "4378 ('Newspeak', 'ADJ')\n",
      "4379 ('words', 'NOUN')\n",
      "4380 (':', '')\n",
      "4381 ('more', 'ADV')\n",
      "4382 ('Newspeak', 'ADJ')\n",
      "4383 ('words', 'NOUN')\n",
      "4384 (',', '')\n",
      "4385 ('indeed', 'ADV')\n",
      "4386 (',', '')\n",
      "4387 ('than', 'CONJ')\n",
      "4388 ('any', 'DET')\n",
      "4389 ('Party', 'NOUN')\n",
      "4390 ('member', 'NOUN')\n",
      "4391 ('would', 'VERB')\n",
      "4392 ('normally', 'ADV')\n",
      "4393 ('use', 'VERB')\n",
      "4394 ('in', 'ADP')\n",
      "4395 ('real', 'ADJ')\n",
      "4396 ('life', 'NOUN')\n",
      "4397 ('.', '')\n",
      "4398 ('And', 'CONJ')\n",
      "4399 ('all', 'DET')\n",
      "4400 ('the', 'DET')\n",
      "4401 ('while', 'CONJ')\n",
      "4402 (',', '')\n",
      "4403 ('lest', 'CONJ')\n",
      "4404 ('one', 'PRON')\n",
      "4405 ('should', 'VERB')\n",
      "4406 ('be', 'VERB')\n",
      "4407 ('in', 'ADP')\n",
      "4408 ('any', 'DET')\n",
      "4409 ('doubt', 'NOUN')\n",
      "4410 ('as', 'CONJ')\n",
      "4411 ('to', 'ADP')\n",
      "4412 ('the', 'DET')\n",
      "4413 ('reality', 'NOUN')\n",
      "4414 ('which', 'PRON')\n",
      "4415 ('Goldstein', 'NOUN')\n",
      "4416 (\"'s\", 'ADP')\n",
      "4417 ('specious', 'ADJ')\n",
      "4418 ('claptrap', 'NOUN')\n",
      "4419 ('covered', 'VERB')\n",
      "4420 (',', '')\n",
      "4421 ('behind', 'ADP')\n",
      "4422 ('his', 'DET')\n",
      "4423 ('head', 'NOUN')\n",
      "4424 ('on', 'ADP')\n",
      "4425 ('the', 'DET')\n",
      "4426 ('telescreen', 'NOUN')\n",
      "4427 ('there', 'PRON')\n",
      "4428 ('marched', 'VERB')\n",
      "4429 ('the', 'DET')\n",
      "4430 ('endless', 'ADJ')\n",
      "4431 ('columns', 'NOUN')\n",
      "4432 ('of', 'ADP')\n",
      "4433 ('the', 'DET')\n",
      "4434 ('Eurasian', 'ADJ')\n",
      "4435 ('army', 'NOUN')\n",
      "4436 ('-', '')\n",
      "4437 ('row', 'NOUN')\n",
      "4438 ('after', 'ADP')\n",
      "4439 ('row', 'NOUN')\n",
      "4440 ('of', 'ADP')\n",
      "4441 ('solid-looking', 'ADJ')\n",
      "4442 ('men', 'NOUN')\n",
      "4443 ('with', 'ADP')\n",
      "4444 ('expressionless', 'ADJ')\n",
      "4445 ('Asiatic', 'ADJ')\n",
      "4446 ('faces', 'NOUN')\n",
      "4447 (',', '')\n",
      "4448 ('who', 'PRON')\n",
      "4449 ('swam', 'VERB')\n",
      "4450 ('up', 'ADP')\n",
      "4451 ('to', 'ADP')\n",
      "4452 ('the', 'DET')\n",
      "4453 ('surface', 'NOUN')\n",
      "4454 ('of', 'ADP')\n",
      "4455 ('the', 'DET')\n",
      "4456 ('screen', 'NOUN')\n",
      "4457 ('and', 'CONJ')\n",
      "4458 ('vanished', 'VERB')\n",
      "4459 (',', '')\n",
      "4460 ('to', 'ADP')\n",
      "4461 ('be', 'VERB')\n",
      "4462 ('replaced', 'VERB')\n",
      "4463 ('by', 'ADP')\n",
      "4464 ('others', 'PRON')\n",
      "4465 ('exactly', 'ADV')\n",
      "4466 ('similar', 'ADJ')\n",
      "4467 ('.', '')\n",
      "4468 ('The', 'DET')\n",
      "4469 ('dull', 'ADJ')\n",
      "4470 ('rhythmic', 'ADJ')\n",
      "4471 ('tramp', 'NOUN')\n",
      "4472 ('of', 'ADP')\n",
      "4473 ('the', 'DET')\n",
      "4474 ('soldiers', 'NOUN')\n",
      "4475 (\"'\", 'ADP')\n",
      "4476 ('boots', 'NOUN')\n",
      "4477 ('formed', 'VERB')\n",
      "4478 ('the', 'DET')\n",
      "4479 ('background', 'NOUN')\n",
      "4480 ('to', 'ADP')\n",
      "4481 ('Goldstein', 'NOUN')\n",
      "4482 (\"'s\", 'ADP')\n",
      "4483 ('bleating', 'ADJ')\n",
      "4484 ('voice', 'NOUN')\n",
      "4485 ('.', '')\n",
      "4486 ('Before', 'ADP')\n",
      "4487 ('the', 'DET')\n",
      "4488 ('Hate', 'NOUN')\n",
      "4489 ('had', 'VERB')\n",
      "4490 ('proceeded', 'VERB')\n",
      "4491 ('for', 'ADP')\n",
      "4492 ('thirty', 'NUM')\n",
      "4493 ('seconds', 'NOUN')\n",
      "4494 (',', '')\n",
      "4495 ('uncontrollable', 'ADJ')\n",
      "4496 ('exclamations', 'NOUN')\n",
      "4497 ('of', 'ADP')\n",
      "4498 ('rage', 'NOUN')\n",
      "4499 ('were', 'VERB')\n",
      "4500 ('breaking', 'VERB')\n",
      "4501 ('out', 'ADP')\n",
      "4502 ('from', 'ADP')\n",
      "4503 ('half', 'DET')\n",
      "4504 ('the', 'DET')\n",
      "4505 ('people', 'NOUN')\n",
      "4506 ('in', 'ADP')\n",
      "4507 ('the', 'DET')\n",
      "4508 ('room', 'NOUN')\n",
      "4509 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510 ('The', 'DET')\n",
      "4511 ('self-satisfied', 'ADJ')\n",
      "4512 ('sheep-like', 'ADJ')\n",
      "4513 ('face', 'NOUN')\n",
      "4514 ('on', 'ADP')\n",
      "4515 ('the', 'DET')\n",
      "4516 ('screen', 'NOUN')\n",
      "4517 (',', '')\n",
      "4518 ('and', 'CONJ')\n",
      "4519 ('the', 'DET')\n",
      "4520 ('terrifying', 'ADJ')\n",
      "4521 ('power', 'NOUN')\n",
      "4522 ('of', 'ADP')\n",
      "4523 ('the', 'DET')\n",
      "4524 ('Eurasian', 'ADJ')\n",
      "4525 ('army', 'NOUN')\n",
      "4526 ('behind', 'ADP')\n",
      "4527 ('it', 'PRON')\n",
      "4528 (',', '')\n",
      "4529 ('were', 'VERB')\n",
      "4530 ('too', 'ADV')\n",
      "4531 ('much', 'ADJ')\n",
      "4532 ('to', 'ADP')\n",
      "4533 ('be', 'VERB')\n",
      "4534 ('borne', 'VERB')\n",
      "4535 (':', '')\n",
      "4536 ('besides', 'CONJ')\n",
      "4537 (',', '')\n",
      "4538 ('the', 'DET')\n",
      "4539 ('sight', 'NOUN')\n",
      "4540 ('or', 'CONJ')\n",
      "4541 ('even', 'ADV')\n",
      "4542 ('the', 'DET')\n",
      "4543 ('thought', 'NOUN')\n",
      "4544 ('of', 'ADP')\n",
      "4545 ('Goldstein', 'NOUN')\n",
      "4546 ('produced', 'VERB')\n",
      "4547 ('fear', 'NOUN')\n",
      "4548 ('and', 'CONJ')\n",
      "4549 ('anger', 'NOUN')\n",
      "4550 ('automatically', 'ADV')\n",
      "4551 ('.', '')\n",
      "4552 ('He', 'PRON')\n",
      "4553 ('was', 'VERB')\n",
      "4554 ('an', 'DET')\n",
      "4555 ('object', 'NOUN')\n",
      "4556 ('of', 'ADP')\n",
      "4557 ('hatred', 'NOUN')\n",
      "4558 ('more', 'ADV')\n",
      "4559 ('constant', 'ADJ')\n",
      "4560 ('than', 'ADP')\n",
      "4561 ('either', 'CONJ')\n",
      "4562 ('Eurasia', 'NOUN')\n",
      "4563 ('or', 'CONJ')\n",
      "4564 ('Eastasia', 'NOUN')\n",
      "4565 (',', '')\n",
      "4566 ('since', 'CONJ')\n",
      "4567 ('when', 'CONJ')\n",
      "4568 ('Oceania', 'NOUN')\n",
      "4569 ('was', 'VERB')\n",
      "4570 ('at', 'ADP')\n",
      "4571 ('war', 'NOUN')\n",
      "4572 ('with', 'ADP')\n",
      "4573 ('one', 'PRON')\n",
      "4574 ('of', 'ADP')\n",
      "4575 ('these', 'DET')\n",
      "4576 ('Powers', 'NOUN')\n",
      "4577 ('it', 'PRON')\n",
      "4578 ('was', 'VERB')\n",
      "4579 ('generally', 'ADV')\n",
      "4580 ('at', 'ADP')\n",
      "4581 ('peace', 'NOUN')\n",
      "4582 ('with', 'ADP')\n",
      "4583 ('the', 'DET')\n",
      "4584 ('other', 'NOUN')\n",
      "4585 ('.', '')\n",
      "4586 ('But', 'CONJ')\n",
      "4587 ('what', 'PRON')\n",
      "4588 ('was', 'VERB')\n",
      "4589 ('strange', 'ADJ')\n",
      "4590 ('was', 'VERB')\n",
      "4591 ('that', 'CONJ')\n",
      "4592 ('although', 'CONJ')\n",
      "4593 ('Goldstein', 'NOUN')\n",
      "4594 ('was', 'VERB')\n",
      "4595 ('hated', 'VERB')\n",
      "4596 ('and', 'CONJ')\n",
      "4597 ('despised', 'VERB')\n",
      "4598 ('by', 'ADP')\n",
      "4599 ('everybody', 'PRON')\n",
      "4600 (',', '')\n",
      "4601 ('although', 'CONJ')\n",
      "4602 ('every', 'DET')\n",
      "4603 ('day', 'NOUN')\n",
      "4604 ('and', 'CONJ')\n",
      "4605 ('a', 'DET')\n",
      "4606 ('thousand', 'NUM')\n",
      "4607 ('times', 'NOUN')\n",
      "4608 ('a', 'DET')\n",
      "4609 ('day', 'NOUN')\n",
      "4610 (',', '')\n",
      "4611 ('on', 'ADP')\n",
      "4612 ('platforms', 'NOUN')\n",
      "4613 (',', '')\n",
      "4614 ('on', 'ADP')\n",
      "4615 ('the', 'DET')\n",
      "4616 ('telescreen', 'NOUN')\n",
      "4617 (',', '')\n",
      "4618 ('in', 'ADP')\n",
      "4619 ('newspapers', 'NOUN')\n",
      "4620 (',', '')\n",
      "4621 ('in', 'ADP')\n",
      "4622 ('books', 'NOUN')\n",
      "4623 (',', '')\n",
      "4624 ('his', 'DET')\n",
      "4625 ('theories', 'NOUN')\n",
      "4626 ('were', 'VERB')\n",
      "4627 ('refuted', 'VERB')\n",
      "4628 (',', '')\n",
      "4629 ('smashed', 'VERB')\n",
      "4630 (',', '')\n",
      "4631 ('ridiculed', 'VERB')\n",
      "4632 (',', '')\n",
      "4633 ('held', 'VERB')\n",
      "4634 ('up', 'ADP')\n",
      "4635 ('to', 'ADP')\n",
      "4636 ('the', 'DET')\n",
      "4637 ('general', 'ADJ')\n",
      "4638 ('gaze', 'NOUN')\n",
      "4639 ('for', 'ADP')\n",
      "4640 ('the', 'DET')\n",
      "4641 ('pitiful', 'ADJ')\n",
      "4642 ('rubbish', 'NOUN')\n",
      "4643 ('that', 'PRON')\n",
      "4644 ('they', 'PRON')\n",
      "4645 ('were', 'VERB')\n",
      "4646 ('in', 'ADP')\n",
      "4647 ('spite', 'NOUN')\n",
      "4648 ('of', 'ADP')\n",
      "4649 ('all', 'DET')\n",
      "4650 ('this', 'PRON')\n",
      "4651 (',', '')\n",
      "4652 ('his', 'DET')\n",
      "4653 ('influence', 'NOUN')\n",
      "4654 ('never', 'ADV')\n",
      "4655 ('seemed', 'VERB')\n",
      "4656 ('to', 'ADP')\n",
      "4657 ('grow', 'VERB')\n",
      "4658 ('less', 'ADV')\n",
      "4659 ('.', '')\n",
      "4660 ('Always', 'ADV')\n",
      "4661 ('there', 'PRON')\n",
      "4662 ('were', 'VERB')\n",
      "4663 ('fresh', 'ADJ')\n",
      "4664 ('dupes', 'NOUN')\n",
      "4665 ('waiting', 'VERB')\n",
      "4666 ('to', 'ADP')\n",
      "4667 ('be', 'VERB')\n",
      "4668 ('seduced', 'VERB')\n",
      "4669 ('by', 'ADP')\n",
      "4670 ('him', 'PRON')\n",
      "4671 ('.', '')\n",
      "4672 ('A', 'DET')\n",
      "4673 ('day', 'NOUN')\n",
      "4674 ('never', 'ADV')\n",
      "4675 ('passed', 'VERB')\n",
      "4676 ('when', 'CONJ')\n",
      "4677 ('spies', 'NOUN')\n",
      "4678 ('and', 'CONJ')\n",
      "4679 ('saboteurs', 'NOUN')\n",
      "4680 ('acting', 'VERB')\n",
      "4681 ('under', 'ADP')\n",
      "4682 ('his', 'DET')\n",
      "4683 ('directions', 'NOUN')\n",
      "4684 ('were', 'VERB')\n",
      "4685 ('not', 'ADV')\n",
      "4686 ('unmasked', 'VERB')\n",
      "4687 ('by', 'ADP')\n",
      "4688 ('the', 'DET')\n",
      "4689 ('Thought', 'NOUN')\n",
      "4690 ('Police', 'NOUN')\n",
      "4691 ('.', '')\n",
      "4692 ('He', 'PRON')\n",
      "4693 ('was', 'VERB')\n",
      "4694 ('the', 'DET')\n",
      "4695 ('commander', 'NOUN')\n",
      "4696 ('of', 'ADP')\n",
      "4697 ('a', 'DET')\n",
      "4698 ('vast', 'ADJ')\n",
      "4699 ('shadowy', 'ADJ')\n",
      "4700 ('army', 'NOUN')\n",
      "4701 (',', '')\n",
      "4702 ('an', 'DET')\n",
      "4703 ('underground', 'ADJ')\n",
      "4704 ('network', 'NOUN')\n",
      "4705 ('of', 'ADP')\n",
      "4706 ('conspirators', 'NOUN')\n",
      "4707 ('dedicated', 'VERB')\n",
      "4708 ('to', 'ADP')\n",
      "4709 ('the', 'DET')\n",
      "4710 ('overthrow', 'NOUN')\n",
      "4711 ('of', 'ADP')\n",
      "4712 ('the', 'DET')\n",
      "4713 ('State', 'NOUN')\n",
      "4714 ('.', '')\n",
      "4715 ('The', 'DET')\n",
      "4716 ('Brotherhood', 'NOUN')\n",
      "4717 (',', '')\n",
      "4718 ('its', 'DET')\n",
      "4719 ('name', 'NOUN')\n",
      "4720 ('was', 'VERB')\n",
      "4721 ('supposed', 'VERB')\n",
      "4722 ('to', 'ADP')\n",
      "4723 ('be', 'VERB')\n",
      "4724 ('.', '')\n",
      "4725 ('There', 'PRON')\n",
      "4726 ('were', 'VERB')\n",
      "4727 ('also', 'ADV')\n",
      "4728 ('whispered', 'ADJ')\n",
      "4729 ('stories', 'NOUN')\n",
      "4730 ('of', 'ADP')\n",
      "4731 ('a', 'DET')\n",
      "4732 ('terrible', 'ADJ')\n",
      "4733 ('book', 'NOUN')\n",
      "4734 (',', '')\n",
      "4735 ('a', 'DET')\n",
      "4736 ('compendium', 'NOUN')\n",
      "4737 ('of', 'ADP')\n",
      "4738 ('all', 'DET')\n",
      "4739 ('the', 'DET')\n",
      "4740 ('heresies', 'NOUN')\n",
      "4741 (',', '')\n",
      "4742 ('of', 'ADP')\n",
      "4743 ('which', 'PRON')\n",
      "4744 ('Goldstein', 'NOUN')\n",
      "4745 ('was', 'VERB')\n",
      "4746 ('the', 'DET')\n",
      "4747 ('author', 'NOUN')\n",
      "4748 ('and', 'CONJ')\n",
      "4749 ('which', 'PRON')\n",
      "4750 ('circulated', 'VERB')\n",
      "4751 ('clandestinely', 'ADV')\n",
      "4752 ('here', 'ADV')\n",
      "4753 ('and', 'CONJ')\n",
      "4754 ('there', 'ADV')\n",
      "4755 ('.', '')\n",
      "4756 ('It', 'PRON')\n",
      "4757 ('was', 'VERB')\n",
      "4758 ('a', 'DET')\n",
      "4759 ('book', 'NOUN')\n",
      "4760 ('without', 'ADP')\n",
      "4761 ('a', 'DET')\n",
      "4762 ('title', 'NOUN')\n",
      "4763 ('.', '')\n",
      "4764 ('People', 'NOUN')\n",
      "4765 ('referred', 'VERB')\n",
      "4766 ('to', 'ADP')\n",
      "4767 ('it', 'PRON')\n",
      "4768 (',', '')\n",
      "4769 ('if', 'CONJ')\n",
      "4770 ('at', 'ADP')\n",
      "4771 ('all', 'ADV')\n",
      "4772 (',', '')\n",
      "4773 ('simply', 'ADV')\n",
      "4774 ('as', 'ADP')\n",
      "4775 ('the', 'DET')\n",
      "4776 ('book', 'NOUN')\n",
      "4777 ('.', '')\n",
      "4778 ('But', 'CONJ')\n",
      "4779 ('one', 'PRON')\n",
      "4780 ('knew', 'VERB')\n",
      "4781 ('of', 'ADP')\n",
      "4782 ('such', 'DET')\n",
      "4783 ('things', 'NOUN')\n",
      "4784 ('only', 'ADV')\n",
      "4785 ('through', 'ADP')\n",
      "4786 ('vague', 'ADJ')\n",
      "4787 ('rumours', 'NOUN')\n",
      "4788 ('.', '')\n",
      "4789 ('Neither', 'CONJ')\n",
      "4790 ('the', 'DET')\n",
      "4791 ('Brotherhood', 'NOUN')\n",
      "4792 ('nor', 'CONJ')\n",
      "4793 ('the', 'DET')\n",
      "4794 ('book', 'NOUN')\n",
      "4795 ('was', 'VERB')\n",
      "4796 ('a', 'DET')\n",
      "4797 ('subject', 'NOUN')\n",
      "4798 ('that', 'PRON')\n",
      "4799 ('any', 'DET')\n",
      "4800 ('ordinary', 'ADJ')\n",
      "4801 ('Party', 'NOUN')\n",
      "4802 ('member', 'NOUN')\n",
      "4803 ('would', 'VERB')\n",
      "4804 ('mention', 'VERB')\n",
      "4805 ('if', 'CONJ')\n",
      "4806 ('there', 'PRON')\n",
      "4807 ('was', 'VERB')\n",
      "4808 ('a', 'DET')\n",
      "4809 ('way', 'NOUN')\n",
      "4810 ('of', 'ADP')\n",
      "4811 ('avoiding', 'VERB')\n",
      "4812 ('it', 'PRON')\n",
      "4813 ('.', '')\n",
      "4814 ('In', 'ADP')\n",
      "4815 ('its', 'DET')\n",
      "4816 ('second', 'NUM')\n",
      "4817 ('minute', 'NOUN')\n",
      "4818 ('the', 'DET')\n",
      "4819 ('Hate', 'NOUN')\n",
      "4820 ('rose', 'VERB')\n",
      "4821 ('to', 'ADP')\n",
      "4822 ('a', 'DET')\n",
      "4823 ('frenzy', 'NOUN')\n",
      "4824 ('.', '')\n",
      "4825 ('People', 'NOUN')\n",
      "4826 ('were', 'VERB')\n",
      "4827 ('leaping', 'VERB')\n",
      "4828 ('up', 'ADP')\n",
      "4829 ('and', 'CONJ')\n",
      "4830 ('down', 'ADV')\n",
      "4831 ('in', 'ADP')\n",
      "4832 ('their', 'DET')\n",
      "4833 ('places', 'NOUN')\n",
      "4834 ('and', 'CONJ')\n",
      "4835 ('shouting', 'VERB')\n",
      "4836 ('at', 'ADP')\n",
      "4837 ('the', 'DET')\n",
      "4838 ('tops', 'NOUN')\n",
      "4839 ('of', 'ADP')\n",
      "4840 ('their', 'DET')\n",
      "4841 ('voices', 'NOUN')\n",
      "4842 ('in', 'ADP')\n",
      "4843 ('an', 'DET')\n",
      "4844 ('effort', 'NOUN')\n",
      "4845 ('to', 'ADP')\n",
      "4846 ('drown', 'VERB')\n",
      "4847 ('the', 'DET')\n",
      "4848 ('maddening', 'ADJ')\n",
      "4849 ('bleating', 'ADJ')\n",
      "4850 ('voice', 'NOUN')\n",
      "4851 ('that', 'PRON')\n",
      "4852 ('came', 'VERB')\n",
      "4853 ('from', 'ADP')\n",
      "4854 ('the', 'DET')\n",
      "4855 ('screen', 'NOUN')\n",
      "4856 ('.', '')\n",
      "4857 ('The', 'DET')\n",
      "4858 ('little', 'ADJ')\n",
      "4859 ('sandy-haired', 'ADJ')\n",
      "4860 ('woman', 'NOUN')\n",
      "4861 ('had', 'VERB')\n",
      "4862 ('turned', 'VERB')\n",
      "4863 ('bright', 'ADJ')\n",
      "4864 ('pink', 'ADJ')\n",
      "4865 (',', '')\n",
      "4866 ('and', 'CONJ')\n",
      "4867 ('her', 'DET')\n",
      "4868 ('mouth', 'NOUN')\n",
      "4869 ('was', 'VERB')\n",
      "4870 ('opening', 'VERB')\n",
      "4871 ('and', 'CONJ')\n",
      "4872 ('shutting', 'VERB')\n",
      "4873 ('like', 'ADP')\n",
      "4874 ('that', 'PRON')\n",
      "4875 ('of', 'ADP')\n",
      "4876 ('a', 'DET')\n",
      "4877 ('landed', 'ADJ')\n",
      "4878 ('fish', 'NOUN')\n",
      "4879 ('.', '')\n",
      "4880 ('Even', 'ADV')\n",
      "4881 (\"O'Brien\", 'NOUN')\n",
      "4882 (\"'s\", 'ADP')\n",
      "4883 ('heavy', 'ADJ')\n",
      "4884 ('face', 'NOUN')\n",
      "4885 ('was', 'VERB')\n",
      "4886 ('flushed', 'ADJ')\n",
      "4887 ('.', '')\n",
      "4888 ('He', 'PRON')\n",
      "4889 ('was', 'VERB')\n",
      "4890 ('sitting', 'VERB')\n",
      "4891 ('very', 'ADV')\n",
      "4892 ('straight', 'ADV')\n",
      "4893 ('in', 'ADP')\n",
      "4894 ('his', 'DET')\n",
      "4895 ('chair', 'NOUN')\n",
      "4896 (',', '')\n",
      "4897 ('his', 'DET')\n",
      "4898 ('powerful', 'ADJ')\n",
      "4899 ('chest', 'NOUN')\n",
      "4900 ('swelling', 'VERB')\n",
      "4901 ('and', 'CONJ')\n",
      "4902 ('quivering', 'VERB')\n",
      "4903 ('as', 'CONJ')\n",
      "4904 ('though', 'CONJ')\n",
      "4905 ('he', 'PRON')\n",
      "4906 ('were', 'VERB')\n",
      "4907 ('standing', 'VERB')\n",
      "4908 ('up', 'ADP')\n",
      "4909 ('to', 'ADP')\n",
      "4910 ('the', 'DET')\n",
      "4911 ('assault', 'NOUN')\n",
      "4912 ('of', 'ADP')\n",
      "4913 ('a', 'DET')\n",
      "4914 ('wave', 'NOUN')\n",
      "4915 ('.', '')\n",
      "4916 ('The', 'DET')\n",
      "4917 ('dark-haired', 'ADJ')\n",
      "4918 ('girl', 'NOUN')\n",
      "4919 ('behind', 'ADP')\n",
      "4920 ('Winston', 'NOUN')\n",
      "4921 ('had', 'VERB')\n",
      "4922 ('begun', 'VERB')\n",
      "4923 ('crying', 'VERB')\n",
      "4924 ('out', 'ADP')\n",
      "4925 ('Swine', 'NOUN')\n",
      "4926 ('!', '')\n",
      "4927 ('Swine', 'NOUN')\n",
      "4928 ('!', '')\n",
      "4929 ('Swine', 'NOUN')\n",
      "4930 ('!', '')\n",
      "4931 ('and', 'CONJ')\n",
      "4932 ('suddenly', 'ADV')\n",
      "4933 ('she', 'PRON')\n",
      "4934 ('picked', 'VERB')\n",
      "4935 ('up', 'ADP')\n",
      "4936 ('a', 'DET')\n",
      "4937 ('heavy', 'ADJ')\n",
      "4938 ('Newspeak', 'NOUN')\n",
      "4939 ('dictionary', 'NOUN')\n",
      "4940 ('and', 'CONJ')\n",
      "4941 ('flung', 'VERB')\n",
      "4942 ('it', 'PRON')\n",
      "4943 ('at', 'ADP')\n",
      "4944 ('the', 'DET')\n",
      "4945 ('screen', 'NOUN')\n",
      "4946 ('.', '')\n",
      "4947 ('It', 'PRON')\n",
      "4948 ('struck', 'VERB')\n",
      "4949 ('Goldstein', 'NOUN')\n",
      "4950 (\"'s\", 'ADP')\n",
      "4951 ('nose', 'NOUN')\n",
      "4952 ('and', 'CONJ')\n",
      "4953 ('bounced', 'VERB')\n",
      "4954 ('off', 'ADV')\n",
      "4955 (';', '')\n",
      "4956 ('the', 'DET')\n",
      "4957 ('voice', 'NOUN')\n",
      "4958 ('continued', 'VERB')\n",
      "4959 ('inexorably', 'ADV')\n",
      "4960 ('.', '')\n",
      "4961 ('In', 'ADP')\n",
      "4962 ('a', 'DET')\n",
      "4963 ('lucid', 'ADJ')\n",
      "4964 ('moment', 'NOUN')\n",
      "4965 ('Winston', 'NOUN')\n",
      "4966 ('found', 'VERB')\n",
      "4967 ('that', 'CONJ')\n",
      "4968 ('he', 'PRON')\n",
      "4969 ('was', 'VERB')\n",
      "4970 ('shouting', 'VERB')\n",
      "4971 ('with', 'ADP')\n",
      "4972 ('the', 'DET')\n",
      "4973 ('others', 'PRON')\n",
      "4974 ('and', 'CONJ')\n",
      "4975 ('kicking', 'VERB')\n",
      "4976 ('his', 'DET')\n",
      "4977 ('heel', 'NOUN')\n",
      "4978 ('violently', 'ADV')\n",
      "4979 ('against', 'ADP')\n",
      "4980 ('the', 'DET')\n",
      "4981 ('rung', 'NOUN')\n",
      "4982 ('of', 'ADP')\n",
      "4983 ('his', 'DET')\n",
      "4984 ('chair', 'NOUN')\n",
      "4985 ('.', '')\n",
      "4986 ('The', 'DET')\n",
      "4987 ('horrible', 'ADJ')\n",
      "4988 ('thing', 'NOUN')\n",
      "4989 ('about', 'ADP')\n",
      "4990 ('the', 'DET')\n",
      "4991 ('Two', 'NUM')\n",
      "4992 ('Minutes', 'NOUN')\n",
      "4993 ('Hate', 'NOUN')\n",
      "4994 ('was', 'VERB')\n",
      "4995 ('not', 'ADV')\n",
      "4996 ('that', 'CONJ')\n",
      "4997 ('one', 'PRON')\n",
      "4998 ('was', 'VERB')\n",
      "4999 ('obliged', 'ADJ')\n",
      "5000 ('to', 'ADP')\n",
      "5001 ('act', 'VERB')\n",
      "5002 ('a', 'DET')\n",
      "5003 ('part', 'NOUN')\n",
      "5004 (',', '')\n",
      "5005 ('but', 'CONJ')\n",
      "5006 (',', '')\n",
      "5007 ('on', 'ADP')\n",
      "5008 ('the', 'DET')\n",
      "5009 ('contrary', 'ADJ')\n",
      "5010 (',', '')\n",
      "5011 ('that', 'CONJ')\n",
      "5012 ('it', 'PRON')\n",
      "5013 ('was', 'VERB')\n",
      "5014 ('impossible', 'ADJ')\n",
      "5015 ('to', 'ADP')\n",
      "5016 ('avoid', 'VERB')\n",
      "5017 ('joining', 'VERB')\n",
      "5018 ('in', 'ADP')\n",
      "5019 ('.', '')\n",
      "5020 ('Within', 'ADP')\n",
      "5021 ('thirty', 'NUM')\n",
      "5022 ('seconds', 'NOUN')\n",
      "5023 ('any', 'DET')\n",
      "5024 ('pretence', 'NOUN')\n",
      "5025 ('was', 'VERB')\n",
      "5026 ('always', 'ADV')\n",
      "5027 ('unnecessary', 'ADJ')\n",
      "5028 ('.', '')\n",
      "5029 ('A', 'DET')\n",
      "5030 ('hideous', 'ADJ')\n",
      "5031 ('ecstasy', 'NOUN')\n",
      "5032 ('of', 'ADP')\n",
      "5033 ('fear', 'NOUN')\n",
      "5034 ('and', 'CONJ')\n",
      "5035 ('vindictiveness', 'NOUN')\n",
      "5036 (',', '')\n",
      "5037 ('a', 'DET')\n",
      "5038 ('desire', 'NOUN')\n",
      "5039 ('to', 'ADP')\n",
      "5040 ('kill', 'VERB')\n",
      "5041 (',', '')\n",
      "5042 ('to', 'ADP')\n",
      "5043 ('torture', 'VERB')\n",
      "5044 (',', '')\n",
      "5045 ('to', 'ADP')\n",
      "5046 ('smash', 'VERB')\n",
      "5047 ('faces', 'NOUN')\n",
      "5048 ('in', 'ADP')\n",
      "5049 ('with', 'ADP')\n",
      "5050 ('a', 'DET')\n",
      "5051 ('sledge-hammer', 'NOUN')\n",
      "5052 (',', '')\n",
      "5053 ('seemed', 'VERB')\n",
      "5054 ('to', 'ADP')\n",
      "5055 ('flow', 'VERB')\n",
      "5056 ('through', 'ADP')\n",
      "5057 ('the', 'DET')\n",
      "5058 ('whole', 'ADJ')\n",
      "5059 ('group', 'NOUN')\n",
      "5060 ('of', 'ADP')\n",
      "5061 ('people', 'NOUN')\n",
      "5062 ('like', 'ADP')\n",
      "5063 ('an', 'DET')\n",
      "5064 ('electric', 'ADJ')\n",
      "5065 ('current', 'NOUN')\n",
      "5066 (',', '')\n",
      "5067 ('turning', 'VERB')\n",
      "5068 ('one', 'PRON')\n",
      "5069 ('even', 'ADV')\n",
      "5070 ('against', 'ADP')\n",
      "5071 ('one', 'PRON')\n",
      "5072 (\"'s\", 'ADP')\n",
      "5073 ('will', 'NOUN')\n",
      "5074 ('into', 'ADP')\n",
      "5075 ('a', 'DET')\n",
      "5076 ('grimacing', 'ADJ')\n",
      "5077 (',', '')\n",
      "5078 ('screaming', 'ADJ')\n",
      "5079 ('lunatic', 'NOUN')\n",
      "5080 ('.', '')\n",
      "5081 ('And', 'CONJ')\n",
      "5082 ('yet', 'CONJ')\n",
      "5083 ('the', 'DET')\n",
      "5084 ('rage', 'NOUN')\n",
      "5085 ('that', 'PRON')\n",
      "5086 ('one', 'PRON')\n",
      "5087 ('felt', 'VERB')\n",
      "5088 ('was', 'VERB')\n",
      "5089 ('an', 'DET')\n",
      "5090 ('abstract', 'ADJ')\n",
      "5091 (',', '')\n",
      "5092 ('undirected', 'ADJ')\n",
      "5093 ('emotion', 'NOUN')\n",
      "5094 ('which', 'PRON')\n",
      "5095 ('could', 'VERB')\n",
      "5096 ('be', 'VERB')\n",
      "5097 ('switched', 'VERB')\n",
      "5098 ('from', 'ADP')\n",
      "5099 ('one', 'NUM')\n",
      "5100 ('object', 'NOUN')\n",
      "5101 ('to', 'ADP')\n",
      "5102 ('another', 'PRON')\n",
      "5103 ('like', 'ADP')\n",
      "5104 ('the', 'DET')\n",
      "5105 ('flame', 'NOUN')\n",
      "5106 ('of', 'ADP')\n",
      "5107 ('a', 'DET')\n",
      "5108 ('blowlamp', 'NOUN')\n",
      "5109 ('.', '')\n",
      "5110 ('Thus', 'ADV')\n",
      "5111 (',', '')\n",
      "5112 ('at', 'ADP')\n",
      "5113 ('one', 'NUM')\n",
      "5114 ('moment', 'NOUN')\n",
      "5115 ('Winston', 'NOUN')\n",
      "5116 (\"'s\", 'ADP')\n",
      "5117 ('hatred', 'NOUN')\n",
      "5118 ('was', 'VERB')\n",
      "5119 ('not', 'ADV')\n",
      "5120 ('turned', 'VERB')\n",
      "5121 ('against', 'ADP')\n",
      "5122 ('Goldstein', 'NOUN')\n",
      "5123 ('at', 'ADP')\n",
      "5124 ('all', 'ADV')\n",
      "5125 (',', '')\n",
      "5126 ('but', 'CONJ')\n",
      "5127 (',', '')\n",
      "5128 ('on', 'ADP')\n",
      "5129 ('the', 'DET')\n",
      "5130 ('contrary', 'ADJ')\n",
      "5131 (',', '')\n",
      "5132 ('against', 'ADP')\n",
      "5133 ('Big', 'ADJ')\n",
      "5134 ('Brother', 'NOUN')\n",
      "5135 (',', '')\n",
      "5136 ('the', 'DET')\n",
      "5137 ('Party', 'NOUN')\n",
      "5138 (',', '')\n",
      "5139 ('and', 'CONJ')\n",
      "5140 ('the', 'DET')\n",
      "5141 ('Thought', 'NOUN')\n",
      "5142 ('Police', 'NOUN')\n",
      "5143 (';', '')\n",
      "5144 ('and', 'CONJ')\n",
      "5145 ('at', 'ADP')\n",
      "5146 ('such', 'DET')\n",
      "5147 ('moments', 'NOUN')\n",
      "5148 ('his', 'DET')\n",
      "5149 ('heart', 'NOUN')\n",
      "5150 ('went', 'VERB')\n",
      "5151 ('out', 'ADP')\n",
      "5152 ('to', 'ADP')\n",
      "5153 ('the', 'DET')\n",
      "5154 ('lonely', 'ADJ')\n",
      "5155 (',', '')\n",
      "5156 ('derided', 'ADJ')\n",
      "5157 ('heretic', 'NOUN')\n",
      "5158 ('on', 'ADP')\n",
      "5159 ('the', 'DET')\n",
      "5160 ('screen', 'NOUN')\n",
      "5161 (',', '')\n",
      "5162 ('sole', 'ADJ')\n",
      "5163 ('guardian', 'NOUN')\n",
      "5164 ('of', 'ADP')\n",
      "5165 ('truth', 'NOUN')\n",
      "5166 ('and', 'CONJ')\n",
      "5167 ('sanity', 'NOUN')\n",
      "5168 ('in', 'ADP')\n",
      "5169 ('a', 'DET')\n",
      "5170 ('world', 'NOUN')\n",
      "5171 ('of', 'ADP')\n",
      "5172 ('lies', 'NOUN')\n",
      "5173 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5174 ('And', 'CONJ')\n",
      "5175 ('yet', 'CONJ')\n",
      "5176 ('the', 'DET')\n",
      "5177 ('very', 'ADV')\n",
      "5178 ('next', 'ADJ')\n",
      "5179 ('instant', 'NOUN')\n",
      "5180 ('he', 'PRON')\n",
      "5181 ('was', 'VERB')\n",
      "5182 ('at', 'ADP')\n",
      "5183 ('one', 'PRON')\n",
      "5184 ('with', 'ADP')\n",
      "5185 ('the', 'DET')\n",
      "5186 ('people', 'NOUN')\n",
      "5187 ('about', 'ADP')\n",
      "5188 ('him', 'PRON')\n",
      "5189 (',', '')\n",
      "5190 ('and', 'CONJ')\n",
      "5191 ('all', 'PRON')\n",
      "5192 ('that', 'PRON')\n",
      "5193 ('was', 'VERB')\n",
      "5194 ('said', 'VERB')\n",
      "5195 ('of', 'ADP')\n",
      "5196 ('Goldstein', 'NOUN')\n",
      "5197 ('seemed', 'VERB')\n",
      "5198 ('to', 'ADP')\n",
      "5199 ('him', 'PRON')\n",
      "5200 ('to', 'ADP')\n",
      "5201 ('be', 'VERB')\n",
      "5202 ('true', 'ADJ')\n",
      "5203 ('.', '')\n",
      "5204 ('At', 'ADP')\n",
      "5205 ('those', 'DET')\n",
      "5206 ('moments', 'NOUN')\n",
      "5207 ('his', 'DET')\n",
      "5208 ('secret', 'ADJ')\n",
      "5209 ('loathing', 'NOUN')\n",
      "5210 ('of', 'ADP')\n",
      "5211 ('Big', 'ADJ')\n",
      "5212 ('Brother', 'NOUN')\n",
      "5213 ('changed', 'VERB')\n",
      "5214 ('into', 'ADP')\n",
      "5215 ('adoration', 'NOUN')\n",
      "5216 (',', '')\n",
      "5217 ('and', 'CONJ')\n",
      "5218 ('Big', 'ADJ')\n",
      "5219 ('Brother', 'NOUN')\n",
      "5220 ('seemed', 'VERB')\n",
      "5221 ('to', 'ADP')\n",
      "5222 ('tower', 'VERB')\n",
      "5223 ('up', 'ADP')\n",
      "5224 (',', '')\n",
      "5225 ('an', 'DET')\n",
      "5226 ('invincible', 'ADJ')\n",
      "5227 (',', '')\n",
      "5228 ('fearless', 'ADJ')\n",
      "5229 ('protector', 'NOUN')\n",
      "5230 (',', '')\n",
      "5231 ('standing', 'VERB')\n",
      "5232 ('like', 'ADP')\n",
      "5233 ('a', 'DET')\n",
      "5234 ('rock', 'NOUN')\n",
      "5235 ('against', 'ADP')\n",
      "5236 ('the', 'DET')\n",
      "5237 ('hordes', 'NOUN')\n",
      "5238 ('of', 'ADP')\n",
      "5239 ('Asia', 'NOUN')\n",
      "5240 (',', '')\n",
      "5241 ('and', 'CONJ')\n",
      "5242 ('Goldstein', 'NOUN')\n",
      "5243 (',', '')\n",
      "5244 ('in', 'ADP')\n",
      "5245 ('spite', 'NOUN')\n",
      "5246 ('of', 'ADP')\n",
      "5247 ('his', 'DET')\n",
      "5248 ('isolation', 'NOUN')\n",
      "5249 (',', '')\n",
      "5250 ('his', 'DET')\n",
      "5251 ('helplessness', 'NOUN')\n",
      "5252 (',', '')\n",
      "5253 ('and', 'CONJ')\n",
      "5254 ('the', 'DET')\n",
      "5255 ('doubt', 'NOUN')\n",
      "5256 ('that', 'PRON')\n",
      "5257 ('hung', 'VERB')\n",
      "5258 ('about', 'ADP')\n",
      "5259 ('his', 'DET')\n",
      "5260 ('very', 'ADJ')\n",
      "5261 ('existence', 'NOUN')\n",
      "5262 (',', '')\n",
      "5263 ('seemed', 'VERB')\n",
      "5264 ('like', 'ADP')\n",
      "5265 ('some', 'DET')\n",
      "5266 ('sinister', 'ADJ')\n",
      "5267 ('enchanter', 'NOUN')\n",
      "5268 (',', '')\n",
      "5269 ('capable', 'ADJ')\n",
      "5270 ('by', 'ADP')\n",
      "5271 ('the', 'DET')\n",
      "5272 ('mere', 'ADJ')\n",
      "5273 ('power', 'NOUN')\n",
      "5274 ('of', 'ADP')\n",
      "5275 ('his', 'DET')\n",
      "5276 ('voice', 'NOUN')\n",
      "5277 ('of', 'ADP')\n",
      "5278 ('wrecking', 'VERB')\n",
      "5279 ('the', 'DET')\n",
      "5280 ('structure', 'NOUN')\n",
      "5281 ('of', 'ADP')\n",
      "5282 ('civilization', 'NOUN')\n",
      "5283 ('.', '')\n",
      "5284 ('It', 'PRON')\n",
      "5285 ('was', 'VERB')\n",
      "5286 ('even', 'ADV')\n",
      "5287 ('possible', 'ADJ')\n",
      "5288 (',', '')\n",
      "5289 ('at', 'ADP')\n",
      "5290 ('moments', 'NOUN')\n",
      "5291 (',', '')\n",
      "5292 ('to', 'ADP')\n",
      "5293 ('switch', 'VERB')\n",
      "5294 ('one', 'PRON')\n",
      "5295 (\"'s\", 'ADP')\n",
      "5296 ('hatred', 'NOUN')\n",
      "5297 ('this', 'DET')\n",
      "5298 ('way', 'NOUN')\n",
      "5299 ('or', 'CONJ')\n",
      "5300 ('that', 'DET')\n",
      "5301 ('by', 'ADP')\n",
      "5302 ('a', 'DET')\n",
      "5303 ('voluntary', 'ADJ')\n",
      "5304 ('act', 'NOUN')\n",
      "5305 ('.', '')\n",
      "5306 ('Suddenly', 'ADV')\n",
      "5307 (',', '')\n",
      "5308 ('by', 'ADP')\n",
      "5309 ('the', 'DET')\n",
      "5310 ('sort', 'NOUN')\n",
      "5311 ('of', 'ADP')\n",
      "5312 ('violent', 'ADJ')\n",
      "5313 ('effort', 'NOUN')\n",
      "5314 ('with', 'ADP')\n",
      "5315 ('which', 'PRON')\n",
      "5316 ('one', 'PRON')\n",
      "5317 ('wrenches', 'VERB')\n",
      "5318 ('one', 'PRON')\n",
      "5319 (\"'s\", 'ADP')\n",
      "5320 ('head', 'NOUN')\n",
      "5321 ('away', 'ADV')\n",
      "5322 ('from', 'ADP')\n",
      "5323 ('the', 'DET')\n",
      "5324 ('pillow', 'NOUN')\n",
      "5325 ('in', 'ADP')\n",
      "5326 ('a', 'DET')\n",
      "5327 ('nightmare', 'NOUN')\n",
      "5328 (',', '')\n",
      "5329 ('Winston', 'NOUN')\n",
      "5330 ('succeeded', 'VERB')\n",
      "5331 ('in', 'ADP')\n",
      "5332 ('transferring', 'VERB')\n",
      "5333 ('his', 'DET')\n",
      "5334 ('hatred', 'NOUN')\n",
      "5335 ('from', 'ADP')\n",
      "5336 ('the', 'DET')\n",
      "5337 ('face', 'NOUN')\n",
      "5338 ('on', 'ADP')\n",
      "5339 ('the', 'DET')\n",
      "5340 ('screen', 'NOUN')\n",
      "5341 ('to', 'ADP')\n",
      "5342 ('the', 'DET')\n",
      "5343 ('dark-haired', 'ADJ')\n",
      "5344 ('girl', 'NOUN')\n",
      "5345 ('behind', 'ADP')\n",
      "5346 ('him', 'PRON')\n",
      "5347 ('.', '')\n",
      "5348 ('Vivid', 'ADJ')\n",
      "5349 (',', '')\n",
      "5350 ('beautiful', 'ADJ')\n",
      "5351 ('hallucinations', 'NOUN')\n",
      "5352 ('flashed', 'VERB')\n",
      "5353 ('through', 'ADP')\n",
      "5354 ('his', 'DET')\n",
      "5355 ('mind', 'NOUN')\n",
      "5356 ('.', '')\n",
      "5357 ('He', 'PRON')\n",
      "5358 ('would', 'VERB')\n",
      "5359 ('flog', 'VERB')\n",
      "5360 ('her', 'PRON')\n",
      "5361 ('to', 'ADP')\n",
      "5362 ('death', 'NOUN')\n",
      "5363 ('with', 'ADP')\n",
      "5364 ('a', 'DET')\n",
      "5365 ('rubber', 'NOUN')\n",
      "5366 ('truncheon', 'NOUN')\n",
      "5367 ('.', '')\n",
      "5368 ('He', 'PRON')\n",
      "5369 ('would', 'VERB')\n",
      "5370 ('tie', 'VERB')\n",
      "5371 ('her', 'PRON')\n",
      "5372 ('naked', 'ADJ')\n",
      "5373 ('to', 'ADP')\n",
      "5374 ('a', 'DET')\n",
      "5375 ('stake', 'NOUN')\n",
      "5376 ('and', 'CONJ')\n",
      "5377 ('shoot', 'VERB')\n",
      "5378 ('her', 'PRON')\n",
      "5379 ('full', 'ADJ')\n",
      "5380 ('of', 'ADP')\n",
      "5381 ('arrows', 'NOUN')\n",
      "5382 ('like', 'ADP')\n",
      "5383 ('Saint', 'NOUN')\n",
      "5384 ('Sebastian', 'NOUN')\n",
      "5385 ('.', '')\n",
      "5386 ('He', 'PRON')\n",
      "5387 ('would', 'VERB')\n",
      "5388 ('ravish', 'VERB')\n",
      "5389 ('her', 'PRON')\n",
      "5390 ('and', 'CONJ')\n",
      "5391 ('cut', 'VERB')\n",
      "5392 ('her', 'DET')\n",
      "5393 ('throat', 'NOUN')\n",
      "5394 ('at', 'ADP')\n",
      "5395 ('the', 'DET')\n",
      "5396 ('moment', 'NOUN')\n",
      "5397 ('of', 'ADP')\n",
      "5398 ('climax', 'NOUN')\n",
      "5399 ('.', '')\n",
      "5400 ('Better', 'ADV')\n",
      "5401 ('than', 'CONJ')\n",
      "5402 ('before', 'ADV')\n",
      "5403 (',', '')\n",
      "5404 ('moreover', 'ADV')\n",
      "5405 (',', '')\n",
      "5406 ('he', 'PRON')\n",
      "5407 ('realized', 'VERB')\n",
      "5408 ('why', 'ADV')\n",
      "5409 ('it', 'PRON')\n",
      "5410 ('was', 'VERB')\n",
      "5411 ('that', 'CONJ')\n",
      "5412 ('he', 'PRON')\n",
      "5413 ('hated', 'VERB')\n",
      "5414 ('her', 'PRON')\n",
      "5415 ('.', '')\n",
      "5416 ('He', 'PRON')\n",
      "5417 ('hated', 'VERB')\n",
      "5418 ('her', 'PRON')\n",
      "5419 ('because', 'CONJ')\n",
      "5420 ('she', 'PRON')\n",
      "5421 ('was', 'VERB')\n",
      "5422 ('young', 'ADJ')\n",
      "5423 ('and', 'CONJ')\n",
      "5424 ('pretty', 'ADJ')\n",
      "5425 ('and', 'CONJ')\n",
      "5426 ('sexless', 'ADJ')\n",
      "5427 (',', '')\n",
      "5428 ('because', 'CONJ')\n",
      "5429 ('he', 'PRON')\n",
      "5430 ('wanted', 'VERB')\n",
      "5431 ('to', 'ADP')\n",
      "5432 ('go', 'VERB')\n",
      "5433 ('to', 'ADP')\n",
      "5434 ('bed', 'NOUN')\n",
      "5435 ('with', 'ADP')\n",
      "5436 ('her', 'PRON')\n",
      "5437 ('and', 'CONJ')\n",
      "5438 ('would', 'VERB')\n",
      "5439 ('never', 'ADV')\n",
      "5440 ('do', 'VERB')\n",
      "5441 ('so', 'ADV')\n",
      "5442 (',', '')\n",
      "5443 ('because', 'CONJ')\n",
      "5444 ('round', 'ADP')\n",
      "5445 ('her', 'DET')\n",
      "5446 ('sweet', 'ADJ')\n",
      "5447 ('supple', 'ADJ')\n",
      "5448 ('waist', 'NOUN')\n",
      "5449 (',', '')\n",
      "5450 ('which', 'PRON')\n",
      "5451 ('seemed', 'VERB')\n",
      "5452 ('to', 'ADP')\n",
      "5453 ('ask', 'VERB')\n",
      "5454 ('you', 'PRON')\n",
      "5455 ('to', 'ADP')\n",
      "5456 ('encircle', 'VERB')\n",
      "5457 ('it', 'PRON')\n",
      "5458 ('with', 'ADP')\n",
      "5459 ('your', 'DET')\n",
      "5460 ('arm', 'NOUN')\n",
      "5461 (',', '')\n",
      "5462 ('there', 'PRON')\n",
      "5463 ('was', 'VERB')\n",
      "5464 ('only', 'ADV')\n",
      "5465 ('the', 'DET')\n",
      "5466 ('odious', 'ADJ')\n",
      "5467 ('scarlet', 'ADJ')\n",
      "5468 ('sash', 'NOUN')\n",
      "5469 (',', '')\n",
      "5470 ('aggressive', 'ADJ')\n",
      "5471 ('symbol', 'NOUN')\n",
      "5472 ('of', 'ADP')\n",
      "5473 ('chastity', 'NOUN')\n",
      "5474 ('.', '')\n",
      "5475 ('The', 'DET')\n",
      "5476 ('Hate', 'NOUN')\n",
      "5477 ('rose', 'VERB')\n",
      "5478 ('to', 'ADP')\n",
      "5479 ('its', 'DET')\n",
      "5480 ('climax', 'NOUN')\n",
      "5481 ('.', '')\n",
      "5482 ('The', 'DET')\n",
      "5483 ('voice', 'NOUN')\n",
      "5484 ('of', 'ADP')\n",
      "5485 ('Goldstein', 'NOUN')\n",
      "5486 ('had', 'VERB')\n",
      "5487 ('become', 'VERB')\n",
      "5488 ('an', 'DET')\n",
      "5489 ('actual', 'ADJ')\n",
      "5490 ('sheep', 'NOUN')\n",
      "5491 (\"'s\", 'ADP')\n",
      "5492 ('bleat', 'NOUN')\n",
      "5493 (',', '')\n",
      "5494 ('and', 'CONJ')\n",
      "5495 ('for', 'ADP')\n",
      "5496 ('an', 'DET')\n",
      "5497 ('instant', 'NOUN')\n",
      "5498 ('the', 'DET')\n",
      "5499 ('face', 'NOUN')\n",
      "5500 ('changed', 'VERB')\n",
      "5501 ('into', 'ADP')\n",
      "5502 ('that', 'PRON')\n",
      "5503 ('of', 'ADP')\n",
      "5504 ('a', 'DET')\n",
      "5505 ('sheep', 'NOUN')\n",
      "5506 ('.', '')\n",
      "5507 ('Then', 'ADV')\n",
      "5508 ('the', 'DET')\n",
      "5509 ('sheep-face', 'NOUN')\n",
      "5510 ('melted', 'VERB')\n",
      "5511 ('into', 'ADP')\n",
      "5512 ('the', 'DET')\n",
      "5513 ('figure', 'NOUN')\n",
      "5514 ('of', 'ADP')\n",
      "5515 ('a', 'DET')\n",
      "5516 ('Eurasian', 'ADJ')\n",
      "5517 ('soldier', 'NOUN')\n",
      "5518 ('who', 'PRON')\n",
      "5519 ('seemed', 'VERB')\n",
      "5520 ('to', 'ADP')\n",
      "5521 ('be', 'VERB')\n",
      "5522 ('advancing', 'VERB')\n",
      "5523 (',', '')\n",
      "5524 ('huge', 'ADJ')\n",
      "5525 ('and', 'CONJ')\n",
      "5526 ('terrible', 'ADJ')\n",
      "5527 (',', '')\n",
      "5528 ('his', 'DET')\n",
      "5529 ('sub-machine', 'ADJ')\n",
      "5530 ('gun', 'NOUN')\n",
      "5531 ('roaring', 'VERB')\n",
      "5532 (',', '')\n",
      "5533 ('and', 'CONJ')\n",
      "5534 ('seeming', 'VERB')\n",
      "5535 ('to', 'ADP')\n",
      "5536 ('spring', 'VERB')\n",
      "5537 ('out', 'ADP')\n",
      "5538 ('of', 'ADP')\n",
      "5539 ('the', 'DET')\n",
      "5540 ('surface', 'NOUN')\n",
      "5541 ('of', 'ADP')\n",
      "5542 ('the', 'DET')\n",
      "5543 ('screen', 'NOUN')\n",
      "5544 (',', '')\n",
      "5545 ('so', 'CONJ')\n",
      "5546 ('that', 'CONJ')\n",
      "5547 ('some', 'DET')\n",
      "5548 ('of', 'ADP')\n",
      "5549 ('the', 'DET')\n",
      "5550 ('people', 'NOUN')\n",
      "5551 ('in', 'ADP')\n",
      "5552 ('the', 'DET')\n",
      "5553 ('front', 'ADJ')\n",
      "5554 ('row', 'NOUN')\n",
      "5555 ('actually', 'ADV')\n",
      "5556 ('flinched', 'VERB')\n",
      "5557 ('backwards', 'ADV')\n",
      "5558 ('in', 'ADP')\n",
      "5559 ('their', 'DET')\n",
      "5560 ('seats', 'NOUN')\n",
      "5561 ('.', '')\n",
      "5562 ('But', 'CONJ')\n",
      "5563 ('in', 'ADP')\n",
      "5564 ('the', 'DET')\n",
      "5565 ('same', 'ADJ')\n",
      "5566 ('moment', 'NOUN')\n",
      "5567 (',', '')\n",
      "5568 ('drawing', 'VERB')\n",
      "5569 ('a', 'DET')\n",
      "5570 ('deep', 'ADJ')\n",
      "5571 ('sigh', 'NOUN')\n",
      "5572 ('of', 'ADP')\n",
      "5573 ('relief', 'NOUN')\n",
      "5574 ('from', 'ADP')\n",
      "5575 ('everybody', 'PRON')\n",
      "5576 (',', '')\n",
      "5577 ('the', 'DET')\n",
      "5578 ('hostile', 'ADJ')\n",
      "5579 ('figure', 'NOUN')\n",
      "5580 ('melted', 'VERB')\n",
      "5581 ('into', 'ADP')\n",
      "5582 ('the', 'DET')\n",
      "5583 ('face', 'NOUN')\n",
      "5584 ('of', 'ADP')\n",
      "5585 ('Big', 'ADJ')\n",
      "5586 ('Brother', 'NOUN')\n",
      "5587 (',', '')\n",
      "5588 ('black-haired', 'ADJ')\n",
      "5589 (',', '')\n",
      "5590 (\"blackmoustachio'd\", 'ADJ')\n",
      "5591 (',', '')\n",
      "5592 ('full', 'ADJ')\n",
      "5593 ('of', 'ADP')\n",
      "5594 ('power', 'NOUN')\n",
      "5595 ('and', 'CONJ')\n",
      "5596 ('mysterious', 'ADJ')\n",
      "5597 ('calm', 'NOUN')\n",
      "5598 (',', '')\n",
      "5599 ('and', 'CONJ')\n",
      "5600 ('so', 'ADV')\n",
      "5601 ('vast', 'ADJ')\n",
      "5602 ('that', 'CONJ')\n",
      "5603 ('it', 'PRON')\n",
      "5604 ('almost', 'ADV')\n",
      "5605 ('filled', 'VERB')\n",
      "5606 ('up', 'ADP')\n",
      "5607 ('the', 'DET')\n",
      "5608 ('screen', 'NOUN')\n",
      "5609 ('.', '')\n",
      "5610 ('Nobody', 'PRON')\n",
      "5611 ('heard', 'VERB')\n",
      "5612 ('what', 'PRON')\n",
      "5613 ('Big', 'ADJ')\n",
      "5614 ('Brother', 'NOUN')\n",
      "5615 ('was', 'VERB')\n",
      "5616 ('saying', 'VERB')\n",
      "5617 ('.', '')\n",
      "5618 ('It', 'PRON')\n",
      "5619 ('was', 'VERB')\n",
      "5620 ('merely', 'ADV')\n",
      "5621 ('a', 'DET')\n",
      "5622 ('few', 'DET')\n",
      "5623 ('words', 'NOUN')\n",
      "5624 ('of', 'ADP')\n",
      "5625 ('encouragement', 'NOUN')\n",
      "5626 (',', '')\n",
      "5627 ('the', 'DET')\n",
      "5628 ('sort', 'NOUN')\n",
      "5629 ('of', 'ADP')\n",
      "5630 ('words', 'NOUN')\n",
      "5631 ('that', 'PRON')\n",
      "5632 ('are', 'VERB')\n",
      "5633 ('uttered', 'VERB')\n",
      "5634 ('in', 'ADP')\n",
      "5635 ('the', 'DET')\n",
      "5636 ('din', 'NOUN')\n",
      "5637 ('of', 'ADP')\n",
      "5638 ('battle', 'NOUN')\n",
      "5639 (',', '')\n",
      "5640 ('not', 'ADV')\n",
      "5641 ('distinguishable', 'ADJ')\n",
      "5642 ('individually', 'ADV')\n",
      "5643 ('but', 'CONJ')\n",
      "5644 ('restoring', 'VERB')\n",
      "5645 ('confidence', 'NOUN')\n",
      "5646 ('by', 'ADP')\n",
      "5647 ('the', 'DET')\n",
      "5648 ('fact', 'NOUN')\n",
      "5649 ('of', 'ADP')\n",
      "5650 ('being', 'VERB')\n",
      "5651 ('spoken', 'VERB')\n",
      "5652 ('.', '')\n",
      "5653 ('Then', 'ADV')\n",
      "5654 ('the', 'DET')\n",
      "5655 ('face', 'NOUN')\n",
      "5656 ('of', 'ADP')\n",
      "5657 ('Big', 'ADJ')\n",
      "5658 ('Brother', 'NOUN')\n",
      "5659 ('faded', 'VERB')\n",
      "5660 ('away', 'ADV')\n",
      "5661 ('again', 'ADV')\n",
      "5662 (',', '')\n",
      "5663 ('and', 'CONJ')\n",
      "5664 ('instead', 'ADV')\n",
      "5665 ('the', 'DET')\n",
      "5666 ('three', 'NUM')\n",
      "5667 ('slogans', 'NOUN')\n",
      "5668 ('of', 'ADP')\n",
      "5669 ('the', 'DET')\n",
      "5670 ('Party', 'NOUN')\n",
      "5671 ('stood', 'VERB')\n",
      "5672 ('out', 'ADP')\n",
      "5673 ('in', 'ADP')\n",
      "5674 ('bold', 'ADJ')\n",
      "5675 ('capitals', 'NOUN')\n",
      "5676 (':', '')\n",
      "5677 ('War', 'NOUN')\n",
      "5678 ('is', 'VERB')\n",
      "5679 ('peace', 'NOUN')\n",
      "5680 ('Freedom', 'NOUN')\n",
      "5681 ('is', 'VERB')\n",
      "5682 ('slavery', 'NOUN')\n",
      "5683 ('Ignorance', 'NOUN')\n",
      "5684 ('is', 'VERB')\n",
      "5685 ('strength', 'NOUN')\n",
      "5686 ('.', '')\n",
      "5687 ('But', 'CONJ')\n",
      "5688 ('the', 'DET')\n",
      "5689 ('face', 'NOUN')\n",
      "5690 ('of', 'ADP')\n",
      "5691 ('Big', 'ADJ')\n",
      "5692 ('Brother', 'NOUN')\n",
      "5693 ('seemed', 'VERB')\n",
      "5694 ('to', 'ADP')\n",
      "5695 ('persist', 'VERB')\n",
      "5696 ('for', 'ADP')\n",
      "5697 ('several', 'ADJ')\n",
      "5698 ('seconds', 'NOUN')\n",
      "5699 ('on', 'ADP')\n",
      "5700 ('the', 'DET')\n",
      "5701 ('screen', 'NOUN')\n",
      "5702 (',', '')\n",
      "5703 ('as', 'CONJ')\n",
      "5704 ('though', 'CONJ')\n",
      "5705 ('the', 'DET')\n",
      "5706 ('impact', 'NOUN')\n",
      "5707 ('that', 'PRON')\n",
      "5708 ('it', 'PRON')\n",
      "5709 ('had', 'VERB')\n",
      "5710 ('made', 'VERB')\n",
      "5711 ('on', 'ADP')\n",
      "5712 ('everyone', 'PRON')\n",
      "5713 (\"'s\", 'ADP')\n",
      "5714 ('eyeballs', 'NOUN')\n",
      "5715 ('was', 'VERB')\n",
      "5716 ('too', 'ADV')\n",
      "5717 ('vivid', 'ADJ')\n",
      "5718 ('to', 'ADP')\n",
      "5719 ('wear', 'VERB')\n",
      "5720 ('off', 'ADV')\n",
      "5721 ('immediately', 'ADV')\n",
      "5722 ('.', '')\n",
      "5723 ('The', 'DET')\n",
      "5724 ('little', 'ADJ')\n",
      "5725 ('sandyhaired', 'ADJ')\n",
      "5726 ('woman', 'NOUN')\n",
      "5727 ('had', 'VERB')\n",
      "5728 ('flung', 'VERB')\n",
      "5729 ('herself', 'PRON')\n",
      "5730 ('forward', 'ADV')\n",
      "5731 ('over', 'ADP')\n",
      "5732 ('the', 'DET')\n",
      "5733 ('back', 'NOUN')\n",
      "5734 ('of', 'ADP')\n",
      "5735 ('the', 'DET')\n",
      "5736 ('chair', 'NOUN')\n",
      "5737 ('in', 'ADP')\n",
      "5738 ('front', 'NOUN')\n",
      "5739 ('of', 'ADP')\n",
      "5740 ('her', 'PRON')\n",
      "5741 ('.', '')\n",
      "5742 ('With', 'ADP')\n",
      "5743 ('a', 'DET')\n",
      "5744 ('tremulous', 'ADJ')\n",
      "5745 ('murmur', 'NOUN')\n",
      "5746 ('that', 'PRON')\n",
      "5747 ('sounded', 'VERB')\n",
      "5748 ('like', 'ADP')\n",
      "5749 ('My', 'DET')\n",
      "5750 ('Saviour', 'NOUN')\n",
      "5751 ('!', '')\n",
      "5752 ('she', 'PRON')\n",
      "5753 ('extended', 'VERB')\n",
      "5754 ('her', 'DET')\n",
      "5755 ('arms', 'NOUN')\n",
      "5756 ('towards', 'ADP')\n",
      "5757 ('the', 'DET')\n",
      "5758 ('screen', 'NOUN')\n",
      "5759 ('.', '')\n",
      "5760 ('Then', 'ADV')\n",
      "5761 ('she', 'PRON')\n",
      "5762 ('buried', 'VERB')\n",
      "5763 ('her', 'DET')\n",
      "5764 ('face', 'NOUN')\n",
      "5765 ('in', 'ADP')\n",
      "5766 ('her', 'DET')\n",
      "5767 ('hands', 'NOUN')\n",
      "5768 ('.', '')\n",
      "5769 ('It', 'PRON')\n",
      "5770 ('was', 'VERB')\n",
      "5771 ('apparent', 'ADJ')\n",
      "5772 ('that', 'CONJ')\n",
      "5773 ('she', 'PRON')\n",
      "5774 ('was', 'VERB')\n",
      "5775 ('uttering', 'VERB')\n",
      "5776 ('a', 'DET')\n",
      "5777 ('prayer', 'NOUN')\n",
      "5778 ('.', '')\n",
      "5779 ('At', 'ADP')\n",
      "5780 ('this', 'DET')\n",
      "5781 ('moment', 'NOUN')\n",
      "5782 ('the', 'DET')\n",
      "5783 ('entire', 'ADJ')\n",
      "5784 ('group', 'NOUN')\n",
      "5785 ('of', 'ADP')\n",
      "5786 ('people', 'NOUN')\n",
      "5787 ('broke', 'VERB')\n",
      "5788 ('into', 'ADP')\n",
      "5789 ('a', 'DET')\n",
      "5790 ('deep', 'ADJ')\n",
      "5791 (',', '')\n",
      "5792 ('slow', 'ADJ')\n",
      "5793 (',', '')\n",
      "5794 ('rhythmical', 'ADJ')\n",
      "5795 ('chant', 'NOUN')\n",
      "5796 ('of', 'ADP')\n",
      "5797 ('B-B', 'NOUN')\n",
      "5798 ('!', '')\n",
      "\n",
      "5799 ('...', '')\n",
      "5800 ('B-B', 'NOUN')\n",
      "5801 ('!', '')\n",
      "\n",
      "5802 ('...', '')\n",
      "5803 ('B-B', 'NOUN')\n",
      "5804 ('!', '')\n",
      "5805 ('-', '')\n",
      "5806 ('over', 'ADV')\n",
      "5807 ('and', 'CONJ')\n",
      "5808 ('over', 'ADV')\n",
      "5809 ('again', 'ADV')\n",
      "5810 (',', '')\n",
      "5811 ('very', 'ADV')\n",
      "5812 ('slowly', 'ADV')\n",
      "5813 (',', '')\n",
      "5814 ('with', 'ADP')\n",
      "5815 ('a', 'DET')\n",
      "5816 ('long', 'ADJ')\n",
      "5817 ('pause', 'NOUN')\n",
      "5818 ('between', 'ADP')\n",
      "5819 ('the', 'DET')\n",
      "5820 ('first', 'ADJ')\n",
      "5821 ('B', 'NOUN')\n",
      "5822 ('and', 'CONJ')\n",
      "5823 ('the', 'DET')\n",
      "5824 ('second', 'ADJ')\n",
      "5825 ('-', '')\n",
      "5826 ('a', 'DET')\n",
      "5827 ('heavy', 'ADJ')\n",
      "5828 (',', '')\n",
      "5829 ('murmurous', 'ADJ')\n",
      "5830 ('sound', 'NOUN')\n",
      "5831 (',', '')\n",
      "5832 ('somehow', 'ADV')\n",
      "5833 ('curiously', 'ADV')\n",
      "5834 ('savage', 'ADJ')\n",
      "5835 (',', '')\n",
      "5836 ('in', 'ADP')\n",
      "5837 ('the', 'DET')\n",
      "5838 ('background', 'NOUN')\n",
      "5839 ('of', 'ADP')\n",
      "5840 ('which', 'PRON')\n",
      "5841 ('one', 'PRON')\n",
      "5842 ('seemed', 'VERB')\n",
      "5843 ('to', 'ADP')\n",
      "5844 ('hear', 'VERB')\n",
      "5845 ('the', 'DET')\n",
      "5846 ('stamp', 'NOUN')\n",
      "5847 ('of', 'ADP')\n",
      "5848 ('naked', 'ADJ')\n",
      "5849 ('feet', 'NOUN')\n",
      "5850 ('and', 'CONJ')\n",
      "5851 ('the', 'DET')\n",
      "5852 ('throbbing', 'NOUN')\n",
      "5853 ('of', 'ADP')\n",
      "5854 ('tom-toms', 'NOUN')\n",
      "5855 ('.', '')\n",
      "5856 ('For', 'ADP')\n",
      "5857 ('perhaps', 'ADV')\n",
      "5858 ('as', 'ADV')\n",
      "5859 ('much', 'ADJ')\n",
      "5860 ('as', 'CONJ')\n",
      "5861 ('thirty', 'NUM')\n",
      "5862 ('seconds', 'NOUN')\n",
      "5863 ('they', 'PRON')\n",
      "5864 ('kept', 'VERB')\n",
      "5865 ('it', 'PRON')\n",
      "5866 ('up', 'ADP')\n",
      "5867 ('.', '')\n",
      "5868 ('It', 'PRON')\n",
      "5869 ('was', 'VERB')\n",
      "5870 ('a', 'DET')\n",
      "5871 ('refrain', 'NOUN')\n",
      "5872 ('that', 'PRON')\n",
      "5873 ('was', 'VERB')\n",
      "5874 ('often', 'ADV')\n",
      "5875 ('heard', 'VERB')\n",
      "5876 ('in', 'ADP')\n",
      "5877 ('moments', 'NOUN')\n",
      "5878 ('of', 'ADP')\n",
      "5879 ('overwhelming', 'ADJ')\n",
      "5880 ('emotion', 'NOUN')\n",
      "5881 ('.', '')\n",
      "5882 ('Partly', 'ADV')\n",
      "5883 ('it', 'PRON')\n",
      "5884 ('was', 'VERB')\n",
      "5885 ('a', 'DET')\n",
      "5886 ('sort', 'NOUN')\n",
      "5887 ('of', 'ADP')\n",
      "5888 ('hymn', 'NOUN')\n",
      "5889 ('to', 'ADP')\n",
      "5890 ('the', 'DET')\n",
      "5891 ('wisdom', 'NOUN')\n",
      "5892 ('and', 'CONJ')\n",
      "5893 ('majesty', 'NOUN')\n",
      "5894 ('of', 'ADP')\n",
      "5895 ('Big', 'ADJ')\n",
      "5896 ('Brother', 'NOUN')\n",
      "5897 (',', '')\n",
      "5898 ('but', 'CONJ')\n",
      "5899 ('still', 'ADV')\n",
      "5900 ('more', 'ADV')\n",
      "5901 ('it', 'PRON')\n",
      "5902 ('was', 'VERB')\n",
      "5903 ('an', 'DET')\n",
      "5904 ('act', 'NOUN')\n",
      "5905 ('of', 'ADP')\n",
      "5906 ('self-hypnosis', 'NOUN')\n",
      "5907 (',', '')\n",
      "5908 ('a', 'DET')\n",
      "5909 ('deliberate', 'ADJ')\n",
      "5910 ('drowning', 'NOUN')\n",
      "5911 ('of', 'ADP')\n",
      "5912 ('consciousness', 'NOUN')\n",
      "5913 ('by', 'ADP')\n",
      "5914 ('means', 'NOUN')\n",
      "5915 ('of', 'ADP')\n",
      "5916 ('rhythmic', 'ADJ')\n",
      "5917 ('noise', 'NOUN')\n",
      "5918 ('.', '')\n",
      "5919 ('Winston', 'NOUN')\n",
      "5920 (\"'s\", 'ADP')\n",
      "5920 (\"'s\", 'ADP')\n",
      "5921 ('entrails', 'NOUN')\n",
      "5922 ('seemed', 'VERB')\n",
      "5923 ('to', 'ADP')\n",
      "5924 ('grow', 'VERB')\n",
      "5925 ('cold', 'ADJ')\n",
      "5926 ('.', '')\n",
      "5927 ('In', 'ADP')\n",
      "5928 ('the', 'DET')\n",
      "5929 ('Two', 'NUM')\n",
      "5930 ('Minutes', 'NOUN')\n",
      "5931 ('Hate', 'NOUN')\n",
      "5932 ('he', 'PRON')\n",
      "5933 ('could', 'VERB')\n",
      "5934 ('not', 'ADV')\n",
      "5935 ('help', 'VERB')\n",
      "5936 ('sharing', 'VERB')\n",
      "5937 ('in', 'ADP')\n",
      "5938 ('the', 'DET')\n",
      "5939 ('general', 'ADJ')\n",
      "5940 ('delirium', 'NOUN')\n",
      "5941 (',', '')\n",
      "5942 ('but', 'CONJ')\n",
      "5943 ('this', 'DET')\n",
      "5944 ('sub-human', 'ADJ')\n",
      "5945 ('chanting', 'NOUN')\n",
      "5946 ('of', 'ADP')\n",
      "5947 ('B-B', 'NOUN')\n",
      "5948 ('!', '')\n",
      "\n",
      "5949 ('...', '')\n",
      "5950 ('B-B', 'NOUN')\n",
      "5951 ('!', '')\n",
      "5952 ('always', 'ADV')\n",
      "5953 ('filled', 'VERB')\n",
      "5954 ('him', 'PRON')\n",
      "5955 ('with', 'ADP')\n",
      "5956 ('horror', 'NOUN')\n",
      "5957 ('.', '')\n",
      "5958 ('Of', 'ADP')\n",
      "5959 ('course', 'NOUN')\n",
      "5960 ('he', 'PRON')\n",
      "5961 ('chanted', 'VERB')\n",
      "5962 ('with', 'ADP')\n",
      "5963 ('the', 'DET')\n",
      "5964 ('rest', 'NOUN')\n",
      "5965 (':', '')\n",
      "5966 ('it', 'PRON')\n",
      "5967 ('was', 'VERB')\n",
      "5968 ('impossible', 'ADJ')\n",
      "5969 ('to', 'ADP')\n",
      "5970 ('do', 'VERB')\n",
      "5971 ('otherwise', 'ADV')\n",
      "5972 ('.', '')\n",
      "5973 ('To', 'ADP')\n",
      "5974 ('dissemble', 'VERB')\n",
      "5975 ('your', 'DET')\n",
      "5976 ('feelings', 'NOUN')\n",
      "5977 (',', '')\n",
      "5978 ('to', 'ADP')\n",
      "5979 ('control', 'VERB')\n",
      "5980 ('your', 'DET')\n",
      "5981 ('face', 'NOUN')\n",
      "5982 (',', '')\n",
      "5983 ('to', 'ADP')\n",
      "5984 ('do', 'VERB')\n",
      "5985 ('what', 'PRON')\n",
      "5986 ('everyone', 'PRON')\n",
      "5987 ('else', 'ADV')\n",
      "5988 ('was', 'VERB')\n",
      "5989 ('doing', 'VERB')\n",
      "5990 (',', '')\n",
      "5991 ('was', 'VERB')\n",
      "5992 ('an', 'DET')\n",
      "5993 ('instinctive', 'ADJ')\n",
      "5994 ('reaction', 'NOUN')\n",
      "5995 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996 ('But', 'CONJ')\n",
      "5997 ('there', 'PRON')\n",
      "5998 ('was', 'VERB')\n",
      "5999 ('a', 'DET')\n",
      "6000 ('space', 'NOUN')\n",
      "6001 ('of', 'ADP')\n",
      "6002 ('a', 'DET')\n",
      "6003 ('couple', 'NOUN')\n",
      "6004 ('of', 'ADP')\n",
      "6005 ('seconds', 'NOUN')\n",
      "6006 ('during', 'ADP')\n",
      "6007 ('which', 'PRON')\n",
      "6008 ('the', 'DET')\n",
      "6009 ('expression', 'NOUN')\n",
      "6010 ('of', 'ADP')\n",
      "6011 ('his', 'DET')\n",
      "6012 ('eyes', 'NOUN')\n",
      "6013 ('might', 'VERB')\n",
      "6014 ('conceivably', 'ADV')\n",
      "6015 ('have', 'VERB')\n",
      "6016 ('betrayed', 'VERB')\n",
      "6017 ('him', 'PRON')\n",
      "6018 ('.', '')\n",
      "6019 ('And', 'CONJ')\n",
      "6020 ('it', 'PRON')\n",
      "6021 ('was', 'VERB')\n",
      "6022 ('exactly', 'ADV')\n",
      "6023 ('at', 'ADP')\n",
      "6024 ('this', 'DET')\n",
      "6025 ('moment', 'NOUN')\n",
      "6026 ('that', 'CONJ')\n",
      "6027 ('the', 'DET')\n",
      "6028 ('significant', 'ADJ')\n",
      "6029 ('thing', 'NOUN')\n",
      "6030 ('happened', 'VERB')\n",
      "6031 ('-', '')\n",
      "6032 ('if', 'CONJ')\n",
      "6033 (',', '')\n",
      "6034 ('indeed', 'ADV')\n",
      "6035 (',', '')\n",
      "6036 ('it', 'PRON')\n",
      "6037 ('did', 'VERB')\n",
      "6038 ('happen', 'VERB')\n",
      "6039 ('.', '')\n",
      "6040 ('Momentarily', 'ADV')\n",
      "6041 ('he', 'PRON')\n",
      "6042 ('caught', 'VERB')\n",
      "6043 (\"O'Brien\", 'NOUN')\n",
      "6044 (\"'s\", 'ADP')\n",
      "6045 ('eye', 'NOUN')\n",
      "6046 ('.', '')\n",
      "6047 (\"O'Brien\", 'NOUN')\n",
      "6048 ('had', 'VERB')\n",
      "6049 ('stood', 'VERB')\n",
      "6050 ('up', 'ADP')\n",
      "6051 ('.', '')\n",
      "6052 ('He', 'PRON')\n",
      "6053 ('had', 'VERB')\n",
      "6054 ('taken', 'VERB')\n",
      "6055 ('off', 'ADV')\n",
      "6056 ('his', 'DET')\n",
      "6057 ('spectacles', 'NOUN')\n",
      "6058 ('and', 'CONJ')\n",
      "6059 ('was', 'VERB')\n",
      "6060 ('in', 'ADP')\n",
      "6061 ('the', 'DET')\n",
      "6062 ('act', 'NOUN')\n",
      "6063 ('of', 'ADP')\n",
      "6064 ('resettling', 'VERB')\n",
      "6065 ('them', 'PRON')\n",
      "6066 ('on', 'ADP')\n",
      "6067 ('his', 'DET')\n",
      "6068 ('nose', 'NOUN')\n",
      "6069 ('with', 'ADP')\n",
      "6070 ('his', 'DET')\n",
      "6071 ('characteristic', 'ADJ')\n",
      "6072 ('gesture', 'NOUN')\n",
      "6073 ('.', '')\n",
      "6074 ('But', 'CONJ')\n",
      "6075 ('there', 'PRON')\n",
      "6076 ('was', 'VERB')\n",
      "6077 ('a', 'DET')\n",
      "6078 ('fraction', 'NOUN')\n",
      "6079 ('of', 'ADP')\n",
      "6080 ('a', 'DET')\n",
      "6081 ('second', 'NOUN')\n",
      "6082 ('when', 'CONJ')\n",
      "6083 ('their', 'DET')\n",
      "6084 ('eyes', 'VERB')\n",
      "6085 ('met', 'VERB')\n",
      "6086 (',', '')\n",
      "6087 ('and', 'CONJ')\n",
      "6088 ('for', 'ADP')\n",
      "6089 ('as', 'CONJ')\n",
      "6090 ('long', 'ADV')\n",
      "6091 ('as', 'CONJ')\n",
      "6092 ('it', 'PRON')\n",
      "6093 ('took', 'VERB')\n",
      "6094 ('to', 'ADP')\n",
      "6095 ('happen', 'VERB')\n",
      "6096 ('Winston', 'NOUN')\n",
      "6097 ('knew', 'VERB')\n",
      "6098 ('-', '')\n",
      "6099 ('yes', 'NOUN')\n",
      "6100 (',', '')\n",
      "6101 ('he', 'PRON')\n",
      "6102 ('knew', 'VERB')\n",
      "6103 ('!', '')\n",
      "6104 ('-', '')\n",
      "6105 ('that', 'CONJ')\n",
      "6106 (\"O'Brien\", 'NOUN')\n",
      "6107 ('was', 'VERB')\n",
      "6108 ('thinking', 'VERB')\n",
      "6109 ('the', 'DET')\n",
      "6110 ('same', 'ADJ')\n",
      "6111 ('thing', 'NOUN')\n",
      "6112 ('as', 'ADP')\n",
      "6113 ('himself', 'PRON')\n",
      "6114 ('.', '')\n",
      "6115 ('An', 'DET')\n",
      "6116 ('unmistakable', 'ADJ')\n",
      "6117 ('message', 'NOUN')\n",
      "6118 ('had', 'VERB')\n",
      "6119 ('passed', 'VERB')\n",
      "6120 ('.', '')\n",
      "6121 ('It', 'PRON')\n",
      "6122 ('was', 'VERB')\n",
      "6123 ('as', 'CONJ')\n",
      "6124 ('though', 'CONJ')\n",
      "6125 ('their', 'DET')\n",
      "6126 ('two', 'NUM')\n",
      "6127 ('minds', 'NOUN')\n",
      "6128 ('had', 'VERB')\n",
      "6129 ('opened', 'VERB')\n",
      "6130 ('and', 'CONJ')\n",
      "6131 ('the', 'DET')\n",
      "6132 ('thoughts', 'NOUN')\n",
      "6133 ('were', 'VERB')\n",
      "6134 ('flowing', 'VERB')\n",
      "6135 ('from', 'ADP')\n",
      "6136 ('one', 'PRON')\n",
      "6137 ('into', 'ADP')\n",
      "6138 ('the', 'DET')\n",
      "6139 ('other', 'NOUN')\n",
      "6140 ('through', 'ADP')\n",
      "6141 ('their', 'DET')\n",
      "6142 ('eyes', 'NOUN')\n",
      "6143 ('.', '')\n",
      "6144 ('I', 'PRON')\n",
      "6145 ('am', 'VERB')\n",
      "6146 ('with', 'ADP')\n",
      "6147 ('you', 'PRON')\n",
      "6148 (',', '')\n",
      "6149 (\"O'Brien\", 'NOUN')\n",
      "6150 ('seemed', 'VERB')\n",
      "6151 ('to', 'ADP')\n",
      "6152 ('be', 'VERB')\n",
      "6153 ('saying', 'VERB')\n",
      "6154 ('to', 'ADP')\n",
      "6155 ('him', 'PRON')\n",
      "6156 ('.', '')\n",
      "6157 ('I', 'PRON')\n",
      "6158 ('know', 'VERB')\n",
      "6159 ('precisely', 'ADV')\n",
      "6160 ('what', 'PRON')\n",
      "6161 ('you', 'PRON')\n",
      "6162 ('are', 'VERB')\n",
      "6163 ('feeling', 'VERB')\n",
      "6164 ('.', '')\n",
      "6165 ('I', 'PRON')\n",
      "6166 ('know', 'VERB')\n",
      "6167 ('all', 'PRON')\n",
      "6168 ('about', 'ADP')\n",
      "6169 ('your', 'DET')\n",
      "6170 ('contempt', 'NOUN')\n",
      "6171 (',', '')\n",
      "6172 ('your', 'DET')\n",
      "6173 ('hatred', 'NOUN')\n",
      "6174 (',', '')\n",
      "6175 ('your', 'DET')\n",
      "6176 ('disgust', 'NOUN')\n",
      "6177 ('.', '')\n",
      "6178 ('But', 'CONJ')\n",
      "6179 (\"don't\", 'VERB')\n",
      "6180 ('worry', 'VERB')\n",
      "6181 (',', '')\n",
      "6182 ('I', 'PRON')\n",
      "6183 ('am', 'VERB')\n",
      "6184 ('on', 'ADP')\n",
      "6185 ('your', 'DET')\n",
      "6186 ('side', 'NOUN')\n",
      "6187 ('!', '')\n",
      "6188 ('And', 'CONJ')\n",
      "6189 ('then', 'ADV')\n",
      "6190 ('the', 'DET')\n",
      "6191 ('flash', 'NOUN')\n",
      "6192 ('of', 'ADP')\n",
      "6193 ('intelligence', 'NOUN')\n",
      "6194 ('was', 'VERB')\n",
      "6195 ('gone', 'VERB')\n",
      "6196 (',', '')\n",
      "6197 ('and', 'CONJ')\n",
      "6198 (\"O'Brien\", 'NOUN')\n",
      "6199 (\"'s\", 'ADP')\n",
      "6200 ('face', 'NOUN')\n",
      "6201 ('was', 'VERB')\n",
      "6202 ('as', 'ADV')\n",
      "6203 ('inscrutable', 'ADJ')\n",
      "6204 ('as', 'ADP')\n",
      "6205 ('everybody', 'PRON')\n",
      "6206 ('else', 'ADV')\n",
      "6207 (\"'s\", 'ADP')\n",
      "6208 ('.', '')\n",
      "6209 ('That', 'PRON')\n",
      "6210 ('was', 'VERB')\n",
      "6211 ('all', 'PRON')\n",
      "6212 (',', '')\n",
      "6213 ('and', 'CONJ')\n",
      "6214 ('he', 'PRON')\n",
      "6215 ('was', 'VERB')\n",
      "6216 ('already', 'ADV')\n",
      "6217 ('uncertain', 'ADJ')\n",
      "6218 ('whether', 'CONJ')\n",
      "6219 ('it', 'PRON')\n",
      "6220 ('had', 'VERB')\n",
      "6221 ('happened', 'VERB')\n",
      "6222 ('.', '')\n",
      "6223 ('Such', 'DET')\n",
      "6224 ('incidents', 'NOUN')\n",
      "6225 ('never', 'ADV')\n",
      "6226 ('had', 'VERB')\n",
      "6227 ('any', 'DET')\n",
      "6228 ('sequel', 'NOUN')\n",
      "6229 ('.', '')\n",
      "6230 ('All', 'PRON')\n",
      "6231 ('that', 'PRON')\n",
      "6232 ('they', 'PRON')\n",
      "6233 ('did', 'VERB')\n",
      "6234 ('was', 'VERB')\n",
      "6235 ('to', 'ADP')\n",
      "6236 ('keep', 'VERB')\n",
      "6237 ('alive', 'ADJ')\n",
      "6238 ('in', 'ADP')\n",
      "6239 ('him', 'PRON')\n",
      "6240 ('the', 'DET')\n",
      "6241 ('belief', 'NOUN')\n",
      "6242 (',', '')\n",
      "6243 ('or', 'CONJ')\n",
      "6244 ('hope', 'VERB')\n",
      "6245 (',', '')\n",
      "6246 ('that', 'CONJ')\n",
      "6247 ('others', 'PRON')\n",
      "6248 ('besides', 'ADP')\n",
      "6249 ('himself', 'PRON')\n",
      "6250 ('were', 'VERB')\n",
      "6251 ('the', 'DET')\n",
      "6252 ('enemies', 'NOUN')\n",
      "6253 ('of', 'ADP')\n",
      "6254 ('the', 'DET')\n",
      "6255 ('Party', 'NOUN')\n",
      "6256 ('.', '')\n",
      "6257 ('Perhaps', 'ADV')\n",
      "6258 ('the', 'DET')\n",
      "6259 ('rumours', 'NOUN')\n",
      "6260 ('of', 'ADP')\n",
      "6261 ('vast', 'ADJ')\n",
      "6262 ('underground', 'ADJ')\n",
      "6263 ('conspiracies', 'NOUN')\n",
      "6264 ('were', 'VERB')\n",
      "6265 ('true', 'ADJ')\n",
      "6266 ('after', 'ADP')\n",
      "6267 ('all', 'PRON')\n",
      "6268 ('-', '')\n",
      "6269 ('perhaps', 'ADV')\n",
      "6270 ('the', 'DET')\n",
      "6271 ('Brotherhood', 'NOUN')\n",
      "6272 ('really', 'ADV')\n",
      "6273 ('existed', 'VERB')\n",
      "6274 ('!', '')\n",
      "6275 ('It', 'PRON')\n",
      "6276 ('was', 'VERB')\n",
      "6277 ('impossible', 'ADJ')\n",
      "6278 (',', '')\n",
      "6279 ('in', 'ADP')\n",
      "6280 ('spite', 'NOUN')\n",
      "6281 ('of', 'ADP')\n",
      "6282 ('the', 'DET')\n",
      "6283 ('endless', 'ADJ')\n",
      "6284 ('arrests', 'NOUN')\n",
      "6285 ('and', 'CONJ')\n",
      "6286 ('confessions', 'NOUN')\n",
      "6287 ('and', 'CONJ')\n",
      "6288 ('executions', 'NOUN')\n",
      "6289 (',', '')\n",
      "6290 ('to', 'ADP')\n",
      "6291 ('be', 'VERB')\n",
      "6292 ('sure', 'ADJ')\n",
      "6293 ('that', 'CONJ')\n",
      "6294 ('the', 'DET')\n",
      "6295 ('Brotherhood', 'NOUN')\n",
      "6296 ('was', 'VERB')\n",
      "6297 ('not', 'ADV')\n",
      "6298 ('simply', 'ADV')\n",
      "6299 ('a', 'DET')\n",
      "6300 ('myth', 'NOUN')\n",
      "6301 ('.', '')\n",
      "6302 ('Some', 'DET')\n",
      "6303 ('days', 'NOUN')\n",
      "6304 ('he', 'PRON')\n",
      "6305 ('believed', 'VERB')\n",
      "6306 ('in', 'ADP')\n",
      "6307 ('it', 'PRON')\n",
      "6308 (',', '')\n",
      "6309 ('some', 'DET')\n",
      "6310 ('days', 'NOUN')\n",
      "6311 ('not', 'ADV')\n",
      "6312 ('.', '')\n",
      "6313 ('There', 'PRON')\n",
      "6314 ('was', 'VERB')\n",
      "6315 ('no', 'DET')\n",
      "6316 ('evidence', 'NOUN')\n",
      "6317 (',', '')\n",
      "6318 ('only', 'ADV')\n",
      "6319 ('fleeting', 'ADJ')\n",
      "6320 ('glimpses', 'NOUN')\n",
      "6321 ('that', 'PRON')\n",
      "6322 ('might', 'VERB')\n",
      "6323 ('mean', 'VERB')\n",
      "6324 ('anything', 'PRON')\n",
      "6325 ('or', 'CONJ')\n",
      "6326 ('nothing', 'PRON')\n",
      "6327 (':', '')\n",
      "6328 ('snatches', 'NOUN')\n",
      "6329 ('of', 'ADP')\n",
      "6330 ('overheard', 'ADJ')\n",
      "6331 ('conversation', 'NOUN')\n",
      "6332 (',', '')\n",
      "6333 ('faint', 'ADJ')\n",
      "6334 ('scribbles', 'NOUN')\n",
      "6335 ('on', 'ADP')\n",
      "6336 ('lavatory', 'NOUN')\n",
      "6337 ('walls', 'NOUN')\n",
      "6338 ('-', '')\n",
      "6339 ('once', 'ADV')\n",
      "6340 (',', '')\n",
      "6341 ('even', 'ADV')\n",
      "6342 (',', '')\n",
      "6343 ('when', 'CONJ')\n",
      "6344 ('two', 'NUM')\n",
      "6345 ('strangers', 'NOUN')\n",
      "6346 ('met', 'VERB')\n",
      "6347 (',', '')\n",
      "6348 ('a', 'DET')\n",
      "6349 ('small', 'ADJ')\n",
      "6350 ('movement', 'NOUN')\n",
      "6351 ('of', 'ADP')\n",
      "6352 ('the', 'DET')\n",
      "6353 ('hand', 'NOUN')\n",
      "6354 ('which', 'PRON')\n",
      "6355 ('had', 'VERB')\n",
      "6356 ('looked', 'VERB')\n",
      "6357 ('as', 'ADP')\n",
      "6358 ('though', 'CONJ')\n",
      "6359 ('it', 'PRON')\n",
      "6360 ('might', 'VERB')\n",
      "6361 ('be', 'VERB')\n",
      "6362 ('a', 'DET')\n",
      "6363 ('signal', 'NOUN')\n",
      "6364 ('of', 'ADP')\n",
      "6365 ('recognition', 'NOUN')\n",
      "6366 ('.', '')\n",
      "6367 ('It', 'PRON')\n",
      "6368 ('was', 'VERB')\n",
      "6369 ('all', 'PRON')\n",
      "6370 ('guesswork', 'NOUN')\n",
      "6371 (':', '')\n",
      "6372 ('very', 'ADV')\n",
      "6373 ('likely', 'ADV')\n",
      "6374 ('he', 'PRON')\n",
      "6375 ('had', 'VERB')\n",
      "6376 ('imagined', 'VERB')\n",
      "6377 ('everything', 'PRON')\n",
      "6378 ('.', '')\n",
      "6379 ('He', 'PRON')\n",
      "6380 ('had', 'VERB')\n",
      "6381 ('gone', 'VERB')\n",
      "6382 ('back', 'ADV')\n",
      "6383 ('to', 'ADP')\n",
      "6384 ('his', 'DET')\n",
      "6385 ('cubicle', 'NOUN')\n",
      "6386 ('without', 'ADP')\n",
      "6387 ('looking', 'VERB')\n",
      "6388 ('at', 'ADP')\n",
      "6389 (\"O'Brien\", 'NOUN')\n",
      "6390 ('again', 'ADV')\n",
      "6391 ('.', '')\n",
      "6392 ('The', 'DET')\n",
      "6393 ('idea', 'NOUN')\n",
      "6394 ('of', 'ADP')\n",
      "6395 ('following', 'VERB')\n",
      "6396 ('up', 'ADP')\n",
      "6397 ('their', 'DET')\n",
      "6398 ('momentary', 'ADJ')\n",
      "6399 ('contact', 'NOUN')\n",
      "6400 ('hardly', 'ADV')\n",
      "6401 ('crossed', 'VERB')\n",
      "6402 ('his', 'DET')\n",
      "6403 ('mind', 'NOUN')\n",
      "6404 ('.', '')\n",
      "6405 ('It', 'PRON')\n",
      "6406 ('would', 'VERB')\n",
      "6407 ('have', 'VERB')\n",
      "6408 ('been', 'VERB')\n",
      "6409 ('inconceivably', 'ADV')\n",
      "6410 ('dangerous', 'ADJ')\n",
      "6411 ('even', 'ADV')\n",
      "6412 ('if', 'CONJ')\n",
      "6413 ('he', 'PRON')\n",
      "6414 ('had', 'VERB')\n",
      "6415 ('known', 'VERB')\n",
      "6416 ('how', 'ADV')\n",
      "6417 ('to', 'ADP')\n",
      "6418 ('set', 'VERB')\n",
      "6419 ('about', 'ADP')\n",
      "6420 ('doing', 'VERB')\n",
      "6421 ('it', 'PRON')\n",
      "6422 ('.', '')\n",
      "6423 ('For', 'ADP')\n",
      "6424 ('a', 'DET')\n",
      "6425 ('second', 'NOUN')\n",
      "6426 (',', '')\n",
      "6427 ('two', 'NUM')\n",
      "6428 ('seconds', 'NOUN')\n",
      "6429 (',', '')\n",
      "6430 ('they', 'PRON')\n",
      "6431 ('had', 'VERB')\n",
      "6432 ('exchanged', 'VERB')\n",
      "6433 ('an', 'DET')\n",
      "6434 ('equivocal', 'ADJ')\n",
      "6435 ('glance', 'NOUN')\n",
      "6436 (',', '')\n",
      "6437 ('and', 'CONJ')\n",
      "6438 ('that', 'PRON')\n",
      "6439 ('was', 'VERB')\n",
      "6440 ('the', 'DET')\n",
      "6441 ('end', 'NOUN')\n",
      "6442 ('of', 'ADP')\n",
      "6443 ('the', 'DET')\n",
      "6444 ('story', 'NOUN')\n",
      "6445 ('.', '')\n",
      "6446 ('But', 'CONJ')\n",
      "6447 ('even', 'ADV')\n",
      "6448 ('that', 'PRON')\n",
      "6449 ('was', 'VERB')\n",
      "6450 ('a', 'DET')\n",
      "6451 ('memorable', 'ADJ')\n",
      "6452 ('event', 'NOUN')\n",
      "6453 (',', '')\n",
      "6454 ('in', 'ADP')\n",
      "6455 ('the', 'DET')\n",
      "6456 ('locked', 'ADJ')\n",
      "6457 ('loneliness', 'NOUN')\n",
      "6458 ('in', 'ADP')\n",
      "6459 ('which', 'PRON')\n",
      "6460 ('one', 'PRON')\n",
      "6461 ('had', 'VERB')\n",
      "6462 ('to', 'ADP')\n",
      "6463 ('live', 'VERB')\n",
      "6464 ('.', '')\n",
      "6465 ('Winston', 'NOUN')\n",
      "6466 ('roused', 'VERB')\n",
      "6467 ('himself', 'PRON')\n",
      "6468 ('and', 'CONJ')\n",
      "6469 ('sat', 'VERB')\n",
      "6470 ('up', 'ADP')\n",
      "6471 ('straighter', 'ADJ')\n",
      "6472 ('.', '')\n",
      "6473 ('He', 'PRON')\n",
      "6474 ('let', 'VERB')\n",
      "6475 ('out', 'ADP')\n",
      "6476 ('a', 'DET')\n",
      "6477 ('belch', 'NOUN')\n",
      "6478 ('.', '')\n",
      "6479 ('The', 'DET')\n",
      "6480 ('gin', 'NOUN')\n",
      "6481 ('was', 'VERB')\n",
      "6482 ('rising', 'VERB')\n",
      "6483 ('from', 'ADP')\n",
      "6484 ('his', 'DET')\n",
      "6485 ('stomach', 'NOUN')\n",
      "6486 ('.', '')\n",
      "6487 ('His', 'DET')\n",
      "6488 ('eyes', 'NOUN')\n",
      "6489 ('re-focused', 'VERB')\n",
      "6490 ('on', 'ADP')\n",
      "6491 ('the', 'DET')\n",
      "6492 ('page', 'NOUN')\n",
      "6493 ('.', '')\n",
      "6494 ('He', 'PRON')\n",
      "6495 ('discovered', 'VERB')\n",
      "6496 ('that', 'CONJ')\n",
      "6497 ('while', 'CONJ')\n",
      "6498 ('he', 'PRON')\n",
      "6499 ('sat', 'VERB')\n",
      "6500 ('helplessly', 'ADV')\n",
      "6501 ('musing', 'VERB')\n",
      "6502 ('he', 'PRON')\n",
      "6503 ('had', 'VERB')\n",
      "6504 ('also', 'ADV')\n",
      "6505 ('been', 'VERB')\n",
      "6506 ('writing', 'VERB')\n",
      "6507 (',', '')\n",
      "6508 ('as', 'CONJ')\n",
      "6509 ('though', 'CONJ')\n",
      "6510 ('by', 'ADP')\n",
      "6511 ('automatic', 'ADJ')\n",
      "6512 ('action', 'NOUN')\n",
      "6513 ('.', '')\n",
      "6514 ('And', 'CONJ')\n",
      "6515 ('it', 'PRON')\n",
      "6516 ('was', 'VERB')\n",
      "6517 ('no', 'ADV')\n",
      "6518 ('longer', 'ADV')\n",
      "6519 ('the', 'DET')\n",
      "6520 ('same', 'ADJ')\n",
      "6521 ('cramped', 'ADJ')\n",
      "6522 (',', '')\n",
      "6523 ('awkward', 'ADJ')\n",
      "6524 ('handwriting', 'NOUN')\n",
      "6525 ('as', 'CONJ')\n",
      "6526 ('before', 'ADV')\n",
      "6527 ('.', '')\n",
      "6528 ('His', 'DET')\n",
      "6529 ('pen', 'NOUN')\n",
      "6530 ('had', 'VERB')\n",
      "6531 ('slid', 'VERB')\n",
      "6532 ('voluptuously', 'ADV')\n",
      "6533 ('over', 'ADP')\n",
      "6534 ('the', 'DET')\n",
      "6535 ('smooth', 'ADJ')\n",
      "6536 ('paper', 'NOUN')\n",
      "6537 (',', '')\n",
      "6538 ('printing', 'VERB')\n",
      "6539 ('in', 'ADP')\n",
      "6540 ('large', 'ADJ')\n",
      "6541 ('neat', 'ADJ')\n",
      "6542 ('capitals', 'NOUN')\n",
      "6543 ('Down', 'ADV')\n",
      "6544 ('with', 'ADP')\n",
      "6545 ('Big', 'ADJ')\n",
      "6546 ('Brother', 'NOUN')\n",
      "6547 ('Down', 'ADV')\n",
      "6548 ('with', 'ADP')\n",
      "6549 ('Big', 'ADJ')\n",
      "6550 ('Brother', 'NOUN')\n",
      "6551 ('Down', 'ADV')\n",
      "6552 ('with', 'ADP')\n",
      "6553 ('Big', 'ADJ')\n",
      "6554 ('Brother', 'NOUN')\n",
      "6555 ('Down', 'ADV')\n",
      "6556 ('with', 'ADP')\n",
      "6557 ('Big', 'ADJ')\n",
      "6558 ('Brother', 'NOUN')\n",
      "6559 ('Down', 'ADV')\n",
      "6560 ('with', 'ADP')\n",
      "6561 ('Big', 'ADJ')\n",
      "6562 ('Brother', 'NOUN')\n",
      "6563 ('over', 'ADV')\n",
      "6564 ('and', 'CONJ')\n",
      "6565 ('over', 'ADV')\n",
      "6566 ('again', 'ADV')\n",
      "6567 (',', '')\n",
      "6568 ('filling', 'VERB')\n",
      "6569 ('half', 'ADJ')\n",
      "6570 ('a', 'DET')\n",
      "6571 ('page', 'NOUN')\n",
      "6572 ('.', '')\n",
      "6573 ('He', 'PRON')\n",
      "6574 ('could', 'VERB')\n",
      "6575 ('not', 'ADV')\n",
      "6576 ('help', 'VERB')\n",
      "6577 ('feeling', 'VERB')\n",
      "6578 ('a', 'DET')\n",
      "6579 ('twinge', 'NOUN')\n",
      "6580 ('of', 'ADP')\n",
      "6581 ('panic', 'NOUN')\n",
      "6582 ('.', '')\n",
      "6583 ('It', 'PRON')\n",
      "6584 ('was', 'VERB')\n",
      "6585 ('absurd', 'ADJ')\n",
      "6586 (',', '')\n",
      "6587 ('since', 'CONJ')\n",
      "6588 ('the', 'DET')\n",
      "6589 ('writing', 'VERB')\n",
      "6590 ('of', 'ADP')\n",
      "6591 ('those', 'DET')\n",
      "6592 ('particular', 'ADJ')\n",
      "6593 ('words', 'NOUN')\n",
      "6594 ('was', 'VERB')\n",
      "6595 ('not', 'ADV')\n",
      "6596 ('more', 'ADV')\n",
      "6597 ('dangerous', 'ADJ')\n",
      "6598 ('than', 'ADP')\n",
      "6599 ('the', 'DET')\n",
      "6600 ('initial', 'ADJ')\n",
      "6601 ('act', 'NOUN')\n",
      "6602 ('of', 'ADP')\n",
      "6603 ('opening', 'VERB')\n",
      "6604 ('the', 'DET')\n",
      "6605 ('diary', 'NOUN')\n",
      "6606 (',', '')\n",
      "6607 ('but', 'CONJ')\n",
      "6608 ('for', 'ADP')\n",
      "6609 ('a', 'DET')\n",
      "6610 ('moment', 'NOUN')\n",
      "6611 ('he', 'PRON')\n",
      "6612 ('was', 'VERB')\n",
      "6613 ('tempted', 'VERB')\n",
      "6614 ('to', 'ADP')\n",
      "6615 ('tear', 'VERB')\n",
      "6616 ('out', 'ADP')\n",
      "6617 ('the', 'DET')\n",
      "6618 ('spoiled', 'VERB')\n",
      "6619 ('pages', 'NOUN')\n",
      "6620 ('and', 'CONJ')\n",
      "6621 ('abandon', 'VERB')\n",
      "6622 ('the', 'DET')\n",
      "6623 ('enterprise', 'NOUN')\n",
      "6624 ('altogether', 'ADV')\n",
      "6625 ('.', '')\n",
      "6626 ('He', 'PRON')\n",
      "6627 ('did', 'VERB')\n",
      "6628 ('not', 'ADV')\n",
      "6629 ('do', 'VERB')\n",
      "6630 ('so', 'ADV')\n",
      "6631 (',', '')\n",
      "6632 ('however', 'ADV')\n",
      "6633 (',', '')\n",
      "6634 ('because', 'CONJ')\n",
      "6635 ('he', 'PRON')\n",
      "6636 ('knew', 'VERB')\n",
      "6637 ('that', 'CONJ')\n",
      "6638 ('it', 'PRON')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6639 ('was', 'VERB')\n",
      "6640 ('useless', 'ADJ')\n",
      "6641 ('.', '')\n",
      "6642 ('Whether', 'CONJ')\n",
      "6643 ('he', 'PRON')\n",
      "6644 ('wrote', 'VERB')\n",
      "6645 ('Down', 'ADV')\n",
      "6646 ('with', 'ADP')\n",
      "6647 ('Big', 'ADJ')\n",
      "6648 ('Brother', 'NOUN')\n",
      "6649 (',', '')\n",
      "6650 ('or', 'CONJ')\n",
      "6651 ('whether', 'CONJ')\n",
      "6652 ('he', 'PRON')\n",
      "6653 ('refrained', 'VERB')\n",
      "6654 ('from', 'ADP')\n",
      "6655 ('writing', 'VERB')\n",
      "6656 ('it', 'PRON')\n",
      "6657 (',', '')\n",
      "6658 ('made', 'VERB')\n",
      "6659 ('no', 'DET')\n",
      "6660 ('difference', 'NOUN')\n",
      "6661 ('.', '')\n",
      "6662 ('Whether', 'CONJ')\n",
      "6663 ('he', 'PRON')\n",
      "6664 ('went', 'VERB')\n",
      "6665 ('on', 'ADP')\n",
      "6666 ('with', 'ADP')\n",
      "6667 ('the', 'DET')\n",
      "6668 ('diary', 'NOUN')\n",
      "6669 (',', '')\n",
      "6670 ('or', 'CONJ')\n",
      "6671 ('whether', 'CONJ')\n",
      "6672 ('he', 'PRON')\n",
      "6673 ('did', 'VERB')\n",
      "6674 ('not', 'ADV')\n",
      "6675 ('go', 'VERB')\n",
      "6676 ('on', 'ADP')\n",
      "6677 ('with', 'ADP')\n",
      "6678 ('it', 'PRON')\n",
      "6679 (',', '')\n",
      "6680 ('made', 'VERB')\n",
      "6681 ('no', 'DET')\n",
      "6682 ('difference', 'NOUN')\n",
      "6683 ('.', '')\n",
      "6684 ('The', 'DET')\n",
      "6685 ('Thought', 'NOUN')\n",
      "6686 ('Police', 'NOUN')\n",
      "6687 ('would', 'VERB')\n",
      "6688 ('get', 'VERB')\n",
      "6689 ('him', 'PRON')\n",
      "6690 ('just', 'ADV')\n",
      "6691 ('the', 'DET')\n",
      "6692 ('same', 'ADJ')\n",
      "6693 ('.', '')\n",
      "6694 ('He', 'PRON')\n",
      "6695 ('had', 'VERB')\n",
      "6696 ('committed', 'VERB')\n",
      "6697 ('-', '')\n",
      "6698 ('would', 'VERB')\n",
      "6699 ('still', 'ADV')\n",
      "6700 ('have', 'VERB')\n",
      "6701 ('committed', 'VERB')\n",
      "6702 (',', '')\n",
      "6703 ('even', 'ADV')\n",
      "6704 ('if', 'CONJ')\n",
      "6705 ('he', 'PRON')\n",
      "6706 ('had', 'VERB')\n",
      "6707 ('never', 'ADV')\n",
      "6708 ('set', 'VERB')\n",
      "6709 ('pen', 'NOUN')\n",
      "6710 ('to', 'ADP')\n",
      "6711 ('paper', 'NOUN')\n",
      "6712 ('-', '')\n",
      "6713 ('the', 'DET')\n",
      "6714 ('essential', 'ADJ')\n",
      "6715 ('crime', 'NOUN')\n",
      "6716 ('that', 'PRON')\n",
      "6717 ('contained', 'VERB')\n",
      "6718 ('all', 'DET')\n",
      "6719 ('others', 'PRON')\n",
      "6720 ('in', 'ADP')\n",
      "6721 ('itself', 'PRON')\n",
      "6722 ('.', '')\n",
      "6723 ('Thoughtcrime', 'NOUN')\n",
      "6724 (',', '')\n",
      "6725 ('they', 'PRON')\n",
      "6726 ('called', 'VERB')\n",
      "6727 ('it', 'PRON')\n",
      "6728 ('.', '')\n",
      "6729 ('Thoughtcrime', 'NOUN')\n",
      "6730 ('was', 'VERB')\n",
      "6731 ('not', 'ADV')\n",
      "6732 ('a', 'DET')\n",
      "6733 ('thing', 'NOUN')\n",
      "6734 ('that', 'PRON')\n",
      "6735 ('could', 'VERB')\n",
      "6736 ('be', 'VERB')\n",
      "6737 ('concealed', 'VERB')\n",
      "6738 ('for', 'ADP')\n",
      "6739 ('ever', 'ADV')\n",
      "6740 ('.', '')\n",
      "6741 ('You', 'PRON')\n",
      "6742 ('might', 'VERB')\n",
      "6743 ('dodge', 'VERB')\n",
      "6744 ('successfully', 'ADV')\n",
      "6745 ('for', 'ADP')\n",
      "6746 ('a', 'DET')\n",
      "6747 ('while', 'CONJ')\n",
      "6748 (',', '')\n",
      "6749 ('even', 'ADV')\n",
      "6750 ('for', 'ADP')\n",
      "6751 ('years', 'NOUN')\n",
      "6752 (',', '')\n",
      "6753 ('but', 'CONJ')\n",
      "6754 ('sooner', 'ADV')\n",
      "6755 ('or', 'CONJ')\n",
      "6756 ('later', 'ADV')\n",
      "6757 ('they', 'PRON')\n",
      "6758 ('were', 'VERB')\n",
      "6759 ('bound', 'ADJ')\n",
      "6760 ('to', 'ADP')\n",
      "6761 ('get', 'VERB')\n",
      "6762 ('you', 'PRON')\n",
      "6763 ('.', '')\n",
      "6764 ('It', 'PRON')\n",
      "6765 ('was', 'VERB')\n",
      "6766 ('always', 'ADV')\n",
      "6767 ('at', 'ADP')\n",
      "6768 ('night', 'NOUN')\n",
      "6769 ('-', '')\n",
      "6770 ('the', 'DET')\n",
      "6771 ('arrests', 'NOUN')\n",
      "6772 ('invariably', 'ADV')\n",
      "6773 ('happened', 'VERB')\n",
      "6774 ('at', 'ADP')\n",
      "6775 ('night', 'NOUN')\n",
      "6776 ('.', '')\n",
      "6777 ('The', 'DET')\n",
      "6778 ('sudden', 'ADJ')\n",
      "6779 ('jerk', 'NOUN')\n",
      "6780 ('out', 'ADP')\n",
      "6781 ('of', 'ADP')\n",
      "6782 ('sleep', 'NOUN')\n",
      "6783 (',', '')\n",
      "6784 ('the', 'DET')\n",
      "6785 ('rough', 'ADJ')\n",
      "6786 ('hand', 'NOUN')\n",
      "6787 ('shaking', 'VERB')\n",
      "6788 ('your', 'DET')\n",
      "6789 ('shoulder', 'NOUN')\n",
      "6790 (',', '')\n",
      "6791 ('the', 'DET')\n",
      "6792 ('lights', 'NOUN')\n",
      "6793 ('glaring', 'VERB')\n",
      "6794 ('in', 'ADP')\n",
      "6795 ('your', 'DET')\n",
      "6796 ('eyes', 'NOUN')\n",
      "6797 (',', '')\n",
      "6798 ('the', 'DET')\n",
      "6799 ('ring', 'NOUN')\n",
      "6800 ('of', 'ADP')\n",
      "6801 ('hard', 'ADV')\n",
      "6802 ('faces', 'NOUN')\n",
      "6803 ('round', 'ADP')\n",
      "6804 ('the', 'DET')\n",
      "6805 ('bed', 'NOUN')\n",
      "6806 ('.', '')\n",
      "6807 ('In', 'ADP')\n",
      "6808 ('the', 'DET')\n",
      "6809 ('vast', 'ADJ')\n",
      "6810 ('majority', 'NOUN')\n",
      "6811 ('of', 'ADP')\n",
      "6812 ('cases', 'NOUN')\n",
      "6813 ('there', 'PRON')\n",
      "6814 ('was', 'VERB')\n",
      "6815 ('no', 'DET')\n",
      "6816 ('trial', 'NOUN')\n",
      "6817 (',', '')\n",
      "6818 ('no', 'DET')\n",
      "6819 ('report', 'NOUN')\n",
      "6820 ('of', 'ADP')\n",
      "6821 ('the', 'DET')\n",
      "6822 ('arrest', 'NOUN')\n",
      "6823 ('.', '')\n",
      "6824 ('People', 'NOUN')\n",
      "6825 ('simply', 'ADV')\n",
      "6826 ('disappeared', 'VERB')\n",
      "6827 (',', '')\n",
      "6828 ('always', 'ADV')\n",
      "6829 ('during', 'ADP')\n",
      "6830 ('the', 'DET')\n",
      "6831 ('night', 'NOUN')\n",
      "6832 ('.', '')\n",
      "6833 ('Your', 'DET')\n",
      "6834 ('name', 'NOUN')\n",
      "6835 ('was', 'VERB')\n",
      "6836 ('removed', 'VERB')\n",
      "6837 ('from', 'ADP')\n",
      "6838 ('the', 'DET')\n",
      "6839 ('registers', 'NOUN')\n",
      "6840 (',', '')\n",
      "6841 ('every', 'DET')\n",
      "6842 ('record', 'NOUN')\n",
      "6843 ('of', 'ADP')\n",
      "6844 ('everything', 'PRON')\n",
      "6845 ('you', 'PRON')\n",
      "6846 ('had', 'VERB')\n",
      "6847 ('ever', 'ADV')\n",
      "6848 ('done', 'VERB')\n",
      "6849 ('was', 'VERB')\n",
      "6850 ('wiped', 'VERB')\n",
      "6851 ('out', 'ADP')\n",
      "6852 (',', '')\n",
      "6853 ('your', 'DET')\n",
      "6854 ('one-time', 'ADJ')\n",
      "6855 ('existence', 'NOUN')\n",
      "6856 ('was', 'VERB')\n",
      "6857 ('denied', 'VERB')\n",
      "6858 ('and', 'CONJ')\n",
      "6859 ('then', 'ADV')\n",
      "6860 ('forgotten', 'VERB')\n",
      "6861 ('.', '')\n",
      "6862 ('You', 'PRON')\n",
      "6863 ('were', 'VERB')\n",
      "6864 ('abolished', 'VERB')\n",
      "6865 (',', '')\n",
      "6866 ('annihilated', 'VERB')\n",
      "6867 (':', '')\n",
      "6868 ('vaporized', 'VERB')\n",
      "6869 ('was', 'VERB')\n",
      "6870 ('the', 'DET')\n",
      "6871 ('usual', 'ADJ')\n",
      "6872 ('word', 'NOUN')\n",
      "6873 ('.', '')\n",
      "6874 ('For', 'ADP')\n",
      "6875 ('a', 'DET')\n",
      "6876 ('moment', 'NOUN')\n",
      "6877 ('he', 'PRON')\n",
      "6878 ('was', 'VERB')\n",
      "6879 ('seized', 'VERB')\n",
      "6880 ('by', 'ADP')\n",
      "6881 ('a', 'DET')\n",
      "6882 ('kind', 'NOUN')\n",
      "6883 ('of', 'ADP')\n",
      "6884 ('hysteria', 'NOUN')\n",
      "6885 ('.', '')\n",
      "6886 ('He', 'PRON')\n",
      "6887 ('began', 'VERB')\n",
      "6888 ('writing', 'VERB')\n",
      "6889 ('in', 'ADP')\n",
      "6890 ('a', 'DET')\n",
      "6891 ('hurried', 'ADJ')\n",
      "6892 ('untidy', 'ADJ')\n",
      "6893 ('scrawl', 'NOUN')\n",
      "6894 (':', '')\n",
      "6895 ('theyll', 'X')\n",
      "6896 ('shoot', 'VERB')\n",
      "6897 ('me', 'PRON')\n",
      "6898 ('i', 'NOUN')\n",
      "6899 (\"don't\", 'VERB')\n",
      "6900 ('care', 'VERB')\n",
      "6901 ('theyll', 'X')\n",
      "6902 ('shoot', 'VERB')\n",
      "6903 ('me', 'PRON')\n",
      "6904 ('in', 'ADP')\n",
      "6905 ('the', 'DET')\n",
      "6906 ('back', 'NOUN')\n",
      "6907 ('of', 'ADP')\n",
      "6908 ('the', 'DET')\n",
      "6909 ('neck', 'NOUN')\n",
      "6910 ('i', 'NOUN')\n",
      "6911 ('dont', 'VERB')\n",
      "6912 ('care', 'VERB')\n",
      "6913 ('down', 'ADV')\n",
      "6914 ('with', 'ADP')\n",
      "6915 ('big', 'ADJ')\n",
      "6916 ('brother', 'NOUN')\n",
      "6917 ('they', 'PRON')\n",
      "6918 ('always', 'ADV')\n",
      "6919 ('shoot', 'VERB')\n",
      "6920 ('you', 'PRON')\n",
      "6921 ('in', 'ADP')\n",
      "6922 ('the', 'DET')\n",
      "6923 ('back', 'NOUN')\n",
      "6924 ('of', 'ADP')\n",
      "6925 ('the', 'DET')\n",
      "6926 ('neck', 'NOUN')\n",
      "6927 ('i', 'NOUN')\n",
      "6928 ('dont', 'VERB')\n",
      "6929 ('care', 'VERB')\n",
      "6930 ('down', 'ADV')\n",
      "6931 ('with', 'ADP')\n",
      "6932 ('big', 'ADJ')\n",
      "6933 ('brother', 'NOUN')\n",
      "6934 ('He', 'PRON')\n",
      "6935 ('sat', 'VERB')\n",
      "6936 ('back', 'ADV')\n",
      "6937 ('in', 'ADP')\n",
      "6938 ('his', 'DET')\n",
      "6939 ('chair', 'NOUN')\n",
      "6940 (',', '')\n",
      "6941 ('slightly', 'ADV')\n",
      "6942 ('ashamed', 'ADJ')\n",
      "6943 ('of', 'ADP')\n",
      "6944 ('himself', 'PRON')\n",
      "6945 (',', '')\n",
      "6946 ('and', 'CONJ')\n",
      "6947 ('laid', 'VERB')\n",
      "6948 ('down', 'ADV')\n",
      "6949 ('the', 'DET')\n",
      "6950 ('pen', 'NOUN')\n",
      "6951 ('.', '')\n",
      "6952 ('The', 'DET')\n",
      "6953 ('next', 'ADJ')\n",
      "6954 ('moment', 'NOUN')\n",
      "6955 ('he', 'PRON')\n",
      "6956 ('started', 'VERB')\n",
      "6957 ('violently', 'ADV')\n",
      "6958 ('.', '')\n",
      "6959 ('There', 'PRON')\n",
      "6960 ('was', 'VERB')\n",
      "6961 ('a', 'DET')\n",
      "6962 ('knocking', 'NOUN')\n",
      "6963 ('at', 'ADP')\n",
      "6964 ('the', 'DET')\n",
      "6965 ('door', 'NOUN')\n",
      "6966 ('.', '')\n",
      "6967 ('Already', 'ADV')\n",
      "6968 ('!', '')\n",
      "6969 ('He', 'PRON')\n",
      "6970 ('sat', 'VERB')\n",
      "6971 ('as', 'ADV')\n",
      "6972 ('still', 'ADV')\n",
      "6973 ('as', 'ADP')\n",
      "6974 ('a', 'DET')\n",
      "6975 ('mouse', 'NOUN')\n",
      "6976 (',', '')\n",
      "6977 ('in', 'ADP')\n",
      "6978 ('the', 'DET')\n",
      "6979 ('futile', 'ADJ')\n",
      "6980 ('hope', 'NOUN')\n",
      "6981 ('that', 'CONJ')\n",
      "6982 ('whoever', 'PRON')\n",
      "6983 ('it', 'PRON')\n",
      "6984 ('was', 'VERB')\n",
      "6985 ('might', 'VERB')\n",
      "6986 ('go', 'VERB')\n",
      "6987 ('away', 'ADV')\n",
      "6988 ('after', 'ADP')\n",
      "6989 ('a', 'DET')\n",
      "6990 ('single', 'ADJ')\n",
      "6991 ('attempt', 'NOUN')\n",
      "6992 ('.', '')\n",
      "6993 ('But', 'CONJ')\n",
      "6994 ('no', 'ADV')\n",
      "6995 (',', '')\n",
      "6996 ('the', 'DET')\n",
      "6997 ('knocking', 'NOUN')\n",
      "6998 ('was', 'VERB')\n",
      "6999 ('repeated', 'VERB')\n",
      "7000 ('.', '')\n",
      "7001 ('The', 'DET')\n",
      "7002 ('worst', 'ADJ')\n",
      "7003 ('thing', 'NOUN')\n",
      "7004 ('of', 'ADP')\n",
      "7005 ('all', 'PRON')\n",
      "7006 ('would', 'VERB')\n",
      "7007 ('be', 'VERB')\n",
      "7008 ('to', 'ADP')\n",
      "7009 ('delay', 'VERB')\n",
      "7010 ('.', '')\n",
      "7011 ('His', 'DET')\n",
      "7012 ('heart', 'NOUN')\n",
      "7013 ('was', 'VERB')\n",
      "7014 ('thumping', 'VERB')\n",
      "7015 ('like', 'ADP')\n",
      "7016 ('a', 'DET')\n",
      "7017 ('drum', 'NOUN')\n",
      "7018 (',', '')\n",
      "7019 ('but', 'CONJ')\n",
      "7020 ('his', 'DET')\n",
      "7021 ('face', 'NOUN')\n",
      "7022 (',', '')\n",
      "7023 ('from', 'ADP')\n",
      "7024 ('long', 'ADJ')\n",
      "7025 ('habit', 'NOUN')\n",
      "7026 (',', '')\n",
      "7027 ('was', 'VERB')\n",
      "7028 ('probably', 'ADV')\n",
      "7029 ('expressionless', 'ADJ')\n",
      "7030 ('.', '')\n",
      "7031 ('He', 'PRON')\n",
      "7032 ('got', 'VERB')\n",
      "7033 ('up', 'ADP')\n",
      "7034 ('and', 'CONJ')\n",
      "7035 ('moved', 'VERB')\n",
      "7036 ('heavily', 'ADV')\n",
      "7037 ('towards', 'ADP')\n",
      "7038 ('the', 'DET')\n",
      "7039 ('door', 'NOUN')\n",
      "7040 ('.', '')\n",
      "7041 ('As', 'CONJ')\n",
      "7042 ('he', 'PRON')\n",
      "7043 ('put', 'VERB')\n",
      "7044 ('his', 'DET')\n",
      "7045 ('hand', 'NOUN')\n",
      "7046 ('to', 'ADP')\n",
      "7047 ('the', 'DET')\n",
      "7048 ('door-knob', 'NOUN')\n",
      "7049 ('Winston', 'NOUN')\n",
      "7050 ('saw', 'VERB')\n",
      "7051 ('that', 'CONJ')\n",
      "7052 ('he', 'PRON')\n",
      "7053 ('had', 'VERB')\n",
      "7054 ('left', 'VERB')\n",
      "7055 ('the', 'DET')\n",
      "7056 ('diary', 'NOUN')\n",
      "7057 ('open', 'ADJ')\n",
      "7058 ('on', 'ADP')\n",
      "7059 ('the', 'DET')\n",
      "7060 ('table', 'NOUN')\n",
      "7061 ('.', '')\n",
      "7062 ('Down', 'ADV')\n",
      "7063 ('with', 'ADP')\n",
      "7064 ('Big', 'ADJ')\n",
      "7065 ('Brother', 'NOUN')\n",
      "7066 ('was', 'VERB')\n",
      "7067 ('written', 'VERB')\n",
      "7068 ('all', 'ADV')\n",
      "7069 ('over', 'ADP')\n",
      "7070 ('it', 'PRON')\n",
      "7071 (',', '')\n",
      "7072 ('in', 'ADP')\n",
      "7073 ('letters', 'NOUN')\n",
      "7074 ('almost', 'ADV')\n",
      "7075 ('big', 'ADJ')\n",
      "7076 ('enough', 'ADV')\n",
      "7077 ('to', 'ADP')\n",
      "7078 ('be', 'VERB')\n",
      "7079 ('legible', 'ADJ')\n",
      "7080 ('across', 'ADP')\n",
      "7081 ('the', 'DET')\n",
      "7082 ('room', 'NOUN')\n",
      "7083 ('.', '')\n",
      "7084 ('It', 'PRON')\n",
      "7085 ('was', 'VERB')\n",
      "7086 ('an', 'DET')\n",
      "7087 ('inconceivably', 'ADV')\n",
      "7088 ('stupid', 'ADJ')\n",
      "7089 ('thing', 'NOUN')\n",
      "7090 ('to', 'ADP')\n",
      "7091 ('have', 'VERB')\n",
      "7092 ('done', 'VERB')\n",
      "7093 ('.', '')\n",
      "7094 ('But', 'CONJ')\n",
      "7095 (',', '')\n",
      "7096 ('he', 'PRON')\n",
      "7097 ('realized', 'VERB')\n",
      "7098 (',', '')\n",
      "7099 ('even', 'ADV')\n",
      "7100 ('in', 'ADP')\n",
      "7101 ('his', 'DET')\n",
      "7102 ('panic', 'NOUN')\n",
      "7103 ('he', 'PRON')\n",
      "7104 ('had', 'VERB')\n",
      "7105 ('not', 'ADV')\n",
      "7106 ('wanted', 'VERB')\n",
      "7107 ('to', 'ADP')\n",
      "7108 ('smudge', 'VERB')\n",
      "7109 ('the', 'DET')\n",
      "7110 ('creamy', 'ADJ')\n",
      "7111 ('paper', 'NOUN')\n",
      "7112 ('by', 'ADP')\n",
      "7113 ('shutting', 'VERB')\n",
      "7114 ('the', 'DET')\n",
      "7115 ('book', 'NOUN')\n",
      "7116 ('while', 'CONJ')\n",
      "7117 ('the', 'DET')\n",
      "7118 ('ink', 'NOUN')\n",
      "7119 ('was', 'VERB')\n",
      "7120 ('wet', 'ADJ')\n",
      "7121 ('.', '')\n",
      "7122 ('He', 'PRON')\n",
      "7123 ('drew', 'VERB')\n",
      "7124 ('in', 'ADP')\n",
      "7125 ('his', 'DET')\n",
      "7126 ('breath', 'NOUN')\n",
      "7127 ('and', 'CONJ')\n",
      "7128 ('opened', 'VERB')\n",
      "7129 ('the', 'DET')\n",
      "7130 ('door', 'NOUN')\n",
      "7131 ('.', '')\n",
      "7132 ('Instantly', 'ADV')\n",
      "7133 ('a', 'DET')\n",
      "7134 ('warm', 'ADJ')\n",
      "7135 ('wave', 'NOUN')\n",
      "7136 ('of', 'ADP')\n",
      "7137 ('relief', 'NOUN')\n",
      "7138 ('flowed', 'VERB')\n",
      "7139 ('through', 'ADP')\n",
      "7140 ('him', 'PRON')\n",
      "7141 ('.', '')\n",
      "7142 ('A', 'DET')\n",
      "7143 ('colourless', 'ADJ')\n",
      "7144 (',', '')\n",
      "7145 ('crushed-looking', 'ADJ')\n",
      "7146 ('woman', 'NOUN')\n",
      "7147 (',', '')\n",
      "7148 ('with', 'ADP')\n",
      "7149 ('wispy', 'ADJ')\n",
      "7150 ('hair', 'NOUN')\n",
      "7151 ('and', 'CONJ')\n",
      "7152 ('a', 'DET')\n",
      "7153 ('lined', 'VERB')\n",
      "7154 ('face', 'NOUN')\n",
      "7155 (',', '')\n",
      "7156 ('was', 'VERB')\n",
      "7157 ('standing', 'VERB')\n",
      "7158 ('outside', 'ADV')\n",
      "7159 ('.', '')\n",
      "7160 ('Oh', 'X')\n",
      "7161 (',', '')\n",
      "7162 ('comrade', 'NOUN')\n",
      "7163 (',', '')\n",
      "7164 ('she', 'PRON')\n",
      "7165 ('began', 'VERB')\n",
      "7166 ('in', 'ADP')\n",
      "7167 ('a', 'DET')\n",
      "7168 ('dreary', 'ADJ')\n",
      "7169 (',', '')\n",
      "7170 ('whining', 'VERB')\n",
      "7171 ('sort', 'NOUN')\n",
      "7172 ('of', 'ADP')\n",
      "7173 ('voice', 'NOUN')\n",
      "7174 (',', '')\n",
      "7175 ('I', 'PRON')\n",
      "7176 ('thought', 'VERB')\n",
      "7177 ('I', 'PRON')\n",
      "7178 ('heard', 'VERB')\n",
      "7179 ('you', 'PRON')\n",
      "7180 ('come', 'VERB')\n",
      "7181 ('in', 'ADP')\n",
      "7182 ('.', '')\n",
      "7183 ('Do', 'VERB')\n",
      "7184 ('you', 'PRON')\n",
      "7185 ('think', 'VERB')\n",
      "7186 ('you', 'PRON')\n",
      "7187 ('could', 'VERB')\n",
      "7188 ('come', 'VERB')\n",
      "7189 ('across', 'ADP')\n",
      "7190 ('and', 'CONJ')\n",
      "7191 ('have', 'VERB')\n",
      "7192 ('a', 'DET')\n",
      "7193 ('look', 'NOUN')\n",
      "7194 ('at', 'ADP')\n",
      "7195 ('our', 'DET')\n",
      "7196 ('kitchen', 'NOUN')\n",
      "7197 ('sink', 'NOUN')\n",
      "7198 ('?', '')\n",
      "7199 ('It', 'PRON')\n",
      "7200 (\"'s\", 'VERB')\n",
      "7200 (\"'s\", 'VERB')\n",
      "7201 ('got', 'VERB')\n",
      "7202 ('blocked', 'VERB')\n",
      "7203 ('up', 'ADP')\n",
      "7204 ('and', 'CONJ')\n",
      "7205 ('-', '')\n",
      "7206 ('It', 'PRON')\n",
      "7207 ('was', 'VERB')\n",
      "7208 ('Mrs', 'NOUN')\n",
      "7209 ('Parsons', 'NOUN')\n",
      "7210 (',', '')\n",
      "7211 ('the', 'DET')\n",
      "7212 ('wife', 'NOUN')\n",
      "7213 ('of', 'ADP')\n",
      "7214 ('a', 'DET')\n",
      "7215 ('neighbour', 'NOUN')\n",
      "7216 ('on', 'ADP')\n",
      "7217 ('the', 'DET')\n",
      "7218 ('same', 'ADJ')\n",
      "7219 ('floor', 'NOUN')\n",
      "7220 ('.', '')\n",
      "7221 ('(', '')\n",
      "7222 ('Mrs', 'NOUN')\n",
      "7223 ('was', 'VERB')\n",
      "7224 ('a', 'DET')\n",
      "7225 ('word', 'NOUN')\n",
      "7226 ('somewhat', 'ADV')\n",
      "7227 ('discountenanced', 'VERB')\n",
      "7228 ('by', 'ADP')\n",
      "7229 ('the', 'DET')\n",
      "7230 ('Party', 'NOUN')\n",
      "7231 ('-', '')\n",
      "7232 ('you', 'PRON')\n",
      "7233 ('were', 'VERB')\n",
      "7234 ('supposed', 'ADJ')\n",
      "7235 ('to', 'ADP')\n",
      "7236 ('call', 'VERB')\n",
      "7237 ('everyone', 'PRON')\n",
      "7238 ('comrade', 'NOUN')\n",
      "7239 ('-', '')\n",
      "7240 ('but', 'CONJ')\n",
      "7241 ('with', 'ADP')\n",
      "7242 ('some', 'DET')\n",
      "7243 ('women', 'NOUN')\n",
      "7244 ('one', 'PRON')\n",
      "7245 ('used', 'VERB')\n",
      "7246 ('it', 'PRON')\n",
      "7247 ('instinctively', 'ADV')\n",
      "7248 ('.', '')\n",
      "7249 (')', '')\n",
      "7250 ('She', 'PRON')\n",
      "7251 ('was', 'VERB')\n",
      "7252 ('a', 'DET')\n",
      "7253 ('woman', 'NOUN')\n",
      "7254 ('of', 'ADP')\n",
      "7255 ('about', 'ADV')\n",
      "7256 ('thirty', 'NUM')\n",
      "7257 (',', '')\n",
      "7258 ('but', 'CONJ')\n",
      "7259 ('looking', 'VERB')\n",
      "7260 ('much', 'ADV')\n",
      "7261 ('older', 'ADJ')\n",
      "7262 ('.', '')\n",
      "7263 ('One', 'PRON')\n",
      "7264 ('had', 'VERB')\n",
      "7265 ('the', 'DET')\n",
      "7266 ('impression', 'NOUN')\n",
      "7267 ('that', 'CONJ')\n",
      "7268 ('there', 'PRON')\n",
      "7269 ('was', 'VERB')\n",
      "7270 ('dust', 'NOUN')\n",
      "7271 ('in', 'ADP')\n",
      "7272 ('the', 'DET')\n",
      "7273 ('creases', 'NOUN')\n",
      "7274 ('of', 'ADP')\n",
      "7275 ('her', 'DET')\n",
      "7276 ('face', 'NOUN')\n",
      "7277 ('.', '')\n",
      "7278 ('Winston', 'NOUN')\n",
      "7279 ('followed', 'VERB')\n",
      "7280 ('her', 'PRON')\n",
      "7281 ('down', 'ADP')\n",
      "7282 ('the', 'DET')\n",
      "7283 ('passage', 'NOUN')\n",
      "7284 ('.', '')\n",
      "7285 ('These', 'DET')\n",
      "7286 ('amateur', 'ADJ')\n",
      "7287 ('repair', 'NOUN')\n",
      "7288 ('jobs', 'NOUN')\n",
      "7289 ('were', 'VERB')\n",
      "7290 ('an', 'DET')\n",
      "7291 ('almost', 'ADV')\n",
      "7292 ('daily', 'ADJ')\n",
      "7293 ('irritation', 'NOUN')\n",
      "7294 ('.', '')\n",
      "7295 ('Victory', 'NOUN')\n",
      "7296 ('Mansions', 'NOUN')\n",
      "7297 ('were', 'VERB')\n",
      "7298 ('old', 'ADJ')\n",
      "7299 ('flats', 'NOUN')\n",
      "7300 (',', '')\n",
      "7301 ('built', 'VERB')\n",
      "7302 ('in', 'ADP')\n",
      "7303 ('1930', 'NUM')\n",
      "7304 ('or', 'CONJ')\n",
      "7305 ('thereabouts', 'ADV')\n",
      "7306 (',', '')\n",
      "7307 ('and', 'CONJ')\n",
      "7308 ('were', 'VERB')\n",
      "7309 ('falling', 'VERB')\n",
      "7310 ('to', 'ADP')\n",
      "7311 ('pieces', 'NOUN')\n",
      "7312 ('.', '')\n",
      "7313 ('The', 'DET')\n",
      "7314 ('plaster', 'NOUN')\n",
      "7315 ('flaked', 'VERB')\n",
      "7316 ('constantly', 'ADV')\n",
      "7317 ('from', 'ADP')\n",
      "7318 ('ceilings', 'NOUN')\n",
      "7319 ('and', 'CONJ')\n",
      "7320 ('walls', 'NOUN')\n",
      "7321 (',', '')\n",
      "7322 ('the', 'DET')\n",
      "7323 ('pipes', 'NOUN')\n",
      "7324 ('burst', 'VERB')\n",
      "7325 ('in', 'ADP')\n",
      "7326 ('every', 'DET')\n",
      "7327 ('hard', 'ADJ')\n",
      "7328 ('frost', 'NOUN')\n",
      "7329 (',', '')\n",
      "7330 ('the', 'DET')\n",
      "7331 ('roof', 'NOUN')\n",
      "7332 ('leaked', 'VERB')\n",
      "7333 ('whenever', 'CONJ')\n",
      "7334 ('there', 'PRON')\n",
      "7335 ('was', 'VERB')\n",
      "7336 ('snow', 'NOUN')\n",
      "7337 (',', '')\n",
      "7338 ('the', 'DET')\n",
      "7339 ('heating', 'NOUN')\n",
      "7340 ('system', 'NOUN')\n",
      "7341 ('was', 'VERB')\n",
      "7342 ('usually', 'ADV')\n",
      "7343 ('running', 'VERB')\n",
      "7344 ('at', 'ADP')\n",
      "7345 ('half', 'ADJ')\n",
      "7346 ('steam', 'NOUN')\n",
      "7347 ('when', 'CONJ')\n",
      "7348 ('it', 'PRON')\n",
      "7349 ('was', 'VERB')\n",
      "7350 ('not', 'ADV')\n",
      "7351 ('closed', 'VERB')\n",
      "7352 ('down', 'ADV')\n",
      "7353 ('altogether', 'ADV')\n",
      "7354 ('from', 'ADP')\n",
      "7355 ('motives', 'NOUN')\n",
      "7356 ('of', 'ADP')\n",
      "7357 ('economy', 'NOUN')\n",
      "7358 ('.', '')\n",
      "7359 ('Repairs', 'NOUN')\n",
      "7360 (',', '')\n",
      "7361 ('except', 'ADP')\n",
      "7362 ('what', 'PRON')\n",
      "7363 ('you', 'PRON')\n",
      "7364 ('could', 'VERB')\n",
      "7365 ('do', 'VERB')\n",
      "7366 ('for', 'ADP')\n",
      "7367 ('yourself', 'PRON')\n",
      "7368 (',', '')\n",
      "7369 ('had', 'VERB')\n",
      "7370 ('to', 'ADP')\n",
      "7371 ('be', 'VERB')\n",
      "7372 ('sanctioned', 'VERB')\n",
      "7373 ('by', 'ADP')\n",
      "7374 ('remote', 'ADJ')\n",
      "7375 ('committees', 'NOUN')\n",
      "7376 ('which', 'PRON')\n",
      "7377 ('were', 'VERB')\n",
      "7378 ('liable', 'ADJ')\n",
      "7379 ('to', 'ADP')\n",
      "7380 ('hold', 'VERB')\n",
      "7381 ('up', 'ADP')\n",
      "7382 ('even', 'ADV')\n",
      "7383 ('the', 'DET')\n",
      "7384 ('mending', 'NOUN')\n",
      "7385 ('of', 'ADP')\n",
      "7386 ('a', 'DET')\n",
      "7387 ('window-pane', 'NOUN')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7388 ('for', 'ADP')\n",
      "7389 ('two', 'NUM')\n",
      "7390 ('years', 'NOUN')\n",
      "7391 ('.', '')\n",
      "7392 ('Of', 'ADP')\n",
      "7393 ('course', 'NOUN')\n",
      "7394 ('it', 'PRON')\n",
      "7395 (\"'s\", 'VERB')\n",
      "7396 ('only', 'ADV')\n",
      "7397 ('because', 'CONJ')\n",
      "7398 ('Tom', 'NOUN')\n",
      "7399 (\"isn't\", 'VERB')\n",
      "7400 ('home', 'ADV')\n",
      "7401 (',', '')\n",
      "7402 ('said', 'VERB')\n",
      "7403 ('Mrs', 'NOUN')\n",
      "7404 ('Parsons', 'NOUN')\n",
      "7405 ('vaguely', 'ADV')\n",
      "7406 ('.', '')\n",
      "7407 ('The', 'DET')\n",
      "7408 ('Parsons', 'NOUN')\n",
      "7409 (\"'\", 'ADP')\n",
      "7410 ('flat', 'NOUN')\n",
      "7411 ('was', 'VERB')\n",
      "7412 ('bigger', 'ADJ')\n",
      "7413 ('than', 'ADP')\n",
      "7414 ('Winston', 'NOUN')\n",
      "7415 (\"'s\", 'ADP')\n",
      "7416 (',', '')\n",
      "7417 ('and', 'CONJ')\n",
      "7418 ('dingy', 'ADJ')\n",
      "7419 ('in', 'ADP')\n",
      "7420 ('a', 'DET')\n",
      "7421 ('different', 'ADJ')\n",
      "7422 ('way', 'NOUN')\n",
      "7423 ('.', '')\n",
      "7424 ('Everything', 'PRON')\n",
      "7425 ('had', 'VERB')\n",
      "7426 ('a', 'DET')\n",
      "7427 ('battered', 'ADJ')\n",
      "7428 (',', '')\n",
      "7429 ('trampled-on', 'VERB')\n",
      "7430 ('look', 'NOUN')\n",
      "7431 (',', '')\n",
      "7432 ('as', 'CONJ')\n",
      "7433 ('though', 'CONJ')\n",
      "7434 ('the', 'DET')\n",
      "7435 ('place', 'NOUN')\n",
      "7436 ('had', 'VERB')\n",
      "7437 ('just', 'ADV')\n",
      "7438 ('been', 'VERB')\n",
      "7439 ('visited', 'VERB')\n",
      "7440 ('by', 'ADP')\n",
      "7441 ('some', 'DET')\n",
      "7442 ('large', 'ADJ')\n",
      "7443 ('violent', 'ADJ')\n",
      "7444 ('animal', 'NOUN')\n",
      "7445 ('.', '')\n",
      "7446 ('Games', 'NOUN')\n",
      "7447 ('impedimenta', 'NOUN')\n",
      "7448 ('-', '')\n",
      "7449 ('hockey-sticks', 'NOUN')\n",
      "7450 (',', '')\n",
      "7451 ('boxing-gloves', 'NOUN')\n",
      "7452 (',', '')\n",
      "7453 ('a', 'DET')\n",
      "7454 ('burst', 'VERB')\n",
      "7455 ('football', 'NOUN')\n",
      "7456 (',', '')\n",
      "7457 ('a', 'DET')\n",
      "7458 ('pair', 'NOUN')\n",
      "7459 ('of', 'ADP')\n",
      "7460 ('sweaty', 'ADJ')\n",
      "7461 ('shorts', 'NOUN')\n",
      "7462 ('turned', 'VERB')\n",
      "7463 ('inside', 'NOUN')\n",
      "7464 ('out', 'ADP')\n",
      "7465 ('-', '')\n",
      "7466 ('lay', 'VERB')\n",
      "7467 ('all', 'ADV')\n",
      "7468 ('over', 'ADP')\n",
      "7469 ('the', 'DET')\n",
      "7470 ('floor', 'NOUN')\n",
      "7471 (',', '')\n",
      "7472 ('and', 'CONJ')\n",
      "7473 ('on', 'ADP')\n",
      "7474 ('the', 'DET')\n",
      "7475 ('table', 'NOUN')\n",
      "7476 ('there', 'PRON')\n",
      "7477 ('was', 'VERB')\n",
      "7478 ('a', 'DET')\n",
      "7479 ('litter', 'NOUN')\n",
      "7480 ('of', 'ADP')\n",
      "7481 ('dirty', 'ADJ')\n",
      "7482 ('dishes', 'NOUN')\n",
      "7483 ('and', 'CONJ')\n",
      "7484 ('dog-eared', 'ADJ')\n",
      "7485 ('exercise-books', 'NOUN')\n",
      "7486 ('.', '')\n",
      "7487 ('On', 'ADP')\n",
      "7488 ('the', 'DET')\n",
      "7489 ('walls', 'NOUN')\n",
      "7490 ('were', 'VERB')\n",
      "7491 ('scarlet', 'ADJ')\n",
      "7492 ('banners', 'NOUN')\n",
      "7493 ('of', 'ADP')\n",
      "7494 ('the', 'DET')\n",
      "7495 ('Youth', 'NOUN')\n",
      "7496 ('League', 'NOUN')\n",
      "7497 ('and', 'CONJ')\n",
      "7498 ('the', 'DET')\n",
      "7499 ('Spies', 'NOUN')\n",
      "7500 (',', '')\n",
      "7501 ('and', 'CONJ')\n",
      "7502 ('a', 'DET')\n",
      "7503 ('full-sized', 'ADJ')\n",
      "7504 ('poster', 'NOUN')\n",
      "7505 ('of', 'ADP')\n",
      "7506 ('Big', 'ADJ')\n",
      "7507 ('Brother', 'NOUN')\n",
      "7508 ('.', '')\n",
      "7509 ('There', 'PRON')\n",
      "7510 ('was', 'VERB')\n",
      "7511 ('the', 'DET')\n",
      "7512 ('usual', 'ADJ')\n",
      "7513 ('boiled-cabbage', 'NOUN')\n",
      "7514 ('smell', 'NOUN')\n",
      "7515 (',', '')\n",
      "7516 ('common', 'ADJ')\n",
      "7517 ('to', 'ADP')\n",
      "7518 ('the', 'DET')\n",
      "7519 ('whole', 'NOUN')\n",
      "7520 ('building', 'NOUN')\n",
      "7521 (',', '')\n",
      "7522 ('but', 'CONJ')\n",
      "7523 ('it', 'PRON')\n",
      "7524 ('was', 'VERB')\n",
      "7525 ('shot', 'VERB')\n",
      "7526 ('through', 'ADV')\n",
      "7527 ('by', 'ADP')\n",
      "7528 ('a', 'DET')\n",
      "7529 ('sharper', 'ADJ')\n",
      "7530 ('reek', 'NOUN')\n",
      "7531 ('of', 'ADP')\n",
      "7532 ('sweat', 'NOUN')\n",
      "7533 (',', '')\n",
      "7534 ('which', 'PRON')\n",
      "7535 ('-', '')\n",
      "7536 ('one', 'PRON')\n",
      "7537 ('knew', 'VERB')\n",
      "7538 ('this', 'PRON')\n",
      "7539 ('at', 'ADP')\n",
      "7540 ('the', 'DET')\n",
      "7541 ('first', 'ADJ')\n",
      "7542 ('sniff', 'NOUN')\n",
      "7543 (',', '')\n",
      "7544 ('though', 'CONJ')\n",
      "7545 ('it', 'PRON')\n",
      "7546 ('was', 'VERB')\n",
      "7547 ('hard', 'ADJ')\n",
      "7548 ('to', 'ADP')\n",
      "7549 ('say', 'VERB')\n",
      "7550 ('how', 'ADV')\n",
      "7551 ('was', 'VERB')\n",
      "7552 ('the', 'DET')\n",
      "7553 ('sweat', 'NOUN')\n",
      "7554 ('of', 'ADP')\n",
      "7555 ('some', 'DET')\n",
      "7556 ('person', 'NOUN')\n",
      "7557 ('not', 'ADV')\n",
      "7558 ('present', 'ADJ')\n",
      "7559 ('at', 'ADP')\n",
      "7560 ('the', 'DET')\n",
      "7561 ('moment', 'NOUN')\n",
      "7562 ('.', '')\n",
      "7563 ('In', 'ADP')\n",
      "7564 ('another', 'DET')\n",
      "7565 ('room', 'NOUN')\n",
      "7566 ('someone', 'PRON')\n",
      "7567 ('with', 'ADP')\n",
      "7568 ('a', 'DET')\n",
      "7569 ('comb', 'NOUN')\n",
      "7570 ('and', 'CONJ')\n",
      "7571 ('a', 'DET')\n",
      "7572 ('piece', 'NOUN')\n",
      "7573 ('of', 'ADP')\n",
      "7574 ('toilet', 'NOUN')\n",
      "7575 ('paper', 'NOUN')\n",
      "7576 ('was', 'VERB')\n",
      "7577 ('trying', 'VERB')\n",
      "7578 ('to', 'ADP')\n",
      "7579 ('keep', 'VERB')\n",
      "7580 ('tune', 'NOUN')\n",
      "7581 ('with', 'ADP')\n",
      "7582 ('the', 'DET')\n",
      "7583 ('military', 'ADJ')\n",
      "7584 ('music', 'NOUN')\n",
      "7585 ('which', 'PRON')\n",
      "7586 ('was', 'VERB')\n",
      "7587 ('still', 'ADV')\n",
      "7588 ('issuing', 'VERB')\n",
      "7589 ('from', 'ADP')\n",
      "7590 ('the', 'DET')\n",
      "7591 ('telescreen', 'NOUN')\n",
      "7592 ('.', '')\n",
      "7593 ('It', 'PRON')\n",
      "7594 (\"'s\", 'VERB')\n",
      "7595 ('the', 'DET')\n",
      "7596 ('children', 'NOUN')\n",
      "7597 (',', '')\n",
      "7598 ('said', 'VERB')\n",
      "7599 ('Mrs', 'NOUN')\n",
      "7600 ('Parsons', 'NOUN')\n",
      "7601 (',', '')\n",
      "7602 ('casting', 'VERB')\n",
      "7603 ('a', 'DET')\n",
      "7604 ('half-apprehensive', 'ADJ')\n",
      "7605 ('glance', 'NOUN')\n",
      "7606 ('at', 'ADP')\n",
      "7607 ('the', 'DET')\n",
      "7608 ('door', 'NOUN')\n",
      "7609 ('.', '')\n",
      "7610 ('They', 'PRON')\n",
      "7611 (\"haven't\", 'VERB')\n",
      "7612 ('been', 'VERB')\n",
      "7613 ('out', 'ADP')\n",
      "7614 ('today', 'ADV')\n",
      "7615 ('.', '')\n",
      "7616 ('And', 'CONJ')\n",
      "7617 ('of', 'ADP')\n",
      "7618 ('course', 'NOUN')\n",
      "7619 ('-', '')\n",
      "7620 ('She', 'PRON')\n",
      "7621 ('had', 'VERB')\n",
      "7622 ('a', 'DET')\n",
      "7623 ('habit', 'NOUN')\n",
      "7624 ('of', 'ADP')\n",
      "7625 ('breaking', 'VERB')\n",
      "7626 ('off', 'ADV')\n",
      "7627 ('her', 'DET')\n",
      "7628 ('sentences', 'NOUN')\n",
      "7629 ('in', 'ADP')\n",
      "7630 ('the', 'DET')\n",
      "7631 ('middle', 'NOUN')\n",
      "7632 ('.', '')\n",
      "7633 ('The', 'DET')\n",
      "7634 ('kitchen', 'NOUN')\n",
      "7635 ('sink', 'NOUN')\n",
      "7636 ('was', 'VERB')\n",
      "7637 ('full', 'ADJ')\n",
      "7638 ('nearly', 'ADV')\n",
      "7639 ('to', 'ADP')\n",
      "7640 ('the', 'DET')\n",
      "7641 ('brim', 'NOUN')\n",
      "7642 ('with', 'ADP')\n",
      "7643 ('filthy', 'ADJ')\n",
      "7644 ('greenish', 'ADJ')\n",
      "7645 ('water', 'NOUN')\n",
      "7646 ('which', 'PRON')\n",
      "7647 ('smelt', 'VERB')\n",
      "7648 ('worse', 'ADV')\n",
      "7649 ('than', 'CONJ')\n",
      "7650 ('ever', 'ADV')\n",
      "7651 ('of', 'ADP')\n",
      "7652 ('cabbage', 'NOUN')\n",
      "7653 ('.', '')\n",
      "7654 ('Winston', 'NOUN')\n",
      "7655 ('knelt', 'VERB')\n",
      "7656 ('down', 'ADV')\n",
      "7657 ('and', 'CONJ')\n",
      "7658 ('examined', 'VERB')\n",
      "7659 ('the', 'DET')\n",
      "7660 ('angle-joint', 'NOUN')\n",
      "7661 ('of', 'ADP')\n",
      "7662 ('the', 'DET')\n",
      "7663 ('pipe', 'NOUN')\n",
      "7664 ('.', '')\n",
      "7665 ('He', 'PRON')\n",
      "7666 ('hated', 'VERB')\n",
      "7667 ('using', 'VERB')\n",
      "7668 ('his', 'DET')\n",
      "7669 ('hands', 'NOUN')\n",
      "7670 (',', '')\n",
      "7671 ('and', 'CONJ')\n",
      "7672 ('he', 'PRON')\n",
      "7673 ('hated', 'VERB')\n",
      "7674 ('bending', 'VERB')\n",
      "7675 ('down', 'ADV')\n",
      "7676 (',', '')\n",
      "7677 ('which', 'PRON')\n",
      "7678 ('was', 'VERB')\n",
      "7679 ('always', 'ADV')\n",
      "7680 ('liable', 'ADJ')\n",
      "7681 ('to', 'ADP')\n",
      "7682 ('start', 'VERB')\n",
      "7683 ('him', 'PRON')\n",
      "7684 ('coughing', 'VERB')\n",
      "7685 ('.', '')\n",
      "7686 ('Mrs', 'NOUN')\n",
      "7687 ('Parsons', 'NOUN')\n",
      "7688 ('looked', 'VERB')\n",
      "7689 ('on', 'ADP')\n",
      "7690 ('helplessly', 'ADV')\n",
      "7691 ('.', '')\n",
      "7692 ('Of', 'ADP')\n",
      "7693 ('course', 'NOUN')\n",
      "7694 ('if', 'CONJ')\n",
      "7695 ('Tom', 'NOUN')\n",
      "7696 ('was', 'VERB')\n",
      "7697 ('home', 'ADV')\n",
      "7698 ('he', 'PRON')\n",
      "7699 (\"'d\", 'VERB')\n",
      "7700 ('put', 'VERB')\n",
      "7701 ('it', 'PRON')\n",
      "7702 ('right', 'ADJ')\n",
      "7703 ('in', 'ADP')\n",
      "7704 ('a', 'DET')\n",
      "7705 ('moment', 'NOUN')\n",
      "7706 (',', '')\n",
      "7707 ('she', 'PRON')\n",
      "7708 ('said', 'VERB')\n",
      "7709 ('.', '')\n",
      "7710 ('He', 'PRON')\n",
      "7711 ('loves', 'VERB')\n",
      "7712 ('anything', 'PRON')\n",
      "7713 ('like', 'ADP')\n",
      "7714 ('that', 'PRON')\n",
      "7715 ('.', '')\n",
      "7716 ('He', 'PRON')\n",
      "7717 (\"'s\", 'VERB')\n",
      "7718 ('ever', 'ADV')\n",
      "7719 ('so', 'ADV')\n",
      "7720 ('good', 'ADJ')\n",
      "7721 ('with', 'ADP')\n",
      "7722 ('his', 'DET')\n",
      "7723 ('hands', 'NOUN')\n",
      "7724 (',', '')\n",
      "7725 ('Tom', 'NOUN')\n",
      "7726 ('is', 'VERB')\n",
      "7727 ('.', '')\n",
      "7728 ('Parsons', 'NOUN')\n",
      "7729 ('was', 'VERB')\n",
      "7730 ('Winston', 'NOUN')\n",
      "7731 (\"'s\", 'ADP')\n",
      "7732 ('fellow-employee', 'NOUN')\n",
      "7733 ('at', 'ADP')\n",
      "7734 ('the', 'DET')\n",
      "7735 ('Ministry', 'NOUN')\n",
      "7736 ('of', 'ADP')\n",
      "7737 ('Truth', 'NOUN')\n",
      "7738 ('.', '')\n",
      "7739 ('He', 'PRON')\n",
      "7740 ('was', 'VERB')\n",
      "7741 ('a', 'DET')\n",
      "7742 ('fattish', 'ADJ')\n",
      "7743 ('but', 'CONJ')\n",
      "7744 ('active', 'ADJ')\n",
      "7745 ('man', 'NOUN')\n",
      "7746 ('of', 'ADP')\n",
      "7747 ('paralysing', 'VERB')\n",
      "7748 ('stupidity', 'NOUN')\n",
      "7749 (',', '')\n",
      "7750 ('a', 'DET')\n",
      "7751 ('mass', 'NOUN')\n",
      "7752 ('of', 'ADP')\n",
      "7753 ('imbecile', 'ADJ')\n",
      "7754 ('enthusiasms', 'NOUN')\n",
      "7755 ('-', '')\n",
      "7756 ('one', 'PRON')\n",
      "7757 ('of', 'ADP')\n",
      "7758 ('those', 'PRON')\n",
      "7759 ('completely', 'ADV')\n",
      "7760 ('unquestioning', 'ADJ')\n",
      "7761 (',', '')\n",
      "7762 ('devoted', 'ADJ')\n",
      "7763 ('drudges', 'NOUN')\n",
      "7764 ('on', 'ADP')\n",
      "7765 ('whom', 'PRON')\n",
      "7766 (',', '')\n",
      "7767 ('more', 'ADV')\n",
      "7768 ('even', 'ADV')\n",
      "7769 ('than', 'CONJ')\n",
      "7770 ('on', 'ADP')\n",
      "7771 ('the', 'DET')\n",
      "7772 ('Thought', 'NOUN')\n",
      "7773 ('Police', 'NOUN')\n",
      "7774 (',', '')\n",
      "7775 ('the', 'DET')\n",
      "7776 ('stability', 'NOUN')\n",
      "7777 ('of', 'ADP')\n",
      "7778 ('the', 'DET')\n",
      "7779 ('Party', 'NOUN')\n",
      "7780 ('depended', 'VERB')\n",
      "7781 ('.', '')\n",
      "7782 ('At', 'ADP')\n",
      "7783 ('thirty-five', 'NOUN')\n",
      "7784 ('he', 'PRON')\n",
      "7785 ('had', 'VERB')\n",
      "7786 ('just', 'ADV')\n",
      "7787 ('been', 'VERB')\n",
      "7788 ('unwillingly', 'ADV')\n",
      "7789 ('evicted', 'VERB')\n",
      "7790 ('from', 'ADP')\n",
      "7791 ('the', 'DET')\n",
      "7792 ('Youth', 'NOUN')\n",
      "7793 ('League', 'NOUN')\n",
      "7794 (',', '')\n",
      "7795 ('and', 'CONJ')\n",
      "7796 ('before', 'ADP')\n",
      "7797 ('graduating', 'VERB')\n",
      "7798 ('into', 'ADP')\n",
      "7799 ('the', 'DET')\n",
      "7800 ('Youth', 'NOUN')\n",
      "7801 ('League', 'NOUN')\n",
      "7802 ('he', 'PRON')\n",
      "7803 ('had', 'VERB')\n",
      "7804 ('managed', 'VERB')\n",
      "7805 ('to', 'ADP')\n",
      "7806 ('stay', 'VERB')\n",
      "7807 ('on', 'ADP')\n",
      "7808 ('in', 'ADP')\n",
      "7809 ('the', 'DET')\n",
      "7810 ('Spies', 'NOUN')\n",
      "7811 ('for', 'ADP')\n",
      "7812 ('a', 'DET')\n",
      "7813 ('year', 'NOUN')\n",
      "7814 ('beyond', 'ADP')\n",
      "7815 ('the', 'DET')\n",
      "7816 ('statutory', 'ADJ')\n",
      "7817 ('age', 'NOUN')\n",
      "7818 ('.', '')\n",
      "7819 ('At', 'ADP')\n",
      "7820 ('the', 'DET')\n",
      "7821 ('Ministry', 'NOUN')\n",
      "7822 ('he', 'PRON')\n",
      "7823 ('was', 'VERB')\n",
      "7824 ('employed', 'VERB')\n",
      "7825 ('in', 'ADP')\n",
      "7826 ('some', 'DET')\n",
      "7827 ('subordinate', 'ADJ')\n",
      "7828 ('post', 'NOUN')\n",
      "7829 ('for', 'ADP')\n",
      "7830 ('which', 'PRON')\n",
      "7831 ('intelligence', 'NOUN')\n",
      "7832 ('was', 'VERB')\n",
      "7833 ('not', 'ADV')\n",
      "7834 ('required', 'VERB')\n",
      "7835 (',', '')\n",
      "7836 ('but', 'CONJ')\n",
      "7837 ('on', 'ADP')\n",
      "7838 ('the', 'DET')\n",
      "7839 ('other', 'ADJ')\n",
      "7840 ('hand', 'NOUN')\n",
      "7841 ('he', 'PRON')\n",
      "7842 ('was', 'VERB')\n",
      "7843 ('a', 'DET')\n",
      "7844 ('leading', 'ADJ')\n",
      "7845 ('figure', 'NOUN')\n",
      "7846 ('on', 'ADP')\n",
      "7847 ('the', 'DET')\n",
      "7848 ('Sports', 'NOUN')\n",
      "7849 ('Committee', 'NOUN')\n",
      "7850 ('and', 'CONJ')\n",
      "7851 ('all', 'DET')\n",
      "7852 ('the', 'DET')\n",
      "7853 ('other', 'ADJ')\n",
      "7854 ('committees', 'NOUN')\n",
      "7855 ('engaged', 'VERB')\n",
      "7856 ('in', 'ADP')\n",
      "7857 ('organizing', 'VERB')\n",
      "7858 ('community', 'NOUN')\n",
      "7859 ('hikes', 'NOUN')\n",
      "7860 (',', '')\n",
      "7861 ('spontaneous', 'ADJ')\n",
      "7862 ('demonstrations', 'NOUN')\n",
      "7863 (',', '')\n",
      "7864 ('savings', 'NOUN')\n",
      "7865 ('campaigns', 'NOUN')\n",
      "7866 (',', '')\n",
      "7867 ('and', 'CONJ')\n",
      "7868 ('voluntary', 'ADJ')\n",
      "7869 ('activities', 'NOUN')\n",
      "7870 ('generally', 'ADV')\n",
      "7871 ('.', '')\n",
      "7872 ('He', 'PRON')\n",
      "7873 ('would', 'VERB')\n",
      "7874 ('inform', 'VERB')\n",
      "7875 ('you', 'PRON')\n",
      "7876 ('with', 'ADP')\n",
      "7877 ('quiet', 'ADJ')\n",
      "7878 ('pride', 'NOUN')\n",
      "7879 (',', '')\n",
      "7880 ('between', 'ADP')\n",
      "7881 ('whiffs', 'NOUN')\n",
      "7882 ('of', 'ADP')\n",
      "7883 ('his', 'DET')\n",
      "7884 ('pipe', 'NOUN')\n",
      "7885 (',', '')\n",
      "7886 ('that', 'CONJ')\n",
      "7887 ('he', 'PRON')\n",
      "7888 ('had', 'VERB')\n",
      "7889 ('put', 'VERB')\n",
      "7890 ('in', 'ADP')\n",
      "7891 ('an', 'DET')\n",
      "7892 ('appearance', 'NOUN')\n",
      "7893 ('at', 'ADP')\n",
      "7894 ('the', 'DET')\n",
      "7895 ('Community', 'NOUN')\n",
      "7896 ('Centre', 'NOUN')\n",
      "7897 ('every', 'DET')\n",
      "7898 ('evening', 'NOUN')\n",
      "7899 ('for', 'ADP')\n",
      "7900 ('the', 'DET')\n",
      "7901 ('past', 'ADJ')\n",
      "7902 ('four', 'NUM')\n",
      "7903 ('years', 'NOUN')\n",
      "7904 ('.', '')\n",
      "7905 ('An', 'DET')\n",
      "7906 ('overpowering', 'ADJ')\n",
      "7907 ('smell', 'NOUN')\n",
      "7908 ('of', 'ADP')\n",
      "7909 ('sweat', 'NOUN')\n",
      "7910 (',', '')\n",
      "7911 ('a', 'DET')\n",
      "7912 ('sort', 'NOUN')\n",
      "7913 ('of', 'ADP')\n",
      "7914 ('unconscious', 'ADJ')\n",
      "7915 ('testimony', 'NOUN')\n",
      "7916 ('to', 'ADP')\n",
      "7917 ('the', 'DET')\n",
      "7918 ('strenuousness', 'NOUN')\n",
      "7919 ('of', 'ADP')\n",
      "7920 ('his', 'DET')\n",
      "7921 ('life', 'NOUN')\n",
      "7922 (',', '')\n",
      "7923 ('followed', 'VERB')\n",
      "7924 ('him', 'PRON')\n",
      "7925 ('about', 'ADV')\n",
      "7926 ('wherever', 'CONJ')\n",
      "7927 ('he', 'PRON')\n",
      "7928 ('went', 'VERB')\n",
      "7929 (',', '')\n",
      "7930 ('and', 'CONJ')\n",
      "7931 ('even', 'ADV')\n",
      "7932 ('remained', 'VERB')\n",
      "7933 ('behind', 'ADP')\n",
      "7934 ('him', 'PRON')\n",
      "7935 ('after', 'CONJ')\n",
      "7936 ('he', 'PRON')\n",
      "7937 ('had', 'VERB')\n",
      "7938 ('gone', 'VERB')\n",
      "7939 ('.', '')\n",
      "7940 ('Have', 'VERB')\n",
      "7941 ('you', 'PRON')\n",
      "7942 ('got', 'VERB')\n",
      "7943 ('a', 'DET')\n",
      "7944 ('spanner', 'NOUN')\n",
      "7945 ('?', '')\n",
      "7946 ('said', 'VERB')\n",
      "7947 ('Winston', 'NOUN')\n",
      "7948 (',', '')\n",
      "7949 ('fiddling', 'VERB')\n",
      "7950 ('with', 'ADP')\n",
      "7951 ('the', 'DET')\n",
      "7952 ('nut', 'NOUN')\n",
      "7953 ('on', 'ADP')\n",
      "7954 ('the', 'DET')\n",
      "7955 ('angle-joint', 'NOUN')\n",
      "7956 ('.', '')\n",
      "7957 ('A', 'DET')\n",
      "7958 ('spanner', 'NOUN')\n",
      "7959 (',', '')\n",
      "7960 ('said', 'VERB')\n",
      "7961 ('Mrs', 'NOUN')\n",
      "7962 ('Parsons', 'NOUN')\n",
      "7963 (',', '')\n",
      "7964 ('immediately', 'ADV')\n",
      "7965 ('becoming', 'VERB')\n",
      "7966 ('invertebrate', 'ADJ')\n",
      "7967 ('.', '')\n",
      "7968 ('I', 'PRON')\n",
      "7969 (\"don't\", 'VERB')\n",
      "7970 ('know', 'VERB')\n",
      "7971 (',', '')\n",
      "7972 ('I', 'PRON')\n",
      "7973 (\"'m\", 'VERB')\n",
      "7974 ('sure', 'ADJ')\n",
      "7975 ('.', '')\n",
      "7976 ('Perhaps', 'ADV')\n",
      "7977 ('the', 'DET')\n",
      "7978 ('children', 'NOUN')\n",
      "7979 ('-', '')\n",
      "7980 ('There', 'PRON')\n",
      "7981 ('was', 'VERB')\n",
      "7982 ('a', 'DET')\n",
      "7983 ('trampling', 'VERB')\n",
      "7984 ('of', 'ADP')\n",
      "7985 ('boots', 'NOUN')\n",
      "7986 ('and', 'CONJ')\n",
      "7987 ('another', 'DET')\n",
      "7988 ('blast', 'NOUN')\n",
      "7989 ('on', 'ADP')\n",
      "7990 ('the', 'DET')\n",
      "7991 ('comb', 'NOUN')\n",
      "7992 ('as', 'CONJ')\n",
      "7993 ('the', 'DET')\n",
      "7994 ('children', 'NOUN')\n",
      "7995 ('charged', 'VERB')\n",
      "7996 ('into', 'ADP')\n",
      "7997 ('the', 'DET')\n",
      "7998 ('living-room', 'NOUN')\n",
      "7999 ('.', '')\n",
      "8000 ('Mrs', 'NOUN')\n",
      "8001 ('Parsons', 'NOUN')\n",
      "8002 ('brought', 'VERB')\n",
      "8003 ('the', 'DET')\n",
      "8004 ('spanner', 'NOUN')\n",
      "8005 ('.', '')\n",
      "8006 ('Winston', 'NOUN')\n",
      "8007 ('let', 'VERB')\n",
      "8008 ('out', 'ADP')\n",
      "8009 ('the', 'DET')\n",
      "8010 ('water', 'NOUN')\n",
      "8011 ('and', 'CONJ')\n",
      "8012 ('disgustedly', 'ADV')\n",
      "8013 ('removed', 'VERB')\n",
      "8014 ('the', 'DET')\n",
      "8015 ('clot', 'NOUN')\n",
      "8016 ('of', 'ADP')\n",
      "8017 ('human', 'ADJ')\n",
      "8018 ('hair', 'NOUN')\n",
      "8019 ('that', 'PRON')\n",
      "8020 ('had', 'VERB')\n",
      "8021 ('blocked', 'VERB')\n",
      "8022 ('up', 'ADP')\n",
      "8023 ('the', 'DET')\n",
      "8024 ('pipe', 'NOUN')\n",
      "8025 ('.', '')\n",
      "8026 ('He', 'PRON')\n",
      "8027 ('cleaned', 'VERB')\n",
      "8028 ('his', 'DET')\n",
      "8029 ('fingers', 'NOUN')\n",
      "8030 ('as', 'ADV')\n",
      "8031 ('best', 'ADV')\n",
      "8032 ('he', 'PRON')\n",
      "8033 ('could', 'VERB')\n",
      "8034 ('in', 'ADP')\n",
      "8035 ('the', 'DET')\n",
      "8036 ('cold', 'ADJ')\n",
      "8037 ('water', 'NOUN')\n",
      "8038 ('from', 'ADP')\n",
      "8039 ('the', 'DET')\n",
      "8040 ('tap', 'NOUN')\n",
      "8041 ('and', 'CONJ')\n",
      "8042 ('went', 'VERB')\n",
      "8043 ('back', 'ADV')\n",
      "8044 ('into', 'ADP')\n",
      "8045 ('the', 'DET')\n",
      "8046 ('other', 'DET')\n",
      "8047 ('room', 'NOUN')\n",
      "8048 ('.', '')\n",
      "8049 ('Up', 'ADP')\n",
      "8050 ('with', 'ADP')\n",
      "8051 ('your', 'DET')\n",
      "8052 ('hands', 'NOUN')\n",
      "8053 ('!', '')\n",
      "8054 ('yelled', 'VERB')\n",
      "8055 ('a', 'DET')\n",
      "8056 ('savage', 'ADJ')\n",
      "8057 ('voice', 'NOUN')\n",
      "8058 ('.', '')\n",
      "8059 ('A', 'DET')\n",
      "8060 ('handsome', 'ADJ')\n",
      "8061 (',', '')\n",
      "8062 ('tough-looking', 'ADJ')\n",
      "8063 ('boy', 'NOUN')\n",
      "8064 ('of', 'ADP')\n",
      "8065 ('nine', 'NUM')\n",
      "8066 ('had', 'VERB')\n",
      "8067 ('popped', 'VERB')\n",
      "8068 ('up', 'ADP')\n",
      "8069 ('from', 'ADP')\n",
      "8070 ('behind', 'ADP')\n",
      "8071 ('the', 'DET')\n",
      "8072 ('table', 'NOUN')\n",
      "8073 ('and', 'CONJ')\n",
      "8074 ('was', 'VERB')\n",
      "8075 ('menacing', 'VERB')\n",
      "8076 ('him', 'PRON')\n",
      "8077 ('with', 'ADP')\n",
      "8078 ('a', 'DET')\n",
      "8079 ('toy', 'NOUN')\n",
      "8080 ('automatic', 'ADJ')\n",
      "8081 ('pistol', 'NOUN')\n",
      "8082 (',', '')\n",
      "8083 ('while', 'CONJ')\n",
      "8084 ('his', 'DET')\n",
      "8085 ('small', 'ADJ')\n",
      "8086 ('sister', 'NOUN')\n",
      "8087 (',', '')\n",
      "8088 ('about', 'ADV')\n",
      "8089 ('two', 'NUM')\n",
      "8090 ('years', 'NOUN')\n",
      "8091 ('younger', 'ADJ')\n",
      "8092 (',', '')\n",
      "8093 ('made', 'VERB')\n",
      "8094 ('the', 'DET')\n",
      "8095 ('same', 'ADJ')\n",
      "8096 ('gesture', 'NOUN')\n",
      "8097 ('with', 'ADP')\n",
      "8098 ('a', 'DET')\n",
      "8099 ('fragment', 'NOUN')\n",
      "8100 ('of', 'ADP')\n",
      "8101 ('wood', 'NOUN')\n",
      "8102 ('.', '')\n",
      "8103 ('Both', 'PRON')\n",
      "8104 ('of', 'ADP')\n",
      "8105 ('them', 'PRON')\n",
      "8106 ('were', 'VERB')\n",
      "8107 ('dressed', 'VERB')\n",
      "8108 ('in', 'ADP')\n",
      "8109 ('the', 'DET')\n",
      "8110 ('blue', 'ADJ')\n",
      "8111 ('shorts', 'NOUN')\n",
      "8112 (',', '')\n",
      "8113 ('grey', 'ADJ')\n",
      "8114 ('shirts', 'NOUN')\n",
      "8115 (',', '')\n",
      "8116 ('and', 'CONJ')\n",
      "8117 ('red', 'ADJ')\n",
      "8118 ('neckerchiefs', 'NOUN')\n",
      "8119 ('which', 'PRON')\n",
      "8120 ('were', 'VERB')\n",
      "8121 ('the', 'DET')\n",
      "8122 ('uniform', 'NOUN')\n",
      "8123 ('of', 'ADP')\n",
      "8124 ('the', 'DET')\n",
      "8125 ('Spies', 'NOUN')\n",
      "8126 ('.', '')\n",
      "8127 ('Winston', 'NOUN')\n",
      "8128 ('raised', 'VERB')\n",
      "8129 ('his', 'DET')\n",
      "8130 ('hands', 'NOUN')\n",
      "8131 ('above', 'ADP')\n",
      "8132 ('his', 'DET')\n",
      "8133 ('head', 'NOUN')\n",
      "8134 (',', '')\n",
      "8135 ('but', 'CONJ')\n",
      "8136 ('with', 'ADP')\n",
      "8137 ('an', 'DET')\n",
      "8138 ('uneasy', 'ADJ')\n",
      "8139 ('feeling', 'NOUN')\n",
      "8140 (',', '')\n",
      "8141 ('so', 'ADV')\n",
      "8142 ('vicious', 'ADJ')\n",
      "8143 ('was', 'VERB')\n",
      "8144 ('the', 'DET')\n",
      "8145 ('boy', 'NOUN')\n",
      "8146 (\"'s\", 'ADP')\n",
      "8147 ('demeanour', 'NOUN')\n",
      "8148 (',', '')\n",
      "8149 ('that', 'CONJ')\n",
      "8150 ('it', 'PRON')\n",
      "8151 ('was', 'VERB')\n",
      "8152 ('not', 'ADV')\n",
      "8153 ('altogether', 'ADV')\n",
      "8154 ('a', 'DET')\n",
      "8155 ('game', 'NOUN')\n",
      "8156 ('.', '')\n",
      "8157 ('You', 'PRON')\n",
      "8158 (\"'re\", 'VERB')\n",
      "8159 ('a', 'DET')\n",
      "8160 ('traitor', 'NOUN')\n",
      "8161 ('!', '')\n",
      "8162 ('yelled', 'VERB')\n",
      "8163 ('the', 'DET')\n",
      "8164 ('boy', 'NOUN')\n",
      "8165 ('.', '')\n",
      "8166 ('You', 'PRON')\n",
      "8167 (\"'re\", 'VERB')\n",
      "8168 ('a', 'DET')\n",
      "8169 ('thought-criminal', 'NOUN')\n",
      "8170 ('!', '')\n",
      "8171 ('You', 'PRON')\n",
      "8172 (\"'re\", 'VERB')\n",
      "8173 ('a', 'DET')\n",
      "8174 ('Eurasian', 'ADJ')\n",
      "8175 ('spy', 'NOUN')\n",
      "8176 ('!', '')\n",
      "8177 ('I', 'PRON')\n",
      "8178 (\"'ll\", 'VERB')\n",
      "8179 ('shoot', 'VERB')\n",
      "8180 ('you', 'PRON')\n",
      "8181 (',', '')\n",
      "8182 ('I', 'PRON')\n",
      "8183 (\"'ll\", 'VERB')\n",
      "8184 ('vaporize', 'VERB')\n",
      "8185 ('you', 'PRON')\n",
      "8186 (',', '')\n",
      "8187 ('I', 'PRON')\n",
      "8188 (\"'ll\", 'VERB')\n",
      "8189 ('send', 'VERB')\n",
      "8190 ('you', 'PRON')\n",
      "8191 ('to', 'ADP')\n",
      "8192 ('the', 'DET')\n",
      "8193 ('salt', 'NOUN')\n",
      "8194 ('mines', 'NOUN')\n",
      "8195 ('!', '')\n",
      "8196 ('Suddenly', 'ADV')\n",
      "8197 ('they', 'PRON')\n",
      "8198 ('were', 'VERB')\n",
      "8199 ('both', 'PRON')\n",
      "8200 ('leaping', 'VERB')\n",
      "8201 ('round', 'ADP')\n",
      "8202 ('him', 'PRON')\n",
      "8203 (',', '')\n",
      "8204 ('shouting', 'VERB')\n",
      "8205 ('Traitor', 'NOUN')\n",
      "8206 ('!', '')\n",
      "8207 ('and', 'CONJ')\n",
      "8208 ('Thought-criminal', 'NOUN')\n",
      "8209 ('!', '')\n",
      "8210 ('the', 'DET')\n",
      "8211 ('little', 'ADJ')\n",
      "8212 ('girl', 'NOUN')\n",
      "8213 ('imitating', 'VERB')\n",
      "8214 ('her', 'DET')\n",
      "8215 ('brother', 'NOUN')\n",
      "8216 ('in', 'ADP')\n",
      "8217 ('every', 'DET')\n",
      "8218 ('movement', 'NOUN')\n",
      "8219 ('.', '')\n",
      "8220 ('It', 'PRON')\n",
      "8221 ('was', 'VERB')\n",
      "8222 ('somehow', 'ADV')\n",
      "8223 ('slightly', 'ADV')\n",
      "8224 ('frightening', 'ADJ')\n",
      "8225 (',', '')\n",
      "8226 ('like', 'ADP')\n",
      "8227 ('the', 'DET')\n",
      "8228 ('gambolling', 'VERB')\n",
      "8229 ('of', 'ADP')\n",
      "8230 ('tiger', 'NOUN')\n",
      "8231 ('cubs', 'NOUN')\n",
      "8232 ('which', 'PRON')\n",
      "8233 ('will', 'VERB')\n",
      "8234 ('soon', 'ADV')\n",
      "8235 ('grow', 'VERB')\n",
      "8236 ('up', 'ADP')\n",
      "8237 ('into', 'ADP')\n",
      "8238 ('man-eaters', 'NOUN')\n",
      "8239 ('.', '')\n",
      "8240 ('There', 'PRON')\n",
      "8241 ('was', 'VERB')\n",
      "8242 ('a', 'DET')\n",
      "8243 ('sort', 'NOUN')\n",
      "8244 ('of', 'ADP')\n",
      "8245 ('calculating', 'ADJ')\n",
      "8246 ('ferocity', 'NOUN')\n",
      "8247 ('in', 'ADP')\n",
      "8248 ('the', 'DET')\n",
      "8249 ('boy', 'NOUN')\n",
      "8250 (\"'s\", 'ADP')\n",
      "8251 ('eye', 'NOUN')\n",
      "8252 (',', '')\n",
      "8253 ('a', 'DET')\n",
      "8254 ('quite', 'ADV')\n",
      "8255 ('evident', 'ADJ')\n",
      "8256 ('desire', 'NOUN')\n",
      "8257 ('to', 'ADP')\n",
      "8258 ('hit', 'VERB')\n",
      "8259 ('or', 'CONJ')\n",
      "8260 ('kick', 'VERB')\n",
      "8261 ('Winston', 'NOUN')\n",
      "8262 ('and', 'CONJ')\n",
      "8263 ('a', 'DET')\n",
      "8264 ('consciousness', 'NOUN')\n",
      "8265 ('of', 'ADP')\n",
      "8266 ('being', 'VERB')\n",
      "8267 ('very', 'ADV')\n",
      "8268 ('nearly', 'ADV')\n",
      "8269 ('big', 'ADJ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8270 ('enough', 'ADV')\n",
      "8271 ('to', 'ADP')\n",
      "8272 ('do', 'VERB')\n",
      "8273 ('so', 'ADV')\n",
      "8274 ('.', '')\n",
      "8275 ('It', 'PRON')\n",
      "8276 ('was', 'VERB')\n",
      "8277 ('a', 'DET')\n",
      "8278 ('good', 'ADJ')\n",
      "8279 ('job', 'NOUN')\n",
      "8280 ('it', 'PRON')\n",
      "8281 ('was', 'VERB')\n",
      "8282 ('not', 'ADV')\n",
      "8283 ('a', 'DET')\n",
      "8284 ('real', 'ADJ')\n",
      "8285 ('pistol', 'NOUN')\n",
      "8286 ('he', 'PRON')\n",
      "8287 ('was', 'VERB')\n",
      "8288 ('holding', 'VERB')\n",
      "8289 (',', '')\n",
      "8290 ('Winston', 'NOUN')\n",
      "8291 ('thought', 'VERB')\n",
      "8292 ('.', '')\n",
      "8293 ('Mrs', 'NOUN')\n",
      "8294 ('Parsons', 'NOUN')\n",
      "8295 (\"'\", 'ADP')\n",
      "8296 ('eyes', 'NOUN')\n",
      "8297 ('flitted', 'VERB')\n",
      "8298 ('nervously', 'ADV')\n",
      "8299 ('from', 'ADP')\n",
      "8300 ('Winston', 'NOUN')\n",
      "8301 ('to', 'ADP')\n",
      "8302 ('the', 'DET')\n",
      "8303 ('children', 'NOUN')\n",
      "8304 (',', '')\n",
      "8305 ('and', 'CONJ')\n",
      "8306 ('back', 'ADV')\n",
      "8307 ('again', 'ADV')\n",
      "8308 ('.', '')\n",
      "8309 ('In', 'ADP')\n",
      "8310 ('the', 'DET')\n",
      "8311 ('better', 'ADJ')\n",
      "8312 ('light', 'NOUN')\n",
      "8313 ('of', 'ADP')\n",
      "8314 ('the', 'DET')\n",
      "8315 ('living-room', 'NOUN')\n",
      "8316 ('he', 'PRON')\n",
      "8317 ('noticed', 'VERB')\n",
      "8318 ('with', 'ADP')\n",
      "8319 ('interest', 'NOUN')\n",
      "8320 ('that', 'CONJ')\n",
      "8321 ('there', 'PRON')\n",
      "8322 ('actually', 'ADV')\n",
      "8323 ('was', 'VERB')\n",
      "8324 ('dust', 'NOUN')\n",
      "8325 ('in', 'ADP')\n",
      "8326 ('the', 'DET')\n",
      "8327 ('creases', 'NOUN')\n",
      "8328 ('of', 'ADP')\n",
      "8329 ('her', 'DET')\n",
      "8330 ('face', 'NOUN')\n",
      "8331 ('.', '')\n",
      "8332 ('They', 'PRON')\n",
      "8333 ('do', 'VERB')\n",
      "8334 ('get', 'VERB')\n",
      "8335 ('so', 'ADV')\n",
      "8336 ('noisy', 'ADJ')\n",
      "8337 (',', '')\n",
      "8338 ('she', 'PRON')\n",
      "8339 ('said', 'VERB')\n",
      "8340 ('.', '')\n",
      "8341 ('They', 'PRON')\n",
      "8342 (\"'re\", 'VERB')\n",
      "8343 ('disappointed', 'ADJ')\n",
      "8344 ('because', 'CONJ')\n",
      "8345 ('they', 'PRON')\n",
      "8346 (\"couldn't\", 'VERB')\n",
      "8347 ('go', 'VERB')\n",
      "8348 ('to', 'ADP')\n",
      "8349 ('see', 'VERB')\n",
      "8350 ('the', 'DET')\n",
      "8351 ('hanging', 'NOUN')\n",
      "8352 (',', '')\n",
      "8353 ('that', 'PRON')\n",
      "8354 (\"'s\", 'VERB')\n",
      "8355 ('what', 'PRON')\n",
      "8356 ('it', 'PRON')\n",
      "8357 ('is', 'VERB')\n",
      "8358 ('.', '')\n",
      "8359 ('I', 'PRON')\n",
      "m,VERB\n",
      "8360 (\"'m\", 'VERB')\n",
      "8361 ('too', 'ADV')\n",
      "8362 ('busy', 'ADJ')\n",
      "8363 ('to', 'ADP')\n",
      "8364 ('take', 'VERB')\n",
      "8365 ('them', 'PRON')\n",
      "8366 ('.', '')\n",
      "8367 ('and', 'CONJ')\n",
      "8368 ('Tom', 'NOUN')\n",
      "8369 (\"won't\", 'VERB')\n",
      "8370 ('be', 'VERB')\n",
      "8371 ('back', 'ADV')\n",
      "8372 ('from', 'ADP')\n",
      "8373 ('work', 'NOUN')\n",
      "8374 ('in', 'ADP')\n",
      "8375 ('time', 'NOUN')\n",
      "8376 ('.', '')\n",
      "8377 ('Why', 'ADV')\n",
      "8378 (\"can't\", 'VERB')\n",
      "8379 ('we', 'PRON')\n",
      "8380 ('go', 'VERB')\n",
      "8381 ('and', 'CONJ')\n",
      "8382 ('see', 'VERB')\n",
      "8383 ('the', 'DET')\n",
      "8384 ('hanging', 'NOUN')\n",
      "8385 ('?', '')\n",
      "8386 ('roared', 'VERB')\n",
      "8387 ('the', 'DET')\n",
      "8388 ('boy', 'NOUN')\n",
      "8389 ('in', 'ADP')\n",
      "8390 ('his', 'DET')\n",
      "8391 ('huge', 'ADJ')\n",
      "8392 ('voice', 'NOUN')\n",
      "8393 ('.', '')\n",
      "8394 ('Want', 'VERB')\n",
      "8395 ('to', 'ADP')\n",
      "8396 ('see', 'VERB')\n",
      "8397 ('the', 'DET')\n",
      "8398 ('hanging', 'NOUN')\n",
      "8399 ('!', '')\n",
      "8400 ('Want', 'VERB')\n",
      "8401 ('to', 'ADP')\n",
      "8402 ('see', 'VERB')\n",
      "8403 ('the', 'DET')\n",
      "8404 ('hanging', 'NOUN')\n",
      "8405 ('!', '')\n",
      "8406 ('chanted', 'VERB')\n",
      "8407 ('the', 'DET')\n",
      "8408 ('little', 'ADJ')\n",
      "8409 ('girl', 'NOUN')\n",
      "8410 (',', '')\n",
      "8411 ('still', 'ADV')\n",
      "8412 ('capering', 'VERB')\n",
      "8413 ('round', 'ADV')\n",
      "8414 ('.', '')\n",
      "8415 ('Some', 'DET')\n",
      "8416 ('Eurasian', 'ADJ')\n",
      "8417 ('prisoners', 'NOUN')\n",
      "8418 (',', '')\n",
      "8419 ('guilty', 'ADJ')\n",
      "8420 ('of', 'ADP')\n",
      "8421 ('war', 'NOUN')\n",
      "8422 ('crimes', 'NOUN')\n",
      "8423 (',', '')\n",
      "8424 ('were', 'VERB')\n",
      "8425 ('to', 'ADP')\n",
      "8426 ('be', 'VERB')\n",
      "8427 ('hanged', 'VERB')\n",
      "8428 ('in', 'ADP')\n",
      "8429 ('the', 'DET')\n",
      "8430 ('Park', 'NOUN')\n",
      "8431 ('that', 'DET')\n",
      "8432 ('evening', 'NOUN')\n",
      "8433 (',', '')\n",
      "8434 ('Winston', 'NOUN')\n",
      "8435 ('remembered', 'VERB')\n",
      "8436 ('.', '')\n",
      "8437 ('This', 'PRON')\n",
      "8438 ('happened', 'VERB')\n",
      "8439 ('about', 'ADV')\n",
      "8440 ('once', 'ADV')\n",
      "8441 ('a', 'DET')\n",
      "8442 ('month', 'NOUN')\n",
      "8443 (',', '')\n",
      "8444 ('and', 'CONJ')\n",
      "8445 ('was', 'VERB')\n",
      "8446 ('a', 'DET')\n",
      "8447 ('popular', 'ADJ')\n",
      "8448 ('spectacle', 'NOUN')\n",
      "8449 ('.', '')\n",
      "8450 ('Children', 'NOUN')\n",
      "8451 ('always', 'ADV')\n",
      "8452 ('clamoured', 'VERB')\n",
      "8453 ('to', 'ADP')\n",
      "8454 ('be', 'VERB')\n",
      "8455 ('taken', 'VERB')\n",
      "8456 ('to', 'ADP')\n",
      "8457 ('see', 'VERB')\n",
      "8458 ('it', 'PRON')\n",
      "8459 ('.', '')\n",
      "8460 ('He', 'PRON')\n",
      "8461 ('took', 'VERB')\n",
      "8462 ('his', 'DET')\n",
      "8463 ('leave', 'NOUN')\n",
      "8464 ('of', 'ADP')\n",
      "8465 ('Mrs', 'NOUN')\n",
      "8466 ('Parsons', 'NOUN')\n",
      "8467 ('and', 'CONJ')\n",
      "8468 ('made', 'VERB')\n",
      "8469 ('for', 'ADP')\n",
      "8470 ('the', 'DET')\n",
      "8471 ('door', 'NOUN')\n",
      "8472 ('.', '')\n",
      "8473 ('But', 'CONJ')\n",
      "8474 ('he', 'PRON')\n",
      "8475 ('had', 'VERB')\n",
      "8476 ('not', 'ADV')\n",
      "8477 ('gone', 'VERB')\n",
      "8478 ('six', 'NUM')\n",
      "8479 ('steps', 'NOUN')\n",
      "8480 ('down', 'ADP')\n",
      "8481 ('the', 'DET')\n",
      "8482 ('passage', 'NOUN')\n",
      "8483 ('when', 'CONJ')\n",
      "8484 ('something', 'PRON')\n",
      "8485 ('hit', 'VERB')\n",
      "8486 ('the', 'DET')\n",
      "8487 ('back', 'NOUN')\n",
      "8488 ('of', 'ADP')\n",
      "8489 ('his', 'DET')\n",
      "8490 ('neck', 'NOUN')\n",
      "8491 ('an', 'DET')\n",
      "8492 ('agonizingly', 'ADV')\n",
      "8493 ('painful', 'ADJ')\n",
      "8494 ('blow', 'NOUN')\n",
      "8495 ('.', '')\n",
      "8496 ('It', 'PRON')\n",
      "8497 ('was', 'VERB')\n",
      "8498 ('as', 'CONJ')\n",
      "8499 ('though', 'CONJ')\n",
      "8500 ('a', 'DET')\n",
      "8501 ('red-hot', 'ADJ')\n",
      "8502 ('wire', 'NOUN')\n",
      "8503 ('had', 'VERB')\n",
      "8504 ('been', 'VERB')\n",
      "8505 ('jabbed', 'VERB')\n",
      "8506 ('into', 'ADP')\n",
      "8507 ('him', 'PRON')\n",
      "8508 ('.', '')\n",
      "8509 ('He', 'PRON')\n",
      "8510 ('spun', 'VERB')\n",
      "8511 ('round', 'ADV')\n",
      "8512 ('just', 'ADV')\n",
      "8513 ('in', 'ADP')\n",
      "8514 ('time', 'NOUN')\n",
      "8515 ('to', 'ADP')\n",
      "8516 ('see', 'VERB')\n",
      "8517 ('Mrs', 'NOUN')\n",
      "8518 ('Parsons', 'NOUN')\n",
      "8519 ('dragging', 'VERB')\n",
      "8520 ('her', 'DET')\n",
      "8521 ('son', 'NOUN')\n",
      "8522 ('back', 'ADV')\n",
      "8523 ('into', 'ADP')\n",
      "8524 ('the', 'DET')\n",
      "8525 ('doorway', 'NOUN')\n",
      "8526 ('while', 'CONJ')\n",
      "8527 ('the', 'DET')\n",
      "8528 ('boy', 'NOUN')\n",
      "8529 ('pocketed', 'VERB')\n",
      "8530 ('a', 'DET')\n",
      "8531 ('catapult', 'NOUN')\n",
      "8532 ('.', '')\n",
      "8533 ('Goldstein', 'NOUN')\n",
      "8534 ('!', '')\n",
      "8535 ('bellowed', 'VERB')\n",
      "8536 ('the', 'DET')\n",
      "8537 ('boy', 'NOUN')\n",
      "8538 ('as', 'CONJ')\n",
      "8539 ('the', 'DET')\n",
      "8540 ('door', 'NOUN')\n",
      "8541 ('closed', 'VERB')\n",
      "8542 ('on', 'ADP')\n",
      "8543 ('him', 'PRON')\n",
      "8544 ('.', '')\n",
      "8545 ('But', 'CONJ')\n",
      "8546 ('what', 'PRON')\n",
      "8547 ('most', 'ADV')\n",
      "8548 ('struck', 'VERB')\n",
      "8549 ('Winston', 'NOUN')\n",
      "8550 ('was', 'VERB')\n",
      "8551 ('the', 'DET')\n",
      "8552 ('look', 'NOUN')\n",
      "8553 ('of', 'ADP')\n",
      "8554 ('helpless', 'ADJ')\n",
      "8555 ('fright', 'NOUN')\n",
      "8556 ('on', 'ADP')\n",
      "8557 ('the', 'DET')\n",
      "8558 ('woman', 'NOUN')\n",
      "8559 (\"'s\", 'ADP')\n",
      "8560 ('greyish', 'ADJ')\n",
      "8561 ('face', 'NOUN')\n",
      "8562 ('.', '')\n",
      "8563 ('Back', 'ADV')\n",
      "8564 ('in', 'ADP')\n",
      "8565 ('the', 'DET')\n",
      "8566 ('flat', 'NOUN')\n",
      "8567 ('he', 'PRON')\n",
      "8568 ('stepped', 'VERB')\n",
      "8569 ('quickly', 'ADV')\n",
      "8570 ('past', 'ADP')\n",
      "8571 ('the', 'DET')\n",
      "8572 ('telescreen', 'NOUN')\n",
      "8573 ('and', 'CONJ')\n",
      "8574 ('sat', 'VERB')\n",
      "8575 ('down', 'ADV')\n",
      "8576 ('at', 'ADP')\n",
      "8577 ('the', 'DET')\n",
      "8578 ('table', 'NOUN')\n",
      "8579 ('again', 'ADV')\n",
      "8580 (',', '')\n",
      "8581 ('still', 'ADV')\n",
      "8582 ('rubbing', 'VERB')\n",
      "8583 ('his', 'DET')\n",
      "8584 ('neck', 'NOUN')\n",
      "8585 ('.', '')\n",
      "8586 ('The', 'DET')\n",
      "8587 ('music', 'NOUN')\n",
      "8588 ('from', 'ADP')\n",
      "8589 ('the', 'DET')\n",
      "8590 ('telescreen', 'NOUN')\n",
      "8591 ('had', 'VERB')\n",
      "8592 ('stopped', 'VERB')\n",
      "8593 ('.', '')\n",
      "8594 ('Instead', 'ADV')\n",
      "8595 (',', '')\n",
      "8596 ('a', 'DET')\n",
      "8597 ('clipped', 'ADJ')\n",
      "8598 ('military', 'ADJ')\n",
      "8599 ('voice', 'NOUN')\n",
      "8600 ('was', 'VERB')\n",
      "8601 ('reading', 'VERB')\n",
      "8602 ('out', 'ADP')\n",
      "8603 (',', '')\n",
      "8604 ('with', 'ADP')\n",
      "8605 ('a', 'DET')\n",
      "8606 ('sort', 'NOUN')\n",
      "8607 ('of', 'ADP')\n",
      "8608 ('brutal', 'ADJ')\n",
      "8609 ('relish', 'NOUN')\n",
      "8610 (',', '')\n",
      "8611 ('a', 'DET')\n",
      "8612 ('description', 'NOUN')\n",
      "8613 ('of', 'ADP')\n",
      "8614 ('the', 'DET')\n",
      "8615 ('armaments', 'NOUN')\n",
      "8616 ('of', 'ADP')\n",
      "8617 ('the', 'DET')\n",
      "8618 ('new', 'ADJ')\n",
      "8619 ('Floating', 'ADJ')\n",
      "8620 ('Fortress', 'NOUN')\n",
      "8621 ('which', 'PRON')\n",
      "8622 ('had', 'VERB')\n",
      "8623 ('just', 'ADV')\n",
      "8624 ('been', 'VERB')\n",
      "8625 ('anchored', 'VERB')\n",
      "8626 ('between', 'ADP')\n",
      "8627 ('Iceland', 'NOUN')\n",
      "8628 ('and', 'CONJ')\n",
      "8629 ('the', 'DET')\n",
      "8630 ('Faroe', 'NOUN')\n",
      "8631 ('islands', 'NOUN')\n",
      "8632 ('.', '')\n",
      "8633 ('With', 'ADP')\n",
      "8634 ('those', 'DET')\n",
      "8635 ('children', 'NOUN')\n",
      "8636 (',', '')\n",
      "8637 ('he', 'PRON')\n",
      "8638 ('thought', 'VERB')\n",
      "8639 (',', '')\n",
      "8640 ('that', 'DET')\n",
      "8641 ('wretched', 'ADJ')\n",
      "8642 ('woman', 'NOUN')\n",
      "8643 ('must', 'VERB')\n",
      "8644 ('lead', 'VERB')\n",
      "8645 ('a', 'DET')\n",
      "8646 ('life', 'NOUN')\n",
      "8647 ('of', 'ADP')\n",
      "8648 ('terror', 'NOUN')\n",
      "8649 ('.', '')\n",
      "8650 ('Another', 'DET')\n",
      "8651 ('year', 'NOUN')\n",
      "8652 (',', '')\n",
      "8653 ('two', 'NUM')\n",
      "8654 ('years', 'NOUN')\n",
      "8655 (',', '')\n",
      "8656 ('and', 'CONJ')\n",
      "8657 ('they', 'PRON')\n",
      "8658 ('would', 'VERB')\n",
      "8659 ('be', 'VERB')\n",
      "8660 ('watching', 'VERB')\n",
      "8661 ('her', 'PRON')\n",
      "8662 ('night', 'NOUN')\n",
      "8663 ('and', 'CONJ')\n",
      "8664 ('day', 'NOUN')\n",
      "8665 ('for', 'ADP')\n",
      "8666 ('symptoms', 'NOUN')\n",
      "8667 ('of', 'ADP')\n",
      "8668 ('unorthodoxy', 'NOUN')\n",
      "8669 ('.', '')\n",
      "8670 ('Nearly', 'ADV')\n",
      "8671 ('all', 'DET')\n",
      "8672 ('children', 'NOUN')\n",
      "8673 ('nowadays', 'ADV')\n",
      "8674 ('were', 'VERB')\n",
      "8675 ('horrible', 'ADJ')\n",
      "8676 ('.', '')\n",
      "8677 ('What', 'PRON')\n",
      "8678 ('was', 'VERB')\n",
      "8679 ('worst', 'ADJ')\n",
      "8680 ('of', 'ADP')\n",
      "8681 ('all', 'PRON')\n",
      "8682 ('was', 'VERB')\n",
      "8683 ('that', 'CONJ')\n",
      "8684 ('by', 'ADP')\n",
      "8685 ('means', 'NOUN')\n",
      "8686 ('of', 'ADP')\n",
      "8687 ('such', 'DET')\n",
      "8688 ('organizations', 'NOUN')\n",
      "8689 ('as', 'ADP')\n",
      "8690 ('the', 'DET')\n",
      "8691 ('Spies', 'NOUN')\n",
      "8692 ('they', 'PRON')\n",
      "8693 ('were', 'VERB')\n",
      "8694 ('systematically', 'ADV')\n",
      "8695 ('turned', 'VERB')\n",
      "8696 ('into', 'ADP')\n",
      "8697 ('ungovernable', 'ADJ')\n",
      "8698 ('little', 'ADJ')\n",
      "8699 ('savages', 'NOUN')\n",
      "8700 (',', '')\n",
      "8701 ('and', 'CONJ')\n",
      "8702 ('yet', 'CONJ')\n",
      "8703 ('this', 'PRON')\n",
      "8704 ('produced', 'VERB')\n",
      "8705 ('in', 'ADP')\n",
      "8706 ('them', 'PRON')\n",
      "8707 ('no', 'DET')\n",
      "8708 ('tendency', 'NOUN')\n",
      "8709 ('whatever', 'ADV')\n",
      "8710 ('to', 'ADP')\n",
      "8711 ('rebel', 'VERB')\n",
      "8712 ('against', 'ADP')\n",
      "8713 ('the', 'DET')\n",
      "8714 ('discipline', 'NOUN')\n",
      "8715 ('of', 'ADP')\n",
      "8716 ('the', 'DET')\n",
      "8717 ('Party', 'NOUN')\n",
      "8718 ('.', '')\n",
      "8719 ('On', 'ADP')\n",
      "8720 ('the', 'DET')\n",
      "8721 ('contrary', 'ADJ')\n",
      "8722 (',', '')\n",
      "8723 ('they', 'PRON')\n",
      "8724 ('adored', 'VERB')\n",
      "8725 ('the', 'DET')\n",
      "8726 ('Party', 'NOUN')\n",
      "8727 ('and', 'CONJ')\n",
      "8728 ('everything', 'PRON')\n",
      "8729 ('connected', 'VERB')\n",
      "8730 ('with', 'ADP')\n",
      "8731 ('it', 'PRON')\n",
      "8732 ('.', '')\n",
      "8733 ('The', 'DET')\n",
      "8734 ('songs', 'NOUN')\n",
      "8735 (',', '')\n",
      "8736 ('the', 'DET')\n",
      "8737 ('processions', 'NOUN')\n",
      "8738 (',', '')\n",
      "8739 ('the', 'DET')\n",
      "8740 ('banners', 'NOUN')\n",
      "8741 (',', '')\n",
      "8742 ('the', 'DET')\n",
      "8743 ('hiking', 'NOUN')\n",
      "8744 (',', '')\n",
      "8745 ('the', 'DET')\n",
      "8746 ('drilling', 'VERB')\n",
      "8747 ('with', 'ADP')\n",
      "8748 ('dummy', 'ADJ')\n",
      "8749 ('rifles', 'NOUN')\n",
      "8750 (',', '')\n",
      "8751 ('the', 'DET')\n",
      "8752 ('yelling', 'VERB')\n",
      "8753 ('of', 'ADP')\n",
      "8754 ('slogans', 'NOUN')\n",
      "8755 (',', '')\n",
      "8756 ('the', 'DET')\n",
      "8757 ('worship', 'NOUN')\n",
      "8758 ('of', 'ADP')\n",
      "8759 ('Big', 'ADJ')\n",
      "8760 ('Brother', 'NOUN')\n",
      "8761 ('-', '')\n",
      "8762 ('it', 'PRON')\n",
      "8763 ('was', 'VERB')\n",
      "8764 ('all', 'PRON')\n",
      "8765 ('a', 'DET')\n",
      "8766 ('sort', 'NOUN')\n",
      "8767 ('of', 'ADP')\n",
      "8768 ('glorious', 'ADJ')\n",
      "8769 ('game', 'NOUN')\n",
      "8770 ('to', 'ADP')\n",
      "8771 ('them', 'PRON')\n",
      "8772 ('.', '')\n",
      "8773 ('All', 'DET')\n",
      "8774 ('their', 'DET')\n",
      "8775 ('ferocity', 'NOUN')\n",
      "8776 ('was', 'VERB')\n",
      "8777 ('turned', 'VERB')\n",
      "8778 ('outwards', 'ADV')\n",
      "8779 (',', '')\n",
      "8780 ('against', 'ADP')\n",
      "8781 ('the', 'DET')\n",
      "8782 ('enemies', 'NOUN')\n",
      "8783 ('of', 'ADP')\n",
      "8784 ('the', 'DET')\n",
      "8785 ('State', 'NOUN')\n",
      "8786 (',', '')\n",
      "8787 ('against', 'ADP')\n",
      "8788 ('foreigners', 'NOUN')\n",
      "8789 (',', '')\n",
      "8790 ('traitors', 'NOUN')\n",
      "8791 (',', '')\n",
      "8792 ('saboteurs', 'NOUN')\n",
      "8793 (',', '')\n",
      "8794 ('thought-criminals', 'NOUN')\n",
      "8795 ('.', '')\n",
      "8796 ('It', 'PRON')\n",
      "8797 ('was', 'VERB')\n",
      "8798 ('almost', 'ADV')\n",
      "8799 ('normal', 'ADJ')\n",
      "8800 ('for', 'ADP')\n",
      "8801 ('people', 'NOUN')\n",
      "8802 ('over', 'ADP')\n",
      "8803 ('thirty', 'NUM')\n",
      "8804 ('to', 'ADP')\n",
      "8805 ('be', 'VERB')\n",
      "8806 ('frightened', 'ADJ')\n",
      "8807 ('of', 'ADP')\n",
      "8808 ('their', 'DET')\n",
      "8809 ('own', 'ADJ')\n",
      "8810 ('children', 'NOUN')\n",
      "8811 ('.', '')\n",
      "8812 ('And', 'CONJ')\n",
      "8813 ('with', 'ADP')\n",
      "8814 ('good', 'ADJ')\n",
      "8815 ('reason', 'NOUN')\n",
      "8816 (',', '')\n",
      "8817 ('for', 'CONJ')\n",
      "8818 ('hardly', 'ADV')\n",
      "8819 ('a', 'DET')\n",
      "8820 ('week', 'NOUN')\n",
      "8821 ('passed', 'VERB')\n",
      "8822 ('in', 'ADP')\n",
      "8823 ('which', 'PRON')\n",
      "8824 ('the', 'DET')\n",
      "8825 ('Times', 'NOUN')\n",
      "8826 ('did', 'VERB')\n",
      "8827 ('not', 'ADV')\n",
      "8828 ('carry', 'VERB')\n",
      "8829 ('a', 'DET')\n",
      "8830 ('paragraph', 'NOUN')\n",
      "8831 ('describing', 'VERB')\n",
      "8832 ('how', 'ADV')\n",
      "8833 ('some', 'DET')\n",
      "8834 ('eavesdropping', 'VERB')\n",
      "8835 ('little', 'ADJ')\n",
      "8836 ('sneak', 'NOUN')\n",
      "8837 ('-', '')\n",
      "8838 ('child', 'NOUN')\n",
      "8839 ('hero', 'NOUN')\n",
      "8840 ('was', 'VERB')\n",
      "8841 ('the', 'DET')\n",
      "8842 ('phrase', 'NOUN')\n",
      "8843 ('generally', 'ADV')\n",
      "8844 ('used', 'VERB')\n",
      "8845 ('-', '')\n",
      "8846 ('had', 'VERB')\n",
      "8847 ('overheard', 'VERB')\n",
      "8848 ('some', 'DET')\n",
      "8849 ('compromising', 'ADJ')\n",
      "8850 ('remark', 'NOUN')\n",
      "8851 ('and', 'CONJ')\n",
      "8852 ('denounced', 'VERB')\n",
      "8853 ('its', 'DET')\n",
      "8854 ('parents', 'NOUN')\n",
      "8855 ('to', 'ADP')\n",
      "8856 ('the', 'DET')\n",
      "8857 ('Thought', 'NOUN')\n",
      "8858 ('Police', 'NOUN')\n",
      "8859 ('.', '')\n",
      "8860 ('The', 'DET')\n",
      "8861 ('sting', 'NOUN')\n",
      "8862 ('of', 'ADP')\n",
      "8863 ('the', 'DET')\n",
      "8864 ('catapult', 'NOUN')\n",
      "8865 ('bullet', 'NOUN')\n",
      "8866 ('had', 'VERB')\n",
      "8867 ('worn', 'VERB')\n",
      "8868 ('off', 'ADV')\n",
      "8869 ('.', '')\n",
      "8870 ('He', 'PRON')\n",
      "8871 ('picked', 'VERB')\n",
      "8872 ('up', 'ADP')\n",
      "8873 ('his', 'DET')\n",
      "8874 ('pen', 'NOUN')\n",
      "8875 ('half-heartedly', 'ADV')\n",
      "8876 (',', '')\n",
      "8877 ('wondering', 'VERB')\n",
      "8878 ('whether', 'CONJ')\n",
      "8879 ('he', 'PRON')\n",
      "8880 ('could', 'VERB')\n",
      "8881 ('find', 'VERB')\n",
      "8882 ('something', 'PRON')\n",
      "8883 ('more', 'ADV')\n",
      "8884 ('to', 'ADP')\n",
      "8885 ('write', 'VERB')\n",
      "8886 ('in', 'ADP')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8887 ('the', 'DET')\n",
      "8888 ('diary', 'NOUN')\n",
      "8889 ('.', '')\n",
      "8890 ('Suddenly', 'ADV')\n",
      "8891 ('he', 'PRON')\n",
      "8892 ('began', 'VERB')\n",
      "8893 ('thinking', 'VERB')\n",
      "8894 ('of', 'ADP')\n",
      "8895 (\"O'Brien\", 'NOUN')\n",
      "8896 ('again', 'ADV')\n",
      "8897 ('.', '')\n",
      "8898 ('Years', 'NOUN')\n",
      "8899 ('ago', 'ADP')\n",
      "8900 ('-', '')\n",
      "8901 ('how', 'ADV')\n",
      "8902 ('long', 'ADV')\n",
      "8903 ('was', 'VERB')\n",
      "8904 ('it', 'PRON')\n",
      "8905 ('?', '')\n",
      "8906 ('Seven', 'NUM')\n",
      "8907 ('years', 'NOUN')\n",
      "8908 ('it', 'PRON')\n",
      "8909 ('must', 'VERB')\n",
      "8910 ('be', 'VERB')\n",
      "8911 ('-', '')\n",
      "8912 ('he', 'PRON')\n",
      "8913 ('had', 'VERB')\n",
      "8914 ('dreamed', 'VERB')\n",
      "8915 ('that', 'CONJ')\n",
      "8916 ('he', 'PRON')\n",
      "8917 ('was', 'VERB')\n",
      "8918 ('walking', 'VERB')\n",
      "8919 ('through', 'ADP')\n",
      "8920 ('a', 'DET')\n",
      "8921 ('pitch-dark', 'ADJ')\n",
      "8922 ('room', 'NOUN')\n",
      "8923 ('.', '')\n",
      "8924 ('And', 'CONJ')\n",
      "8925 ('someone', 'PRON')\n",
      "8926 ('sitting', 'VERB')\n",
      "8927 ('to', 'ADP')\n",
      "8928 ('one', 'NUM')\n",
      "8929 ('side', 'NOUN')\n",
      "8930 ('of', 'ADP')\n",
      "8931 ('him', 'PRON')\n",
      "8932 ('had', 'VERB')\n",
      "8933 ('said', 'VERB')\n",
      "8934 ('as', 'CONJ')\n",
      "8935 ('he', 'PRON')\n",
      "8936 ('passed', 'VERB')\n",
      "8937 (':', '')\n",
      "8938 ('We', 'PRON')\n",
      "8939 ('shall', 'VERB')\n",
      "8940 ('meet', 'VERB')\n",
      "8941 ('in', 'ADP')\n",
      "8942 ('the', 'DET')\n",
      "8943 ('place', 'NOUN')\n",
      "8944 ('where', 'CONJ')\n",
      "8945 ('there', 'PRON')\n",
      "8946 ('is', 'VERB')\n",
      "8947 ('no', 'DET')\n",
      "8948 ('darkness', 'NOUN')\n",
      "8949 ('.', '')\n",
      "8950 ('It', 'PRON')\n",
      "8951 ('was', 'VERB')\n",
      "8952 ('said', 'VERB')\n",
      "8953 ('very', 'ADV')\n",
      "8954 ('quietly', 'ADV')\n",
      "8955 (',', '')\n",
      "8956 ('almost', 'ADV')\n",
      "8957 ('casually', 'ADV')\n",
      "8958 ('-', '')\n",
      "8959 ('a', 'DET')\n",
      "8960 ('statement', 'NOUN')\n",
      "8961 (',', '')\n",
      "8962 ('not', 'ADV')\n",
      "8963 ('a', 'DET')\n",
      "8964 ('command', 'NOUN')\n",
      "8965 ('.', '')\n",
      "8966 ('He', 'PRON')\n",
      "8967 ('had', 'VERB')\n",
      "8968 ('walked', 'VERB')\n",
      "8969 ('on', 'ADP')\n",
      "8970 ('without', 'ADP')\n",
      "8971 ('pausing', 'VERB')\n",
      "8972 ('.', '')\n",
      "8973 ('What', 'PRON')\n",
      "8974 ('was', 'VERB')\n",
      "8975 ('curious', 'ADJ')\n",
      "8976 ('was', 'VERB')\n",
      "8977 ('that', 'CONJ')\n",
      "8978 ('at', 'ADP')\n",
      "8979 ('the', 'DET')\n",
      "8980 ('time', 'NOUN')\n",
      "8981 (',', '')\n",
      "8982 ('in', 'ADP')\n",
      "8983 ('the', 'DET')\n",
      "8984 ('dream', 'NOUN')\n",
      "8985 (',', '')\n",
      "8986 ('the', 'DET')\n",
      "8987 ('words', 'NOUN')\n",
      "8988 ('had', 'VERB')\n",
      "8989 ('not', 'ADV')\n",
      "8990 ('made', 'VERB')\n",
      "8991 ('much', 'DET')\n",
      "8992 ('impression', 'NOUN')\n",
      "8993 ('on', 'ADP')\n",
      "8994 ('him', 'PRON')\n",
      "8995 ('.', '')\n",
      "8996 ('It', 'PRON')\n",
      "8997 ('was', 'VERB')\n",
      "8998 ('only', 'ADV')\n",
      "8999 ('later', 'ADV')\n",
      "9000 ('and', 'CONJ')\n",
      "9001 ('by', 'ADP')\n",
      "9002 ('degrees', 'NOUN')\n",
      "9003 ('that', 'CONJ')\n",
      "9004 ('they', 'PRON')\n",
      "9005 ('had', 'VERB')\n",
      "9006 ('seemed', 'VERB')\n",
      "9007 ('to', 'ADP')\n",
      "9008 ('take', 'VERB')\n",
      "9009 ('on', 'ADP')\n",
      "9010 ('significance', 'NOUN')\n",
      "9011 ('.', '')\n",
      "9012 ('He', 'PRON')\n",
      "9013 ('could', 'VERB')\n",
      "9014 ('not', 'ADV')\n",
      "9015 ('now', 'ADV')\n",
      "9016 ('remember', 'VERB')\n",
      "9017 ('whether', 'CONJ')\n",
      "9018 ('it', 'PRON')\n",
      "9019 ('was', 'VERB')\n",
      "9020 ('before', 'ADP')\n",
      "9021 ('or', 'CONJ')\n",
      "9022 ('after', 'ADP')\n",
      "9023 ('having', 'VERB')\n",
      "9024 ('the', 'DET')\n",
      "9025 ('dream', 'NOUN')\n",
      "9026 ('that', 'CONJ')\n",
      "9027 ('he', 'PRON')\n",
      "9028 ('had', 'VERB')\n",
      "9029 ('seen', 'VERB')\n",
      "9030 (\"O'Brien\", 'NOUN')\n",
      "9031 ('for', 'ADP')\n",
      "9032 ('the', 'DET')\n",
      "9033 ('first', 'ADJ')\n",
      "9034 ('time', 'NOUN')\n",
      "9035 (',', '')\n",
      "9036 ('nor', 'CONJ')\n",
      "9037 ('could', 'VERB')\n",
      "9038 ('he', 'PRON')\n",
      "9039 ('remember', 'VERB')\n",
      "9040 ('when', 'ADV')\n",
      "9041 ('he', 'PRON')\n",
      "9042 ('had', 'VERB')\n",
      "9043 ('first', 'ADV')\n",
      "9044 ('identified', 'VERB')\n",
      "9045 ('the', 'DET')\n",
      "9046 ('voice', 'NOUN')\n",
      "9047 ('as', 'ADP')\n",
      "9048 (\"O'Brien\", 'NOUN')\n",
      "9049 (\"'s\", 'ADP')\n",
      "9050 ('.', '')\n",
      "9051 ('But', 'CONJ')\n",
      "9052 ('at', 'ADP')\n",
      "9053 ('any', 'DET')\n",
      "9054 ('rate', 'NOUN')\n",
      "9055 ('the', 'DET')\n",
      "9056 ('identification', 'NOUN')\n",
      "9057 ('existed', 'VERB')\n",
      "9058 ('.', '')\n",
      "9059 ('It', 'PRON')\n",
      "9060 ('was', 'VERB')\n",
      "9061 (\"O'Brien\", 'NOUN')\n",
      "9062 ('who', 'PRON')\n",
      "9063 ('had', 'VERB')\n",
      "9064 ('spoken', 'VERB')\n",
      "9065 ('to', 'ADP')\n",
      "9066 ('him', 'PRON')\n",
      "9067 ('out', 'ADP')\n",
      "9068 ('of', 'ADP')\n",
      "9069 ('the', 'DET')\n",
      "9070 ('dark', 'NOUN')\n",
      "9071 ('.', '')\n",
      "9072 ('Winston', 'NOUN')\n",
      "9073 ('had', 'VERB')\n",
      "9074 ('never', 'ADV')\n",
      "9075 ('been', 'VERB')\n",
      "9076 ('able', 'ADJ')\n",
      "9077 ('to', 'ADP')\n",
      "9078 ('feel', 'VERB')\n",
      "9079 ('sure', 'ADJ')\n",
      "9080 ('-', '')\n",
      "9081 ('even', 'ADV')\n",
      "9082 ('after', 'ADP')\n",
      "9083 ('this', 'DET')\n",
      "9084 ('morning', 'NOUN')\n",
      "9085 (\"'s\", 'ADP')\n",
      "9086 ('flash', 'NOUN')\n",
      "9087 ('of', 'ADP')\n",
      "9088 ('the', 'DET')\n",
      "9089 ('eyes', 'NOUN')\n",
      "9090 ('it', 'PRON')\n",
      "9091 ('was', 'VERB')\n",
      "9092 ('still', 'ADV')\n",
      "9093 ('impossible', 'ADJ')\n",
      "9094 ('to', 'ADP')\n",
      "9095 ('be', 'VERB')\n",
      "9096 ('sure', 'ADJ')\n",
      "9097 ('whether', 'CONJ')\n",
      "9098 (\"O'Brien\", 'NOUN')\n",
      "9099 ('was', 'VERB')\n",
      "9100 ('a', 'DET')\n",
      "9101 ('friend', 'NOUN')\n",
      "9102 ('or', 'CONJ')\n",
      "9103 ('an', 'DET')\n",
      "9104 ('enemy', 'NOUN')\n",
      "9105 ('.', '')\n",
      "9106 ('Nor', 'CONJ')\n",
      "9107 ('did', 'VERB')\n",
      "9108 ('it', 'PRON')\n",
      "9109 ('even', 'ADV')\n",
      "9110 ('seem', 'VERB')\n",
      "9111 ('to', 'ADP')\n",
      "9112 ('matter', 'VERB')\n",
      "9113 ('greatly', 'ADV')\n",
      "9114 ('.', '')\n",
      "9115 ('There', 'PRON')\n",
      "9116 ('was', 'VERB')\n",
      "9117 ('a', 'DET')\n",
      "9118 ('link', 'NOUN')\n",
      "9119 ('of', 'ADP')\n",
      "9120 ('understanding', 'NOUN')\n",
      "9121 ('between', 'ADP')\n",
      "9122 ('them', 'PRON')\n",
      "9123 (',', '')\n",
      "9124 ('more', 'ADV')\n",
      "9125 ('important', 'ADJ')\n",
      "9126 ('than', 'ADP')\n",
      "9127 ('affection', 'NOUN')\n",
      "9128 ('or', 'CONJ')\n",
      "9129 ('partisanship', 'NOUN')\n",
      "9130 ('.', '')\n",
      "9131 ('We', 'PRON')\n",
      "9132 ('shall', 'VERB')\n",
      "9133 ('meet', 'VERB')\n",
      "9134 ('in', 'ADP')\n",
      "9135 ('the', 'DET')\n",
      "9136 ('place', 'NOUN')\n",
      "9137 ('where', 'CONJ')\n",
      "9138 ('there', 'PRON')\n",
      "9139 ('is', 'VERB')\n",
      "9140 ('no', 'DET')\n",
      "9141 ('darkness', 'NOUN')\n",
      "9142 (',', '')\n",
      "9143 ('he', 'PRON')\n",
      "9144 ('had', 'VERB')\n",
      "9145 ('said', 'VERB')\n",
      "9146 ('.', '')\n",
      "9147 ('Winston', 'NOUN')\n",
      "9148 ('did', 'VERB')\n",
      "9149 ('not', 'ADV')\n",
      "9150 ('know', 'VERB')\n",
      "9151 ('what', 'PRON')\n",
      "9152 ('it', 'PRON')\n",
      "9153 ('meant', 'VERB')\n",
      "9154 (',', '')\n",
      "9155 ('only', 'ADV')\n",
      "9156 ('that', 'CONJ')\n",
      "9157 ('in', 'ADP')\n",
      "9158 ('some', 'DET')\n",
      "9159 ('way', 'NOUN')\n",
      "9160 ('or', 'CONJ')\n",
      "9161 ('another', 'PRON')\n",
      "9162 ('it', 'PRON')\n",
      "9163 ('would', 'VERB')\n",
      "9164 ('come', 'VERB')\n",
      "9165 ('true', 'ADJ')\n",
      "9166 ('.', '')\n",
      "9167 ('The', 'DET')\n",
      "9168 ('voice', 'NOUN')\n",
      "9169 ('from', 'ADP')\n",
      "9170 ('the', 'DET')\n",
      "9171 ('telescreen', 'NOUN')\n",
      "9172 ('paused', 'VERB')\n",
      "9173 ('.', '')\n",
      "9174 ('A', 'DET')\n",
      "9175 ('trumpet', 'NOUN')\n",
      "9176 ('call', 'NOUN')\n",
      "9177 (',', '')\n",
      "9178 ('clear', 'ADJ')\n",
      "9179 ('and', 'CONJ')\n",
      "9180 ('beautiful', 'ADJ')\n",
      "9181 (',', '')\n",
      "9182 ('floated', 'VERB')\n",
      "9183 ('into', 'ADP')\n",
      "9184 ('the', 'DET')\n",
      "9185 ('stagnant', 'ADJ')\n",
      "9186 ('air', 'NOUN')\n",
      "9187 ('.', '')\n",
      "9188 ('The', 'DET')\n",
      "9189 ('voice', 'NOUN')\n",
      "9190 ('continued', 'VERB')\n",
      "9191 ('raspingly', 'ADV')\n",
      "9192 (':', '')\n",
      "9193 ('Attention', 'NOUN')\n",
      "9194 ('!', '')\n",
      "9195 ('Your', 'DET')\n",
      "9196 ('attention', 'NOUN')\n",
      "9197 (',', '')\n",
      "9198 ('please', 'ADV')\n",
      "9199 ('!', '')\n",
      "9200 ('A', 'DET')\n",
      "9201 ('newsflash', 'NOUN')\n",
      "9202 ('has', 'VERB')\n",
      "9203 ('this', 'DET')\n",
      "9204 ('moment', 'NOUN')\n",
      "9205 ('arrived', 'VERB')\n",
      "9206 ('from', 'ADP')\n",
      "9207 ('the', 'DET')\n",
      "9208 ('Malabar', 'NOUN')\n",
      "9209 ('front', 'NOUN')\n",
      "9210 ('.', '')\n",
      "9211 ('Our', 'DET')\n",
      "9212 ('forces', 'NOUN')\n",
      "9213 ('in', 'ADP')\n",
      "9214 ('South', 'ADJ')\n",
      "9215 ('India', 'NOUN')\n",
      "9216 ('have', 'VERB')\n",
      "9217 ('won', 'VERB')\n",
      "9218 ('a', 'DET')\n",
      "9219 ('glorious', 'ADJ')\n",
      "9220 ('victory', 'NOUN')\n",
      "9221 ('.', '')\n",
      "9222 ('I', 'PRON')\n",
      "9223 ('am', 'VERB')\n",
      "9224 ('authorized', 'VERB')\n",
      "9225 ('to', 'ADP')\n",
      "9226 ('say', 'VERB')\n",
      "9227 ('that', 'CONJ')\n",
      "9228 ('the', 'DET')\n",
      "9229 ('action', 'NOUN')\n",
      "9230 ('we', 'PRON')\n",
      "9231 ('are', 'VERB')\n",
      "9232 ('now', 'ADV')\n",
      "9233 ('reporting', 'VERB')\n",
      "9234 ('may', 'VERB')\n",
      "9235 ('well', 'ADV')\n",
      "9236 ('bring', 'VERB')\n",
      "9237 ('the', 'DET')\n",
      "9238 ('war', 'NOUN')\n",
      "9239 ('within', 'ADP')\n",
      "9240 ('measurable', 'ADJ')\n",
      "9241 ('distance', 'NOUN')\n",
      "9242 ('of', 'ADP')\n",
      "9243 ('its', 'DET')\n",
      "9244 ('end', 'NOUN')\n",
      "9245 ('.', '')\n",
      "9246 ('Here', 'ADV')\n",
      "9247 ('is', 'VERB')\n",
      "9248 ('the', 'DET')\n",
      "9249 ('newsflash', 'NOUN')\n",
      "9250 ('-', '')\n",
      "9251 ('Bad', 'ADJ')\n",
      "9252 ('news', 'NOUN')\n",
      "9253 ('coming', 'VERB')\n",
      "9254 (',', '')\n",
      "9255 ('thought', 'VERB')\n",
      "9256 ('Winston', 'NOUN')\n",
      "9257 ('.', '')\n",
      "9258 ('And', 'CONJ')\n",
      "9259 ('sure', 'ADJ')\n",
      "9260 ('enough', 'ADV')\n",
      "9261 (',', '')\n",
      "9262 ('following', 'VERB')\n",
      "9263 ('on', 'ADP')\n",
      "9264 ('a', 'DET')\n",
      "9265 ('gory', 'ADJ')\n",
      "9266 ('description', 'NOUN')\n",
      "9267 ('of', 'ADP')\n",
      "9268 ('the', 'DET')\n",
      "9269 ('annihilation', 'NOUN')\n",
      "9270 ('of', 'ADP')\n",
      "9271 ('a', 'DET')\n",
      "9272 ('Eurasian', 'ADJ')\n",
      "9273 ('army', 'NOUN')\n",
      "9274 (',', '')\n",
      "9275 ('with', 'ADP')\n",
      "9276 ('stupendous', 'ADJ')\n",
      "9277 ('figures', 'NOUN')\n",
      "9278 ('of', 'ADP')\n",
      "9279 ('killed', 'NOUN')\n",
      "9280 ('and', 'CONJ')\n",
      "9281 ('prisoners', 'NOUN')\n",
      "9282 (',', '')\n",
      "9283 ('came', 'VERB')\n",
      "9284 ('the', 'DET')\n",
      "9285 ('announcement', 'NOUN')\n",
      "9286 ('that', 'CONJ')\n",
      "9287 (',', '')\n",
      "9288 ('as', 'CONJ')\n",
      "9289 ('from', 'ADP')\n",
      "9290 ('next', 'ADJ')\n",
      "9291 ('week', 'NOUN')\n",
      "9292 (',', '')\n",
      "9293 ('the', 'DET')\n",
      "9294 ('chocolate', 'NOUN')\n",
      "9295 ('ration', 'NOUN')\n",
      "9296 ('would', 'VERB')\n",
      "9297 ('be', 'VERB')\n",
      "9298 ('reduced', 'VERB')\n",
      "9299 ('from', 'ADP')\n",
      "9300 ('thirty', 'NUM')\n",
      "9301 ('grammes', 'NOUN')\n",
      "9302 ('to', 'ADP')\n",
      "9303 ('twenty', 'NUM')\n",
      "9304 ('.', '')\n",
      "9305 ('Winston', 'NOUN')\n",
      "9306 ('belched', 'VERB')\n",
      "9307 ('again', 'ADV')\n",
      "9308 ('.', '')\n",
      "9309 ('The', 'DET')\n",
      "9310 ('gin', 'NOUN')\n",
      "9311 ('was', 'VERB')\n",
      "9312 ('wearing', 'VERB')\n",
      "9313 ('off', 'ADV')\n",
      "9314 (',', '')\n",
      "9315 ('leaving', 'VERB')\n",
      "9316 ('a', 'DET')\n",
      "9317 ('deflated', 'ADJ')\n",
      "9318 ('feeling', 'NOUN')\n",
      "9319 ('.', '')\n",
      "9320 ('The', 'DET')\n",
      "9321 ('telescreen', 'NOUN')\n",
      "9322 ('-', '')\n",
      "9323 ('perhaps', 'ADV')\n",
      "9324 ('to', 'ADP')\n",
      "9325 ('celebrate', 'VERB')\n",
      "9326 ('the', 'DET')\n",
      "9327 ('victory', 'NOUN')\n",
      "9328 (',', '')\n",
      "9329 ('perhaps', 'ADV')\n",
      "9330 ('to', 'ADP')\n",
      "9331 ('drown', 'VERB')\n",
      "9332 ('the', 'DET')\n",
      "9333 ('memory', 'NOUN')\n",
      "9334 ('of', 'ADP')\n",
      "9335 ('the', 'DET')\n",
      "9336 ('lost', 'ADJ')\n",
      "9337 ('chocolate', 'NOUN')\n",
      "9338 ('-', '')\n",
      "9339 ('crashed', 'VERB')\n",
      "9340 ('into', 'ADP')\n",
      "9341 ('Oceania', 'NOUN')\n",
      "9342 (',', '')\n",
      "9343 (\"'t\", 'PRON')\n",
      "9344 ('is', 'VERB')\n",
      "9345 ('for', 'ADP')\n",
      "9346 ('thee', 'ADJ')\n",
      "9347 ('.', '')\n",
      "9348 ('You', 'PRON')\n",
      "9349 ('were', 'VERB')\n",
      "9350 ('supposed', 'ADJ')\n",
      "9351 ('to', 'ADP')\n",
      "9352 ('stand', 'VERB')\n",
      "9353 ('to', 'ADP')\n",
      "9354 ('attention', 'NOUN')\n",
      "9355 ('.', '')\n",
      "9356 ('However', 'CONJ')\n",
      "9357 (',', '')\n",
      "9358 ('in', 'ADP')\n",
      "9359 ('his', 'DET')\n",
      "9360 ('present', 'ADJ')\n",
      "9361 ('position', 'NOUN')\n",
      "9362 ('he', 'PRON')\n",
      "9363 ('was', 'VERB')\n",
      "9364 ('invisible', 'ADJ')\n",
      "9365 ('.', '')\n",
      "9366 ('Oceania', 'NOUN')\n",
      "9367 (',', '')\n",
      "9368 (\"'t\", 'PRON')\n",
      "9369 ('is', 'VERB')\n",
      "9370 ('for', 'ADP')\n",
      "9371 ('thee', 'ADJ')\n",
      "9372 ('gave', 'VERB')\n",
      "9373 ('way', 'NOUN')\n",
      "9374 ('to', 'ADP')\n",
      "9375 ('lighter', 'ADJ')\n",
      "9376 ('music', 'NOUN')\n",
      "9377 ('.', '')\n",
      "9378 ('Winston', 'NOUN')\n",
      "9379 ('walked', 'VERB')\n",
      "9380 ('over', 'ADV')\n",
      "9381 ('to', 'ADP')\n",
      "9382 ('the', 'DET')\n",
      "9383 ('window', 'NOUN')\n",
      "9384 (',', '')\n",
      "9385 ('keeping', 'VERB')\n",
      "9386 ('his', 'DET')\n",
      "9387 ('back', 'NOUN')\n",
      "9388 ('to', 'ADP')\n",
      "9389 ('the', 'DET')\n",
      "9390 ('telescreen', 'NOUN')\n",
      "9391 ('.', '')\n",
      "9392 ('The', 'DET')\n",
      "9393 ('day', 'NOUN')\n",
      "9394 ('was', 'VERB')\n",
      "9395 ('still', 'ADV')\n",
      "9396 ('cold', 'ADJ')\n",
      "9397 ('and', 'CONJ')\n",
      "9398 ('clear', 'ADJ')\n",
      "9399 ('.', '')\n",
      "9400 ('Somewhere', 'ADV')\n",
      "9401 ('far', 'ADV')\n",
      "9402 ('away', 'ADV')\n",
      "9403 ('a', 'DET')\n",
      "9404 ('rocket', 'NOUN')\n",
      "9405 ('bomb', 'NOUN')\n",
      "9406 ('exploded', 'VERB')\n",
      "9407 ('with', 'ADP')\n",
      "9408 ('a', 'DET')\n",
      "9409 ('dull', 'ADJ')\n",
      "9410 (',', '')\n",
      "9411 ('reverberating', 'VERB')\n",
      "9412 ('roar', 'NOUN')\n",
      "9413 ('.', '')\n",
      "9414 ('About', 'ADV')\n",
      "9415 ('twenty', 'NUM')\n",
      "9416 ('or', 'CONJ')\n",
      "9417 ('thirty', 'NUM')\n",
      "9418 ('of', 'ADP')\n",
      "9419 ('them', 'PRON')\n",
      "9420 ('a', 'DET')\n",
      "9421 ('week', 'NOUN')\n",
      "9422 ('were', 'VERB')\n",
      "9423 ('falling', 'VERB')\n",
      "9424 ('on', 'ADP')\n",
      "9425 ('London', 'NOUN')\n",
      "9426 ('at', 'ADP')\n",
      "9427 ('present', 'NOUN')\n",
      "9428 ('.', '')\n",
      "9429 ('Down', 'ADV')\n",
      "9430 ('in', 'ADP')\n",
      "9431 ('the', 'DET')\n",
      "9432 ('street', 'NOUN')\n",
      "9433 ('the', 'DET')\n",
      "9434 ('wind', 'NOUN')\n",
      "9435 ('flapped', 'VERB')\n",
      "9436 ('the', 'DET')\n",
      "9437 ('torn', 'ADJ')\n",
      "9438 ('poster', 'NOUN')\n",
      "9439 ('to', 'ADP')\n",
      "9440 ('and', 'CONJ')\n",
      "9441 ('fro', 'ADV')\n",
      "9442 (',', '')\n",
      "9443 ('and', 'CONJ')\n",
      "9444 ('the', 'DET')\n",
      "9445 ('word', 'NOUN')\n",
      "9446 ('Ingsoc', 'NOUN')\n",
      "9447 ('fitfully', 'ADV')\n",
      "9448 ('appeared', 'VERB')\n",
      "9449 ('and', 'CONJ')\n",
      "9450 ('vanished', 'VERB')\n",
      "9451 ('.', '')\n",
      "9452 ('Ingsoc', 'NOUN')\n",
      "9453 ('.', '')\n",
      "9454 ('The', 'DET')\n",
      "9455 ('sacred', 'ADJ')\n",
      "9456 ('principles', 'NOUN')\n",
      "9457 ('of', 'ADP')\n",
      "9458 ('Ingsoc', 'NOUN')\n",
      "9459 ('.', '')\n",
      "9460 ('Newspeak', 'NOUN')\n",
      "9461 (',', '')\n",
      "9462 ('doublethink', 'NOUN')\n",
      "9463 (',', '')\n",
      "9464 ('the', 'DET')\n",
      "9465 ('mutability', 'NOUN')\n",
      "9466 ('of', 'ADP')\n",
      "9467 ('the', 'DET')\n",
      "9468 ('past', 'NOUN')\n",
      "9469 ('.', '')\n",
      "9470 ('He', 'PRON')\n",
      "9471 ('felt', 'VERB')\n",
      "9472 ('as', 'CONJ')\n",
      "9473 ('though', 'CONJ')\n",
      "9474 ('he', 'PRON')\n",
      "9475 ('were', 'VERB')\n",
      "9476 ('wandering', 'VERB')\n",
      "9477 ('in', 'ADP')\n",
      "9478 ('the', 'DET')\n",
      "9479 ('forests', 'NOUN')\n",
      "9480 ('of', 'ADP')\n",
      "9481 ('the', 'DET')\n",
      "9482 ('sea', 'NOUN')\n",
      "9483 ('bottom', 'NOUN')\n",
      "9484 (',', '')\n",
      "9485 ('lost', 'VERB')\n",
      "9486 ('in', 'ADP')\n",
      "9487 ('a', 'DET')\n",
      "9488 ('monstrous', 'ADJ')\n",
      "9489 ('world', 'NOUN')\n",
      "9490 ('where', 'CONJ')\n",
      "9491 ('he', 'PRON')\n",
      "9492 ('himself', 'PRON')\n",
      "9493 ('was', 'VERB')\n",
      "9494 ('the', 'DET')\n",
      "9495 ('monster', 'NOUN')\n",
      "9496 ('.', '')\n",
      "9497 ('He', 'PRON')\n",
      "9498 ('was', 'VERB')\n",
      "9499 ('alone', 'ADJ')\n",
      "9500 ('.', '')\n",
      "9501 ('The', 'DET')\n",
      "9502 ('past', 'NOUN')\n",
      "9503 ('was', 'VERB')\n",
      "9504 ('dead', 'ADJ')\n",
      "9505 (',', '')\n",
      "9506 ('the', 'DET')\n",
      "9507 ('future', 'NOUN')\n",
      "9508 ('was', 'VERB')\n",
      "9509 ('unimaginable', 'ADJ')\n",
      "9510 ('.', '')\n",
      "9511 ('What', 'DET')\n",
      "9512 ('certainty', 'NOUN')\n",
      "9513 ('had', 'VERB')\n",
      "9514 ('he', 'PRON')\n",
      "9515 ('that', 'CONJ')\n",
      "9516 ('a', 'DET')\n",
      "9517 ('single', 'ADJ')\n",
      "9518 ('human', 'ADJ')\n",
      "9519 ('creature', 'NOUN')\n",
      "9520 ('now', 'ADV')\n",
      "9521 ('living', 'VERB')\n",
      "9522 ('was', 'VERB')\n",
      "9523 ('on', 'ADP')\n",
      "9524 ('his', 'DET')\n",
      "9525 ('side', 'NOUN')\n",
      "9526 ('?', '')\n",
      "9527 ('And', 'CONJ')\n",
      "9528 ('what', 'DET')\n",
      "9529 ('way', 'NOUN')\n",
      "9530 ('of', 'ADP')\n",
      "9531 ('knowing', 'VERB')\n",
      "9532 ('that', 'CONJ')\n",
      "9533 ('the', 'DET')\n",
      "9534 ('dominion', 'NOUN')\n",
      "9535 ('of', 'ADP')\n",
      "9536 ('the', 'DET')\n",
      "9537 ('Party', 'NOUN')\n",
      "9538 ('would', 'VERB')\n",
      "9539 ('not', 'ADV')\n",
      "9540 ('endure', 'VERB')\n",
      "9541 ('for', 'ADP')\n",
      "9542 ('ever', 'ADV')\n",
      "9543 ('?', '')\n",
      "9544 ('Like', 'ADP')\n",
      "9545 ('an', 'DET')\n",
      "9546 ('answer', 'NOUN')\n",
      "9547 (',', '')\n",
      "9548 ('the', 'DET')\n",
      "9549 ('three', 'NUM')\n",
      "9550 ('slogans', 'NOUN')\n",
      "9551 ('on', 'ADP')\n",
      "9552 ('the', 'DET')\n",
      "9553 ('white', 'ADJ')\n",
      "9554 ('face', 'NOUN')\n",
      "9555 ('of', 'ADP')\n",
      "9556 ('the', 'DET')\n",
      "9557 ('Ministry', 'NOUN')\n",
      "9558 ('of', 'ADP')\n",
      "9559 ('Truth', 'NOUN')\n",
      "9560 ('came', 'VERB')\n",
      "9561 ('back', 'ADV')\n",
      "9562 ('to', 'ADP')\n",
      "9563 ('him', 'PRON')\n",
      "9564 (':', '')\n",
      "9565 ('War', 'NOUN')\n",
      "9566 ('is', 'VERB')\n",
      "9567 ('peace', 'NOUN')\n",
      "9568 ('Freedom', 'NOUN')\n",
      "9569 ('is', 'VERB')\n",
      "9570 ('slavery', 'NOUN')\n",
      "9571 ('Ignorance', 'NOUN')\n",
      "9572 ('is', 'VERB')\n",
      "9573 ('strength', 'NOUN')\n",
      "9574 ('He', 'PRON')\n",
      "9575 ('took', 'VERB')\n",
      "9576 ('a', 'DET')\n",
      "9577 ('twenty-five', 'NUM')\n",
      "9578 ('cent', 'NOUN')\n",
      "9579 ('piece', 'NOUN')\n",
      "9580 ('out', 'ADP')\n",
      "9581 ('of', 'ADP')\n",
      "9582 ('his', 'DET')\n",
      "9583 ('pocket', 'NOUN')\n",
      "9584 ('.', '')\n",
      "9585 ('There', 'ADV')\n",
      "9586 (',', '')\n",
      "9587 ('too', 'ADV')\n",
      "9588 (',', '')\n",
      "9589 ('in', 'ADP')\n",
      "9590 ('tiny', 'ADJ')\n",
      "9591 ('clear', 'ADJ')\n",
      "9592 ('lettering', 'NOUN')\n",
      "9593 (',', '')\n",
      "9594 ('the', 'DET')\n",
      "9595 ('same', 'ADJ')\n",
      "9596 ('slogans', 'NOUN')\n",
      "9597 ('were', 'VERB')\n",
      "9598 ('inscribed', 'VERB')\n",
      "9599 (',', '')\n",
      "9600 ('and', 'CONJ')\n",
      "9601 ('on', 'ADP')\n",
      "9602 ('the', 'DET')\n",
      "9603 ('other', 'DET')\n",
      "9604 ('face', 'NOUN')\n",
      "9605 ('of', 'ADP')\n",
      "9606 ('the', 'DET')\n",
      "9607 ('coin', 'NOUN')\n",
      "9608 ('the', 'DET')\n",
      "9609 ('head', 'NOUN')\n",
      "9610 ('of', 'ADP')\n",
      "9611 ('Big', 'ADJ')\n",
      "9612 ('Brother', 'NOUN')\n",
      "9613 ('.', '')\n",
      "9614 ('Even', 'ADV')\n",
      "9615 ('from', 'ADP')\n",
      "9616 ('the', 'DET')\n",
      "9617 ('coin', 'NOUN')\n",
      "9618 ('the', 'DET')\n",
      "9619 ('eyes', 'NOUN')\n",
      "9620 ('pursued', 'VERB')\n",
      "9621 ('you', 'PRON')\n",
      "9622 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9623 ('On', 'ADP')\n",
      "9624 ('coins', 'NOUN')\n",
      "9625 (',', '')\n",
      "9626 ('on', 'ADP')\n",
      "9627 ('stamps', 'NOUN')\n",
      "9628 (',', '')\n",
      "9629 ('on', 'ADP')\n",
      "9630 ('the', 'DET')\n",
      "9631 ('covers', 'NOUN')\n",
      "9632 ('of', 'ADP')\n",
      "9633 ('books', 'NOUN')\n",
      "9634 (',', '')\n",
      "9635 ('on', 'ADP')\n",
      "9636 ('banners', 'NOUN')\n",
      "9637 (',', '')\n",
      "9638 ('on', 'ADP')\n",
      "9639 ('posters', 'NOUN')\n",
      "9640 (',', '')\n",
      "9641 ('and', 'CONJ')\n",
      "9642 ('on', 'ADP')\n",
      "9643 ('the', 'DET')\n",
      "9644 ('wrappings', 'NOUN')\n",
      "9645 ('of', 'ADP')\n",
      "9646 ('a', 'DET')\n",
      "9647 ('cigarette', 'NOUN')\n",
      "9648 ('Packet', 'NOUN')\n",
      "9649 ('-', '')\n",
      "9650 ('everywhere', 'ADV')\n",
      "9651 ('.', '')\n",
      "9652 ('Always', 'ADV')\n",
      "9653 ('the', 'DET')\n",
      "9654 ('eyes', 'NOUN')\n",
      "9655 ('watching', 'VERB')\n",
      "9656 ('you', 'PRON')\n",
      "9657 ('and', 'CONJ')\n",
      "9658 ('the', 'DET')\n",
      "9659 ('voice', 'NOUN')\n",
      "9660 ('enveloping', 'VERB')\n",
      "9661 ('you', 'PRON')\n",
      "9662 ('.', '')\n",
      "9663 ('Asleep', 'ADJ')\n",
      "9664 ('or', 'CONJ')\n",
      "9665 ('awake', 'ADJ')\n",
      "9666 (',', '')\n",
      "9667 ('working', 'VERB')\n",
      "9668 ('or', 'CONJ')\n",
      "9669 ('eating', 'VERB')\n",
      "9670 (',', '')\n",
      "9671 ('indoors', 'ADV')\n",
      "9672 ('or', 'CONJ')\n",
      "9673 ('out', 'ADP')\n",
      "9674 ('of', 'ADP')\n",
      "9675 ('doors', 'NOUN')\n",
      "9676 (',', '')\n",
      "9677 ('in', 'ADP')\n",
      "9678 ('the', 'DET')\n",
      "9679 ('bath', 'NOUN')\n",
      "9680 ('or', 'CONJ')\n",
      "9681 ('in', 'ADP')\n",
      "9682 ('bed', 'NOUN')\n",
      "9683 ('-', '')\n",
      "9684 ('no', 'DET')\n",
      "9685 ('escape', 'NOUN')\n",
      "9686 ('.', '')\n",
      "9687 ('Nothing', 'PRON')\n",
      "9688 ('was', 'VERB')\n",
      "9689 ('your', 'DET')\n",
      "9690 ('own', 'PRON')\n",
      "9691 ('except', 'ADP')\n",
      "9692 ('the', 'DET')\n",
      "9693 ('few', 'DET')\n",
      "9694 ('cubic', 'ADJ')\n",
      "9695 ('centimetres', 'NOUN')\n",
      "9696 ('inside', 'ADP')\n",
      "9697 ('your', 'DET')\n",
      "9698 ('skull', 'NOUN')\n",
      "9699 ('.', '')\n",
      "9700 ('The', 'DET')\n",
      "9701 ('sun', 'NOUN')\n",
      "9702 ('had', 'VERB')\n",
      "9703 ('shifted', 'VERB')\n",
      "9704 ('round', 'ADV')\n",
      "9705 (',', '')\n",
      "9706 ('and', 'CONJ')\n",
      "9707 ('the', 'DET')\n",
      "9708 ('myriad', 'ADJ')\n",
      "9709 ('windows', 'NOUN')\n",
      "9710 ('of', 'ADP')\n",
      "9711 ('the', 'DET')\n",
      "9712 ('Ministry', 'NOUN')\n",
      "9713 ('of', 'ADP')\n",
      "9714 ('Truth', 'NOUN')\n",
      "9715 (',', '')\n",
      "9716 ('with', 'ADP')\n",
      "9717 ('the', 'DET')\n",
      "9718 ('light', 'NOUN')\n",
      "9719 ('no', 'ADV')\n",
      "9720 ('longer', 'ADV')\n",
      "9721 ('shining', 'VERB')\n",
      "9722 ('on', 'ADP')\n",
      "9723 ('them', 'PRON')\n",
      "9724 (',', '')\n",
      "9725 ('looked', 'VERB')\n",
      "9726 ('grim', 'ADJ')\n",
      "9727 ('as', 'ADP')\n",
      "9728 ('the', 'DET')\n",
      "9729 ('loopholes', 'NOUN')\n",
      "9730 ('of', 'ADP')\n",
      "9731 ('a', 'DET')\n",
      "9732 ('fortress', 'NOUN')\n",
      "9733 ('.', '')\n",
      "9734 ('His', 'DET')\n",
      "9735 ('heart', 'NOUN')\n",
      "9736 ('quailed', 'VERB')\n",
      "9737 ('before', 'ADP')\n",
      "9738 ('the', 'DET')\n",
      "9739 ('enormous', 'ADJ')\n",
      "9740 ('pyramidal', 'ADJ')\n",
      "9741 ('shape', 'NOUN')\n",
      "9742 ('.', '')\n",
      "9743 ('It', 'PRON')\n",
      "9744 ('was', 'VERB')\n",
      "9745 ('too', 'ADV')\n",
      "9746 ('strong', 'ADJ')\n",
      "9747 (',', '')\n",
      "9748 ('it', 'PRON')\n",
      "9749 ('could', 'VERB')\n",
      "9750 ('not', 'ADV')\n",
      "9751 ('be', 'VERB')\n",
      "9752 ('stormed', 'VERB')\n",
      "9753 ('.', '')\n",
      "9754 ('A', 'DET')\n",
      "9755 ('thousand', 'NUM')\n",
      "9756 ('rocket', 'NOUN')\n",
      "9757 ('bombs', 'NOUN')\n",
      "9758 ('would', 'VERB')\n",
      "9759 ('not', 'ADV')\n",
      "9760 ('batter', 'VERB')\n",
      "9761 ('it', 'PRON')\n",
      "9762 ('down', 'ADV')\n",
      "9763 ('.', '')\n",
      "9764 ('He', 'PRON')\n",
      "9765 ('wondered', 'VERB')\n",
      "9766 ('again', 'ADV')\n",
      "9767 ('for', 'ADP')\n",
      "9768 ('whom', 'PRON')\n",
      "9769 ('he', 'PRON')\n",
      "9770 ('was', 'VERB')\n",
      "9771 ('writing', 'VERB')\n",
      "9772 ('the', 'DET')\n",
      "9773 ('diary', 'NOUN')\n",
      "9774 ('.', '')\n",
      "9775 ('For', 'ADP')\n",
      "9776 ('the', 'DET')\n",
      "9777 ('future', 'NOUN')\n",
      "9778 (',', '')\n",
      "9779 ('for', 'ADP')\n",
      "9780 ('the', 'DET')\n",
      "9781 ('past', 'NOUN')\n",
      "9782 ('-', '')\n",
      "9783 ('for', 'ADP')\n",
      "9784 ('an', 'DET')\n",
      "9785 ('age', 'NOUN')\n",
      "9786 ('that', 'PRON')\n",
      "9787 ('might', 'VERB')\n",
      "9788 ('be', 'VERB')\n",
      "9789 ('imaginary', 'ADJ')\n",
      "9790 ('.', '')\n",
      "9791 ('And', 'CONJ')\n",
      "9792 ('in', 'ADP')\n",
      "9793 ('front', 'NOUN')\n",
      "9794 ('of', 'ADP')\n",
      "9795 ('him', 'PRON')\n",
      "9796 ('there', 'PRON')\n",
      "9797 ('lay', 'VERB')\n",
      "9798 ('not', 'ADV')\n",
      "9799 ('death', 'NOUN')\n",
      "9800 ('but', 'CONJ')\n",
      "9801 ('annihilation', 'NOUN')\n",
      "9802 ('.', '')\n",
      "9803 ('The', 'DET')\n",
      "9804 ('diary', 'NOUN')\n",
      "9805 ('would', 'VERB')\n",
      "9806 ('be', 'VERB')\n",
      "9807 ('reduced', 'VERB')\n",
      "9808 ('to', 'ADP')\n",
      "9809 ('ashes', 'NOUN')\n",
      "9810 ('and', 'CONJ')\n",
      "9811 ('himself', 'PRON')\n",
      "9812 ('to', 'ADP')\n",
      "9813 ('vapour', 'NOUN')\n",
      "9814 ('.', '')\n",
      "9815 ('Only', 'ADV')\n",
      "9816 ('the', 'DET')\n",
      "9817 ('Thought', 'NOUN')\n",
      "9818 ('Police', 'NOUN')\n",
      "9819 ('would', 'VERB')\n",
      "9820 ('read', 'VERB')\n",
      "9821 ('what', 'PRON')\n",
      "9822 ('he', 'PRON')\n",
      "9823 ('had', 'VERB')\n",
      "9824 ('written', 'VERB')\n",
      "9825 (',', '')\n",
      "9826 ('before', 'CONJ')\n",
      "9827 ('they', 'PRON')\n",
      "9828 ('wiped', 'VERB')\n",
      "9829 ('it', 'PRON')\n",
      "9830 ('out', 'ADP')\n",
      "9831 ('of', 'ADP')\n",
      "9832 ('existence', 'NOUN')\n",
      "9833 ('and', 'CONJ')\n",
      "9834 ('out', 'ADP')\n",
      "9835 ('of', 'ADP')\n",
      "9836 ('memory', 'NOUN')\n",
      "9837 ('.', '')\n",
      "9838 ('How', 'ADV')\n",
      "9839 ('could', 'VERB')\n",
      "9840 ('you', 'PRON')\n",
      "9841 ('make', 'VERB')\n",
      "9842 ('appeal', 'NOUN')\n",
      "9843 ('to', 'ADP')\n",
      "9844 ('the', 'DET')\n",
      "9845 ('future', 'NOUN')\n",
      "9846 ('when', 'CONJ')\n",
      "9847 ('not', 'ADV')\n",
      "9848 ('a', 'DET')\n",
      "9849 ('trace', 'NOUN')\n",
      "9850 ('of', 'ADP')\n",
      "9851 ('you', 'PRON')\n",
      "9852 (',', '')\n",
      "9853 ('not', 'ADV')\n",
      "9854 ('even', 'ADV')\n",
      "9855 ('an', 'DET')\n",
      "9856 ('anonymous', 'ADJ')\n",
      "9857 ('word', 'NOUN')\n",
      "9858 ('scribbled', 'VERB')\n",
      "9859 ('on', 'ADP')\n",
      "9860 ('a', 'DET')\n",
      "9861 ('piece', 'NOUN')\n",
      "9862 ('of', 'ADP')\n",
      "9863 ('paper', 'NOUN')\n",
      "9864 (',', '')\n",
      "9865 ('could', 'VERB')\n",
      "9866 ('physically', 'ADV')\n",
      "9867 ('survive', 'VERB')\n",
      "9868 ('?', '')\n",
      "9869 ('The', 'DET')\n",
      "9870 ('telescreen', 'NOUN')\n",
      "9871 ('struck', 'VERB')\n",
      "9872 ('fourteen', 'NUM')\n",
      "9873 ('.', '')\n",
      "9874 ('He', 'PRON')\n",
      "9875 ('must', 'VERB')\n",
      "9876 ('leave', 'VERB')\n",
      "9877 ('in', 'ADP')\n",
      "9878 ('ten', 'NUM')\n",
      "9879 ('minutes', 'NOUN')\n",
      "9880 ('.', '')\n",
      "9881 ('He', 'PRON')\n",
      "9882 ('had', 'VERB')\n",
      "9883 ('to', 'ADP')\n",
      "9884 ('be', 'VERB')\n",
      "9885 ('back', 'ADV')\n",
      "9886 ('at', 'ADP')\n",
      "9887 ('work', 'NOUN')\n",
      "9888 ('by', 'ADP')\n",
      "9889 ('fourteen-thirty', 'NOUN')\n",
      "9890 ('.', '')\n",
      "9891 ('Curiously', 'ADV')\n",
      "9892 (',', '')\n",
      "9893 ('the', 'DET')\n",
      "9894 ('chiming', 'VERB')\n",
      "9895 ('of', 'ADP')\n",
      "9896 ('the', 'DET')\n",
      "9897 ('hour', 'NOUN')\n",
      "9898 ('seemed', 'VERB')\n",
      "9899 ('to', 'ADP')\n",
      "9900 ('have', 'VERB')\n",
      "9901 ('put', 'VERB')\n",
      "9902 ('new', 'ADJ')\n",
      "9903 ('heart', 'NOUN')\n",
      "9904 ('into', 'ADP')\n",
      "9905 ('him', 'PRON')\n",
      "9906 ('.', '')\n",
      "9907 ('He', 'PRON')\n",
      "9908 ('was', 'VERB')\n",
      "9909 ('a', 'DET')\n",
      "9910 ('lonely', 'ADJ')\n",
      "9911 ('ghost', 'NOUN')\n",
      "9912 ('uttering', 'VERB')\n",
      "9913 ('a', 'DET')\n",
      "9914 ('truth', 'NOUN')\n",
      "9915 ('that', 'PRON')\n",
      "9916 ('nobody', 'PRON')\n",
      "9917 ('would', 'VERB')\n",
      "9918 ('ever', 'ADV')\n",
      "9919 ('hear', 'VERB')\n",
      "9920 ('.', '')\n",
      "9921 ('But', 'CONJ')\n",
      "9922 ('so', 'ADV')\n",
      "9923 ('long', 'ADV')\n",
      "9924 ('as', 'CONJ')\n",
      "9925 ('he', 'PRON')\n",
      "9926 ('uttered', 'VERB')\n",
      "9927 ('it', 'PRON')\n",
      "9928 (',', '')\n",
      "9929 ('in', 'ADP')\n",
      "9930 ('some', 'DET')\n",
      "9931 ('obscure', 'ADJ')\n",
      "9932 ('way', 'NOUN')\n",
      "9933 ('the', 'DET')\n",
      "9934 ('continuity', 'NOUN')\n",
      "9935 ('was', 'VERB')\n",
      "9936 ('not', 'ADV')\n",
      "9937 ('broken', 'VERB')\n",
      "9938 ('.', '')\n",
      "9939 ('It', 'PRON')\n",
      "9940 ('was', 'VERB')\n",
      "9941 ('not', 'ADV')\n",
      "9942 ('by', 'ADP')\n",
      "9943 ('making', 'VERB')\n",
      "9944 ('yourself', 'PRON')\n",
      "9945 ('heard', 'VERB')\n",
      "9946 ('but', 'CONJ')\n",
      "9947 ('by', 'ADP')\n",
      "9948 ('staying', 'VERB')\n",
      "9949 ('sane', 'ADJ')\n",
      "9950 ('that', 'CONJ')\n",
      "9951 ('you', 'PRON')\n",
      "9952 ('carried', 'VERB')\n",
      "9953 ('on', 'ADP')\n",
      "9954 ('the', 'DET')\n",
      "9955 ('human', 'ADJ')\n",
      "9956 ('heritage', 'NOUN')\n",
      "9957 ('.', '')\n",
      "9958 ('He', 'PRON')\n",
      "9959 ('went', 'VERB')\n",
      "9960 ('back', 'ADV')\n",
      "9961 ('to', 'ADP')\n",
      "9962 ('the', 'DET')\n",
      "9963 ('table', 'NOUN')\n",
      "9964 (',', '')\n",
      "9965 ('dipped', 'VERB')\n",
      "9966 ('his', 'DET')\n",
      "9967 ('pen', 'NOUN')\n",
      "9968 (',', '')\n",
      "9969 ('and', 'CONJ')\n",
      "9970 ('wrote', 'VERB')\n",
      "9971 (':', '')\n",
      "9972 ('To', 'ADP')\n",
      "9973 ('the', 'DET')\n",
      "9974 ('future', 'NOUN')\n",
      "9975 ('or', 'CONJ')\n",
      "9976 ('to', 'ADP')\n",
      "9977 ('the', 'DET')\n",
      "9978 ('past', 'NOUN')\n",
      "9979 (',', '')\n",
      "9980 ('to', 'ADP')\n",
      "9981 ('a', 'DET')\n",
      "9982 ('time', 'NOUN')\n",
      "9983 ('when', 'CONJ')\n",
      "9984 ('thought', 'NOUN')\n",
      "9985 ('is', 'VERB')\n",
      "9986 ('free', 'ADJ')\n",
      "9987 (',', '')\n",
      "9988 ('when', 'CONJ')\n",
      "9989 ('men', 'NOUN')\n",
      "9990 ('are', 'VERB')\n",
      "9991 ('different', 'ADJ')\n",
      "9992 ('from', 'ADP')\n",
      "9993 ('one', 'PRON')\n",
      "9994 ('another', 'PRON')\n",
      "9995 ('and', 'CONJ')\n",
      "9996 ('do', 'VERB')\n",
      "9997 ('not', 'ADV')\n",
      "9998 ('live', 'VERB')\n",
      "9999 ('alone', 'ADJ')\n",
      "10000 ('-', '')\n",
      "10001 ('to', 'ADP')\n",
      "10002 ('a', 'DET')\n",
      "10003 ('time', 'NOUN')\n",
      "10004 ('when', 'CONJ')\n",
      "10005 ('truth', 'NOUN')\n",
      "10006 ('exists', 'VERB')\n",
      "10007 ('and', 'CONJ')\n",
      "10008 ('what', 'PRON')\n",
      "10009 ('is', 'VERB')\n",
      "10010 ('done', 'VERB')\n",
      "10011 ('cannot', 'VERB')\n",
      "10012 ('be', 'VERB')\n",
      "10013 ('undone', 'VERB')\n",
      "10014 (':', '')\n",
      "10015 ('From', 'ADP')\n",
      "10016 ('the', 'DET')\n",
      "10017 ('age', 'NOUN')\n",
      "10018 ('of', 'ADP')\n",
      "10019 ('uniformity', 'NOUN')\n",
      "10020 (',', '')\n",
      "10021 ('from', 'ADP')\n",
      "10022 ('the', 'DET')\n",
      "10023 ('age', 'NOUN')\n",
      "10024 ('of', 'ADP')\n",
      "10025 ('solitude', 'NOUN')\n",
      "10026 (',', '')\n",
      "10027 ('from', 'ADP')\n",
      "10028 ('the', 'DET')\n",
      "10029 ('age', 'NOUN')\n",
      "10030 ('of', 'ADP')\n",
      "10031 ('Big', 'ADJ')\n",
      "10032 ('Brother', 'NOUN')\n",
      "10033 (',', '')\n",
      "10034 ('from', 'ADP')\n",
      "10035 ('the', 'DET')\n",
      "10036 ('age', 'NOUN')\n",
      "10037 ('of', 'ADP')\n",
      "10038 ('doublethink', 'NOUN')\n",
      "10039 ('-', '')\n",
      "10040 ('greetings', 'NOUN')\n",
      "10041 ('!', '')\n",
      "10042 ('He', 'PRON')\n",
      "10043 ('was', 'VERB')\n",
      "10044 ('already', 'ADV')\n",
      "10045 ('dead', 'ADJ')\n",
      "10046 (',', '')\n",
      "10047 ('he', 'PRON')\n",
      "10048 ('reflected', 'VERB')\n",
      "10049 ('.', '')\n",
      "10050 ('It', 'PRON')\n",
      "10051 ('seemed', 'VERB')\n",
      "10052 ('to', 'ADP')\n",
      "10053 ('him', 'PRON')\n",
      "10054 ('that', 'CONJ')\n",
      "10055 ('it', 'PRON')\n",
      "10056 ('was', 'VERB')\n",
      "10057 ('only', 'ADV')\n",
      "10058 ('now', 'ADV')\n",
      "10059 (',', '')\n",
      "10060 ('when', 'CONJ')\n",
      "10061 ('he', 'PRON')\n",
      "10062 ('had', 'VERB')\n",
      "10063 ('begun', 'VERB')\n",
      "10064 ('to', 'ADP')\n",
      "10065 ('be', 'VERB')\n",
      "10066 ('able', 'ADJ')\n",
      "10067 ('to', 'ADP')\n",
      "10068 ('formulate', 'VERB')\n",
      "10069 ('his', 'DET')\n",
      "10070 ('thoughts', 'NOUN')\n",
      "10071 (',', '')\n",
      "10072 ('that', 'CONJ')\n",
      "10073 ('he', 'PRON')\n",
      "10074 ('had', 'VERB')\n",
      "10075 ('taken', 'VERB')\n",
      "10076 ('the', 'DET')\n",
      "10077 ('decisive', 'ADJ')\n",
      "10078 ('step', 'NOUN')\n",
      "10079 ('.', '')\n",
      "10080 ('The', 'DET')\n",
      "10081 ('consequences', 'NOUN')\n",
      "10082 ('of', 'ADP')\n",
      "10083 ('every', 'DET')\n",
      "10084 ('act', 'NOUN')\n",
      "10085 ('are', 'VERB')\n",
      "10086 ('included', 'VERB')\n",
      "10087 ('in', 'ADP')\n",
      "10088 ('the', 'DET')\n",
      "10089 ('act', 'NOUN')\n",
      "10090 ('itself', 'PRON')\n",
      "10091 ('.', '')\n",
      "10092 ('He', 'PRON')\n",
      "10093 ('wrote', 'VERB')\n",
      "10094 (':', '')\n",
      "10095 ('Thoughtcrime', 'NOUN')\n",
      "10096 ('does', 'VERB')\n",
      "10097 ('not', 'ADV')\n",
      "10098 ('entail', 'VERB')\n",
      "10099 ('death', 'NOUN')\n",
      "10100 (':', '')\n",
      "10101 ('thoughtcrime', 'NOUN')\n",
      "10102 ('is', 'VERB')\n",
      "10103 ('death', 'NOUN')\n",
      "10104 ('.', '')\n",
      "10105 ('Now', 'CONJ')\n",
      "10106 ('he', 'PRON')\n",
      "10107 ('had', 'VERB')\n",
      "10108 ('recognized', 'VERB')\n",
      "10109 ('himself', 'PRON')\n",
      "10110 ('as', 'ADP')\n",
      "10111 ('a', 'DET')\n",
      "10112 ('dead', 'ADJ')\n",
      "10113 ('man', 'NOUN')\n",
      "10114 ('it', 'PRON')\n",
      "10115 ('became', 'VERB')\n",
      "10116 ('important', 'ADJ')\n",
      "10117 ('to', 'ADP')\n",
      "10118 ('stay', 'VERB')\n",
      "10119 ('alive', 'ADJ')\n",
      "10120 ('as', 'ADV')\n",
      "10121 ('long', 'ADV')\n",
      "10122 ('as', 'CONJ')\n",
      "10123 ('possible', 'ADJ')\n",
      "10124 ('.', '')\n",
      "10125 ('Two', 'NUM')\n",
      "10126 ('fingers', 'NOUN')\n",
      "10127 ('of', 'ADP')\n",
      "10128 ('his', 'DET')\n",
      "10129 ('right', 'ADJ')\n",
      "10130 ('hand', 'NOUN')\n",
      "10131 ('were', 'VERB')\n",
      "10132 ('inkstained', 'ADJ')\n",
      "10133 ('.', '')\n",
      "10134 ('It', 'PRON')\n",
      "10135 ('was', 'VERB')\n",
      "10136 ('exactly', 'ADV')\n",
      "10137 ('the', 'DET')\n",
      "10138 ('kind', 'NOUN')\n",
      "10139 ('of', 'ADP')\n",
      "10140 ('detail', 'NOUN')\n",
      "10141 ('that', 'PRON')\n",
      "10142 ('might', 'VERB')\n",
      "10143 ('betray', 'VERB')\n",
      "10144 ('you', 'PRON')\n",
      "10145 ('.', '')\n",
      "10146 ('Some', 'DET')\n",
      "10147 ('nosing', 'VERB')\n",
      "10148 ('zealot', 'NOUN')\n",
      "10149 ('in', 'ADP')\n",
      "10150 ('the', 'DET')\n",
      "10151 ('Ministry', 'NOUN')\n",
      "10152 ('(', '')\n",
      "10153 ('a', 'DET')\n",
      "10154 ('woman', 'NOUN')\n",
      "10155 (',', '')\n",
      "10156 ('probably', 'ADV')\n",
      "10157 (':', '')\n",
      "10158 ('someone', 'PRON')\n",
      "10159 ('like', 'ADP')\n",
      "10160 ('the', 'DET')\n",
      "10161 ('little', 'ADJ')\n",
      "10162 ('sandy-haired', 'ADJ')\n",
      "10163 ('woman', 'NOUN')\n",
      "10164 ('or', 'CONJ')\n",
      "10165 ('the', 'DET')\n",
      "10166 ('dark-haired', 'ADJ')\n",
      "10167 ('girl', 'NOUN')\n",
      "10168 ('from', 'ADP')\n",
      "10169 ('the', 'DET')\n",
      "10170 ('Fiction', 'NOUN')\n",
      "10171 ('Department', 'NOUN')\n",
      "10172 (')', '')\n",
      "10173 ('might', 'VERB')\n",
      "10174 ('start', 'VERB')\n",
      "10175 ('wondering', 'VERB')\n",
      "10176 ('why', 'ADV')\n",
      "10177 ('he', 'PRON')\n",
      "10178 ('had', 'VERB')\n",
      "10179 ('been', 'VERB')\n",
      "10180 ('writing', 'VERB')\n",
      "10181 ('during', 'ADP')\n",
      "10182 ('the', 'DET')\n",
      "10183 ('lunch', 'NOUN')\n",
      "10184 ('interval', 'NOUN')\n",
      "10185 (',', '')\n",
      "10186 ('why', 'ADV')\n",
      "10187 ('he', 'PRON')\n",
      "10188 ('had', 'VERB')\n",
      "10189 ('used', 'VERB')\n",
      "10190 ('an', 'DET')\n",
      "10191 ('oldfashioned', 'ADJ')\n",
      "10192 ('pen', 'NOUN')\n",
      "10193 (',', '')\n",
      "10194 ('what', 'PRON')\n",
      "10195 ('he', 'PRON')\n",
      "10196 ('had', 'VERB')\n",
      "10197 ('been', 'VERB')\n",
      "10198 ('writing', 'VERB')\n",
      "10199 ('-', '')\n",
      "10200 ('and', 'CONJ')\n",
      "10201 ('then', 'ADV')\n",
      "10202 ('drop', 'VERB')\n",
      "10203 ('a', 'DET')\n",
      "10204 ('hint', 'NOUN')\n",
      "10205 ('in', 'ADP')\n",
      "10206 ('the', 'DET')\n",
      "10207 ('appropriate', 'ADJ')\n",
      "10208 ('quarter', 'NOUN')\n",
      "10209 ('.', '')\n",
      "10210 ('He', 'PRON')\n",
      "10211 ('went', 'VERB')\n",
      "10212 ('to', 'ADP')\n",
      "10213 ('the', 'DET')\n",
      "10214 ('bathroom', 'NOUN')\n",
      "10215 ('and', 'CONJ')\n",
      "10216 ('carefully', 'ADV')\n",
      "10217 ('scrubbed', 'VERB')\n",
      "10218 ('the', 'DET')\n",
      "10219 ('ink', 'NOUN')\n",
      "10220 ('away', 'ADV')\n",
      "10221 ('with', 'ADP')\n",
      "10222 ('the', 'DET')\n",
      "10223 ('gritty', 'ADJ')\n",
      "10224 ('dark-brown', 'ADJ')\n",
      "10225 ('soap', 'NOUN')\n",
      "10226 ('which', 'PRON')\n",
      "10227 ('rasped', 'VERB')\n",
      "10228 ('your', 'DET')\n",
      "10229 ('skin', 'NOUN')\n",
      "10230 ('like', 'ADP')\n",
      "10231 ('sandpaper', 'NOUN')\n",
      "10232 ('and', 'CONJ')\n",
      "10233 ('was', 'VERB')\n",
      "10234 ('therefore', 'ADV')\n",
      "10235 ('well', 'ADV')\n",
      "10236 ('adapted', 'VERB')\n",
      "10237 ('for', 'ADP')\n",
      "10238 ('this', 'DET')\n",
      "10239 ('purpose', 'NOUN')\n",
      "10240 ('.', '')\n",
      "10241 ('He', 'PRON')\n",
      "10242 ('put', 'VERB')\n",
      "10243 ('the', 'DET')\n",
      "10244 ('diary', 'NOUN')\n",
      "10245 ('away', 'ADV')\n",
      "10246 ('in', 'ADP')\n",
      "10247 ('the', 'DET')\n",
      "10248 ('drawer', 'NOUN')\n",
      "10249 ('.', '')\n",
      "10250 ('It', 'PRON')\n",
      "10251 ('was', 'VERB')\n",
      "10252 ('quite', 'ADV')\n",
      "10253 ('useless', 'ADJ')\n",
      "10254 ('to', 'ADP')\n",
      "10255 ('think', 'VERB')\n",
      "10256 ('of', 'ADP')\n",
      "10257 ('hiding', 'VERB')\n",
      "10258 ('it', 'PRON')\n",
      "10259 (',', '')\n",
      "10260 ('but', 'CONJ')\n",
      "10261 ('he', 'PRON')\n",
      "10262 ('could', 'VERB')\n",
      "10263 ('at', 'ADP')\n",
      "10264 ('least', 'ADJ')\n",
      "10265 ('make', 'VERB')\n",
      "10266 ('sure', 'ADJ')\n",
      "10267 ('whether', 'CONJ')\n",
      "10268 ('or', 'CONJ')\n",
      "10269 ('not', 'ADV')\n",
      "10270 ('its', 'DET')\n",
      "10271 ('existence', 'NOUN')\n",
      "10272 ('had', 'VERB')\n",
      "10273 ('been', 'VERB')\n",
      "10274 ('discovered', 'VERB')\n",
      "10275 ('.', '')\n",
      "10276 ('A', 'DET')\n",
      "10277 ('hair', 'NOUN')\n",
      "10278 ('laid', 'VERB')\n",
      "10279 ('across', 'ADP')\n",
      "10280 ('the', 'DET')\n",
      "10281 ('page-ends', 'NOUN')\n",
      "10282 ('was', 'VERB')\n",
      "10283 ('too', 'ADV')\n",
      "10284 ('obvious', 'ADJ')\n",
      "10285 ('.', '')\n",
      "10286 ('With', 'ADP')\n",
      "10287 ('the', 'DET')\n",
      "10288 ('tip', 'NOUN')\n",
      "10289 ('of', 'ADP')\n",
      "10290 ('his', 'DET')\n",
      "10291 ('finger', 'NOUN')\n",
      "10292 ('he', 'PRON')\n",
      "10293 ('picked', 'VERB')\n",
      "10294 ('up', 'ADP')\n",
      "10295 ('an', 'DET')\n",
      "10296 ('identifiable', 'ADJ')\n",
      "10297 ('grain', 'NOUN')\n",
      "10298 ('of', 'ADP')\n",
      "10299 ('whitish', 'ADJ')\n",
      "10300 ('dust', 'NOUN')\n",
      "10301 ('and', 'CONJ')\n",
      "10302 ('deposited', 'VERB')\n",
      "10303 ('it', 'PRON')\n",
      "10304 ('on', 'ADP')\n",
      "10305 ('the', 'DET')\n",
      "10306 ('corner', 'NOUN')\n",
      "10307 ('of', 'ADP')\n",
      "10308 ('the', 'DET')\n",
      "10309 ('cover', 'NOUN')\n",
      "10310 (',', '')\n",
      "10311 ('where', 'CONJ')\n",
      "10312 ('it', 'PRON')\n",
      "10313 ('was', 'VERB')\n",
      "10314 ('bound', 'VERB')\n",
      "10315 ('to', 'ADP')\n",
      "10316 ('be', 'VERB')\n",
      "10317 ('shaken', 'VERB')\n",
      "10318 ('off', 'ADV')\n",
      "10319 ('if', 'CONJ')\n",
      "10320 ('the', 'DET')\n",
      "10321 ('book', 'NOUN')\n",
      "10322 ('was', 'VERB')\n",
      "10323 ('moved', 'VERB')\n",
      "10324 ('.', '')\n",
      "10325 ('Winston', 'NOUN')\n",
      "10326 ('was', 'VERB')\n",
      "10327 ('dreaming', 'VERB')\n",
      "10328 ('of', 'ADP')\n",
      "10329 ('his', 'DET')\n",
      "10330 ('mother', 'NOUN')\n",
      "10331 ('.', '')\n",
      "10332 ('He', 'PRON')\n",
      "10333 ('must', 'VERB')\n",
      "10334 (',', '')\n",
      "10335 ('he', 'PRON')\n",
      "10336 ('thought', 'VERB')\n",
      "10337 (',', '')\n",
      "10338 ('have', 'VERB')\n",
      "10339 ('been', 'VERB')\n",
      "10340 ('ten', 'NUM')\n",
      "10341 ('or', 'CONJ')\n",
      "10342 ('eleven', 'NUM')\n",
      "10343 ('years', 'NOUN')\n",
      "10344 ('old', 'ADJ')\n",
      "10345 ('when', 'CONJ')\n",
      "10346 ('his', 'DET')\n",
      "10347 ('mother', 'NOUN')\n",
      "10348 ('had', 'VERB')\n",
      "10349 ('disappeared', 'VERB')\n",
      "10350 ('.', '')\n",
      "10351 ('She', 'PRON')\n",
      "10352 ('was', 'VERB')\n",
      "10353 ('a', 'DET')\n",
      "10354 ('tall', 'ADJ')\n",
      "10355 (',', '')\n",
      "10356 ('statuesque', 'ADJ')\n",
      "10357 (',', '')\n",
      "10358 ('rather', 'ADV')\n",
      "10359 ('silent', 'ADJ')\n",
      "10360 ('woman', 'NOUN')\n",
      "10361 ('with', 'ADP')\n",
      "10362 ('slow', 'ADJ')\n",
      "10363 ('movements', 'NOUN')\n",
      "10364 ('and', 'CONJ')\n",
      "10365 ('magnificent', 'ADJ')\n",
      "10366 ('fair', 'ADJ')\n",
      "10367 ('hair', 'NOUN')\n",
      "10368 ('.', '')\n",
      "10369 ('His', 'DET')\n",
      "10370 ('father', 'NOUN')\n",
      "10371 ('he', 'PRON')\n",
      "10372 ('remembered', 'VERB')\n",
      "10373 ('more', 'ADV')\n",
      "10374 ('vaguely', 'ADV')\n",
      "10375 ('as', 'ADP')\n",
      "10376 ('dark', 'ADJ')\n",
      "10377 ('and', 'CONJ')\n",
      "10378 ('thin', 'ADJ')\n",
      "10379 (',', '')\n",
      "10380 ('dressed', 'VERB')\n",
      "10381 ('always', 'ADV')\n",
      "10382 ('in', 'ADP')\n",
      "10383 ('neat', 'ADJ')\n",
      "10384 ('dark', 'ADJ')\n",
      "10385 ('clothes', 'NOUN')\n",
      "10386 ('(', '')\n",
      "10387 ('Winston', 'NOUN')\n",
      "10388 ('remembered', 'VERB')\n",
      "10389 ('especially', 'ADV')\n",
      "10390 ('the', 'DET')\n",
      "10391 ('very', 'ADV')\n",
      "10392 ('thin', 'ADJ')\n",
      "10393 ('soles', 'NOUN')\n",
      "10394 ('of', 'ADP')\n",
      "10395 ('his', 'DET')\n",
      "10396 ('father', 'NOUN')\n",
      "10397 (\"'s\", 'ADP')\n",
      "10398 ('shoes', 'NOUN')\n",
      "10399 (')', '')\n",
      "10400 ('and', 'CONJ')\n",
      "10401 ('wearing', 'VERB')\n",
      "10402 ('spectacles', 'NOUN')\n",
      "10403 ('.', '')\n",
      "10404 ('The', 'DET')\n",
      "10405 ('two', 'NUM')\n",
      "10406 ('of', 'ADP')\n",
      "10407 ('them', 'PRON')\n",
      "10408 ('must', 'VERB')\n",
      "10409 ('evidently', 'ADV')\n",
      "10410 ('have', 'VERB')\n",
      "10411 ('been', 'VERB')\n",
      "10412 ('swallowed', 'VERB')\n",
      "10413 ('up', 'ADP')\n",
      "10414 ('in', 'ADP')\n",
      "10415 ('one', 'PRON')\n",
      "10416 ('of', 'ADP')\n",
      "10417 ('the', 'DET')\n",
      "10418 ('first', 'ADJ')\n",
      "10419 ('great', 'ADJ')\n",
      "10420 ('purges', 'NOUN')\n",
      "10421 ('of', 'ADP')\n",
      "10422 ('the', 'DET')\n",
      "10423 ('fifties', 'NOUN')\n",
      "10424 ('.', '')\n",
      "10425 ('At', 'ADP')\n",
      "10426 ('this', 'DET')\n",
      "10427 ('moment', 'NOUN')\n",
      "10428 ('his', 'DET')\n",
      "10429 ('mother', 'NOUN')\n",
      "10430 ('was', 'VERB')\n",
      "10431 ('sitting', 'VERB')\n",
      "10432 ('in', 'ADP')\n",
      "10433 ('some', 'DET')\n",
      "10434 ('place', 'NOUN')\n",
      "10435 ('deep', 'ADV')\n",
      "10436 ('down', 'ADV')\n",
      "10437 ('beneath', 'ADP')\n",
      "10438 ('him', 'PRON')\n",
      "10439 (',', '')\n",
      "10440 ('with', 'ADP')\n",
      "10441 ('his', 'DET')\n",
      "10442 ('young', 'ADJ')\n",
      "10443 ('sister', 'NOUN')\n",
      "10444 ('in', 'ADP')\n",
      "10445 ('her', 'DET')\n",
      "10446 ('arms', 'NOUN')\n",
      "10447 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10448 ('He', 'PRON')\n",
      "10449 ('did', 'VERB')\n",
      "10450 ('not', 'ADV')\n",
      "10451 ('remember', 'VERB')\n",
      "10452 ('his', 'DET')\n",
      "10453 ('sister', 'NOUN')\n",
      "10454 ('at', 'ADP')\n",
      "10455 ('all', 'ADV')\n",
      "10456 (',', '')\n",
      "10457 ('except', 'CONJ')\n",
      "10458 ('as', 'ADP')\n",
      "10459 ('a', 'DET')\n",
      "10460 ('tiny', 'ADJ')\n",
      "10461 (',', '')\n",
      "10462 ('feeble', 'ADJ')\n",
      "10463 ('baby', 'NOUN')\n",
      "10464 (',', '')\n",
      "10465 ('always', 'ADV')\n",
      "10466 ('silent', 'ADJ')\n",
      "10467 (',', '')\n",
      "10468 ('with', 'ADP')\n",
      "10469 ('large', 'ADJ')\n",
      "10470 (',', '')\n",
      "10471 ('watchful', 'ADJ')\n",
      "10472 ('eyes', 'NOUN')\n",
      "10473 ('.', '')\n",
      "10474 ('Both', 'PRON')\n",
      "10475 ('of', 'ADP')\n",
      "10476 ('them', 'PRON')\n",
      "10477 ('were', 'VERB')\n",
      "10478 ('looking', 'VERB')\n",
      "10479 ('up', 'ADP')\n",
      "10480 ('at', 'ADP')\n",
      "10481 ('him', 'PRON')\n",
      "10482 ('.', '')\n",
      "10483 ('They', 'PRON')\n",
      "10484 ('were', 'VERB')\n",
      "10485 ('down', 'ADV')\n",
      "10486 ('in', 'ADP')\n",
      "10487 ('some', 'DET')\n",
      "10488 ('subterranean', 'ADJ')\n",
      "10489 ('place', 'NOUN')\n",
      "10490 ('-', '')\n",
      "10491 ('the', 'DET')\n",
      "10492 ('bottom', 'NOUN')\n",
      "10493 ('of', 'ADP')\n",
      "10494 ('a', 'DET')\n",
      "10495 ('well', 'NOUN')\n",
      "10496 (',', '')\n",
      "10497 ('for', 'ADP')\n",
      "10498 ('instance', 'NOUN')\n",
      "10499 (',', '')\n",
      "10500 ('or', 'CONJ')\n",
      "10501 ('a', 'DET')\n",
      "10502 ('very', 'ADV')\n",
      "10503 ('deep', 'ADJ')\n",
      "10504 ('grave', 'NOUN')\n",
      "10505 ('-', '')\n",
      "10506 ('but', 'CONJ')\n",
      "10507 ('it', 'PRON')\n",
      "10508 ('was', 'VERB')\n",
      "10509 ('a', 'DET')\n",
      "10510 ('place', 'NOUN')\n",
      "10511 ('which', 'PRON')\n",
      "10512 (',', '')\n",
      "10513 ('already', 'ADV')\n",
      "10514 ('far', 'ADV')\n",
      "10515 ('below', 'ADP')\n",
      "10516 ('him', 'PRON')\n",
      "10517 (',', '')\n",
      "10518 ('was', 'VERB')\n",
      "10519 ('itself', 'PRON')\n",
      "10520 ('moving', 'VERB')\n",
      "10521 ('downwards', 'ADV')\n",
      "10522 ('.', '')\n",
      "10523 ('They', 'PRON')\n",
      "10524 ('were', 'VERB')\n",
      "10525 ('in', 'ADP')\n",
      "10526 ('the', 'DET')\n",
      "10527 ('saloon', 'NOUN')\n",
      "10528 ('of', 'ADP')\n",
      "10529 ('a', 'DET')\n",
      "10530 ('sinking', 'VERB')\n",
      "10531 ('ship', 'NOUN')\n",
      "10532 (',', '')\n",
      "10533 ('looking', 'VERB')\n",
      "10534 ('up', 'ADP')\n",
      "10535 ('at', 'ADP')\n",
      "10536 ('him', 'PRON')\n",
      "10537 ('through', 'ADP')\n",
      "10538 ('the', 'DET')\n",
      "10539 ('darkening', 'VERB')\n",
      "10540 ('water', 'NOUN')\n",
      "10541 ('.', '')\n",
      "10542 ('There', 'PRON')\n",
      "10543 ('was', 'VERB')\n",
      "10544 ('still', 'ADV')\n",
      "10545 ('air', 'NOUN')\n",
      "10546 ('in', 'ADP')\n",
      "10547 ('the', 'DET')\n",
      "10548 ('saloon', 'NOUN')\n",
      "10549 (',', '')\n",
      "10550 ('they', 'PRON')\n",
      "10551 ('could', 'VERB')\n",
      "10552 ('still', 'ADV')\n",
      "10553 ('see', 'VERB')\n",
      "10554 ('him', 'PRON')\n",
      "10555 ('and', 'CONJ')\n",
      "10556 ('he', 'PRON')\n",
      "10557 ('them', 'PRON')\n",
      "10558 (',', '')\n",
      "10559 ('but', 'CONJ')\n",
      "10560 ('all', 'DET')\n",
      "10561 ('the', 'DET')\n",
      "10562 ('while', 'CONJ')\n",
      "10563 ('they', 'PRON')\n",
      "10564 ('were', 'VERB')\n",
      "10565 ('sinking', 'VERB')\n",
      "10566 ('down', 'ADV')\n",
      "10567 (',', '')\n",
      "10568 ('down', 'ADV')\n",
      "10569 ('into', 'ADP')\n",
      "10570 ('the', 'DET')\n",
      "10571 ('green', 'ADJ')\n",
      "10572 ('waters', 'NOUN')\n",
      "10573 ('which', 'PRON')\n",
      "10574 ('in', 'ADP')\n",
      "10575 ('another', 'DET')\n",
      "10576 ('moment', 'NOUN')\n",
      "10577 ('must', 'VERB')\n",
      "10578 ('hide', 'VERB')\n",
      "10579 ('them', 'PRON')\n",
      "10580 ('from', 'ADP')\n",
      "10581 ('sight', 'NOUN')\n",
      "10582 ('for', 'ADP')\n",
      "10583 ('ever', 'ADV')\n",
      "10584 ('.', '')\n",
      "10585 ('He', 'PRON')\n",
      "10586 ('was', 'VERB')\n",
      "10587 ('out', 'ADP')\n",
      "10588 ('in', 'ADP')\n",
      "10589 ('the', 'DET')\n",
      "10590 ('light', 'NOUN')\n",
      "10591 ('and', 'CONJ')\n",
      "10592 ('air', 'NOUN')\n",
      "10593 ('while', 'CONJ')\n",
      "10594 ('they', 'PRON')\n",
      "10595 ('were', 'VERB')\n",
      "10596 ('being', 'VERB')\n",
      "10597 ('sucked', 'VERB')\n",
      "10598 ('down', 'ADV')\n",
      "10599 ('to', 'ADP')\n",
      "10600 ('death', 'NOUN')\n",
      "10601 (',', '')\n",
      "10602 ('and', 'CONJ')\n",
      "10603 ('they', 'PRON')\n",
      "10604 ('were', 'VERB')\n",
      "10605 ('down', 'ADV')\n",
      "10606 ('there', 'ADV')\n",
      "10607 ('because', 'CONJ')\n",
      "10608 ('he', 'PRON')\n",
      "10609 ('was', 'VERB')\n",
      "10610 ('up', 'ADP')\n",
      "10611 ('here', 'ADV')\n",
      "10612 ('.', '')\n",
      "10613 ('He', 'PRON')\n",
      "10614 ('knew', 'VERB')\n",
      "10615 ('it', 'PRON')\n",
      "10616 ('and', 'CONJ')\n",
      "10617 ('they', 'PRON')\n",
      "10618 ('knew', 'VERB')\n",
      "10619 ('it', 'PRON')\n",
      "10620 (',', '')\n",
      "10621 ('and', 'CONJ')\n",
      "10622 ('he', 'PRON')\n",
      "10623 ('could', 'VERB')\n",
      "10624 ('see', 'VERB')\n",
      "10625 ('the', 'DET')\n",
      "10626 ('knowledge', 'NOUN')\n",
      "10627 ('in', 'ADP')\n",
      "10628 ('their', 'DET')\n",
      "10629 ('faces', 'NOUN')\n",
      "10630 ('.', '')\n",
      "10631 ('There', 'PRON')\n",
      "10632 ('was', 'VERB')\n",
      "10633 ('no', 'DET')\n",
      "10634 ('reproach', 'NOUN')\n",
      "10635 ('either', 'CONJ')\n",
      "10636 ('in', 'ADP')\n",
      "10637 ('their', 'DET')\n",
      "10638 ('faces', 'NOUN')\n",
      "10639 ('or', 'CONJ')\n",
      "10640 ('in', 'ADP')\n",
      "10641 ('their', 'DET')\n",
      "10642 ('hearts', 'NOUN')\n",
      "10643 (',', '')\n",
      "10644 ('only', 'ADV')\n",
      "10645 ('the', 'DET')\n",
      "10646 ('knowledge', 'NOUN')\n",
      "10647 ('that', 'CONJ')\n",
      "10648 ('they', 'PRON')\n",
      "10649 ('must', 'VERB')\n",
      "10650 ('die', 'VERB')\n",
      "10651 ('in', 'ADP')\n",
      "10652 ('order', 'NOUN')\n",
      "10653 ('that', 'CONJ')\n",
      "10654 ('he', 'PRON')\n",
      "10655 ('might', 'VERB')\n",
      "10656 ('remain', 'VERB')\n",
      "10657 ('alive', 'ADJ')\n",
      "10658 (',', '')\n",
      "10659 ('and', 'CONJ')\n",
      "10660 ('that', 'CONJ')\n",
      "10661 ('this', 'PRON')\n",
      "10662 ('was', 'VERB')\n",
      "10663 ('part', 'NOUN')\n",
      "10664 ('of', 'ADP')\n",
      "10665 ('the', 'DET')\n",
      "10666 ('unavoidable', 'ADJ')\n",
      "10667 ('order', 'NOUN')\n",
      "10668 ('of', 'ADP')\n",
      "10669 ('things', 'NOUN')\n",
      "10670 ('.', '')\n",
      "10671 ('He', 'PRON')\n",
      "10672 ('could', 'VERB')\n",
      "10673 ('not', 'ADV')\n",
      "10674 ('remember', 'VERB')\n",
      "10675 ('what', 'PRON')\n",
      "10676 ('had', 'VERB')\n",
      "10677 ('happened', 'VERB')\n",
      "10678 (',', '')\n",
      "10679 ('but', 'CONJ')\n",
      "10680 ('he', 'PRON')\n",
      "10681 ('knew', 'VERB')\n",
      "10682 ('in', 'ADP')\n",
      "10683 ('his', 'DET')\n",
      "10684 ('dream', 'NOUN')\n",
      "10685 ('that', 'CONJ')\n",
      "10686 ('in', 'ADP')\n",
      "10687 ('some', 'DET')\n",
      "10688 ('way', 'NOUN')\n",
      "10689 ('the', 'DET')\n",
      "10690 ('lives', 'NOUN')\n",
      "10691 ('of', 'ADP')\n",
      "10692 ('his', 'DET')\n",
      "10693 ('mother', 'NOUN')\n",
      "10694 ('and', 'CONJ')\n",
      "10695 ('his', 'DET')\n",
      "10696 ('sister', 'NOUN')\n",
      "10697 ('had', 'VERB')\n",
      "10698 ('been', 'VERB')\n",
      "10699 ('sacrificed', 'VERB')\n",
      "10700 ('to', 'ADP')\n",
      "10701 ('his', 'DET')\n",
      "10702 ('own', 'PRON')\n",
      "10703 ('.', '')\n",
      "10704 ('It', 'PRON')\n",
      "10705 ('was', 'VERB')\n",
      "10706 ('one', 'PRON')\n",
      "10707 ('of', 'ADP')\n",
      "10708 ('those', 'DET')\n",
      "10709 ('dreams', 'NOUN')\n",
      "10710 ('which', 'PRON')\n",
      "10711 (',', '')\n",
      "10712 ('while', 'CONJ')\n",
      "10713 ('retaining', 'VERB')\n",
      "10714 ('the', 'DET')\n",
      "10715 ('characteristic', 'ADJ')\n",
      "10716 ('dream', 'NOUN')\n",
      "10717 ('scenery', 'NOUN')\n",
      "10718 (',', '')\n",
      "10719 ('are', 'VERB')\n",
      "10720 ('a', 'DET')\n",
      "10721 ('continuation', 'NOUN')\n",
      "10722 ('of', 'ADP')\n",
      "10723 ('one', 'PRON')\n",
      "10724 (\"'s\", 'ADP')\n",
      "10725 ('intellectual', 'ADJ')\n",
      "10726 ('life', 'NOUN')\n",
      "10727 (',', '')\n",
      "10728 ('and', 'CONJ')\n",
      "10729 ('in', 'ADP')\n",
      "10730 ('which', 'PRON')\n",
      "10731 ('one', 'PRON')\n",
      "10732 ('becomes', 'VERB')\n",
      "10733 ('aware', 'ADJ')\n",
      "10734 ('of', 'ADP')\n",
      "10735 ('facts', 'NOUN')\n",
      "10736 ('and', 'CONJ')\n",
      "10737 ('ideas', 'NOUN')\n",
      "10738 ('which', 'PRON')\n",
      "10739 ('still', 'ADV')\n",
      "10740 ('seem', 'VERB')\n",
      "10741 ('new', 'ADJ')\n",
      "10742 ('and', 'CONJ')\n",
      "10743 ('valuable', 'ADJ')\n",
      "10744 ('after', 'CONJ')\n",
      "10745 ('one', 'PRON')\n",
      "10746 ('is', 'VERB')\n",
      "10747 ('awake', 'ADJ')\n",
      "10748 ('.', '')\n",
      "10749 ('The', 'DET')\n",
      "10750 ('thing', 'NOUN')\n",
      "10751 ('that', 'PRON')\n",
      "10752 ('now', 'ADV')\n",
      "10753 ('suddenly', 'ADV')\n",
      "10754 ('struck', 'VERB')\n",
      "10755 ('Winston', 'NOUN')\n",
      "10756 ('was', 'VERB')\n",
      "10757 ('that', 'CONJ')\n",
      "10758 ('his', 'DET')\n",
      "10759 ('mother', 'NOUN')\n",
      "s',ADP\n",
      "10760 (\"'s\", 'ADP')\n",
      "10761 ('death', 'NOUN')\n",
      "10762 (',', '')\n",
      "10763 ('nearly', 'ADV')\n",
      "10764 ('thirty', 'NUM')\n",
      "10765 ('years', 'NOUN')\n",
      "10766 ('ago', 'ADP')\n",
      "10767 (',', '')\n",
      "10768 ('had', 'VERB')\n",
      "10769 ('been', 'VERB')\n",
      "10770 ('tragic', 'ADJ')\n",
      "10771 ('and', 'CONJ')\n",
      "10772 ('sorrowful', 'ADJ')\n",
      "10773 ('in', 'ADP')\n",
      "10774 ('a', 'DET')\n",
      "10775 ('way', 'NOUN')\n",
      "10776 ('that', 'PRON')\n",
      "10777 ('was', 'VERB')\n",
      "10778 ('no', 'ADV')\n",
      "10779 ('longer', 'ADV')\n",
      "10780 ('possible', 'ADJ')\n",
      "10781 ('.', '')\n",
      "10782 ('Tragedy', 'NOUN')\n",
      "10783 (',', '')\n",
      "10784 ('he', 'PRON')\n",
      "10785 ('perceived', 'VERB')\n",
      "10786 (',', '')\n",
      "10787 ('belonged', 'VERB')\n",
      "10788 ('to', 'ADP')\n",
      "10789 ('the', 'DET')\n",
      "10790 ('ancient', 'ADJ')\n",
      "10791 ('time', 'NOUN')\n",
      "10792 (',', '')\n",
      "10793 ('to', 'ADP')\n",
      "10794 ('a', 'DET')\n",
      "10795 ('time', 'NOUN')\n",
      "10796 ('when', 'CONJ')\n",
      "10797 ('there', 'PRON')\n",
      "10798 ('was', 'VERB')\n",
      "10799 ('still', 'ADV')\n",
      "10800 ('privacy', 'NOUN')\n",
      "10801 (',', '')\n",
      "10802 ('love', 'NOUN')\n",
      "10803 (',', '')\n",
      "10804 ('and', 'CONJ')\n",
      "10805 ('friendship', 'NOUN')\n",
      "10806 (',', '')\n",
      "10807 ('and', 'CONJ')\n",
      "10808 ('when', 'CONJ')\n",
      "10809 ('the', 'DET')\n",
      "10810 ('members', 'NOUN')\n",
      "10811 ('of', 'ADP')\n",
      "10812 ('a', 'DET')\n",
      "10813 ('family', 'NOUN')\n",
      "10814 ('stood', 'VERB')\n",
      "10815 ('by', 'ADP')\n",
      "10816 ('one', 'PRON')\n",
      "10817 ('another', 'PRON')\n",
      "10818 ('without', 'ADP')\n",
      "10819 ('needing', 'VERB')\n",
      "10820 ('to', 'ADP')\n",
      "10821 ('know', 'VERB')\n",
      "10822 ('the', 'DET')\n",
      "10823 ('reason', 'NOUN')\n",
      "10824 ('.', '')\n",
      "10825 ('His', 'DET')\n",
      "10826 ('mother', 'NOUN')\n",
      "10827 (\"'s\", 'ADP')\n",
      "10828 ('memory', 'NOUN')\n",
      "10829 ('tore', 'VERB')\n",
      "10830 ('at', 'ADP')\n",
      "10831 ('his', 'DET')\n",
      "10832 ('heart', 'NOUN')\n",
      "10833 ('because', 'CONJ')\n",
      "10834 ('she', 'PRON')\n",
      "10835 ('had', 'VERB')\n",
      "10836 ('died', 'VERB')\n",
      "10837 ('loving', 'VERB')\n",
      "10838 ('him', 'PRON')\n",
      "10839 (',', '')\n",
      "10840 ('when', 'CONJ')\n",
      "10841 ('he', 'PRON')\n",
      "10842 ('was', 'VERB')\n",
      "10843 ('too', 'ADV')\n",
      "10844 ('young', 'ADJ')\n",
      "10845 ('and', 'CONJ')\n",
      "10846 ('selfish', 'ADJ')\n",
      "10847 ('to', 'ADP')\n",
      "10848 ('love', 'VERB')\n",
      "10849 ('her', 'PRON')\n",
      "10850 ('in', 'ADP')\n",
      "10851 ('return', 'NOUN')\n",
      "10852 (',', '')\n",
      "10853 ('and', 'CONJ')\n",
      "10854 ('because', 'CONJ')\n",
      "10855 ('somehow', 'ADV')\n",
      "10856 (',', '')\n",
      "10857 ('he', 'PRON')\n",
      "10858 ('did', 'VERB')\n",
      "10859 ('not', 'ADV')\n",
      "10860 ('remember', 'VERB')\n",
      "10861 ('how', 'ADV')\n",
      "10862 (',', '')\n",
      "10863 ('she', 'PRON')\n",
      "10864 ('had', 'VERB')\n",
      "10865 ('sacrificed', 'VERB')\n",
      "10866 ('herself', 'PRON')\n",
      "10867 ('to', 'ADP')\n",
      "10868 ('a', 'DET')\n",
      "10869 ('conception', 'NOUN')\n",
      "10870 ('of', 'ADP')\n",
      "10871 ('loyalty', 'NOUN')\n",
      "10872 ('that', 'PRON')\n",
      "10873 ('was', 'VERB')\n",
      "10874 ('private', 'ADJ')\n",
      "10875 ('and', 'CONJ')\n",
      "10876 ('unalterable', 'ADJ')\n",
      "10877 ('.', '')\n",
      "10878 ('Such', 'DET')\n",
      "10879 ('things', 'NOUN')\n",
      "10880 (',', '')\n",
      "10881 ('he', 'PRON')\n",
      "10882 ('saw', 'VERB')\n",
      "10883 (',', '')\n",
      "10884 ('could', 'VERB')\n",
      "10885 ('not', 'ADV')\n",
      "10886 ('happen', 'VERB')\n",
      "10887 ('today', 'ADV')\n",
      "10888 ('.', '')\n",
      "10889 ('Today', 'ADV')\n",
      "10890 ('there', 'PRON')\n",
      "10891 ('were', 'VERB')\n",
      "10892 ('fear', 'NOUN')\n",
      "10893 (',', '')\n",
      "10894 ('hatred', 'NOUN')\n",
      "10895 (',', '')\n",
      "10896 ('and', 'CONJ')\n",
      "10897 ('pain', 'NOUN')\n",
      "10898 (',', '')\n",
      "10899 ('but', 'CONJ')\n",
      "10900 ('no', 'DET')\n",
      "10901 ('dignity', 'NOUN')\n",
      "10902 ('of', 'ADP')\n",
      "10903 ('emotion', 'NOUN')\n",
      "10904 (',', '')\n",
      "10905 ('no', 'DET')\n",
      "10906 ('deep', 'ADJ')\n",
      "10907 ('or', 'CONJ')\n",
      "10908 ('complex', 'ADJ')\n",
      "10909 ('sorrows', 'NOUN')\n",
      "10910 ('.', '')\n",
      "10911 ('All', 'DET')\n",
      "10912 ('this', 'PRON')\n",
      "10913 ('he', 'PRON')\n",
      "10914 ('seemed', 'VERB')\n",
      "10915 ('to', 'ADP')\n",
      "10916 ('see', 'VERB')\n",
      "10917 ('in', 'ADP')\n",
      "10918 ('the', 'DET')\n",
      "10919 ('large', 'ADJ')\n",
      "10920 ('eyes', 'NOUN')\n",
      "10921 ('of', 'ADP')\n",
      "10922 ('his', 'DET')\n",
      "10923 ('mother', 'NOUN')\n",
      "10924 ('and', 'CONJ')\n",
      "10925 ('his', 'DET')\n",
      "10926 ('sister', 'NOUN')\n",
      "10927 (',', '')\n",
      "10928 ('looking', 'VERB')\n",
      "10929 ('up', 'ADP')\n",
      "10930 ('at', 'ADP')\n",
      "10931 ('him', 'PRON')\n",
      "10932 ('through', 'ADP')\n",
      "10933 ('the', 'DET')\n",
      "10934 ('green', 'ADJ')\n",
      "10935 ('water', 'NOUN')\n",
      "10936 (',', '')\n",
      "10937 ('hundreds', 'NOUN')\n",
      "10938 ('of', 'ADP')\n",
      "10939 ('fathoms', 'NOUN')\n",
      "10940 ('down', 'ADV')\n",
      "10941 ('and', 'CONJ')\n",
      "10942 ('still', 'ADV')\n",
      "10943 ('sinking', 'VERB')\n",
      "10944 ('.', '')\n",
      "10945 ('Suddenly', 'ADV')\n",
      "10946 ('he', 'PRON')\n",
      "10947 ('was', 'VERB')\n",
      "10948 ('standing', 'VERB')\n",
      "10949 ('on', 'ADP')\n",
      "10950 ('short', 'ADJ')\n",
      "10951 ('springy', 'ADJ')\n",
      "10952 ('turf', 'NOUN')\n",
      "10953 (',', '')\n",
      "10954 ('on', 'ADP')\n",
      "10955 ('a', 'DET')\n",
      "10956 ('summer', 'NOUN')\n",
      "10957 ('evening', 'NOUN')\n",
      "10958 ('when', 'CONJ')\n",
      "10959 ('the', 'DET')\n",
      "10960 ('slanting', 'ADJ')\n",
      "10961 ('rays', 'NOUN')\n",
      "10962 ('of', 'ADP')\n",
      "10963 ('the', 'DET')\n",
      "10964 ('sun', 'NOUN')\n",
      "10965 ('gilded', 'VERB')\n",
      "10966 ('the', 'DET')\n",
      "10967 ('ground', 'NOUN')\n",
      "10968 ('.', '')\n",
      "10969 ('The', 'DET')\n",
      "10970 ('landscape', 'NOUN')\n",
      "10971 ('that', 'PRON')\n",
      "10972 ('he', 'PRON')\n",
      "10973 ('was', 'VERB')\n",
      "10974 ('looking', 'VERB')\n",
      "10975 ('at', 'ADP')\n",
      "10976 ('recurred', 'VERB')\n",
      "10977 ('so', 'ADV')\n",
      "10978 ('often', 'ADV')\n",
      "10979 ('in', 'ADP')\n",
      "10980 ('his', 'DET')\n",
      "10981 ('dreams', 'NOUN')\n",
      "10982 ('that', 'CONJ')\n",
      "10983 ('he', 'PRON')\n",
      "10984 ('was', 'VERB')\n",
      "10985 ('never', 'ADV')\n",
      "10986 ('fully', 'ADV')\n",
      "10987 ('certain', 'ADJ')\n",
      "10988 ('whether', 'CONJ')\n",
      "10989 ('or', 'CONJ')\n",
      "10990 ('not', 'ADV')\n",
      "10991 ('he', 'PRON')\n",
      "10992 ('had', 'VERB')\n",
      "10993 ('seen', 'VERB')\n",
      "10994 ('it', 'PRON')\n",
      "10995 ('in', 'ADP')\n",
      "10996 ('the', 'DET')\n",
      "10997 ('real', 'ADJ')\n",
      "10998 ('world', 'NOUN')\n",
      "10999 ('.', '')\n",
      "11000 ('In', 'ADP')\n",
      "11001 ('his', 'DET')\n",
      "11002 ('waking', 'ADJ')\n",
      "11003 ('thoughts', 'NOUN')\n",
      "11004 ('he', 'PRON')\n",
      "11005 ('called', 'VERB')\n",
      "11006 ('it', 'PRON')\n",
      "11007 ('the', 'DET')\n",
      "11008 ('Golden', 'ADJ')\n",
      "11009 ('Country', 'NOUN')\n",
      "11010 ('.', '')\n",
      "11011 ('It', 'PRON')\n",
      "11012 ('was', 'VERB')\n",
      "11013 ('an', 'DET')\n",
      "11014 ('old', 'ADJ')\n",
      "11015 (',', '')\n",
      "11016 ('rabbit-bitten', 'ADJ')\n",
      "11017 ('pasture', 'NOUN')\n",
      "11018 (',', '')\n",
      "11019 ('with', 'ADP')\n",
      "11020 ('a', 'DET')\n",
      "11021 ('foot-track', 'NOUN')\n",
      "11022 ('wandering', 'VERB')\n",
      "11023 ('across', 'ADP')\n",
      "11024 ('it', 'PRON')\n",
      "11025 ('and', 'CONJ')\n",
      "11026 ('a', 'DET')\n",
      "11027 ('molehill', 'NOUN')\n",
      "11028 ('here', 'ADV')\n",
      "11029 ('and', 'CONJ')\n",
      "11030 ('there', 'ADV')\n",
      "11031 ('.', '')\n",
      "11032 ('In', 'ADP')\n",
      "11033 ('the', 'DET')\n",
      "11034 ('ragged', 'ADJ')\n",
      "11035 ('hedge', 'NOUN')\n",
      "11036 ('on', 'ADP')\n",
      "11037 ('the', 'DET')\n",
      "11038 ('opposite', 'ADJ')\n",
      "11039 ('side', 'NOUN')\n",
      "11040 ('of', 'ADP')\n",
      "11041 ('the', 'DET')\n",
      "11042 ('field', 'NOUN')\n",
      "11043 ('the', 'DET')\n",
      "11044 ('boughs', 'NOUN')\n",
      "11045 ('of', 'ADP')\n",
      "11046 ('the', 'DET')\n",
      "11047 ('elm', 'NOUN')\n",
      "11048 ('trees', 'NOUN')\n",
      "11049 ('were', 'VERB')\n",
      "11050 ('swaying', 'VERB')\n",
      "11051 ('very', 'ADV')\n",
      "11052 ('faintly', 'ADV')\n",
      "11053 ('in', 'ADP')\n",
      "11054 ('the', 'DET')\n",
      "11055 ('breeze', 'NOUN')\n",
      "11056 (',', '')\n",
      "11057 ('their', 'DET')\n",
      "11058 ('leaves', 'NOUN')\n",
      "11059 ('just', 'ADV')\n",
      "11060 ('stirring', 'VERB')\n",
      "11061 ('in', 'ADP')\n",
      "11062 ('dense', 'ADJ')\n",
      "11063 ('masses', 'NOUN')\n",
      "11064 ('like', 'ADP')\n",
      "11065 ('women', 'NOUN')\n",
      "11066 (\"'s\", 'ADP')\n",
      "11067 ('hair', 'NOUN')\n",
      "11068 ('.', '')\n",
      "11069 ('Somewhere', 'ADV')\n",
      "11070 ('near', 'ADV')\n",
      "11071 ('at', 'ADP')\n",
      "11072 ('hand', 'NOUN')\n",
      "11073 (',', '')\n",
      "11074 ('though', 'CONJ')\n",
      "11075 ('out', 'ADP')\n",
      "11076 ('of', 'ADP')\n",
      "11077 ('sight', 'NOUN')\n",
      "11078 (',', '')\n",
      "11079 ('there', 'PRON')\n",
      "11080 ('was', 'VERB')\n",
      "11081 ('a', 'DET')\n",
      "11082 ('clear', 'ADJ')\n",
      "11083 (',', '')\n",
      "11084 ('slow-moving', 'ADJ')\n",
      "11085 ('stream', 'NOUN')\n",
      "11086 ('where', 'CONJ')\n",
      "11087 ('dace', 'NOUN')\n",
      "11088 ('were', 'VERB')\n",
      "11089 ('swimming', 'VERB')\n",
      "11090 ('in', 'ADP')\n",
      "11091 ('the', 'DET')\n",
      "11092 ('pools', 'NOUN')\n",
      "11093 ('under', 'ADP')\n",
      "11094 ('the', 'DET')\n",
      "11095 ('willow', 'NOUN')\n",
      "11096 ('trees', 'NOUN')\n",
      "11097 ('.', '')\n",
      "11098 ('The', 'DET')\n",
      "11099 ('girl', 'NOUN')\n",
      "11100 ('with', 'ADP')\n",
      "11101 ('dark', 'ADJ')\n",
      "11102 ('hair', 'NOUN')\n",
      "11103 ('was', 'VERB')\n",
      "11104 ('coming', 'VERB')\n",
      "11105 ('towards', 'ADP')\n",
      "11106 ('them', 'PRON')\n",
      "11107 ('across', 'ADP')\n",
      "11108 ('the', 'DET')\n",
      "11109 ('field', 'NOUN')\n",
      "11110 ('.', '')\n",
      "11111 ('With', 'ADP')\n",
      "11112 ('what', 'PRON')\n",
      "11113 ('seemed', 'VERB')\n",
      "11114 ('a', 'DET')\n",
      "11115 ('single', 'ADJ')\n",
      "11116 ('movement', 'NOUN')\n",
      "11117 ('she', 'PRON')\n",
      "11118 ('tore', 'VERB')\n",
      "11119 ('off', 'ADV')\n",
      "11120 ('her', 'DET')\n",
      "11121 ('clothes', 'NOUN')\n",
      "11122 ('and', 'CONJ')\n",
      "11123 ('flung', 'VERB')\n",
      "11124 ('them', 'PRON')\n",
      "11125 ('disdainfully', 'ADV')\n",
      "11126 ('aside', 'ADV')\n",
      "11127 ('.', '')\n",
      "11128 ('Her', 'DET')\n",
      "11129 ('body', 'NOUN')\n",
      "11130 ('was', 'VERB')\n",
      "11131 ('white', 'ADJ')\n",
      "11132 ('and', 'CONJ')\n",
      "11133 ('smooth', 'ADJ')\n",
      "11134 (',', '')\n",
      "11135 ('but', 'CONJ')\n",
      "11136 ('it', 'PRON')\n",
      "11137 ('aroused', 'VERB')\n",
      "11138 ('no', 'DET')\n",
      "11139 ('desire', 'NOUN')\n",
      "11140 ('in', 'ADP')\n",
      "11141 ('him', 'PRON')\n",
      "11142 (',', '')\n",
      "11143 ('indeed', 'ADV')\n",
      "11144 ('he', 'PRON')\n",
      "11145 ('barely', 'ADV')\n",
      "11146 ('looked', 'VERB')\n",
      "11147 ('at', 'ADP')\n",
      "11148 ('it', 'PRON')\n",
      "11149 ('.', '')\n",
      "11150 ('What', 'PRON')\n",
      "11151 ('overwhelmed', 'VERB')\n",
      "11152 ('him', 'PRON')\n",
      "11153 ('in', 'ADP')\n",
      "11154 ('that', 'DET')\n",
      "11155 ('instant', 'NOUN')\n",
      "11156 ('was', 'VERB')\n",
      "11157 ('admiration', 'NOUN')\n",
      "11158 ('for', 'ADP')\n",
      "11159 ('the', 'DET')\n",
      "11160 ('gesture', 'NOUN')\n",
      "11161 ('with', 'ADP')\n",
      "11162 ('which', 'PRON')\n",
      "11163 ('she', 'PRON')\n",
      "11164 ('had', 'VERB')\n",
      "11165 ('thrown', 'VERB')\n",
      "11166 ('her', 'DET')\n",
      "11167 ('clothes', 'NOUN')\n",
      "11168 ('aside', 'ADV')\n",
      "11169 ('.', '')\n",
      "11170 ('With', 'ADP')\n",
      "11171 ('its', 'DET')\n",
      "11172 ('grace', 'NOUN')\n",
      "11173 ('and', 'CONJ')\n",
      "11174 ('carelessness', 'NOUN')\n",
      "11175 ('it', 'PRON')\n",
      "11176 ('seemed', 'VERB')\n",
      "11177 ('to', 'ADP')\n",
      "11178 ('annihilate', 'VERB')\n",
      "11179 ('a', 'DET')\n",
      "11180 ('whole', 'ADJ')\n",
      "11181 ('culture', 'NOUN')\n",
      "11182 (',', '')\n",
      "11183 ('a', 'DET')\n",
      "11184 ('whole', 'ADJ')\n",
      "11185 ('system', 'NOUN')\n",
      "11186 ('of', 'ADP')\n",
      "11187 ('thought', 'NOUN')\n",
      "11188 (',', '')\n",
      "11189 ('as', 'CONJ')\n",
      "11190 ('though', 'CONJ')\n",
      "11191 ('Big', 'ADJ')\n",
      "11192 ('Brother', 'NOUN')\n",
      "11193 ('and', 'CONJ')\n",
      "11194 ('the', 'DET')\n",
      "11195 ('Party', 'NOUN')\n",
      "11196 ('and', 'CONJ')\n",
      "11197 ('the', 'DET')\n",
      "11198 ('Thought', 'NOUN')\n",
      "11199 ('Police', 'NOUN')\n",
      "11200 ('could', 'VERB')\n",
      "11201 ('all', 'PRON')\n",
      "11202 ('be', 'VERB')\n",
      "11203 ('swept', 'VERB')\n",
      "11204 ('into', 'ADP')\n",
      "11205 ('nothingness', 'NOUN')\n",
      "11206 ('by', 'ADP')\n",
      "11207 ('a', 'DET')\n",
      "11208 ('single', 'ADJ')\n",
      "11209 ('splendid', 'ADJ')\n",
      "11210 ('movement', 'NOUN')\n",
      "11211 ('of', 'ADP')\n",
      "11212 ('the', 'DET')\n",
      "11213 ('arm', 'NOUN')\n",
      "11214 ('.', '')\n",
      "11215 ('That', 'PRON')\n",
      "11216 ('too', 'ADV')\n",
      "11217 ('was', 'VERB')\n",
      "11218 ('a', 'DET')\n",
      "11219 ('gesture', 'NOUN')\n",
      "11220 ('belonging', 'VERB')\n",
      "11221 ('to', 'ADP')\n",
      "11222 ('the', 'DET')\n",
      "11223 ('ancient', 'ADJ')\n",
      "11224 ('time', 'NOUN')\n",
      "11225 ('.', '')\n",
      "11226 ('Winston', 'NOUN')\n",
      "11227 ('woke', 'VERB')\n",
      "11228 ('up', 'ADP')\n",
      "11229 ('with', 'ADP')\n",
      "11230 ('the', 'DET')\n",
      "11231 ('word', 'NOUN')\n",
      "11232 ('Shakespeare', 'NOUN')\n",
      "11233 ('on', 'ADP')\n",
      "11234 ('his', 'DET')\n",
      "11235 ('lips', 'NOUN')\n",
      "11236 ('.', '')\n",
      "11237 ('The', 'DET')\n",
      "11238 ('telescreen', 'NOUN')\n",
      "11239 ('was', 'VERB')\n",
      "11240 ('giving', 'VERB')\n",
      "11241 ('forth', 'ADV')\n",
      "11242 ('an', 'DET')\n",
      "11243 ('ear-splitting', 'NOUN')\n",
      "11244 ('whistle', 'NOUN')\n",
      "11245 ('which', 'PRON')\n",
      "11246 ('continued', 'VERB')\n",
      "11247 ('on', 'ADP')\n",
      "11248 ('the', 'DET')\n",
      "11249 ('same', 'ADJ')\n",
      "11250 ('note', 'NOUN')\n",
      "11251 ('for', 'ADP')\n",
      "11252 ('thirty', 'NUM')\n",
      "11253 ('seconds', 'NOUN')\n",
      "11254 ('.', '')\n",
      "11255 ('It', 'PRON')\n",
      "11256 ('was', 'VERB')\n",
      "11257 ('nought', 'NOUN')\n",
      "11258 ('seven', 'NUM')\n",
      "11259 ('fifteen', 'NUM')\n",
      "11260 (',', '')\n",
      "11261 ('getting-up', 'VERB')\n",
      "11262 ('time', 'NOUN')\n",
      "11263 ('for', 'ADP')\n",
      "11264 ('office', 'NOUN')\n",
      "11265 ('workers', 'NOUN')\n",
      "11266 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11267 ('Winston', 'NOUN')\n",
      "11268 ('wrenched', 'VERB')\n",
      "11269 ('his', 'DET')\n",
      "11270 ('body', 'NOUN')\n",
      "11271 ('out', 'ADP')\n",
      "11272 ('of', 'ADP')\n",
      "11273 ('bed', 'NOUN')\n",
      "11274 ('-', '')\n",
      "11275 ('naked', 'ADJ')\n",
      "11276 (',', '')\n",
      "11277 ('for', 'CONJ')\n",
      "11278 ('a', 'DET')\n",
      "11279 ('member', 'NOUN')\n",
      "11280 ('of', 'ADP')\n",
      "11281 ('the', 'DET')\n",
      "11282 ('Outer', 'ADJ')\n",
      "11283 ('Party', 'NOUN')\n",
      "11284 ('received', 'VERB')\n",
      "11285 ('only', 'ADV')\n",
      "3,NUM\n",
      "11286 ('3,000', 'NUM')\n",
      "11287 ('clothing', 'NOUN')\n",
      "11288 ('coupons', 'NOUN')\n",
      "11289 ('annually', 'ADV')\n",
      "11290 (',', '')\n",
      "11291 ('and', 'CONJ')\n",
      "11292 ('a', 'DET')\n",
      "11293 ('suit', 'NOUN')\n",
      "11294 ('of', 'ADP')\n",
      "11295 ('pyjamas', 'NOUN')\n",
      "11296 ('was', 'VERB')\n",
      "11297 ('600', 'NUM')\n",
      "11298 ('-', '')\n",
      "11299 ('and', 'CONJ')\n",
      "11300 ('seized', 'VERB')\n",
      "11301 ('a', 'DET')\n",
      "11302 ('dingy', 'ADJ')\n",
      "11303 ('singlet', 'NOUN')\n",
      "11304 ('and', 'CONJ')\n",
      "11305 ('a', 'DET')\n",
      "11306 ('pair', 'NOUN')\n",
      "11307 ('of', 'ADP')\n",
      "11308 ('shorts', 'NOUN')\n",
      "11309 ('that', 'PRON')\n",
      "11310 ('were', 'VERB')\n",
      "11311 ('lying', 'VERB')\n",
      "11312 ('across', 'ADP')\n",
      "11313 ('a', 'DET')\n",
      "11314 ('chair', 'NOUN')\n",
      "11315 ('.', '')\n",
      "11316 ('The', 'DET')\n",
      "11317 ('Physical', 'ADJ')\n",
      "11318 ('Jerks', 'NOUN')\n",
      "11319 ('would', 'VERB')\n",
      "11320 ('begin', 'VERB')\n",
      "11321 ('in', 'ADP')\n",
      "11322 ('three', 'NUM')\n",
      "11323 ('minutes', 'NOUN')\n",
      "11324 ('.', '')\n",
      "11325 ('The', 'DET')\n",
      "11326 ('next', 'ADJ')\n",
      "11327 ('moment', 'NOUN')\n",
      "11328 ('he', 'PRON')\n",
      "11329 ('was', 'VERB')\n",
      "11330 ('doubled', 'VERB')\n",
      "11331 ('up', 'ADP')\n",
      "11332 ('by', 'ADP')\n",
      "11333 ('a', 'DET')\n",
      "11334 ('violent', 'ADJ')\n",
      "11335 ('coughing', 'VERB')\n",
      "11336 ('fit', 'NOUN')\n",
      "11337 ('which', 'PRON')\n",
      "11338 ('nearly', 'ADV')\n",
      "11339 ('always', 'ADV')\n",
      "11340 ('attacked', 'VERB')\n",
      "11341 ('him', 'PRON')\n",
      "11342 ('soon', 'ADV')\n",
      "11343 ('after', 'ADP')\n",
      "11344 ('waking', 'VERB')\n",
      "11345 ('up', 'ADP')\n",
      "11346 ('.', '')\n",
      "11347 ('It', 'PRON')\n",
      "11348 ('emptied', 'VERB')\n",
      "11349 ('his', 'DET')\n",
      "11350 ('lungs', 'NOUN')\n",
      "11351 ('so', 'ADV')\n",
      "11352 ('completely', 'ADV')\n",
      "11353 ('that', 'CONJ')\n",
      "11354 ('he', 'PRON')\n",
      "11355 ('could', 'VERB')\n",
      "11356 ('only', 'ADV')\n",
      "11357 ('begin', 'VERB')\n",
      "11358 ('breathing', 'VERB')\n",
      "11359 ('again', 'ADV')\n",
      "11360 ('by', 'ADP')\n",
      "11361 ('lying', 'VERB')\n",
      "11362 ('on', 'ADP')\n",
      "11363 ('his', 'DET')\n",
      "11364 ('back', 'NOUN')\n",
      "11365 ('and', 'CONJ')\n",
      "11366 ('taking', 'VERB')\n",
      "11367 ('a', 'DET')\n",
      "11368 ('series', 'NOUN')\n",
      "11369 ('of', 'ADP')\n",
      "11370 ('deep', 'ADJ')\n",
      "11371 ('gasps', 'NOUN')\n",
      "11372 ('.', '')\n",
      "11373 ('His', 'DET')\n",
      "11374 ('veins', 'NOUN')\n",
      "11375 ('had', 'VERB')\n",
      "11376 ('swelled', 'VERB')\n",
      "11377 ('with', 'ADP')\n",
      "11378 ('the', 'DET')\n",
      "11379 ('effort', 'NOUN')\n",
      "11380 ('of', 'ADP')\n",
      "11381 ('the', 'DET')\n",
      "11382 ('cough', 'NOUN')\n",
      "11383 (',', '')\n",
      "11384 ('and', 'CONJ')\n",
      "11385 ('the', 'DET')\n",
      "11386 ('varicose', 'ADJ')\n",
      "11387 ('ulcer', 'NOUN')\n",
      "11388 ('had', 'VERB')\n",
      "11389 ('started', 'VERB')\n",
      "11390 ('itching', 'VERB')\n",
      "11391 ('.', '')\n",
      "11392 ('Thirty', 'NUM')\n",
      "11393 ('to', 'ADP')\n",
      "11394 ('forty', 'NUM')\n",
      "11395 ('group', 'NOUN')\n",
      "11396 ('!', '')\n",
      "11397 ('yapped', 'VERB')\n",
      "11398 ('a', 'DET')\n",
      "11399 ('piercing', 'ADJ')\n",
      "11400 ('female', 'ADJ')\n",
      "11401 ('voice', 'NOUN')\n",
      "11402 ('.', '')\n",
      "11403 ('Thirty', 'NUM')\n",
      "11404 ('to', 'ADP')\n",
      "11405 ('forty', 'NUM')\n",
      "11406 ('group', 'NOUN')\n",
      "11407 ('!', '')\n",
      "11408 ('Take', 'VERB')\n",
      "11409 ('your', 'DET')\n",
      "11410 ('places', 'NOUN')\n",
      "11411 (',', '')\n",
      "11412 ('please', 'ADV')\n",
      "11413 ('.', '')\n",
      "11414 ('Thirties', 'NOUN')\n",
      "11415 ('to', 'ADP')\n",
      "11416 ('forties', 'NOUN')\n",
      "11417 ('!', '')\n",
      "11418 ('Winston', 'NOUN')\n",
      "11419 ('sprang', 'VERB')\n",
      "11420 ('to', 'ADP')\n",
      "11421 ('attention', 'NOUN')\n",
      "11422 ('in', 'ADP')\n",
      "11423 ('front', 'NOUN')\n",
      "11424 ('of', 'ADP')\n",
      "11425 ('the', 'DET')\n",
      "11426 ('telescreen', 'NOUN')\n",
      "11427 (',', '')\n",
      "11428 ('upon', 'ADP')\n",
      "11429 ('which', 'PRON')\n",
      "11430 ('the', 'DET')\n",
      "11431 ('image', 'NOUN')\n",
      "11432 ('of', 'ADP')\n",
      "11433 ('a', 'DET')\n",
      "11434 ('youngish', 'ADJ')\n",
      "11435 ('woman', 'NOUN')\n",
      "11436 (',', '')\n",
      "11437 ('scrawny', 'ADJ')\n",
      "11438 ('but', 'CONJ')\n",
      "11439 ('muscular', 'ADJ')\n",
      "11440 (',', '')\n",
      "11441 ('dressed', 'VERB')\n",
      "11442 ('in', 'ADP')\n",
      "11443 ('tunic', 'NOUN')\n",
      "11444 ('and', 'CONJ')\n",
      "11445 ('gym-shoes', 'NOUN')\n",
      "11446 (',', '')\n",
      "11447 ('had', 'VERB')\n",
      "11448 ('already', 'ADV')\n",
      "11449 ('appeared', 'VERB')\n",
      "11450 ('.', '')\n",
      "11451 ('Arms', 'NOUN')\n",
      "11452 ('bending', 'VERB')\n",
      "11453 ('and', 'CONJ')\n",
      "11454 ('stretching', 'VERB')\n",
      "11455 ('!', '')\n",
      "11456 ('she', 'PRON')\n",
      "11457 ('rapped', 'VERB')\n",
      "11458 ('out', 'ADP')\n",
      "11459 ('.', '')\n",
      "11460 ('Take', 'VERB')\n",
      "11461 ('your', 'DET')\n",
      "11462 ('time', 'NOUN')\n",
      "11463 ('by', 'ADP')\n",
      "11464 ('me', 'PRON')\n",
      "11465 ('.', '')\n",
      "11466 ('One', 'NUM')\n",
      "11467 (',', '')\n",
      "11468 ('two', 'NUM')\n",
      "11469 (',', '')\n",
      "11470 ('three', 'NUM')\n",
      "11471 (',', '')\n",
      "11472 ('four', 'NUM')\n",
      "11473 ('!', '')\n",
      "11474 ('One', 'NUM')\n",
      "11475 (',', '')\n",
      "11476 ('two', 'NUM')\n",
      "11477 (',', '')\n",
      "11478 ('three', 'NUM')\n",
      "11479 (',', '')\n",
      "11480 ('four', 'NUM')\n",
      "11481 ('!', '')\n",
      "11482 ('Come', 'VERB')\n",
      "11483 ('on', 'ADP')\n",
      "11484 (',', '')\n",
      "11485 ('comrades', 'NOUN')\n",
      "11486 (',', '')\n",
      "11487 ('put', 'VERB')\n",
      "11488 ('a', 'DET')\n",
      "11489 ('bit', 'NOUN')\n",
      "11490 ('of', 'ADP')\n",
      "11491 ('life', 'NOUN')\n",
      "11492 ('into', 'ADP')\n",
      "11493 ('it', 'PRON')\n",
      "11494 ('!', '')\n",
      "11495 ('One', 'NUM')\n",
      "11496 (',', '')\n",
      "11497 ('two', 'NUM')\n",
      "11498 (',', '')\n",
      "11499 ('three', 'NUM')\n",
      "11500 ('four', 'NUM')\n",
      "11501 ('!', '')\n",
      "11502 ('One', 'NUM')\n",
      "11503 ('two', 'NUM')\n",
      "11504 (',', '')\n",
      "11505 ('three', 'NUM')\n",
      "11506 (',', '')\n",
      "11507 ('four', 'NUM')\n",
      "11508 ('!', '')\n",
      "\n",
      "11509 ('...', '')\n",
      "11510 ('The', 'DET')\n",
      "11511 ('pain', 'NOUN')\n",
      "11512 ('of', 'ADP')\n",
      "11513 ('the', 'DET')\n",
      "11514 ('coughing', 'VERB')\n",
      "11515 ('fit', 'NOUN')\n",
      "11516 ('had', 'VERB')\n",
      "11517 ('not', 'ADV')\n",
      "11518 ('quite', 'ADV')\n",
      "11519 ('driven', 'VERB')\n",
      "11520 ('out', 'ADP')\n",
      "11521 ('of', 'ADP')\n",
      "11522 ('Winston', 'NOUN')\n",
      "11523 (\"'s\", 'ADP')\n",
      "11524 ('mind', 'NOUN')\n",
      "11525 ('the', 'DET')\n",
      "11526 ('impression', 'NOUN')\n",
      "11527 ('made', 'VERB')\n",
      "11528 ('by', 'ADP')\n",
      "11529 ('his', 'DET')\n",
      "11530 ('dream', 'NOUN')\n",
      "11531 (',', '')\n",
      "11532 ('and', 'CONJ')\n",
      "11533 ('the', 'DET')\n",
      "11534 ('rhythmic', 'ADJ')\n",
      "11535 ('movements', 'NOUN')\n",
      "11536 ('of', 'ADP')\n",
      "11537 ('the', 'DET')\n",
      "11538 ('exercise', 'NOUN')\n",
      "11539 ('restored', 'VERB')\n",
      "11540 ('it', 'PRON')\n",
      "11541 ('somewhat', 'ADV')\n",
      "11542 ('.', '')\n",
      "11543 ('As', 'CONJ')\n",
      "11544 ('he', 'PRON')\n",
      "11545 ('mechanically', 'ADV')\n",
      "11546 ('shot', 'VERB')\n",
      "11547 ('his', 'DET')\n",
      "11548 ('arms', 'NOUN')\n",
      "11549 ('back', 'ADV')\n",
      "11550 ('and', 'CONJ')\n",
      "11551 ('forth', 'ADV')\n",
      "11552 (',', '')\n",
      "11553 ('wearing', 'VERB')\n",
      "11554 ('on', 'ADP')\n",
      "11555 ('his', 'DET')\n",
      "11556 ('face', 'NOUN')\n",
      "11557 ('the', 'DET')\n",
      "11558 ('look', 'NOUN')\n",
      "11559 ('of', 'ADP')\n",
      "11560 ('grim', 'ADJ')\n",
      "11561 ('enjoyment', 'NOUN')\n",
      "11562 ('which', 'PRON')\n",
      "11563 ('was', 'VERB')\n",
      "11564 ('considered', 'VERB')\n",
      "11565 ('proper', 'ADJ')\n",
      "11566 ('during', 'ADP')\n",
      "11567 ('the', 'DET')\n",
      "11568 ('Physical', 'ADJ')\n",
      "11569 ('Jerks', 'NOUN')\n",
      "11570 (',', '')\n",
      "11571 ('he', 'PRON')\n",
      "11572 ('was', 'VERB')\n",
      "11573 ('struggling', 'VERB')\n",
      "11574 ('to', 'ADP')\n",
      "11575 ('think', 'VERB')\n",
      "11576 ('his', 'DET')\n",
      "11577 ('way', 'NOUN')\n",
      "11578 ('backward', 'ADV')\n",
      "11579 ('into', 'ADP')\n",
      "11580 ('the', 'DET')\n",
      "11581 ('dim', 'ADJ')\n",
      "11582 ('period', 'NOUN')\n",
      "11583 ('of', 'ADP')\n",
      "11584 ('his', 'DET')\n",
      "11585 ('early', 'ADJ')\n",
      "11586 ('childhood', 'NOUN')\n",
      "11587 ('.', '')\n",
      "11588 ('It', 'PRON')\n",
      "11589 ('was', 'VERB')\n",
      "11590 ('extraordinarily', 'ADV')\n",
      "11591 ('difficult', 'ADJ')\n",
      "11592 ('.', '')\n",
      "11593 ('Beyond', 'ADP')\n",
      "11594 ('the', 'DET')\n",
      "11595 ('late', 'ADJ')\n",
      "11596 ('fifties', 'NOUN')\n",
      "11597 ('everything', 'PRON')\n",
      "11598 ('faded', 'VERB')\n",
      "11599 ('.', '')\n",
      "11600 ('When', 'CONJ')\n",
      "11601 ('there', 'PRON')\n",
      "11602 ('were', 'VERB')\n",
      "11603 ('no', 'DET')\n",
      "11604 ('external', 'ADJ')\n",
      "11605 ('records', 'NOUN')\n",
      "11606 ('that', 'PRON')\n",
      "11607 ('you', 'PRON')\n",
      "11608 ('could', 'VERB')\n",
      "11609 ('refer', 'VERB')\n",
      "11610 ('to', 'ADP')\n",
      "11611 (',', '')\n",
      "11612 ('even', 'ADV')\n",
      "11613 ('the', 'DET')\n",
      "11614 ('outline', 'NOUN')\n",
      "11615 ('of', 'ADP')\n",
      "11616 ('your', 'DET')\n",
      "11617 ('own', 'ADJ')\n",
      "11618 ('life', 'NOUN')\n",
      "11619 ('lost', 'VERB')\n",
      "11620 ('its', 'DET')\n",
      "11621 ('sharpness', 'NOUN')\n",
      "11622 ('.', '')\n",
      "11623 ('You', 'PRON')\n",
      "11624 ('remembered', 'VERB')\n",
      "11625 ('huge', 'ADJ')\n",
      "11626 ('events', 'NOUN')\n",
      "11627 ('which', 'PRON')\n",
      "11628 ('had', 'VERB')\n",
      "11629 ('quite', 'ADV')\n",
      "11630 ('probably', 'ADV')\n",
      "11631 ('not', 'ADV')\n",
      "11632 ('happened', 'VERB')\n",
      "11633 (',', '')\n",
      "11634 ('you', 'PRON')\n",
      "11635 ('remembered', 'VERB')\n",
      "11636 ('the', 'DET')\n",
      "11637 ('detail', 'NOUN')\n",
      "11638 ('of', 'ADP')\n",
      "11639 ('incidents', 'NOUN')\n",
      "11640 ('without', 'ADP')\n",
      "11641 ('being', 'VERB')\n",
      "11642 ('able', 'ADJ')\n",
      "11643 ('to', 'ADP')\n",
      "11644 ('recapture', 'VERB')\n",
      "11645 ('their', 'DET')\n",
      "11646 ('atmosphere', 'NOUN')\n",
      "11647 (',', '')\n",
      "11648 ('and', 'CONJ')\n",
      "11649 ('there', 'PRON')\n",
      "11650 ('were', 'VERB')\n",
      "11651 ('long', 'ADV')\n",
      "11652 ('blank', 'ADJ')\n",
      "11653 ('periods', 'NOUN')\n",
      "11654 ('to', 'ADP')\n",
      "11655 ('which', 'PRON')\n",
      "11656 ('you', 'PRON')\n",
      "11657 ('could', 'VERB')\n",
      "11658 ('assign', 'VERB')\n",
      "11659 ('nothing', 'PRON')\n",
      "11660 ('.', '')\n",
      "11661 ('Everything', 'PRON')\n",
      "11662 ('had', 'VERB')\n",
      "11663 ('been', 'VERB')\n",
      "11664 ('different', 'ADJ')\n",
      "11665 ('then', 'ADV')\n",
      "11666 ('.', '')\n",
      "11667 ('Even', 'ADV')\n",
      "11668 ('the', 'DET')\n",
      "11669 ('names', 'NOUN')\n",
      "11670 ('of', 'ADP')\n",
      "11671 ('countries', 'NOUN')\n",
      "11672 (',', '')\n",
      "11673 ('and', 'CONJ')\n",
      "11674 ('their', 'DET')\n",
      "11675 ('shapes', 'NOUN')\n",
      "11676 ('on', 'ADP')\n",
      "11677 ('the', 'DET')\n",
      "11678 ('map', 'NOUN')\n",
      "11679 (',', '')\n",
      "11680 ('had', 'VERB')\n",
      "11681 ('been', 'VERB')\n",
      "11682 ('different', 'ADJ')\n",
      "11683 ('.', '')\n",
      "11684 ('Airstrip', 'NOUN')\n",
      "11685 ('One', 'NUM')\n",
      "11686 (',', '')\n",
      "11687 ('for', 'ADP')\n",
      "11688 ('instance', 'NOUN')\n",
      "11689 (',', '')\n",
      "11690 ('had', 'VERB')\n",
      "11691 ('not', 'ADV')\n",
      "11692 ('been', 'VERB')\n",
      "11693 ('so', 'ADV')\n",
      "11694 ('called', 'VERB')\n",
      "11695 ('in', 'ADP')\n",
      "11696 ('those', 'DET')\n",
      "11697 ('days', 'NOUN')\n",
      "11698 (':', '')\n",
      "11699 ('it', 'PRON')\n",
      "11700 ('had', 'VERB')\n",
      "11701 ('been', 'VERB')\n",
      "11702 ('called', 'VERB')\n",
      "11703 ('England', 'NOUN')\n",
      "11704 ('or', 'CONJ')\n",
      "11705 ('Britain', 'NOUN')\n",
      "11706 (',', '')\n",
      "11707 ('though', 'CONJ')\n",
      "11708 ('London', 'NOUN')\n",
      "11709 (',', '')\n",
      "11710 ('he', 'PRON')\n",
      "11711 ('felt', 'VERB')\n",
      "11712 ('fairly', 'ADV')\n",
      "11713 ('certain', 'ADJ')\n",
      "11714 (',', '')\n",
      "11715 ('had', 'VERB')\n",
      "11716 ('always', 'ADV')\n",
      "11717 ('been', 'VERB')\n",
      "11718 ('called', 'VERB')\n",
      "11719 ('London', 'NOUN')\n",
      "11720 ('.', '')\n",
      "11721 ('Winston', 'NOUN')\n",
      "11722 ('could', 'VERB')\n",
      "11723 ('not', 'ADV')\n",
      "11724 ('definitely', 'ADV')\n",
      "11725 ('remember', 'VERB')\n",
      "11726 ('a', 'DET')\n",
      "11727 ('time', 'NOUN')\n",
      "11728 ('when', 'CONJ')\n",
      "11729 ('his', 'DET')\n",
      "11730 ('country', 'NOUN')\n",
      "11731 ('had', 'VERB')\n",
      "11732 ('not', 'ADV')\n",
      "11733 ('been', 'VERB')\n",
      "11734 ('at', 'ADP')\n",
      "11735 ('war', 'NOUN')\n",
      "11736 (',', '')\n",
      "11737 ('but', 'CONJ')\n",
      "11738 ('it', 'PRON')\n",
      "11739 ('was', 'VERB')\n",
      "11740 ('evident', 'ADJ')\n",
      "11741 ('that', 'CONJ')\n",
      "11742 ('there', 'PRON')\n",
      "11743 ('had', 'VERB')\n",
      "11744 ('been', 'VERB')\n",
      "11745 ('a', 'DET')\n",
      "11746 ('fairly', 'ADV')\n",
      "11747 ('long', 'ADJ')\n",
      "11748 ('interval', 'NOUN')\n",
      "11749 ('of', 'ADP')\n",
      "11750 ('peace', 'NOUN')\n",
      "11751 ('during', 'ADP')\n",
      "11752 ('his', 'DET')\n",
      "11753 ('childhood', 'NOUN')\n",
      "11754 (',', '')\n",
      "11755 ('because', 'CONJ')\n",
      "11756 ('one', 'PRON')\n",
      "11757 ('of', 'ADP')\n",
      "11758 ('his', 'DET')\n",
      "11759 ('early', 'ADJ')\n",
      "11760 ('memories', 'NOUN')\n",
      "11761 ('was', 'VERB')\n",
      "11762 ('of', 'ADP')\n",
      "11763 ('an', 'DET')\n",
      "11764 ('air', 'NOUN')\n",
      "11765 ('raid', 'NOUN')\n",
      "11766 ('which', 'PRON')\n",
      "11767 ('appeared', 'VERB')\n",
      "11768 ('to', 'ADP')\n",
      "11769 ('take', 'VERB')\n",
      "11770 ('everyone', 'PRON')\n",
      "11771 ('by', 'ADP')\n",
      "11772 ('surprise', 'NOUN')\n",
      "11773 ('.', '')\n",
      "11774 ('Perhaps', 'ADV')\n",
      "11775 ('it', 'PRON')\n",
      "11776 ('was', 'VERB')\n",
      "11777 ('the', 'DET')\n",
      "11778 ('time', 'NOUN')\n",
      "11779 ('when', 'CONJ')\n",
      "11780 ('the', 'DET')\n",
      "11781 ('atomic', 'ADJ')\n",
      "11782 ('bomb', 'NOUN')\n",
      "11783 ('had', 'VERB')\n",
      "11784 ('fallen', 'VERB')\n",
      "11785 ('on', 'ADP')\n",
      "11786 ('Colchester', 'NOUN')\n",
      "11787 ('.', '')\n",
      "11788 ('He', 'PRON')\n",
      "11789 ('did', 'VERB')\n",
      "11790 ('not', 'ADV')\n",
      "11791 ('remember', 'VERB')\n",
      "11792 ('the', 'DET')\n",
      "11793 ('raid', 'NOUN')\n",
      "11794 ('itself', 'PRON')\n",
      "11795 (',', '')\n",
      "11796 ('but', 'CONJ')\n",
      "11797 ('he', 'PRON')\n",
      "11798 ('did', 'VERB')\n",
      "11799 ('remember', 'VERB')\n",
      "11800 ('his', 'DET')\n",
      "11801 ('father', 'NOUN')\n",
      "11802 (\"'s\", 'ADP')\n",
      "11803 ('hand', 'NOUN')\n",
      "11804 ('clutching', 'VERB')\n",
      "11805 ('his', 'DET')\n",
      "11806 ('own', 'PRON')\n",
      "11807 ('as', 'CONJ')\n",
      "11808 ('they', 'PRON')\n",
      "11809 ('hurried', 'VERB')\n",
      "11810 ('down', 'ADV')\n",
      "11811 (',', '')\n",
      "11812 ('down', 'ADV')\n",
      "11813 (',', '')\n",
      "11814 ('down', 'ADV')\n",
      "11815 ('into', 'ADP')\n",
      "11816 ('some', 'DET')\n",
      "11817 ('place', 'NOUN')\n",
      "11818 ('deep', 'ADV')\n",
      "11819 ('in', 'ADP')\n",
      "11820 ('the', 'DET')\n",
      "11821 ('earth', 'NOUN')\n",
      "11822 (',', '')\n",
      "11823 ('round', 'ADP')\n",
      "11824 ('and', 'CONJ')\n",
      "11825 ('round', 'ADP')\n",
      "11826 ('a', 'DET')\n",
      "11827 ('spiral', 'ADJ')\n",
      "11828 ('staircase', 'NOUN')\n",
      "11829 ('which', 'PRON')\n",
      "11830 ('rang', 'VERB')\n",
      "11831 ('under', 'ADP')\n",
      "11832 ('his', 'DET')\n",
      "11833 ('feet', 'NOUN')\n",
      "11834 ('and', 'CONJ')\n",
      "11835 ('which', 'PRON')\n",
      "11836 ('finally', 'ADV')\n",
      "11837 ('so', 'ADV')\n",
      "11838 ('wearied', 'VERB')\n",
      "11839 ('his', 'DET')\n",
      "11840 ('legs', 'NOUN')\n",
      "11841 ('that', 'CONJ')\n",
      "11842 ('he', 'PRON')\n",
      "11843 ('began', 'VERB')\n",
      "11844 ('whimpering', 'VERB')\n",
      "11845 ('and', 'CONJ')\n",
      "11846 ('they', 'PRON')\n",
      "11847 ('had', 'VERB')\n",
      "11848 ('to', 'ADP')\n",
      "11849 ('stop', 'VERB')\n",
      "11850 ('and', 'CONJ')\n",
      "11851 ('rest', 'VERB')\n",
      "11852 ('.', '')\n",
      "11853 ('His', 'DET')\n",
      "11854 ('mother', 'NOUN')\n",
      "11855 (',', '')\n",
      "11856 ('in', 'ADP')\n",
      "11857 ('her', 'DET')\n",
      "11858 ('slow', 'ADJ')\n",
      "11859 (',', '')\n",
      "11860 ('dreamy', 'ADJ')\n",
      "11861 ('way', 'NOUN')\n",
      "11862 (',', '')\n",
      "11863 ('was', 'VERB')\n",
      "11864 ('following', 'VERB')\n",
      "11865 ('a', 'DET')\n",
      "11866 ('long', 'ADJ')\n",
      "11867 ('way', 'NOUN')\n",
      "11868 ('behind', 'ADP')\n",
      "11869 ('them', 'PRON')\n",
      "11870 ('.', '')\n",
      "11871 ('She', 'PRON')\n",
      "11872 ('was', 'VERB')\n",
      "11873 ('carrying', 'VERB')\n",
      "11874 ('his', 'DET')\n",
      "11875 ('baby', 'NOUN')\n",
      "11876 ('sister', 'NOUN')\n",
      "11877 ('-', '')\n",
      "11878 ('or', 'CONJ')\n",
      "11879 ('perhaps', 'ADV')\n",
      "11880 ('it', 'PRON')\n",
      "11881 ('was', 'VERB')\n",
      "11882 ('only', 'ADV')\n",
      "11883 ('a', 'DET')\n",
      "11884 ('bundle', 'NOUN')\n",
      "11885 ('of', 'ADP')\n",
      "11886 ('blankets', 'NOUN')\n",
      "11887 ('that', 'PRON')\n",
      "11888 ('she', 'PRON')\n",
      "11889 ('was', 'VERB')\n",
      "11890 ('carrying', 'VERB')\n",
      "11891 (':', '')\n",
      "11892 ('he', 'PRON')\n",
      "11893 ('was', 'VERB')\n",
      "11894 ('not', 'ADV')\n",
      "11895 ('certain', 'ADJ')\n",
      "11896 ('whether', 'CONJ')\n",
      "11897 ('his', 'DET')\n",
      "11898 ('sister', 'NOUN')\n",
      "11899 ('had', 'VERB')\n",
      "11900 ('been', 'VERB')\n",
      "11901 ('born', 'ADJ')\n",
      "11902 ('then', 'ADV')\n",
      "11903 ('.', '')\n",
      "11904 ('Finally', 'ADV')\n",
      "11905 ('they', 'PRON')\n",
      "11906 ('had', 'VERB')\n",
      "11907 ('emerged', 'VERB')\n",
      "11908 ('into', 'ADP')\n",
      "11909 ('a', 'DET')\n",
      "11910 ('noisy', 'ADJ')\n",
      "11911 (',', '')\n",
      "11912 ('crowded', 'ADJ')\n",
      "11913 ('place', 'NOUN')\n",
      "11914 ('which', 'PRON')\n",
      "11915 ('he', 'PRON')\n",
      "11916 ('had', 'VERB')\n",
      "11917 ('realized', 'VERB')\n",
      "11918 ('to', 'ADP')\n",
      "11919 ('be', 'VERB')\n",
      "11920 ('a', 'DET')\n",
      "11921 ('Tube', 'NOUN')\n",
      "11922 ('station', 'NOUN')\n",
      "11923 ('.', '')\n",
      "11924 ('There', 'PRON')\n",
      "11925 ('were', 'VERB')\n",
      "11926 ('people', 'NOUN')\n",
      "11927 ('sitting', 'VERB')\n",
      "11928 ('all', 'ADV')\n",
      "11929 ('over', 'ADP')\n",
      "11930 ('the', 'DET')\n",
      "11931 ('stone-flagged', 'ADJ')\n",
      "11932 ('floor', 'NOUN')\n",
      "11933 (',', '')\n",
      "11934 ('and', 'CONJ')\n",
      "11935 ('other', 'DET')\n",
      "11936 ('people', 'NOUN')\n",
      "11937 (',', '')\n",
      "11938 ('packed', 'VERB')\n",
      "11939 ('tightly', 'ADV')\n",
      "11940 ('together', 'ADV')\n",
      "11941 (',', '')\n",
      "11942 ('were', 'VERB')\n",
      "11943 ('sitting', 'VERB')\n",
      "11944 ('on', 'ADP')\n",
      "11945 ('metal', 'NOUN')\n",
      "11946 ('bunks', 'NOUN')\n",
      "11947 (',', '')\n",
      "11948 ('one', 'PRON')\n",
      "11949 ('above', 'ADP')\n",
      "11950 ('the', 'DET')\n",
      "11951 ('other', 'NOUN')\n",
      "11952 ('.', '')\n",
      "11953 ('Winston', 'NOUN')\n",
      "11954 ('and', 'CONJ')\n",
      "11955 ('his', 'DET')\n",
      "11956 ('mother', 'NOUN')\n",
      "11957 ('and', 'CONJ')\n",
      "11958 ('father', 'NOUN')\n",
      "11959 ('found', 'VERB')\n",
      "11960 ('themselves', 'PRON')\n",
      "11961 ('a', 'DET')\n",
      "11962 ('place', 'NOUN')\n",
      "11963 ('on', 'ADP')\n",
      "11964 ('the', 'DET')\n",
      "11965 ('floor', 'NOUN')\n",
      "11966 (',', '')\n",
      "11967 ('and', 'CONJ')\n",
      "11968 ('near', 'ADP')\n",
      "11969 ('them', 'PRON')\n",
      "11970 ('an', 'DET')\n",
      "11971 ('old', 'ADJ')\n",
      "11972 ('man', 'NOUN')\n",
      "11973 ('and', 'CONJ')\n",
      "11974 ('an', 'DET')\n",
      "11975 ('old', 'ADJ')\n",
      "11976 ('woman', 'NOUN')\n",
      "11977 ('were', 'VERB')\n",
      "11978 ('sitting', 'VERB')\n",
      "11979 ('side', 'NOUN')\n",
      "11980 ('by', 'ADP')\n",
      "11981 ('side', 'NOUN')\n",
      "11982 ('on', 'ADP')\n",
      "11983 ('a', 'DET')\n",
      "11984 ('bunk', 'NOUN')\n",
      "11985 ('.', '')\n",
      "11986 ('The', 'DET')\n",
      "11987 ('old', 'ADJ')\n",
      "11988 ('man', 'NOUN')\n",
      "11989 ('had', 'VERB')\n",
      "11990 ('on', 'ADP')\n",
      "11991 ('a', 'DET')\n",
      "11992 ('decent', 'ADJ')\n",
      "11993 ('dark', 'ADJ')\n",
      "11994 ('suit', 'NOUN')\n",
      "11995 ('and', 'CONJ')\n",
      "11996 ('a', 'DET')\n",
      "11997 ('black', 'ADJ')\n",
      "11998 ('cloth', 'NOUN')\n",
      "11999 ('cap', 'NOUN')\n",
      "12000 ('pushed', 'VERB')\n",
      "12001 ('back', 'ADV')\n",
      "12002 ('from', 'ADP')\n",
      "12003 ('very', 'ADV')\n",
      "12004 ('white', 'ADJ')\n",
      "12005 ('hair', 'NOUN')\n",
      "12006 (':', '')\n",
      "12007 ('his', 'DET')\n",
      "12008 ('face', 'NOUN')\n",
      "12009 ('was', 'VERB')\n",
      "12010 ('scarlet', 'ADJ')\n",
      "12011 ('and', 'CONJ')\n",
      "12012 ('his', 'DET')\n",
      "12013 ('eyes', 'NOUN')\n",
      "12014 ('were', 'VERB')\n",
      "12015 ('blue', 'ADJ')\n",
      "12016 ('and', 'CONJ')\n",
      "12017 ('full', 'ADJ')\n",
      "12018 ('of', 'ADP')\n",
      "12019 ('tears', 'NOUN')\n",
      "12020 ('.', '')\n",
      "12021 ('He', 'PRON')\n",
      "12022 ('reeked', 'VERB')\n",
      "12023 ('of', 'ADP')\n",
      "12024 ('gin', 'NOUN')\n",
      "12025 ('.', '')\n",
      "12026 ('It', 'PRON')\n",
      "12027 ('seemed', 'VERB')\n",
      "12028 ('to', 'ADP')\n",
      "12029 ('breathe', 'VERB')\n",
      "12030 ('out', 'ADP')\n",
      "12031 ('of', 'ADP')\n",
      "12032 ('his', 'DET')\n",
      "12033 ('skin', 'NOUN')\n",
      "12034 ('in', 'ADP')\n",
      "12035 ('place', 'NOUN')\n",
      "12036 ('of', 'ADP')\n",
      "12037 ('sweat', 'NOUN')\n",
      "12038 (',', '')\n",
      "12039 ('and', 'CONJ')\n",
      "12040 ('one', 'PRON')\n",
      "12041 ('could', 'VERB')\n",
      "12042 ('have', 'VERB')\n",
      "12043 ('fancied', 'VERB')\n",
      "12044 ('that', 'CONJ')\n",
      "12045 ('the', 'DET')\n",
      "12046 ('tears', 'NOUN')\n",
      "12047 ('welling', 'VERB')\n",
      "12048 ('from', 'ADP')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049 ('his', 'DET')\n",
      "12050 ('eyes', 'NOUN')\n",
      "12051 ('were', 'VERB')\n",
      "12052 ('pure', 'ADJ')\n",
      "12053 ('gin', 'NOUN')\n",
      "12054 ('.', '')\n",
      "12055 ('But', 'CONJ')\n",
      "12056 ('though', 'CONJ')\n",
      "12057 ('slightly', 'ADV')\n",
      "12058 ('drunk', 'ADJ')\n",
      "12059 ('he', 'PRON')\n",
      "12060 ('was', 'VERB')\n",
      "12061 ('also', 'ADV')\n",
      "12062 ('suffering', 'VERB')\n",
      "12063 ('under', 'ADP')\n",
      "12064 ('some', 'DET')\n",
      "12065 ('grief', 'NOUN')\n",
      "12066 ('that', 'PRON')\n",
      "12067 ('was', 'VERB')\n",
      "12068 ('genuine', 'ADJ')\n",
      "12069 ('and', 'CONJ')\n",
      "12070 ('unbearable', 'ADJ')\n",
      "12071 ('.', '')\n",
      "12072 ('In', 'ADP')\n",
      "12073 ('his', 'DET')\n",
      "12074 ('childish', 'ADJ')\n",
      "12075 ('way', 'NOUN')\n",
      "12076 ('Winston', 'NOUN')\n",
      "12077 ('grasped', 'VERB')\n",
      "12078 ('that', 'CONJ')\n",
      "12079 ('some', 'DET')\n",
      "12080 ('terrible', 'ADJ')\n",
      "12081 ('thing', 'NOUN')\n",
      "12082 (',', '')\n",
      "12083 ('something', 'PRON')\n",
      "12084 ('that', 'PRON')\n",
      "12085 ('was', 'VERB')\n",
      "12086 ('beyond', 'ADP')\n",
      "12087 ('forgiveness', 'NOUN')\n",
      "12088 ('and', 'CONJ')\n",
      "12089 ('could', 'VERB')\n",
      "12090 ('never', 'ADV')\n",
      "12091 ('be', 'VERB')\n",
      "12092 ('remedied', 'VERB')\n",
      "12093 (',', '')\n",
      "12094 ('had', 'VERB')\n",
      "12095 ('just', 'ADV')\n",
      "12096 ('happened', 'VERB')\n",
      "12097 ('.', '')\n",
      "12098 ('It', 'PRON')\n",
      "12099 ('also', 'ADV')\n",
      "12100 ('seemed', 'VERB')\n",
      "12101 ('to', 'ADP')\n",
      "12102 ('him', 'PRON')\n",
      "12103 ('that', 'CONJ')\n",
      "12104 ('he', 'PRON')\n",
      "12105 ('knew', 'VERB')\n",
      "12106 ('what', 'PRON')\n",
      "12107 ('it', 'PRON')\n",
      "12108 ('was', 'VERB')\n",
      "12109 ('.', '')\n",
      "12110 ('Someone', 'PRON')\n",
      "12111 ('whom', 'PRON')\n",
      "12112 ('the', 'DET')\n",
      "12113 ('old', 'ADJ')\n",
      "12114 ('man', 'NOUN')\n",
      "12115 ('loved', 'VERB')\n",
      "12116 ('-', '')\n",
      "12117 ('a', 'DET')\n",
      "12118 ('little', 'ADJ')\n",
      "12119 ('granddaughter', 'NOUN')\n",
      "12120 (',', '')\n",
      "12121 ('perhaps', 'ADV')\n",
      "12122 ('had', 'VERB')\n",
      "12123 ('been', 'VERB')\n",
      "12124 ('killed', 'VERB')\n",
      "12125 ('.', '')\n",
      "12126 ('Every', 'DET')\n",
      "12127 ('few', 'DET')\n",
      "12128 ('minutes', 'NOUN')\n",
      "12129 ('the', 'DET')\n",
      "12130 ('old', 'ADJ')\n",
      "12131 ('man', 'NOUN')\n",
      "12132 ('kept', 'VERB')\n",
      "12133 ('repeating', 'VERB')\n",
      "12134 (':', '')\n",
      "12135 ('We', 'PRON')\n",
      "12136 (\"didn't\", 'VERB')\n",
      "12137 ('ought', 'VERB')\n",
      "12138 ('to', 'ADP')\n",
      "12139 (\"'ave\", 'VERB')\n",
      "12140 ('trusted', 'VERB')\n",
      "12141 (\"'em\", 'PRON')\n",
      "12142 ('.', '')\n",
      "12143 ('I', 'PRON')\n",
      "12144 ('said', 'VERB')\n",
      "12145 ('so', 'ADV')\n",
      "12146 (',', '')\n",
      "12147 ('Ma', 'NOUN')\n",
      "12148 (',', '')\n",
      "12149 (\"didn't\", 'VERB')\n",
      "12150 ('I', 'PRON')\n",
      "12151 ('?', '')\n",
      "12152 ('That', 'PRON')\n",
      "12153 (\"'s\", 'VERB')\n",
      "12154 ('what', 'PRON')\n",
      "12155 ('comes', 'VERB')\n",
      "12156 ('of', 'ADP')\n",
      "12157 ('trusting', 'VERB')\n",
      "12158 (\"'em\", 'PRON')\n",
      "12159 ('.', '')\n",
      "12160 ('I', 'PRON')\n",
      "12161 ('said', 'VERB')\n",
      "12162 ('so', 'ADV')\n",
      "12163 ('all', 'ADV')\n",
      "12164 ('along', 'ADV')\n",
      "12165 ('.', '')\n",
      "12166 ('We', 'PRON')\n",
      "12167 (\"didn't\", 'VERB')\n",
      "12168 ('ought', 'VERB')\n",
      "12169 ('to', 'ADP')\n",
      "12170 (\"'ave\", 'VERB')\n",
      "12171 ('trusted', 'VERB')\n",
      "12172 ('the', 'DET')\n",
      "12173 ('buggers', 'NOUN')\n",
      "12174 ('.', '')\n",
      "12175 ('But', 'CONJ')\n",
      "12176 ('which', 'DET')\n",
      "12177 ('buggers', 'NOUN')\n",
      "12178 ('they', 'PRON')\n",
      "12179 (\"didn't\", 'VERB')\n",
      "12180 ('ought', 'VERB')\n",
      "12181 ('to', 'ADP')\n",
      "12182 ('have', 'VERB')\n",
      "12183 ('trusted', 'VERB')\n",
      "12184 ('Winston', 'NOUN')\n",
      "12185 ('could', 'VERB')\n",
      "12186 ('not', 'ADV')\n",
      "12187 ('now', 'ADV')\n",
      "12188 ('remember', 'VERB')\n",
      "12189 ('.', '')\n",
      "12190 ('Since', 'ADP')\n",
      "12191 ('about', 'ADV')\n",
      "12192 ('that', 'DET')\n",
      "12193 ('time', 'NOUN')\n",
      "12194 (',', '')\n",
      "12195 ('war', 'NOUN')\n",
      "12196 ('had', 'VERB')\n",
      "12197 ('been', 'VERB')\n",
      "12198 ('literally', 'ADV')\n",
      "12199 ('continuous', 'ADJ')\n",
      "12200 (',', '')\n",
      "12201 ('though', 'CONJ')\n",
      "12202 ('strictly', 'ADV')\n",
      "12203 ('speaking', 'VERB')\n",
      "12204 ('it', 'PRON')\n",
      "12205 ('had', 'VERB')\n",
      "12206 ('not', 'ADV')\n",
      "12207 ('always', 'ADV')\n",
      "12208 ('been', 'VERB')\n",
      "12209 ('the', 'DET')\n",
      "12210 ('same', 'ADJ')\n",
      "12211 ('war', 'NOUN')\n",
      "12212 ('.', '')\n",
      "12213 ('For', 'ADP')\n",
      "12214 ('several', 'ADJ')\n",
      "12215 ('months', 'NOUN')\n",
      "12216 ('during', 'ADP')\n",
      "12217 ('his', 'DET')\n",
      "12218 ('childhood', 'NOUN')\n",
      "12219 ('there', 'PRON')\n",
      "12220 ('had', 'VERB')\n",
      "12221 ('been', 'VERB')\n",
      "12222 ('confused', 'ADJ')\n",
      "12223 ('street', 'NOUN')\n",
      "12224 ('fighting', 'NOUN')\n",
      "12225 ('in', 'ADP')\n",
      "12226 ('London', 'NOUN')\n",
      "12227 ('itself', 'PRON')\n",
      "12228 (',', '')\n",
      "12229 ('some', 'PRON')\n",
      "12230 ('of', 'ADP')\n",
      "12231 ('which', 'PRON')\n",
      "12232 ('he', 'PRON')\n",
      "12233 ('remembered', 'VERB')\n",
      "12234 ('vividly', 'ADV')\n",
      "12235 ('.', '')\n",
      "12236 ('But', 'CONJ')\n",
      "12237 ('to', 'ADP')\n",
      "12238 ('trace', 'VERB')\n",
      "12239 ('out', 'ADP')\n",
      "12240 ('the', 'DET')\n",
      "12241 ('history', 'NOUN')\n",
      "12242 ('of', 'ADP')\n",
      "12243 ('the', 'DET')\n",
      "12244 ('whole', 'ADJ')\n",
      "12245 ('period', 'NOUN')\n",
      "12246 (',', '')\n",
      "12247 ('to', 'ADP')\n",
      "12248 ('say', 'VERB')\n",
      "12249 ('who', 'PRON')\n",
      "12250 ('was', 'VERB')\n",
      "12251 ('fighting', 'VERB')\n",
      "12252 ('whom', 'PRON')\n",
      "12253 ('at', 'ADP')\n",
      "12254 ('any', 'DET')\n",
      "12255 ('given', 'VERB')\n",
      "12256 ('moment', 'NOUN')\n",
      "12257 (',', '')\n",
      "12258 ('would', 'VERB')\n",
      "12259 ('have', 'VERB')\n",
      "12260 ('been', 'VERB')\n",
      "12261 ('utterly', 'ADV')\n",
      "12262 ('impossible', 'ADJ')\n",
      "12263 (',', '')\n",
      "12264 ('since', 'CONJ')\n",
      "12265 ('no', 'DET')\n",
      "12266 ('written', 'VERB')\n",
      "12267 ('record', 'NOUN')\n",
      "12268 (',', '')\n",
      "12269 ('and', 'CONJ')\n",
      "12270 ('no', 'DET')\n",
      "12271 ('spoken', 'VERB')\n",
      "12272 ('word', 'NOUN')\n",
      "12273 (',', '')\n",
      "12274 ('ever', 'ADV')\n",
      "12275 ('made', 'VERB')\n",
      "12276 ('mention', 'NOUN')\n",
      "12277 ('of', 'ADP')\n",
      "12278 ('any', 'DET')\n",
      "12279 ('other', 'DET')\n",
      "12280 ('alignment', 'NOUN')\n",
      "12281 ('than', 'ADP')\n",
      "12282 ('the', 'DET')\n",
      "12283 ('existing', 'ADJ')\n",
      "12284 ('one', 'PRON')\n",
      "12285 ('.', '')\n",
      "12286 ('At', 'ADP')\n",
      "12287 ('this', 'DET')\n",
      "12288 ('moment', 'NOUN')\n",
      "12289 (',', '')\n",
      "12290 ('for', 'ADP')\n",
      "12291 ('example', 'NOUN')\n",
      "12292 (',', '')\n",
      "12293 ('in', 'ADP')\n",
      "12294 ('1984', 'NUM')\n",
      "12295 ('(', '')\n",
      "12296 ('if', 'CONJ')\n",
      "12297 ('it', 'PRON')\n",
      "12298 ('was', 'VERB')\n",
      "12299 ('1984', 'NUM')\n",
      "12300 (')', '')\n",
      "12301 (',', '')\n",
      "12302 ('Oceania', 'NOUN')\n",
      "12303 ('was', 'VERB')\n",
      "12304 ('at', 'ADP')\n",
      "12305 ('war', 'NOUN')\n",
      "12306 ('with', 'ADP')\n",
      "12307 ('Eurasia', 'NOUN')\n",
      "12308 ('and', 'CONJ')\n",
      "12309 ('in', 'ADP')\n",
      "12310 ('alliance', 'NOUN')\n",
      "12311 ('with', 'ADP')\n",
      "12312 ('Eastasia', 'NOUN')\n",
      "12313 ('.', '')\n",
      "12314 ('In', 'ADP')\n",
      "12315 ('no', 'DET')\n",
      "12316 ('public', 'ADJ')\n",
      "12317 ('or', 'CONJ')\n",
      "12318 ('private', 'ADJ')\n",
      "12319 ('utterance', 'NOUN')\n",
      "12320 ('was', 'VERB')\n",
      "12321 ('it', 'PRON')\n",
      "12322 ('ever', 'ADV')\n",
      "12323 ('admitted', 'VERB')\n",
      "12324 ('that', 'CONJ')\n",
      "12325 ('the', 'DET')\n",
      "12326 ('three', 'NUM')\n",
      "12327 ('powers', 'NOUN')\n",
      "12328 ('had', 'VERB')\n",
      "12329 ('at', 'ADP')\n",
      "12330 ('any', 'DET')\n",
      "12331 ('time', 'NOUN')\n",
      "12332 ('been', 'VERB')\n",
      "12333 ('grouped', 'VERB')\n",
      "12334 ('along', 'ADP')\n",
      "12335 ('different', 'ADJ')\n",
      "12336 ('lines', 'NOUN')\n",
      "12337 ('.', '')\n",
      "12338 ('Actually', 'ADV')\n",
      "12339 (',', '')\n",
      "12340 ('as', 'CONJ')\n",
      "12341 ('Winston', 'NOUN')\n",
      "12342 ('well', 'ADV')\n",
      "12343 ('knew', 'VERB')\n",
      "12344 (',', '')\n",
      "12345 ('it', 'PRON')\n",
      "12346 ('was', 'VERB')\n",
      "12347 ('only', 'ADV')\n",
      "12348 ('four', 'NUM')\n",
      "12349 ('years', 'NOUN')\n",
      "12350 ('since', 'CONJ')\n",
      "12351 ('Oceania', 'NOUN')\n",
      "12352 ('had', 'VERB')\n",
      "12353 ('been', 'VERB')\n",
      "12354 ('at', 'ADP')\n",
      "12355 ('war', 'NOUN')\n",
      "12356 ('with', 'ADP')\n",
      "12357 ('Eastasia', 'NOUN')\n",
      "12358 ('and', 'CONJ')\n",
      "12359 ('in', 'ADP')\n",
      "12360 ('alliance', 'NOUN')\n",
      "12361 ('with', 'ADP')\n",
      "12362 ('Eurasia', 'NOUN')\n",
      "12363 ('.', '')\n",
      "12364 ('But', 'CONJ')\n",
      "12365 ('that', 'PRON')\n",
      "12366 ('was', 'VERB')\n",
      "12367 ('merely', 'ADV')\n",
      "12368 ('a', 'DET')\n",
      "12369 ('piece', 'NOUN')\n",
      "12370 ('of', 'ADP')\n",
      "12371 ('furtive', 'ADJ')\n",
      "12372 ('knowledge', 'NOUN')\n",
      "12373 ('which', 'PRON')\n",
      "12374 ('he', 'PRON')\n",
      "12375 ('happened', 'VERB')\n",
      "12376 ('to', 'ADP')\n",
      "12377 ('possess', 'VERB')\n",
      "12378 ('because', 'CONJ')\n",
      "12379 ('his', 'DET')\n",
      "12380 ('memory', 'NOUN')\n",
      "12381 ('was', 'VERB')\n",
      "12382 ('not', 'ADV')\n",
      "12383 ('satisfactorily', 'ADV')\n",
      "12384 ('under', 'ADP')\n",
      "12385 ('control', 'NOUN')\n",
      "12386 ('.', '')\n",
      "12387 ('Officially', 'ADV')\n",
      "12388 ('the', 'DET')\n",
      "12389 ('change', 'NOUN')\n",
      "12390 ('of', 'ADP')\n",
      "12391 ('partners', 'NOUN')\n",
      "12392 ('had', 'VERB')\n",
      "12393 ('never', 'ADV')\n",
      "12394 ('happened', 'VERB')\n",
      "12395 ('.', '')\n",
      "12396 ('Oceania', 'NOUN')\n",
      "12397 ('was', 'VERB')\n",
      "12398 ('at', 'ADP')\n",
      "12399 ('war', 'NOUN')\n",
      "12400 ('with', 'ADP')\n",
      "12401 ('Eurasia', 'NOUN')\n",
      "12402 (':', '')\n",
      "12403 ('therefore', 'ADV')\n",
      "12404 ('Oceania', 'NOUN')\n",
      "12405 ('had', 'VERB')\n",
      "12406 ('always', 'ADV')\n",
      "12407 ('been', 'VERB')\n",
      "12408 ('at', 'ADP')\n",
      "12409 ('war', 'NOUN')\n",
      "12410 ('with', 'ADP')\n",
      "12411 ('Eurasia', 'NOUN')\n",
      "12412 ('.', '')\n",
      "12413 ('The', 'DET')\n",
      "12414 ('enemy', 'NOUN')\n",
      "12415 ('of', 'ADP')\n",
      "12416 ('the', 'DET')\n",
      "12417 ('moment', 'NOUN')\n",
      "12418 ('always', 'ADV')\n",
      "12419 ('represented', 'VERB')\n",
      "12420 ('absolute', 'ADJ')\n",
      "12421 ('evil', 'NOUN')\n",
      "12422 (',', '')\n",
      "12423 ('and', 'CONJ')\n",
      "12424 ('it', 'PRON')\n",
      "12425 ('followed', 'VERB')\n",
      "12426 ('that', 'CONJ')\n",
      "12427 ('any', 'DET')\n",
      "12428 ('past', 'ADJ')\n",
      "12429 ('or', 'CONJ')\n",
      "12430 ('future', 'ADJ')\n",
      "12431 ('agreement', 'NOUN')\n",
      "12432 ('with', 'ADP')\n",
      "12433 ('him', 'PRON')\n",
      "12434 ('was', 'VERB')\n",
      "12435 ('impossible', 'ADJ')\n",
      "12436 ('.', '')\n",
      "12437 ('The', 'DET')\n",
      "12438 ('frightening', 'ADJ')\n",
      "12439 ('thing', 'NOUN')\n",
      "12440 (',', '')\n",
      "12441 ('he', 'PRON')\n",
      "12442 ('reflected', 'VERB')\n",
      "12443 ('for', 'ADP')\n",
      "12444 ('the', 'DET')\n",
      "12445 ('ten', 'NUM')\n",
      "12446 ('thousandth', 'ADJ')\n",
      "12447 ('time', 'NOUN')\n",
      "12448 ('as', 'CONJ')\n",
      "12449 ('he', 'PRON')\n",
      "12450 ('forced', 'VERB')\n",
      "12451 ('his', 'DET')\n",
      "12452 ('shoulders', 'NOUN')\n",
      "12453 ('painfully', 'ADV')\n",
      "12454 ('backward', 'ADV')\n",
      "12455 ('(', '')\n",
      "12456 ('with', 'ADP')\n",
      "12457 ('hands', 'NOUN')\n",
      "12458 ('on', 'ADP')\n",
      "12459 ('hips', 'NOUN')\n",
      "12460 (',', '')\n",
      "12461 ('they', 'PRON')\n",
      "12462 ('were', 'VERB')\n",
      "12463 ('gyrating', 'VERB')\n",
      "12464 ('their', 'DET')\n",
      "12465 ('bodies', 'NOUN')\n",
      "12466 ('from', 'ADP')\n",
      "12467 ('the', 'DET')\n",
      "12468 ('waist', 'NOUN')\n",
      "12469 (',', '')\n",
      "12470 ('an', 'DET')\n",
      "12471 ('exercise', 'NOUN')\n",
      "12472 ('that', 'PRON')\n",
      "12473 ('was', 'VERB')\n",
      "12474 ('supposed', 'ADJ')\n",
      "12475 ('to', 'ADP')\n",
      "12476 ('be', 'VERB')\n",
      "12477 ('good', 'ADJ')\n",
      "12478 ('for', 'ADP')\n",
      "12479 ('the', 'DET')\n",
      "12480 ('back', 'NOUN')\n",
      "12481 ('muscles', 'NOUN')\n",
      "12482 (')', '')\n",
      "12483 ('-', '')\n",
      "12484 ('the', 'DET')\n",
      "12485 ('frightening', 'ADJ')\n",
      "12486 ('thing', 'NOUN')\n",
      "12487 ('was', 'VERB')\n",
      "12488 ('that', 'CONJ')\n",
      "12489 ('it', 'PRON')\n",
      "12490 ('might', 'VERB')\n",
      "12491 ('all', 'PRON')\n",
      "12492 ('be', 'VERB')\n",
      "12493 ('true', 'ADJ')\n",
      "12494 ('.', '')\n",
      "12495 ('If', 'CONJ')\n",
      "12496 ('the', 'DET')\n",
      "12497 ('Party', 'NOUN')\n",
      "12498 ('could', 'VERB')\n",
      "12499 ('thrust', 'VERB')\n",
      "12500 ('its', 'DET')\n",
      "12501 ('hand', 'NOUN')\n",
      "12502 ('into', 'ADP')\n",
      "12503 ('the', 'DET')\n",
      "12504 ('past', 'NOUN')\n",
      "12505 ('and', 'CONJ')\n",
      "12506 ('say', 'VERB')\n",
      "12507 ('of', 'ADP')\n",
      "12508 ('this', 'DET')\n",
      "12509 ('or', 'CONJ')\n",
      "12510 ('that', 'DET')\n",
      "12511 ('event', 'NOUN')\n",
      "12512 (',', '')\n",
      "12513 ('it', 'PRON')\n",
      "12514 ('never', 'ADV')\n",
      "12515 ('happened', 'VERB')\n",
      "12516 ('-', '')\n",
      "12517 ('that', 'PRON')\n",
      "12518 (',', '')\n",
      "12519 ('surely', 'ADV')\n",
      "12520 (',', '')\n",
      "12521 ('was', 'VERB')\n",
      "12522 ('more', 'ADV')\n",
      "12523 ('terrifying', 'ADJ')\n",
      "12524 ('than', 'ADP')\n",
      "12525 ('mere', 'ADJ')\n",
      "12526 ('torture', 'NOUN')\n",
      "12527 ('and', 'CONJ')\n",
      "12528 ('death', 'NOUN')\n",
      "12529 ('?', '')\n",
      "12530 ('The', 'DET')\n",
      "12531 ('Party', 'NOUN')\n",
      "12532 ('said', 'VERB')\n",
      "12533 ('that', 'CONJ')\n",
      "12534 ('Oceania', 'NOUN')\n",
      "12535 ('had', 'VERB')\n",
      "12536 ('never', 'ADV')\n",
      "12537 ('been', 'VERB')\n",
      "12538 ('in', 'ADP')\n",
      "12539 ('alliance', 'NOUN')\n",
      "12540 ('with', 'ADP')\n",
      "12541 ('Eurasia', 'NOUN')\n",
      "12542 ('.', '')\n",
      "12543 ('He', 'PRON')\n",
      "12544 (',', '')\n",
      "12545 ('Winston', 'NOUN')\n",
      "12546 ('Smith', 'NOUN')\n",
      "12547 (',', '')\n",
      "12548 ('knew', 'VERB')\n",
      "12549 ('that', 'CONJ')\n",
      "12550 ('Oceania', 'NOUN')\n",
      "12551 ('had', 'VERB')\n",
      "12552 ('been', 'VERB')\n",
      "12553 ('in', 'ADP')\n",
      "12554 ('alliance', 'NOUN')\n",
      "12555 ('with', 'ADP')\n",
      "12556 ('Eurasia', 'NOUN')\n",
      "12557 ('as', 'ADV')\n",
      "12558 ('short', 'ADJ')\n",
      "12559 ('a', 'DET')\n",
      "12560 ('time', 'NOUN')\n",
      "12561 ('as', 'CONJ')\n",
      "12562 ('four', 'NUM')\n",
      "12563 ('years', 'NOUN')\n",
      "12564 ('ago', 'ADP')\n",
      "12565 ('.', '')\n",
      "12566 ('But', 'CONJ')\n",
      "12567 ('where', 'ADV')\n",
      "12568 ('did', 'VERB')\n",
      "12569 ('that', 'DET')\n",
      "12570 ('knowledge', 'NOUN')\n",
      "12571 ('exist', 'VERB')\n",
      "12572 ('?', '')\n",
      "12573 ('Only', 'ADV')\n",
      "12574 ('in', 'ADP')\n",
      "12575 ('his', 'DET')\n",
      "12576 ('own', 'ADJ')\n",
      "12577 ('consciousness', 'NOUN')\n",
      "12578 (',', '')\n",
      "12579 ('which', 'PRON')\n",
      "12580 ('in', 'ADP')\n",
      "12581 ('any', 'DET')\n",
      "12582 ('case', 'NOUN')\n",
      "12583 ('must', 'VERB')\n",
      "12584 ('soon', 'ADV')\n",
      "12585 ('be', 'VERB')\n",
      "12586 ('annihilated', 'VERB')\n",
      "12587 ('.', '')\n",
      "12588 ('And', 'CONJ')\n",
      "12589 ('if', 'CONJ')\n",
      "12590 ('all', 'DET')\n",
      "12591 ('others', 'PRON')\n",
      "12592 ('accepted', 'VERB')\n",
      "12593 ('the', 'DET')\n",
      "12594 ('lie', 'NOUN')\n",
      "12595 ('which', 'PRON')\n",
      "12596 ('the', 'DET')\n",
      "12597 ('Party', 'NOUN')\n",
      "12598 ('imposed', 'VERB')\n",
      "12599 ('-', '')\n",
      "12600 ('if', 'CONJ')\n",
      "12601 ('all', 'DET')\n",
      "12602 ('records', 'NOUN')\n",
      "12603 ('told', 'VERB')\n",
      "12604 ('the', 'DET')\n",
      "12605 ('same', 'ADJ')\n",
      "12606 ('tale', 'NOUN')\n",
      "12607 ('-', '')\n",
      "12608 ('then', 'ADV')\n",
      "12609 ('the', 'DET')\n",
      "12610 ('lie', 'NOUN')\n",
      "12611 ('passed', 'VERB')\n",
      "12612 ('into', 'ADP')\n",
      "12613 ('history', 'NOUN')\n",
      "12614 ('and', 'CONJ')\n",
      "12615 ('became', 'VERB')\n",
      "12616 ('truth', 'NOUN')\n",
      "12617 ('.', '')\n",
      "12618 ('Who', 'PRON')\n",
      "12619 ('controls', 'VERB')\n",
      "12620 ('the', 'DET')\n",
      "12621 ('past', 'NOUN')\n",
      "12622 (',', '')\n",
      "12623 ('ran', 'VERB')\n",
      "12624 ('the', 'DET')\n",
      "12625 ('Party', 'NOUN')\n",
      "12626 ('slogan', 'NOUN')\n",
      "12627 (',', '')\n",
      "12628 ('controls', 'VERB')\n",
      "12629 ('the', 'DET')\n",
      "12630 ('future', 'NOUN')\n",
      "12631 (':', '')\n",
      "12632 ('who', 'PRON')\n",
      "12633 ('controls', 'VERB')\n",
      "12634 ('the', 'DET')\n",
      "12635 ('present', 'NOUN')\n",
      "12636 ('controls', 'VERB')\n",
      "12637 ('the', 'DET')\n",
      "12638 ('past', 'NOUN')\n",
      "12639 ('.', '')\n",
      "12640 ('And', 'CONJ')\n",
      "12641 ('yet', 'CONJ')\n",
      "12642 ('the', 'DET')\n",
      "12643 ('past', 'NOUN')\n",
      "12644 (',', '')\n",
      "12645 ('though', 'CONJ')\n",
      "12646 ('of', 'ADP')\n",
      "12647 ('its', 'DET')\n",
      "12648 ('nature', 'NOUN')\n",
      "12649 ('alterable', 'ADJ')\n",
      "12650 (',', '')\n",
      "12651 ('never', 'ADV')\n",
      "12652 ('had', 'VERB')\n",
      "12653 ('been', 'VERB')\n",
      "12654 ('altered', 'VERB')\n",
      "12655 ('.', '')\n",
      "12656 ('Whatever', 'PRON')\n",
      "12657 ('was', 'VERB')\n",
      "12658 ('true', 'ADJ')\n",
      "12659 ('now', 'ADV')\n",
      "12660 ('was', 'VERB')\n",
      "12661 ('true', 'ADJ')\n",
      "12662 ('from', 'ADP')\n",
      "12663 ('everlasting', 'ADJ')\n",
      "12664 ('to', 'ADP')\n",
      "12665 ('everlasting', 'ADJ')\n",
      "12666 ('.', '')\n",
      "12667 ('It', 'PRON')\n",
      "12668 ('was', 'VERB')\n",
      "12669 ('quite', 'ADV')\n",
      "12670 ('simple', 'ADJ')\n",
      "12671 ('.', '')\n",
      "12672 ('All', 'DET')\n",
      "12673 ('that', 'PRON')\n",
      "12674 ('was', 'VERB')\n",
      "12675 ('needed', 'VERB')\n",
      "12676 ('was', 'VERB')\n",
      "12677 ('an', 'DET')\n",
      "12678 ('unending', 'ADJ')\n",
      "12679 ('series', 'NOUN')\n",
      "12680 ('of', 'ADP')\n",
      "12681 ('victories', 'NOUN')\n",
      "12682 ('over', 'ADP')\n",
      "12683 ('your', 'DET')\n",
      "12684 ('own', 'ADJ')\n",
      "12685 ('memory', 'NOUN')\n",
      "12686 ('.', '')\n",
      "12687 ('Reality', 'NOUN')\n",
      "12688 ('control', 'NOUN')\n",
      "12689 (',', '')\n",
      "12690 ('they', 'PRON')\n",
      "12691 ('called', 'VERB')\n",
      "12692 ('it', 'PRON')\n",
      "12693 (':', '')\n",
      "12694 ('in', 'ADP')\n",
      "12695 ('Newspeak', 'NOUN')\n",
      "12696 (',', '')\n",
      "12697 ('doublethink', 'NOUN')\n",
      "12698 ('Stand', 'VERB')\n",
      "12699 ('easy', 'ADV')\n",
      "12700 ('!', '')\n",
      "12701 ('barked', 'VERB')\n",
      "12702 ('the', 'DET')\n",
      "12703 ('instructress', 'NOUN')\n",
      "12704 (',', '')\n",
      "12705 ('a', 'DET')\n",
      "12706 ('little', 'ADV')\n",
      "12707 ('more', 'ADV')\n",
      "12708 ('genially', 'ADV')\n",
      "12709 ('.', '')\n",
      "12710 ('Winston', 'NOUN')\n",
      "12711 ('sank', 'VERB')\n",
      "12712 ('his', 'DET')\n",
      "12713 ('arms', 'NOUN')\n",
      "12714 ('to', 'ADP')\n",
      "12715 ('his', 'DET')\n",
      "12716 ('sides', 'NOUN')\n",
      "12717 ('and', 'CONJ')\n",
      "12718 ('slowly', 'ADV')\n",
      "12719 ('refilled', 'VERB')\n",
      "12720 ('his', 'DET')\n",
      "12721 ('lungs', 'NOUN')\n",
      "12722 ('with', 'ADP')\n",
      "12723 ('air', 'NOUN')\n",
      "12724 ('.', '')\n",
      "12725 ('His', 'DET')\n",
      "12726 ('mind', 'NOUN')\n",
      "12727 ('slid', 'VERB')\n",
      "12728 ('away', 'ADV')\n",
      "12729 ('into', 'ADP')\n",
      "12730 ('the', 'DET')\n",
      "12731 ('labyrinthine', 'ADJ')\n",
      "12732 ('world', 'NOUN')\n",
      "12733 ('of', 'ADP')\n",
      "12734 ('doublethink', 'NOUN')\n",
      "12735 ('.', '')\n",
      "12736 ('To', 'ADP')\n",
      "12737 ('know', 'VERB')\n",
      "12738 ('and', 'CONJ')\n",
      "12739 ('not', 'ADV')\n",
      "12740 ('to', 'ADP')\n",
      "12741 ('know', 'VERB')\n",
      "12742 (',', '')\n",
      "12743 ('to', 'ADP')\n",
      "12744 ('be', 'VERB')\n",
      "12745 ('conscious', 'ADJ')\n",
      "12746 ('of', 'ADP')\n",
      "12747 ('complete', 'ADJ')\n",
      "12748 ('truthfulness', 'NOUN')\n",
      "12749 ('while', 'CONJ')\n",
      "12750 ('telling', 'VERB')\n",
      "12751 ('carefully', 'ADV')\n",
      "12752 ('constructed', 'VERB')\n",
      "12753 ('lies', 'NOUN')\n",
      "12754 (',', '')\n",
      "12755 ('to', 'ADP')\n",
      "12756 ('hold', 'VERB')\n",
      "12757 ('simultaneously', 'ADV')\n",
      "12758 ('two', 'NUM')\n",
      "12759 ('opinions', 'NOUN')\n",
      "12760 ('which', 'PRON')\n",
      "12761 ('cancelled', 'VERB')\n",
      "12762 ('out', 'ADP')\n",
      "12763 (',', '')\n",
      "12764 ('knowing', 'VERB')\n",
      "12765 ('them', 'PRON')\n",
      "12766 ('to', 'ADP')\n",
      "12767 ('be', 'VERB')\n",
      "12768 ('contradictory', 'ADJ')\n",
      "12769 ('and', 'CONJ')\n",
      "12770 ('believing', 'VERB')\n",
      "12771 ('in', 'ADP')\n",
      "12772 ('both', 'PRON')\n",
      "12773 ('of', 'ADP')\n",
      "12774 ('them', 'PRON')\n",
      "12775 (',', '')\n",
      "12776 ('to', 'ADP')\n",
      "12777 ('use', 'VERB')\n",
      "12778 ('logic', 'NOUN')\n",
      "12779 ('against', 'ADP')\n",
      "12780 ('logic', 'NOUN')\n",
      "12781 (',', '')\n",
      "12782 ('to', 'ADP')\n",
      "12783 ('repudiate', 'VERB')\n",
      "12784 ('morality', 'NOUN')\n",
      "12785 ('while', 'CONJ')\n",
      "12786 ('laying', 'VERB')\n",
      "12787 ('claim', 'NOUN')\n",
      "12788 ('to', 'ADP')\n",
      "12789 ('it', 'PRON')\n",
      "12790 (',', '')\n",
      "12791 ('to', 'ADP')\n",
      "12792 ('believe', 'VERB')\n",
      "12793 ('that', 'CONJ')\n",
      "12794 ('democracy', 'NOUN')\n",
      "12795 ('was', 'VERB')\n",
      "12796 ('impossible', 'ADJ')\n",
      "12797 ('and', 'CONJ')\n",
      "12798 ('that', 'CONJ')\n",
      "12799 ('the', 'DET')\n",
      "12800 ('Party', 'NOUN')\n",
      "12801 ('was', 'VERB')\n",
      "12802 ('the', 'DET')\n",
      "12803 ('guardian', 'NOUN')\n",
      "12804 ('of', 'ADP')\n",
      "12805 ('democracy', 'NOUN')\n",
      "12806 (',', '')\n",
      "12807 ('to', 'ADP')\n",
      "12808 ('forget', 'VERB')\n",
      "12809 ('whatever', 'PRON')\n",
      "12810 ('it', 'PRON')\n",
      "12811 ('was', 'VERB')\n",
      "12812 ('necessary', 'ADJ')\n",
      "12813 ('to', 'ADP')\n",
      "12814 ('forget', 'VERB')\n",
      "12815 (',', '')\n",
      "12816 ('then', 'ADV')\n",
      "12817 ('to', 'ADP')\n",
      "12818 ('draw', 'VERB')\n",
      "12819 ('it', 'PRON')\n",
      "12820 ('back', 'ADV')\n",
      "12821 ('into', 'ADP')\n",
      "12822 ('memory', 'NOUN')\n",
      "12823 ('again', 'ADV')\n",
      "12824 ('at', 'ADP')\n",
      "12825 ('the', 'DET')\n",
      "12826 ('moment', 'NOUN')\n",
      "12827 ('when', 'CONJ')\n",
      "12828 ('it', 'PRON')\n",
      "12829 ('was', 'VERB')\n",
      "12830 ('needed', 'VERB')\n",
      "12831 (',', '')\n",
      "12832 ('and', 'CONJ')\n",
      "12833 ('then', 'ADV')\n",
      "12834 ('promptly', 'ADV')\n",
      "12835 ('to', 'ADP')\n",
      "12836 ('forget', 'VERB')\n",
      "12837 ('it', 'PRON')\n",
      "12838 ('again', 'ADV')\n",
      "12839 (':', '')\n",
      "12840 ('and', 'CONJ')\n",
      "12841 ('above', 'ADP')\n",
      "12842 ('all', 'PRON')\n",
      "12843 (',', '')\n",
      "12844 ('to', 'ADP')\n",
      "12845 ('apply', 'VERB')\n",
      "12846 ('the', 'DET')\n",
      "12847 ('same', 'ADJ')\n",
      "12848 ('process', 'NOUN')\n",
      "12849 ('to', 'ADP')\n",
      "12850 ('the', 'DET')\n",
      "12851 ('process', 'NOUN')\n",
      "12852 ('itself', 'PRON')\n",
      "12853 ('.', '')\n",
      "12854 ('That', 'PRON')\n",
      "12855 ('was', 'VERB')\n",
      "12856 ('the', 'DET')\n",
      "12857 ('ultimate', 'ADJ')\n",
      "12858 ('subtlety', 'NOUN')\n",
      "12859 (':', '')\n",
      "12860 ('consciously', 'ADV')\n",
      "12861 ('to', 'ADP')\n",
      "12862 ('induce', 'VERB')\n",
      "12863 ('unconsciousness', 'NOUN')\n",
      "12864 (',', '')\n",
      "12865 ('and', 'CONJ')\n",
      "12866 ('then', 'ADV')\n",
      "12867 (',', '')\n",
      "12868 ('once', 'ADV')\n",
      "12869 ('again', 'ADV')\n",
      "12870 (',', '')\n",
      "12871 ('to', 'ADP')\n",
      "12872 ('become', 'VERB')\n",
      "12873 ('unconscious', 'ADJ')\n",
      "12874 ('of', 'ADP')\n",
      "12875 ('the', 'DET')\n",
      "12876 ('act', 'NOUN')\n",
      "12877 ('of', 'ADP')\n",
      "12878 ('hypnosis', 'NOUN')\n",
      "12879 ('you', 'PRON')\n",
      "12880 ('had', 'VERB')\n",
      "12881 ('just', 'ADV')\n",
      "12882 ('performed', 'VERB')\n",
      "12883 ('.', '')\n",
      "12884 ('Even', 'ADV')\n",
      "12885 ('to', 'ADP')\n",
      "12886 ('understand', 'VERB')\n",
      "12887 ('the', 'DET')\n",
      "12888 ('word', 'NOUN')\n",
      "12889 ('doublethink', 'NOUN')\n",
      "12890 ('involved', 'VERB')\n",
      "12891 ('the', 'DET')\n",
      "12892 ('use', 'NOUN')\n",
      "12893 ('of', 'ADP')\n",
      "12894 ('doublethink', 'NOUN')\n",
      "12895 ('.', '')\n",
      "12896 ('The', 'DET')\n",
      "12897 ('instructress', 'NOUN')\n",
      "12898 ('had', 'VERB')\n",
      "12899 ('called', 'VERB')\n",
      "12900 ('them', 'PRON')\n",
      "12901 ('to', 'ADP')\n",
      "12902 ('attention', 'NOUN')\n",
      "12903 ('again', 'ADV')\n",
      "12904 ('.', '')\n",
      "12905 ('And', 'CONJ')\n",
      "12906 ('now', 'ADV')\n",
      "12907 ('let', 'VERB')\n",
      "12908 (\"'s\", 'PRON')\n",
      "12909 ('see', 'VERB')\n",
      "12910 ('which', 'PRON')\n",
      "12911 ('of', 'ADP')\n",
      "12912 ('us', 'PRON')\n",
      "12913 ('can', 'VERB')\n",
      "12914 ('touch', 'VERB')\n",
      "12915 ('our', 'DET')\n",
      "12916 ('toes', 'NOUN')\n",
      "12917 ('!', '')\n",
      "12918 ('she', 'PRON')\n",
      "12919 ('said', 'VERB')\n",
      "12920 ('enthusiastically', 'ADV')\n",
      "12921 ('.', '')\n",
      "12922 ('Right', 'ADV')\n",
      "12923 ('over', 'ADV')\n",
      "12924 ('from', 'ADP')\n",
      "12925 ('the', 'DET')\n",
      "12926 ('hips', 'NOUN')\n",
      "12927 (',', '')\n",
      "12928 ('please', 'ADV')\n",
      "12929 (',', '')\n",
      "12930 ('comrades', 'NOUN')\n",
      "12931 ('.', '')\n",
      "12932 ('One-two', 'NOUN')\n",
      "12933 ('!', '')\n",
      "12934 ('One-two', 'NOUN')\n",
      "12935 ('!', '')\n",
      "\n",
      "12936 ('...', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12937 ('Winston', 'NOUN')\n",
      "12938 ('loathed', 'VERB')\n",
      "12939 ('this', 'DET')\n",
      "12940 ('exercise', 'NOUN')\n",
      "12941 (',', '')\n",
      "12942 ('which', 'PRON')\n",
      "12943 ('sent', 'VERB')\n",
      "12944 ('shooting', 'ADJ')\n",
      "12945 ('pains', 'NOUN')\n",
      "12946 ('all', 'DET')\n",
      "12947 ('the', 'DET')\n",
      "12948 ('way', 'NOUN')\n",
      "12949 ('from', 'ADP')\n",
      "12950 ('his', 'DET')\n",
      "12951 ('heels', 'NOUN')\n",
      "12952 ('to', 'ADP')\n",
      "12953 ('his', 'DET')\n",
      "12954 ('buttocks', 'NOUN')\n",
      "12955 ('and', 'CONJ')\n",
      "12956 ('often', 'ADV')\n",
      "12957 ('ended', 'VERB')\n",
      "12958 ('by', 'ADP')\n",
      "12959 ('bringing', 'VERB')\n",
      "12960 ('on', 'ADP')\n",
      "12961 ('another', 'DET')\n",
      "12962 ('coughing', 'VERB')\n",
      "12963 ('fit', 'NOUN')\n",
      "12964 ('.', '')\n",
      "12965 ('The', 'DET')\n",
      "12966 ('half-pleasant', 'ADJ')\n",
      "12967 ('quality', 'NOUN')\n",
      "12968 ('went', 'VERB')\n",
      "12969 ('out', 'ADP')\n",
      "12970 ('of', 'ADP')\n",
      "12971 ('his', 'DET')\n",
      "12972 ('meditations', 'NOUN')\n",
      "12973 ('.', '')\n",
      "12974 ('The', 'DET')\n",
      "12975 ('past', 'NOUN')\n",
      "12976 (',', '')\n",
      "12977 ('he', 'PRON')\n",
      "12978 ('reflected', 'VERB')\n",
      "12979 (',', '')\n",
      "12980 ('had', 'VERB')\n",
      "12981 ('not', 'ADV')\n",
      "12982 ('merely', 'ADV')\n",
      "12983 ('been', 'VERB')\n",
      "12984 ('altered', 'VERB')\n",
      "12985 (',', '')\n",
      "12986 ('it', 'PRON')\n",
      "12987 ('had', 'VERB')\n",
      "12988 ('been', 'VERB')\n",
      "12989 ('actually', 'ADV')\n",
      "12990 ('destroyed', 'VERB')\n",
      "12991 ('.', '')\n",
      "12992 ('For', 'CONJ')\n",
      "12993 ('how', 'ADV')\n",
      "12994 ('could', 'VERB')\n",
      "12995 ('you', 'PRON')\n",
      "12996 ('establish', 'VERB')\n",
      "12997 ('even', 'ADV')\n",
      "12998 ('the', 'DET')\n",
      "12999 ('most', 'ADV')\n",
      "13000 ('obvious', 'ADJ')\n",
      "13001 ('fact', 'NOUN')\n",
      "13002 ('when', 'CONJ')\n",
      "13003 ('there', 'PRON')\n",
      "13004 ('existed', 'VERB')\n",
      "13005 ('no', 'DET')\n",
      "13006 ('record', 'NOUN')\n",
      "13007 ('outside', 'ADP')\n",
      "13008 ('your', 'DET')\n",
      "13009 ('own', 'ADJ')\n",
      "13010 ('memory', 'NOUN')\n",
      "13011 ('?', '')\n",
      "13012 ('He', 'PRON')\n",
      "13013 ('tried', 'VERB')\n",
      "13014 ('to', 'ADP')\n",
      "13015 ('remember', 'VERB')\n",
      "13016 ('in', 'ADP')\n",
      "13017 ('what', 'DET')\n",
      "13018 ('year', 'NOUN')\n",
      "13019 ('he', 'PRON')\n",
      "13020 ('had', 'VERB')\n",
      "13021 ('first', 'ADV')\n",
      "13022 ('heard', 'VERB')\n",
      "13023 ('mention', 'NOUN')\n",
      "13024 ('of', 'ADP')\n",
      "13025 ('Big', 'ADJ')\n",
      "13026 ('Brother', 'NOUN')\n",
      "13027 ('.', '')\n",
      "13028 ('He', 'PRON')\n",
      "13029 ('thought', 'VERB')\n",
      "13030 ('it', 'PRON')\n",
      "13031 ('must', 'VERB')\n",
      "13032 ('have', 'VERB')\n",
      "13033 ('been', 'VERB')\n",
      "13034 ('at', 'ADP')\n",
      "13035 ('some', 'DET')\n",
      "13036 ('time', 'NOUN')\n",
      "13037 ('in', 'ADP')\n",
      "13038 ('the', 'DET')\n",
      "13039 ('sixties', 'NOUN')\n",
      "13040 (',', '')\n",
      "13041 ('but', 'CONJ')\n",
      "13042 ('it', 'PRON')\n",
      "13043 ('was', 'VERB')\n",
      "13044 ('impossible', 'ADJ')\n",
      "13045 ('to', 'ADP')\n",
      "13046 ('be', 'VERB')\n",
      "13047 ('certain', 'ADJ')\n",
      "13048 ('.', '')\n",
      "13049 ('In', 'ADP')\n",
      "13050 ('the', 'DET')\n",
      "13051 ('Party', 'NOUN')\n",
      "13052 ('histories', 'NOUN')\n",
      "13053 (',', '')\n",
      "13054 ('of', 'ADP')\n",
      "13055 ('course', 'NOUN')\n",
      "13056 (',', '')\n",
      "13057 ('Big', 'ADJ')\n",
      "13058 ('Brother', 'NOUN')\n",
      "13059 ('figured', 'VERB')\n",
      "13060 ('as', 'ADP')\n",
      "13061 ('the', 'DET')\n",
      "13062 ('leader', 'NOUN')\n",
      "13063 ('and', 'CONJ')\n",
      "13064 ('guardian', 'NOUN')\n",
      "13065 ('of', 'ADP')\n",
      "13066 ('the', 'DET')\n",
      "13067 ('Revolution', 'NOUN')\n",
      "13068 ('since', 'ADP')\n",
      "13069 ('its', 'DET')\n",
      "13070 ('very', 'ADV')\n",
      "13071 ('earliest', 'ADJ')\n",
      "13072 ('days', 'NOUN')\n",
      "13073 ('.', '')\n",
      "13074 ('His', 'DET')\n",
      "13075 ('exploits', 'NOUN')\n",
      "13076 ('had', 'VERB')\n",
      "13077 ('been', 'VERB')\n",
      "13078 ('gradually', 'ADV')\n",
      "13079 ('pushed', 'VERB')\n",
      "13080 ('backwards', 'ADV')\n",
      "13081 ('in', 'ADP')\n",
      "13082 ('time', 'NOUN')\n",
      "13083 ('until', 'CONJ')\n",
      "13084 ('already', 'ADV')\n",
      "13085 ('they', 'PRON')\n",
      "13086 ('extended', 'VERB')\n",
      "13087 ('into', 'ADP')\n",
      "13088 ('the', 'DET')\n",
      "13089 ('fabulous', 'ADJ')\n",
      "13090 ('world', 'NOUN')\n",
      "13091 ('of', 'ADP')\n",
      "13092 ('the', 'DET')\n",
      "13093 ('forties', 'NOUN')\n",
      "13094 ('and', 'CONJ')\n",
      "13095 ('the', 'DET')\n",
      "13096 ('thirties', 'NOUN')\n",
      "13097 (',', '')\n",
      "13098 ('when', 'CONJ')\n",
      "13099 ('the', 'DET')\n",
      "13100 ('capitalists', 'NOUN')\n",
      "13101 ('in', 'ADP')\n",
      "13102 ('their', 'DET')\n",
      "13103 ('strange', 'ADJ')\n",
      "13104 ('cylindrical', 'ADJ')\n",
      "13105 ('hats', 'NOUN')\n",
      "13106 ('still', 'ADV')\n",
      "13107 ('rode', 'VERB')\n",
      "13108 ('through', 'ADP')\n",
      "13109 ('the', 'DET')\n",
      "13110 ('streets', 'NOUN')\n",
      "13111 ('of', 'ADP')\n",
      "13112 ('London', 'NOUN')\n",
      "13113 ('in', 'ADP')\n",
      "13114 ('great', 'ADJ')\n",
      "13115 ('gleaming', 'ADJ')\n",
      "13116 ('motor-cars', 'NOUN')\n",
      "13117 ('or', 'CONJ')\n",
      "13118 ('horse', 'NOUN')\n",
      "13119 ('carriages', 'NOUN')\n",
      "13120 ('with', 'ADP')\n",
      "13121 ('glass', 'ADJ')\n",
      "13122 ('sides', 'NOUN')\n",
      "13123 ('.', '')\n",
      "13124 ('There', 'PRON')\n",
      "13125 ('was', 'VERB')\n",
      "13126 ('no', 'DET')\n",
      "13127 ('knowing', 'VERB')\n",
      "13128 ('how', 'ADV')\n",
      "13129 ('much', 'ADJ')\n",
      "13130 ('of', 'ADP')\n",
      "13131 ('this', 'DET')\n",
      "13132 ('legend', 'NOUN')\n",
      "13133 ('was', 'VERB')\n",
      "13134 ('true', 'ADJ')\n",
      "13135 ('and', 'CONJ')\n",
      "13136 ('how', 'ADV')\n",
      "13137 ('much', 'ADJ')\n",
      "13138 ('invented', 'VERB')\n",
      "13139 ('.', '')\n",
      "13140 ('Winston', 'NOUN')\n",
      "13141 ('could', 'VERB')\n",
      "13142 ('not', 'ADV')\n",
      "13143 ('even', 'ADV')\n",
      "13144 ('remember', 'VERB')\n",
      "13145 ('at', 'ADP')\n",
      "13146 ('what', 'DET')\n",
      "13147 ('date', 'NOUN')\n",
      "13148 ('the', 'DET')\n",
      "13149 ('Party', 'NOUN')\n",
      "13150 ('itself', 'PRON')\n",
      "13151 ('had', 'VERB')\n",
      "13152 ('come', 'VERB')\n",
      "13153 ('into', 'ADP')\n",
      "13154 ('existence', 'NOUN')\n",
      "13155 ('.', '')\n",
      "13156 ('He', 'PRON')\n",
      "13157 ('did', 'VERB')\n",
      "13158 ('not', 'ADV')\n",
      "13159 ('believe', 'VERB')\n",
      "13160 ('he', 'PRON')\n",
      "13161 ('had', 'VERB')\n",
      "13162 ('ever', 'ADV')\n",
      "13163 ('heard', 'VERB')\n",
      "13164 ('the', 'DET')\n",
      "13165 ('word', 'NOUN')\n",
      "13166 ('Ingsoc', 'NOUN')\n",
      "13167 ('before', 'ADP')\n",
      "13168 ('1960', 'NUM')\n",
      "13169 (',', '')\n",
      "13170 ('but', 'CONJ')\n",
      "13171 ('it', 'PRON')\n",
      "13172 ('was', 'VERB')\n",
      "13173 ('possible', 'ADJ')\n",
      "13174 ('that', 'CONJ')\n",
      "13175 ('in', 'ADP')\n",
      "13176 ('its', 'DET')\n",
      "13177 ('Oldspeak', 'NOUN')\n",
      "13178 ('form', 'NOUN')\n",
      "13179 ('-', '')\n",
      "13180 ('English', 'ADJ')\n",
      "13181 ('Socialism', 'NOUN')\n",
      "13182 (',', '')\n",
      "13183 ('that', 'PRON')\n",
      "13184 ('is', 'VERB')\n",
      "13185 ('to', 'ADP')\n",
      "13186 ('say', 'VERB')\n",
      "13187 ('-', '')\n",
      "13188 ('it', 'PRON')\n",
      "13189 ('had', 'VERB')\n",
      "13190 ('been', 'VERB')\n",
      "13191 ('current', 'ADJ')\n",
      "13192 ('earlier', 'ADJ')\n",
      "13193 ('.', '')\n",
      "13194 ('Everything', 'PRON')\n",
      "13195 ('melted', 'VERB')\n",
      "13196 ('into', 'ADP')\n",
      "13197 ('mist', 'NOUN')\n",
      "13198 ('.', '')\n",
      "13199 ('Sometimes', 'ADV')\n",
      "13200 (',', '')\n",
      "13201 ('indeed', 'ADV')\n",
      "13202 (',', '')\n",
      "13203 ('you', 'PRON')\n",
      "13204 ('could', 'VERB')\n",
      "13205 ('put', 'VERB')\n",
      "13206 ('your', 'DET')\n",
      "13207 ('finger', 'NOUN')\n",
      "13208 ('on', 'ADP')\n",
      "13209 ('a', 'DET')\n",
      "13210 ('definite', 'ADJ')\n",
      "13211 ('lie', 'NOUN')\n",
      "13212 ('.', '')\n",
      "13213 ('It', 'PRON')\n",
      "13214 ('was', 'VERB')\n",
      "13215 ('not', 'ADV')\n",
      "13216 ('true', 'ADJ')\n",
      "13217 (',', '')\n",
      "13218 ('for', 'ADP')\n",
      "13219 ('example', 'NOUN')\n",
      "13220 (',', '')\n",
      "13221 ('as', 'CONJ')\n",
      "13222 ('was', 'VERB')\n",
      "13223 ('claimed', 'VERB')\n",
      "13224 ('in', 'ADP')\n",
      "13225 ('the', 'DET')\n",
      "13226 ('Party', 'NOUN')\n",
      "13227 ('history', 'NOUN')\n",
      "13228 ('books', 'NOUN')\n",
      "13229 (',', '')\n",
      "13230 ('that', 'CONJ')\n",
      "13231 ('the', 'DET')\n",
      "13232 ('Party', 'NOUN')\n",
      "13233 ('had', 'VERB')\n",
      "13234 ('invented', 'VERB')\n",
      "13235 ('aeroplanes', 'NOUN')\n",
      "13236 ('.', '')\n",
      "13237 ('He', 'PRON')\n",
      "13238 ('remembered', 'VERB')\n",
      "13239 ('aeroplanes', 'NOUN')\n",
      "13240 ('since', 'ADP')\n",
      "13241 ('his', 'DET')\n",
      "13242 ('earliest', 'ADJ')\n",
      "13243 ('childhood', 'NOUN')\n",
      "13244 ('.', '')\n",
      "13245 ('But', 'CONJ')\n",
      "13246 ('you', 'PRON')\n",
      "13247 ('could', 'VERB')\n",
      "13248 ('prove', 'VERB')\n",
      "13249 ('nothing', 'PRON')\n",
      "13250 ('.', '')\n",
      "13251 ('There', 'PRON')\n",
      "13252 ('was', 'VERB')\n",
      "13253 ('never', 'ADV')\n",
      "13254 ('any', 'DET')\n",
      "13255 ('evidence', 'NOUN')\n",
      "13256 ('.', '')\n",
      "13257 ('Just', 'ADV')\n",
      "13258 ('once', 'ADV')\n",
      "13259 ('in', 'ADP')\n",
      "13260 ('his', 'DET')\n",
      "13261 ('whole', 'ADJ')\n",
      "13262 ('life', 'NOUN')\n",
      "13263 ('he', 'PRON')\n",
      "13264 ('had', 'VERB')\n",
      "13265 ('held', 'VERB')\n",
      "13266 ('in', 'ADP')\n",
      "13267 ('his', 'DET')\n",
      "13268 ('hands', 'NOUN')\n",
      "13269 ('unmistakable', 'ADJ')\n",
      "13270 ('documentary', 'ADJ')\n",
      "13271 ('proof', 'NOUN')\n",
      "13272 ('of', 'ADP')\n",
      "13273 ('the', 'DET')\n",
      "13274 ('falsification', 'NOUN')\n",
      "13275 ('of', 'ADP')\n",
      "13276 ('an', 'DET')\n",
      "13277 ('historical', 'ADJ')\n",
      "13278 ('fact', 'NOUN')\n",
      "13279 ('.', '')\n",
      "13280 ('And', 'CONJ')\n",
      "13281 ('on', 'ADP')\n",
      "13282 ('that', 'DET')\n",
      "13283 ('occasion', 'NOUN')\n",
      "13284 ('-', '')\n",
      "13285 ('Smith', 'NOUN')\n",
      "13286 ('!', '')\n",
      "13287 ('screamed', 'VERB')\n",
      "13288 ('the', 'DET')\n",
      "13289 ('shrewish', 'ADJ')\n",
      "13290 ('voice', 'NOUN')\n",
      "13291 ('from', 'ADP')\n",
      "13292 ('the', 'DET')\n",
      "13293 ('telescreen', 'NOUN')\n",
      "13294 ('.', '')\n",
      "13295 ('6079', 'NUM')\n",
      "13296 ('Smith', 'NOUN')\n",
      "13297 ('W.', 'NOUN')\n",
      "13298 ('!', '')\n",
      "13299 ('Yes', 'NOUN')\n",
      "13300 (',', '')\n",
      "13301 ('you', 'PRON')\n",
      "13302 ('!', '')\n",
      "13303 ('Bend', 'VERB')\n",
      "13304 ('lower', 'ADV')\n",
      "13305 (',', '')\n",
      "13306 ('please', 'ADV')\n",
      "13307 ('!', '')\n",
      "13308 ('You', 'PRON')\n",
      "13309 ('can', 'VERB')\n",
      "13310 ('do', 'VERB')\n",
      "13311 ('better', 'ADV')\n",
      "13312 ('than', 'ADP')\n",
      "13313 ('that', 'PRON')\n",
      "13314 ('.', '')\n",
      "13315 ('You', 'PRON')\n",
      "13316 (\"'re\", 'VERB')\n",
      "13317 ('not', 'ADV')\n",
      "13318 ('trying', 'VERB')\n",
      "13319 ('.', '')\n",
      "13320 ('Lower', 'ADV')\n",
      "13321 (',', '')\n",
      "13322 ('please', 'ADV')\n",
      "13323 ('!', '')\n",
      "13324 ('That', 'PRON')\n",
      "13325 (\"'s\", 'VERB')\n",
      "13326 ('better', 'ADJ')\n",
      "13327 (',', '')\n",
      "13328 ('comrade', 'NOUN')\n",
      "13329 ('.', '')\n",
      "13330 ('Now', 'CONJ')\n",
      "13331 ('stand', 'VERB')\n",
      "13332 ('at', 'ADP')\n",
      "13333 ('ease', 'NOUN')\n",
      "13334 (',', '')\n",
      "13335 ('the', 'DET')\n",
      "13336 ('whole', 'ADJ')\n",
      "13337 ('squad', 'NOUN')\n",
      "13338 (',', '')\n",
      "13339 ('and', 'CONJ')\n",
      "13340 ('watch', 'VERB')\n",
      "13341 ('me', 'PRON')\n",
      "13342 ('.', '')\n",
      "13343 ('A', 'DET')\n",
      "13344 ('sudden', 'ADJ')\n",
      "13345 ('hot', 'ADJ')\n",
      "13346 ('sweat', 'NOUN')\n",
      "13347 ('had', 'VERB')\n",
      "13348 ('broken', 'ADJ')\n",
      "13349 ('out', 'ADP')\n",
      "13350 ('all', 'ADV')\n",
      "13351 ('over', 'ADP')\n",
      "13352 ('Winston', 'NOUN')\n",
      "13353 (\"'s\", 'ADP')\n",
      "13354 ('body', 'NOUN')\n",
      "13355 ('.', '')\n",
      "13356 ('His', 'DET')\n",
      "13357 ('face', 'NOUN')\n",
      "13358 ('remained', 'VERB')\n",
      "13359 ('completely', 'ADV')\n",
      "13360 ('inscrutable', 'ADJ')\n",
      "13361 ('.', '')\n",
      "13362 ('Never', 'ADV')\n",
      "13363 ('show', 'VERB')\n",
      "13364 ('dismay', 'NOUN')\n",
      "13365 ('!', '')\n",
      "13366 ('Never', 'ADV')\n",
      "13367 ('show', 'VERB')\n",
      "13368 ('resentment', 'NOUN')\n",
      "13369 ('!', '')\n",
      "13370 ('A', 'DET')\n",
      "13371 ('single', 'ADJ')\n",
      "13372 ('flicker', 'NOUN')\n",
      "13373 ('of', 'ADP')\n",
      "13374 ('the', 'DET')\n",
      "13375 ('eyes', 'NOUN')\n",
      "13376 ('could', 'VERB')\n",
      "13377 ('give', 'VERB')\n",
      "13378 ('you', 'PRON')\n",
      "13379 ('away', 'ADV')\n",
      "13380 ('.', '')\n",
      "13381 ('He', 'PRON')\n",
      "13382 ('stood', 'VERB')\n",
      "13383 ('watching', 'VERB')\n",
      "13384 ('while', 'CONJ')\n",
      "13385 ('the', 'DET')\n",
      "13386 ('instructress', 'NOUN')\n",
      "13387 ('raised', 'VERB')\n",
      "13388 ('her', 'DET')\n",
      "13389 ('arms', 'NOUN')\n",
      "13390 ('above', 'ADP')\n",
      "13391 ('her', 'DET')\n",
      "13392 ('head', 'NOUN')\n",
      "13393 ('and', 'CONJ')\n",
      "13394 ('-', '')\n",
      "13395 ('one', 'PRON')\n",
      "13396 ('could', 'VERB')\n",
      "13397 ('not', 'ADV')\n",
      "13398 ('say', 'VERB')\n",
      "13399 ('gracefully', 'ADV')\n",
      "13400 (',', '')\n",
      "13401 ('but', 'CONJ')\n",
      "13402 ('with', 'ADP')\n",
      "13403 ('remarkable', 'ADJ')\n",
      "13404 ('neatness', 'NOUN')\n",
      "13405 ('and', 'CONJ')\n",
      "13406 ('efficiency', 'NOUN')\n",
      "13407 ('-', '')\n",
      "13408 ('bent', 'VERB')\n",
      "13409 ('over', 'ADV')\n",
      "13410 ('and', 'CONJ')\n",
      "13411 ('tucked', 'VERB')\n",
      "13412 ('the', 'DET')\n",
      "13413 ('first', 'ADJ')\n",
      "13414 ('joint', 'NOUN')\n",
      "13415 ('of', 'ADP')\n",
      "13416 ('her', 'DET')\n",
      "13417 ('fingers', 'NOUN')\n",
      "13418 ('under', 'ADP')\n",
      "13419 ('her', 'DET')\n",
      "13420 ('toes', 'NOUN')\n",
      "13421 ('.', '')\n",
      "13422 ('There', 'ADV')\n",
      "13423 (',', '')\n",
      "13424 ('comrades', 'NOUN')\n",
      "13425 ('!', '')\n",
      "13426 ('That', 'PRON')\n",
      "13427 (\"'s\", 'VERB')\n",
      "13428 ('how', 'ADV')\n",
      "13429 ('I', 'PRON')\n",
      "13430 ('want', 'VERB')\n",
      "13431 ('to', 'ADP')\n",
      "13432 ('see', 'VERB')\n",
      "13433 ('you', 'PRON')\n",
      "13434 ('doing', 'VERB')\n",
      "13435 ('it', 'PRON')\n",
      "13436 ('.', '')\n",
      "13437 ('Watch', 'VERB')\n",
      "13438 ('me', 'PRON')\n",
      "13439 ('again', 'ADV')\n",
      "13440 ('.', '')\n",
      "13441 ('I', 'PRON')\n",
      "13442 (\"'m\", 'VERB')\n",
      "13443 ('thirty-nine', 'NUM')\n",
      "13444 ('and', 'CONJ')\n",
      "13445 ('I', 'PRON')\n",
      "13446 (\"'ve\", 'VERB')\n",
      "13447 ('had', 'VERB')\n",
      "13448 ('four', 'NUM')\n",
      "13449 ('children', 'NOUN')\n",
      "13450 ('.', '')\n",
      "13451 ('Now', 'CONJ')\n",
      "13452 ('look', 'VERB')\n",
      "13453 ('.', '')\n",
      "13454 ('She', 'PRON')\n",
      "13455 ('bent', 'VERB')\n",
      "13456 ('over', 'ADV')\n",
      "13457 ('again', 'ADV')\n",
      "13458 ('.', '')\n",
      "13459 ('You', 'PRON')\n",
      "13460 ('see', 'VERB')\n",
      "13461 ('my', 'DET')\n",
      "13462 ('knees', 'NOUN')\n",
      "13463 (\"aren't\", 'VERB')\n",
      "13464 ('bent', 'VERB')\n",
      "13465 ('.', '')\n",
      "13466 ('You', 'PRON')\n",
      "13467 ('can', 'VERB')\n",
      "13468 ('all', 'PRON')\n",
      "13469 ('do', 'VERB')\n",
      "13470 ('it', 'PRON')\n",
      "13471 ('if', 'CONJ')\n",
      "13472 ('you', 'PRON')\n",
      "13473 ('want', 'VERB')\n",
      "13474 ('to', 'ADP')\n",
      "13475 (',', '')\n",
      "13476 ('she', 'PRON')\n",
      "13477 ('added', 'VERB')\n",
      "13478 ('as', 'CONJ')\n",
      "13479 ('she', 'PRON')\n",
      "13480 ('straightened', 'VERB')\n",
      "13481 ('herself', 'PRON')\n",
      "13482 ('up', 'ADP')\n",
      "13483 ('.', '')\n",
      "13484 ('Anyone', 'PRON')\n",
      "13485 ('under', 'ADP')\n",
      "13486 ('forty-five', 'NUM')\n",
      "13487 ('is', 'VERB')\n",
      "13488 ('perfectly', 'ADV')\n",
      "13489 ('capable', 'ADJ')\n",
      "13490 ('of', 'ADP')\n",
      "13491 ('touching', 'VERB')\n",
      "13492 ('his', 'DET')\n",
      "13493 ('toes', 'NOUN')\n",
      "13494 ('.', '')\n",
      "13495 ('We', 'PRON')\n",
      "13496 (\"don't\", 'VERB')\n",
      "13497 ('all', 'PRON')\n",
      "13498 ('have', 'VERB')\n",
      "13499 ('the', 'DET')\n",
      "13500 ('privilege', 'NOUN')\n",
      "13501 ('of', 'ADP')\n",
      "13502 ('fighting', 'VERB')\n",
      "13503 ('in', 'ADP')\n",
      "13504 ('the', 'DET')\n",
      "13505 ('front', 'ADJ')\n",
      "13506 ('line', 'NOUN')\n",
      "13507 (',', '')\n",
      "13508 ('but', 'CONJ')\n",
      "13509 ('at', 'ADP')\n",
      "13510 ('least', 'ADJ')\n",
      "13511 ('we', 'PRON')\n",
      "13512 ('can', 'VERB')\n",
      "13513 ('all', 'PRON')\n",
      "13514 ('keep', 'VERB')\n",
      "13515 ('fit', 'ADJ')\n",
      "13516 ('.', '')\n",
      "13517 ('Remember', 'VERB')\n",
      "13518 ('our', 'DET')\n",
      "13519 ('boys', 'NOUN')\n",
      "13520 ('on', 'ADP')\n",
      "13521 ('the', 'DET')\n",
      "13522 ('Malabar', 'NOUN')\n",
      "13523 ('front', 'NOUN')\n",
      "13524 ('!', '')\n",
      "13525 ('And', 'CONJ')\n",
      "13526 ('the', 'DET')\n",
      "13527 ('sailors', 'NOUN')\n",
      "13528 ('in', 'ADP')\n",
      "13529 ('the', 'DET')\n",
      "13530 ('Floating', 'ADJ')\n",
      "13531 ('Fortresses', 'NOUN')\n",
      "13532 ('!', '')\n",
      "13533 ('Just', 'ADV')\n",
      "13534 ('think', 'VERB')\n",
      "13535 ('what', 'PRON')\n",
      "13536 ('they', 'PRON')\n",
      "13537 ('have', 'VERB')\n",
      "13538 ('to', 'ADP')\n",
      "13539 ('put', 'VERB')\n",
      "13540 ('up', 'ADP')\n",
      "13541 ('with', 'ADP')\n",
      "13542 ('.', '')\n",
      "13543 ('Now', 'CONJ')\n",
      "13544 ('try', 'VERB')\n",
      "13545 ('again', 'ADV')\n",
      "13546 ('.', '')\n",
      "13547 ('That', 'PRON')\n",
      "13548 (\"'s\", 'VERB')\n",
      "13549 ('better', 'ADJ')\n",
      "13550 (',', '')\n",
      "13551 ('comrade', 'NOUN')\n",
      "13552 (',', '')\n",
      "13553 ('that', 'PRON')\n",
      "13554 (\"'s\", 'VERB')\n",
      "13555 ('much', 'ADV')\n",
      "13556 ('better', 'ADJ')\n",
      "13557 (',', '')\n",
      "13558 ('she', 'PRON')\n",
      "13559 ('added', 'VERB')\n",
      "13560 ('encouragingly', 'ADV')\n",
      "13561 ('as', 'CONJ')\n",
      "13562 ('Winston', 'NOUN')\n",
      "13563 (',', '')\n",
      "13564 ('with', 'ADP')\n",
      "13565 ('a', 'DET')\n",
      "13566 ('violent', 'ADJ')\n",
      "13567 ('lunge', 'NOUN')\n",
      "13568 (',', '')\n",
      "13569 ('succeeded', 'VERB')\n",
      "13570 ('in', 'ADP')\n",
      "13571 ('touching', 'VERB')\n",
      "13572 ('his', 'DET')\n",
      "13573 ('toes', 'NOUN')\n",
      "13574 ('with', 'ADP')\n",
      "13575 ('knees', 'NOUN')\n",
      "13576 ('unbent', 'VERB')\n",
      "13577 (',', '')\n",
      "13578 ('for', 'ADP')\n",
      "13579 ('the', 'DET')\n",
      "13580 ('first', 'ADJ')\n",
      "13581 ('time', 'NOUN')\n",
      "13582 ('in', 'ADP')\n",
      "13583 ('several', 'ADJ')\n",
      "13584 ('years', 'NOUN')\n",
      "13585 ('.', '')\n",
      "13586 ('With', 'ADP')\n",
      "13587 ('the', 'DET')\n",
      "13588 ('deep', 'ADJ')\n",
      "13589 (',', '')\n",
      "13590 ('unconscious', 'ADJ')\n",
      "13591 ('sigh', 'NOUN')\n",
      "13592 ('which', 'PRON')\n",
      "13593 ('not', 'ADV')\n",
      "13594 ('even', 'ADV')\n",
      "13595 ('the', 'DET')\n",
      "13596 ('nearness', 'NOUN')\n",
      "13597 ('of', 'ADP')\n",
      "13598 ('the', 'DET')\n",
      "13599 ('telescreen', 'NOUN')\n",
      "13600 ('could', 'VERB')\n",
      "13601 ('prevent', 'VERB')\n",
      "13602 ('him', 'PRON')\n",
      "13603 ('from', 'ADP')\n",
      "13604 ('uttering', 'VERB')\n",
      "13605 ('when', 'CONJ')\n",
      "13606 ('his', 'DET')\n",
      "13607 ('day', 'NOUN')\n",
      "13608 (\"'s\", 'ADP')\n",
      "13609 ('work', 'NOUN')\n",
      "13610 ('started', 'VERB')\n",
      "13611 (',', '')\n",
      "13612 ('Winston', 'NOUN')\n",
      "13613 ('pulled', 'VERB')\n",
      "13614 ('the', 'DET')\n",
      "13615 ('speakwrite', 'NOUN')\n",
      "13616 ('towards', 'ADP')\n",
      "13617 ('him', 'PRON')\n",
      "13618 (',', '')\n",
      "13619 ('blew', 'VERB')\n",
      "13620 ('the', 'DET')\n",
      "13621 ('dust', 'NOUN')\n",
      "13622 ('from', 'ADP')\n",
      "13623 ('its', 'DET')\n",
      "13624 ('mouthpiece', 'NOUN')\n",
      "13625 (',', '')\n",
      "13626 ('and', 'CONJ')\n",
      "13627 ('put', 'VERB')\n",
      "13628 ('on', 'ADP')\n",
      "13629 ('his', 'DET')\n",
      "13630 ('spectacles', 'NOUN')\n",
      "13631 ('.', '')\n",
      "13632 ('Then', 'ADV')\n",
      "13633 ('he', 'PRON')\n",
      "13634 ('unrolled', 'VERB')\n",
      "13635 ('and', 'CONJ')\n",
      "13636 ('clipped', 'VERB')\n",
      "13637 ('together', 'ADV')\n",
      "13638 ('four', 'NUM')\n",
      "13639 ('small', 'ADJ')\n",
      "13640 ('cylinders', 'NOUN')\n",
      "13641 ('of', 'ADP')\n",
      "13642 ('paper', 'NOUN')\n",
      "13643 ('which', 'PRON')\n",
      "13644 ('had', 'VERB')\n",
      "13645 ('already', 'ADV')\n",
      "13646 ('flopped', 'VERB')\n",
      "13647 ('out', 'ADP')\n",
      "13648 ('of', 'ADP')\n",
      "13649 ('the', 'DET')\n",
      "13650 ('pneumatic', 'ADJ')\n",
      "13651 ('tube', 'NOUN')\n",
      "13652 ('on', 'ADP')\n",
      "13653 ('the', 'DET')\n",
      "13654 ('right-hand', 'ADJ')\n",
      "13655 ('side', 'NOUN')\n",
      "13656 ('of', 'ADP')\n",
      "13657 ('his', 'DET')\n",
      "13658 ('desk', 'NOUN')\n",
      "13659 ('.', '')\n",
      "13660 ('In', 'ADP')\n",
      "13661 ('the', 'DET')\n",
      "13662 ('walls', 'NOUN')\n",
      "13663 ('of', 'ADP')\n",
      "13664 ('the', 'DET')\n",
      "13665 ('cubicle', 'NOUN')\n",
      "13666 ('there', 'PRON')\n",
      "13667 ('were', 'VERB')\n",
      "13668 ('three', 'NUM')\n",
      "13669 ('orifices', 'NOUN')\n",
      "13670 ('.', '')\n",
      "13671 ('To', 'ADP')\n",
      "13672 ('the', 'DET')\n",
      "13673 ('right', 'NOUN')\n",
      "13674 ('of', 'ADP')\n",
      "13675 ('the', 'DET')\n",
      "13676 ('speakwrite', 'NOUN')\n",
      "13677 (',', '')\n",
      "13678 ('a', 'DET')\n",
      "13679 ('small', 'ADJ')\n",
      "13680 ('pneumatic', 'ADJ')\n",
      "13681 ('tube', 'NOUN')\n",
      "13682 ('for', 'ADP')\n",
      "13683 ('written', 'VERB')\n",
      "13684 ('messages', 'NOUN')\n",
      "13685 (',', '')\n",
      "13686 ('to', 'ADP')\n",
      "13687 ('the', 'DET')\n",
      "13688 ('left', 'NOUN')\n",
      "13689 (',', '')\n",
      "13690 ('a', 'DET')\n",
      "13691 ('larger', 'ADJ')\n",
      "13692 ('one', 'PRON')\n",
      "13693 ('for', 'ADP')\n",
      "13694 ('newspapers', 'NOUN')\n",
      "13695 (';', '')\n",
      "13696 ('and', 'CONJ')\n",
      "13697 ('in', 'ADP')\n",
      "13698 ('the', 'DET')\n",
      "13699 ('side', 'NOUN')\n",
      "13700 ('wall', 'NOUN')\n",
      "13701 (',', '')\n",
      "13702 ('within', 'ADP')\n",
      "13703 ('easy', 'ADJ')\n",
      "13704 ('reach', 'NOUN')\n",
      "13705 ('of', 'ADP')\n",
      "13706 ('Winston', 'NOUN')\n",
      "13707 (\"'s\", 'ADP')\n",
      "13708 ('arm', 'NOUN')\n",
      "13709 (',', '')\n",
      "13710 ('a', 'DET')\n",
      "13711 ('large', 'ADJ')\n",
      "13712 ('oblong', 'ADJ')\n",
      "13713 ('slit', 'NOUN')\n",
      "13714 ('protected', 'VERB')\n",
      "13715 ('by', 'ADP')\n",
      "13716 ('a', 'DET')\n",
      "13717 ('wire', 'NOUN')\n",
      "13718 ('grating', 'NOUN')\n",
      "13719 ('.', '')\n",
      "13720 ('This', 'DET')\n",
      "13721 ('last', 'ADJ')\n",
      "13722 ('was', 'VERB')\n",
      "13723 ('for', 'ADP')\n",
      "13724 ('the', 'DET')\n",
      "13725 ('disposal', 'NOUN')\n",
      "13726 ('of', 'ADP')\n",
      "13727 ('waste', 'ADJ')\n",
      "13728 ('paper', 'NOUN')\n",
      "13729 ('.', '')\n",
      "13730 ('Similar', 'ADJ')\n",
      "13731 ('slits', 'NOUN')\n",
      "13732 ('existed', 'VERB')\n",
      "13733 ('in', 'ADP')\n",
      "13734 ('thousands', 'NOUN')\n",
      "13735 ('or', 'CONJ')\n",
      "13736 ('tens', 'NOUN')\n",
      "13737 ('of', 'ADP')\n",
      "13738 ('thousands', 'NOUN')\n",
      "13739 ('throughout', 'ADP')\n",
      "13740 ('the', 'DET')\n",
      "13741 ('building', 'NOUN')\n",
      "13742 (',', '')\n",
      "13743 ('not', 'ADV')\n",
      "13744 ('only', 'ADV')\n",
      "13745 ('in', 'ADP')\n",
      "13746 ('every', 'DET')\n",
      "13747 ('room', 'NOUN')\n",
      "13748 ('but', 'CONJ')\n",
      "13749 ('at', 'ADP')\n",
      "13750 ('short', 'ADJ')\n",
      "13751 ('intervals', 'NOUN')\n",
      "13752 ('in', 'ADP')\n",
      "13753 ('every', 'DET')\n",
      "13754 ('corridor', 'NOUN')\n",
      "13755 ('.', '')\n",
      "13756 ('For', 'ADP')\n",
      "13757 ('some', 'DET')\n",
      "13758 ('reason', 'NOUN')\n",
      "13759 ('they', 'PRON')\n",
      "13760 ('were', 'VERB')\n",
      "13761 ('nicknamed', 'VERB')\n",
      "13762 ('memory', 'NOUN')\n",
      "13763 ('holes', 'NOUN')\n",
      "13764 ('.', '')\n",
      "13765 ('When', 'CONJ')\n",
      "13766 ('one', 'PRON')\n",
      "13767 ('knew', 'VERB')\n",
      "13768 ('that', 'CONJ')\n",
      "13769 ('any', 'DET')\n",
      "13770 ('document', 'NOUN')\n",
      "13771 ('was', 'VERB')\n",
      "13772 ('due', 'ADJ')\n",
      "13773 ('for', 'ADP')\n",
      "13774 ('destruction', 'NOUN')\n",
      "13775 (',', '')\n",
      "13776 ('or', 'CONJ')\n",
      "13777 ('even', 'ADV')\n",
      "13778 ('when', 'CONJ')\n",
      "13779 ('one', 'PRON')\n",
      "13780 ('saw', 'VERB')\n",
      "13781 ('a', 'DET')\n",
      "13782 ('scrap', 'NOUN')\n",
      "13783 ('of', 'ADP')\n",
      "13784 ('waste', 'ADJ')\n",
      "13785 ('paper', 'NOUN')\n",
      "13786 ('lying', 'VERB')\n",
      "13787 ('about', 'ADV')\n",
      "13788 (',', '')\n",
      "13789 ('it', 'PRON')\n",
      "13790 ('was', 'VERB')\n",
      "13791 ('an', 'DET')\n",
      "13792 ('automatic', 'ADJ')\n",
      "13793 ('action', 'NOUN')\n",
      "13794 ('to', 'ADP')\n",
      "13795 ('lift', 'VERB')\n",
      "13796 ('the', 'DET')\n",
      "13797 ('flap', 'NOUN')\n",
      "13798 ('of', 'ADP')\n",
      "13799 ('the', 'DET')\n",
      "13800 ('nearest', 'ADJ')\n",
      "13801 ('memory', 'NOUN')\n",
      "13802 ('hole', 'NOUN')\n",
      "13803 ('and', 'CONJ')\n",
      "13804 ('drop', 'VERB')\n",
      "13805 ('it', 'PRON')\n",
      "13806 ('in', 'ADP')\n",
      "13807 (',', '')\n",
      "13808 ('whereupon', 'ADV')\n",
      "13809 ('it', 'PRON')\n",
      "13810 ('would', 'VERB')\n",
      "13811 ('be', 'VERB')\n",
      "13812 ('whirled', 'VERB')\n",
      "13813 ('away', 'ADV')\n",
      "13814 ('on', 'ADP')\n",
      "13815 ('a', 'DET')\n",
      "13816 ('current', 'NOUN')\n",
      "13817 ('of', 'ADP')\n",
      "13818 ('warm', 'ADJ')\n",
      "13819 ('air', 'NOUN')\n",
      "13820 ('to', 'ADP')\n",
      "13821 ('the', 'DET')\n",
      "13822 ('enormous', 'ADJ')\n",
      "13823 ('furnaces', 'NOUN')\n",
      "13824 ('which', 'PRON')\n",
      "13825 ('were', 'VERB')\n",
      "13826 ('hidden', 'VERB')\n",
      "13827 ('somewhere', 'ADV')\n",
      "13828 ('in', 'ADP')\n",
      "13829 ('the', 'DET')\n",
      "13830 ('recesses', 'NOUN')\n",
      "13831 ('of', 'ADP')\n",
      "13832 ('the', 'DET')\n",
      "13833 ('building', 'NOUN')\n",
      "13834 ('.', '')\n",
      "13835 ('Winston', 'NOUN')\n",
      "13836 ('examined', 'VERB')\n",
      "13837 ('the', 'DET')\n",
      "13838 ('four', 'NUM')\n",
      "13839 ('slips', 'NOUN')\n",
      "13840 ('of', 'ADP')\n",
      "13841 ('paper', 'NOUN')\n",
      "13842 ('which', 'PRON')\n",
      "13843 ('he', 'PRON')\n",
      "13844 ('had', 'VERB')\n",
      "13845 ('unrolled', 'VERB')\n",
      "13846 ('.', '')\n",
      "13847 ('Each', 'PRON')\n",
      "13848 ('contained', 'VERB')\n",
      "13849 ('a', 'DET')\n",
      "13850 ('message', 'NOUN')\n",
      "13851 ('of', 'ADP')\n",
      "13852 ('only', 'ADV')\n",
      "13853 ('one', 'NUM')\n",
      "13854 ('or', 'CONJ')\n",
      "13855 ('two', 'NUM')\n",
      "13856 ('lines', 'NOUN')\n",
      "13857 (',', '')\n",
      "13858 ('in', 'ADP')\n",
      "13859 ('the', 'DET')\n",
      "13860 ('abbreviated', 'ADJ')\n",
      "13861 ('jargon', 'NOUN')\n",
      "13862 ('-', '')\n",
      "13863 ('not', 'ADV')\n",
      "13864 ('actually', 'ADV')\n",
      "13865 ('Newspeak', 'NOUN')\n",
      "13866 (',', '')\n",
      "13867 ('but', 'CONJ')\n",
      "13868 ('consisting', 'VERB')\n",
      "13869 ('largely', 'ADV')\n",
      "13870 ('of', 'ADP')\n",
      "13871 ('Newspeak', 'ADJ')\n",
      "13872 ('words', 'NOUN')\n",
      "13873 ('-', '')\n",
      "13874 ('which', 'PRON')\n",
      "13875 ('was', 'VERB')\n",
      "13876 ('used', 'VERB')\n",
      "13877 ('in', 'ADP')\n",
      "13878 ('the', 'DET')\n",
      "13879 ('Ministry', 'NOUN')\n",
      "13880 ('for', 'ADP')\n",
      "13881 ('internal', 'ADJ')\n",
      "13882 ('purposes', 'NOUN')\n",
      "13883 ('.', '')\n",
      "13884 ('They', 'PRON')\n",
      "13885 ('ran', 'VERB')\n",
      "13886 (':', '')\n",
      "13887 ('times', 'NOUN')\n",
      "13888 ('17.3.84', 'NUM')\n",
      "13889 ('bb', 'X')\n",
      "13890 ('speech', 'NOUN')\n",
      "13891 ('malreported', 'VERB')\n",
      "13892 ('africa', 'NOUN')\n",
      "13893 ('rectify', 'VERB')\n",
      "13894 ('times', 'NOUN')\n",
      "13895 ('19.12.83', 'NUM')\n",
      "13896 ('forecasts', 'NOUN')\n",
      "13897 ('3', 'NUM')\n",
      "13898 ('yp', 'X')\n",
      "13899 ('4th', 'NUM')\n",
      "13900 ('quarter', 'NOUN')\n",
      "13901 ('83', 'NUM')\n",
      "13902 ('misprints', 'NOUN')\n",
      "13903 ('verify', 'VERB')\n",
      "13904 ('current', 'ADJ')\n",
      "13905 ('issue', 'NOUN')\n",
      "13906 ('times', 'NOUN')\n",
      "13907 ('14.2.84', 'NUM')\n",
      "13908 ('miniplenty', 'X')\n",
      "13909 ('malquoted', 'VERB')\n",
      "13910 ('chocolate', 'NOUN')\n",
      "13911 ('rectify', 'VERB')\n",
      "13912 ('times', 'NOUN')\n",
      "13913 ('3.12.83', 'NUM')\n",
      "13914 ('reporting', 'VERB')\n",
      "13915 ('bb', 'X')\n",
      "13916 ('dayorder', 'NOUN')\n",
      "13917 ('dubleplusungood', 'NOUN')\n",
      "13918 ('refs', 'X')\n",
      "13919 ('unpersons', 'NOUN')\n",
      "13920 ('rewrite', 'VERB')\n",
      "13921 ('fullwise', 'VERB')\n",
      "13922 ('upsub', 'X')\n",
      "13923 ('antefiling', 'ADJ')\n",
      "13924 ('.', '')\n",
      "13925 ('With', 'ADP')\n",
      "13926 ('a', 'DET')\n",
      "13927 ('faint', 'ADJ')\n",
      "13928 ('feeling', 'NOUN')\n",
      "13929 ('of', 'ADP')\n",
      "13930 ('satisfaction', 'NOUN')\n",
      "13931 ('Winston', 'NOUN')\n",
      "13932 ('laid', 'VERB')\n",
      "13933 ('the', 'DET')\n",
      "13934 ('fourth', 'ADJ')\n",
      "13935 ('message', 'NOUN')\n",
      "13936 ('aside', 'ADV')\n",
      "13937 ('.', '')\n",
      "13938 ('It', 'PRON')\n",
      "13939 ('was', 'VERB')\n",
      "13940 ('an', 'DET')\n",
      "13941 ('intricate', 'ADJ')\n",
      "13942 ('and', 'CONJ')\n",
      "13943 ('responsible', 'ADJ')\n",
      "13944 ('job', 'NOUN')\n",
      "13945 ('and', 'CONJ')\n",
      "13946 ('had', 'VERB')\n",
      "13947 ('better', 'ADV')\n",
      "13948 ('be', 'VERB')\n",
      "13949 ('dealt', 'VERB')\n",
      "13950 ('with', 'ADP')\n",
      "13951 ('last', 'ADV')\n",
      "13952 ('.', '')\n",
      "13953 ('The', 'DET')\n",
      "13954 ('other', 'DET')\n",
      "13955 ('three', 'NUM')\n",
      "13956 ('were', 'VERB')\n",
      "13957 ('routine', 'ADJ')\n",
      "13958 ('matters', 'NOUN')\n",
      "13959 (',', '')\n",
      "13960 ('though', 'CONJ')\n",
      "13961 ('the', 'DET')\n",
      "13962 ('second', 'ADJ')\n",
      "13963 ('one', 'PRON')\n",
      "13964 ('would', 'VERB')\n",
      "13965 ('probably', 'ADV')\n",
      "13966 ('mean', 'VERB')\n",
      "13967 ('some', 'DET')\n",
      "13968 ('tedious', 'ADJ')\n",
      "13969 ('wading', 'VERB')\n",
      "13970 ('through', 'ADP')\n",
      "13971 ('lists', 'NOUN')\n",
      "13972 ('of', 'ADP')\n",
      "13973 ('figures', 'NOUN')\n",
      "13974 ('.', '')\n",
      "13975 ('Winston', 'NOUN')\n",
      "13976 ('dialled', 'VERB')\n",
      "13977 ('back', 'ADV')\n",
      "13978 ('numbers', 'NOUN')\n",
      "13979 ('on', 'ADP')\n",
      "13980 ('the', 'DET')\n",
      "13981 ('telescreen', 'NOUN')\n",
      "13982 ('and', 'CONJ')\n",
      "13983 ('called', 'VERB')\n",
      "13984 ('for', 'ADP')\n",
      "13985 ('the', 'DET')\n",
      "13986 ('appropriate', 'ADJ')\n",
      "13987 ('issues', 'NOUN')\n",
      "13988 ('of', 'ADP')\n",
      "13989 ('the', 'DET')\n",
      "13990 ('Times', 'NOUN')\n",
      "13991 (',', '')\n",
      "13992 ('which', 'PRON')\n",
      "13993 ('slid', 'VERB')\n",
      "13994 ('out', 'ADP')\n",
      "13995 ('of', 'ADP')\n",
      "13996 ('the', 'DET')\n",
      "13997 ('pneumatic', 'ADJ')\n",
      "13998 ('tube', 'NOUN')\n",
      "13999 ('after', 'ADP')\n",
      "14000 ('only', 'ADV')\n",
      "14001 ('a', 'DET')\n",
      "14002 ('few', 'DET')\n",
      "14003 ('minutes', 'NOUN')\n",
      "14004 (\"'\", 'ADP')\n",
      "14005 ('delay', 'NOUN')\n",
      "14006 ('.', '')\n",
      "14007 ('The', 'DET')\n",
      "14008 ('messages', 'NOUN')\n",
      "14009 ('he', 'PRON')\n",
      "14010 ('had', 'VERB')\n",
      "14011 ('received', 'VERB')\n",
      "14012 ('referred', 'VERB')\n",
      "14013 ('to', 'ADP')\n",
      "14014 ('articles', 'NOUN')\n",
      "14015 ('or', 'CONJ')\n",
      "14016 ('news', 'NOUN')\n",
      "14017 ('items', 'NOUN')\n",
      "14018 ('which', 'PRON')\n",
      "14019 ('for', 'ADP')\n",
      "14020 ('one', 'NUM')\n",
      "14021 ('reason', 'NOUN')\n",
      "14022 ('or', 'CONJ')\n",
      "14023 ('another', 'PRON')\n",
      "14024 ('it', 'PRON')\n",
      "14025 ('was', 'VERB')\n",
      "14026 ('thought', 'VERB')\n",
      "14027 ('necessary', 'ADJ')\n",
      "14028 ('to', 'ADP')\n",
      "14029 ('alter', 'VERB')\n",
      "14030 (',', '')\n",
      "14031 ('or', 'CONJ')\n",
      "14032 (',', '')\n",
      "14033 ('as', 'CONJ')\n",
      "14034 ('the', 'DET')\n",
      "14035 ('official', 'ADJ')\n",
      "14036 ('phrase', 'NOUN')\n",
      "14037 ('had', 'VERB')\n",
      "14038 ('it', 'PRON')\n",
      "14039 (',', '')\n",
      "14040 ('to', 'ADP')\n",
      "14041 ('rectify', 'VERB')\n",
      "14042 ('.', '')\n",
      "14043 ('For', 'ADP')\n",
      "14044 ('example', 'NOUN')\n",
      "14045 (',', '')\n",
      "14046 ('it', 'PRON')\n",
      "14047 ('appeared', 'VERB')\n",
      "14048 ('from', 'ADP')\n",
      "14049 ('the', 'DET')\n",
      "14050 ('Times', 'NOUN')\n",
      "14051 ('of', 'ADP')\n",
      "14052 ('the', 'DET')\n",
      "14053 ('seventeenth', 'NUM')\n",
      "14054 ('of', 'ADP')\n",
      "14055 ('March', 'NOUN')\n",
      "14056 ('that', 'CONJ')\n",
      "14057 ('Big', 'ADJ')\n",
      "14058 ('Brother', 'NOUN')\n",
      "14059 (',', '')\n",
      "14060 ('in', 'ADP')\n",
      "14061 ('his', 'DET')\n",
      "14062 ('speech', 'NOUN')\n",
      "14063 ('of', 'ADP')\n",
      "14064 ('the', 'DET')\n",
      "14065 ('previous', 'ADJ')\n",
      "14066 ('day', 'NOUN')\n",
      "14067 (',', '')\n",
      "14068 ('had', 'VERB')\n",
      "14069 ('predicted', 'VERB')\n",
      "14070 ('that', 'CONJ')\n",
      "14071 ('the', 'DET')\n",
      "14072 ('South', 'ADJ')\n",
      "14073 ('Indian', 'ADJ')\n",
      "14074 ('front', 'NOUN')\n",
      "14075 ('would', 'VERB')\n",
      "14076 ('remain', 'VERB')\n",
      "14077 ('quiet', 'ADJ')\n",
      "14078 ('but', 'CONJ')\n",
      "14079 ('that', 'CONJ')\n",
      "14080 ('a', 'DET')\n",
      "14081 ('Eurasian', 'ADJ')\n",
      "14082 ('offensive', 'NOUN')\n",
      "14083 ('would', 'VERB')\n",
      "14084 ('shortly', 'ADV')\n",
      "14085 ('be', 'VERB')\n",
      "14086 ('launched', 'VERB')\n",
      "14087 ('in', 'ADP')\n",
      "14088 ('North', 'ADJ')\n",
      "14089 ('Africa', 'NOUN')\n",
      "14090 ('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14091 ('As', 'CONJ')\n",
      "14092 ('it', 'PRON')\n",
      "14093 ('happened', 'VERB')\n",
      "14094 (',', '')\n",
      "14095 ('the', 'DET')\n",
      "14096 ('Eurasian', 'ADJ')\n",
      "14097 ('Higher', 'ADJ')\n",
      "14098 ('Command', 'NOUN')\n",
      "14099 ('had', 'VERB')\n",
      "14100 ('launched', 'VERB')\n",
      "14101 ('its', 'DET')\n",
      "14102 ('offensive', 'NOUN')\n",
      "14103 ('in', 'ADP')\n",
      "14104 ('South', 'ADJ')\n",
      "14105 ('India', 'NOUN')\n",
      "14106 ('and', 'CONJ')\n",
      "14107 ('left', 'VERB')\n",
      "14108 ('North', 'ADJ')\n",
      "14109 ('Africa', 'NOUN')\n",
      "14110 ('alone', 'ADJ')\n",
      "14111 ('.', '')\n",
      "14112 ('It', 'PRON')\n",
      "14113 ('was', 'VERB')\n",
      "14114 ('therefore', 'ADV')\n",
      "14115 ('necessary', 'ADJ')\n",
      "14116 ('to', 'ADP')\n",
      "14117 ('rewrite', 'VERB')\n",
      "14118 ('a', 'DET')\n",
      "14119 ('paragraph', 'NOUN')\n",
      "14120 ('of', 'ADP')\n",
      "14121 ('Big', 'ADJ')\n",
      "14122 ('Brother', 'NOUN')\n",
      "14123 (\"'s\", 'ADP')\n",
      "14124 ('speech', 'NOUN')\n",
      "14125 (',', '')\n",
      "14126 ('in', 'ADP')\n",
      "14127 ('such', 'ADJ')\n",
      "14128 ('a', 'DET')\n",
      "14129 ('way', 'NOUN')\n",
      "14130 ('as', 'CONJ')\n",
      "14131 ('to', 'ADP')\n",
      "14132 ('make', 'VERB')\n",
      "14133 ('him', 'PRON')\n",
      "14134 ('predict', 'VERB')\n",
      "14135 ('the', 'DET')\n",
      "14136 ('thing', 'NOUN')\n",
      "14137 ('that', 'PRON')\n",
      "14138 ('had', 'VERB')\n",
      "14139 ('actually', 'ADV')\n",
      "14140 ('happened', 'VERB')\n",
      "14141 ('.', '')\n",
      "14142 ('Or', 'CONJ')\n",
      "14143 ('again', 'ADV')\n",
      "14144 (',', '')\n",
      "14145 ('the', 'DET')\n",
      "14146 ('Times', 'NOUN')\n",
      "14147 ('of', 'ADP')\n",
      "14148 ('the', 'DET')\n",
      "14149 ('nineteenth', 'NUM')\n",
      "14150 ('of', 'ADP')\n",
      "14151 ('December', 'NOUN')\n",
      "14152 ('had', 'VERB')\n",
      "14153 ('published', 'VERB')\n",
      "14154 ('the', 'DET')\n",
      "14155 ('official', 'ADJ')\n",
      "14156 ('forecasts', 'NOUN')\n",
      "14157 ('of', 'ADP')\n",
      "14158 ('the', 'DET')\n",
      "14159 ('output', 'NOUN')\n",
      "14160 ('of', 'ADP')\n",
      "14161 ('various', 'ADJ')\n",
      "14162 ('classes', 'NOUN')\n",
      "14163 ('of', 'ADP')\n",
      "14164 ('consumption', 'NOUN')\n",
      "14165 ('goods', 'NOUN')\n",
      "14166 ('in', 'ADP')\n",
      "14167 ('the', 'DET')\n",
      "14168 ('fourth', 'ADJ')\n",
      "14169 ('quarter', 'NOUN')\n",
      "14170 ('of', 'ADP')\n",
      "14171 ('1983', 'NUM')\n",
      "14172 (',', '')\n",
      "14173 ('which', 'PRON')\n",
      "14174 ('was', 'VERB')\n",
      "14175 ('also', 'ADV')\n",
      "14176 ('the', 'DET')\n",
      "14177 ('sixth', 'ADJ')\n",
      "14178 ('quarter', 'NOUN')\n",
      "14179 ('of', 'ADP')\n",
      "14180 ('the', 'DET')\n",
      "14181 ('Ninth', 'ADJ')\n",
      "14182 ('Three-Year', 'ADJ')\n",
      "14183 ('Plan', 'NOUN')\n",
      "14184 ('.', '')\n",
      "14185 ('Today', 'NOUN')\n",
      "14186 (\"'s\", 'ADP')\n",
      "14187 ('issue', 'NOUN')\n",
      "14188 ('contained', 'VERB')\n",
      "14189 ('a', 'DET')\n",
      "14190 ('statement', 'NOUN')\n",
      "14191 ('of', 'ADP')\n",
      "14192 ('the', 'DET')\n",
      "14193 ('actual', 'ADJ')\n",
      "14194 ('output', 'NOUN')\n",
      "14195 (',', '')\n",
      "14196 ('from', 'ADP')\n",
      "14197 ('which', 'PRON')\n",
      "14198 ('it', 'PRON')\n",
      "14199 ('appeared', 'VERB')\n",
      "14200 ('that', 'CONJ')\n",
      "14201 ('the', 'DET')\n",
      "14202 ('forecasts', 'NOUN')\n",
      "14203 ('were', 'VERB')\n",
      "14204 ('in', 'ADP')\n",
      "14205 ('every', 'DET')\n",
      "14206 ('instance', 'NOUN')\n",
      "14207 ('grossly', 'ADV')\n",
      "14208 ('wrong', 'ADJ')\n",
      "14209 ('.', '')\n",
      "14210 ('Winston', 'NOUN')\n",
      "14211 (\"'s\", 'ADP')\n",
      "14212 ('job', 'NOUN')\n",
      "14213 ('was', 'VERB')\n",
      "14214 ('to', 'ADP')\n",
      "14215 ('rectify', 'VERB')\n",
      "14216 ('the', 'DET')\n",
      "14217 ('original', 'ADJ')\n",
      "14218 ('figures', 'NOUN')\n",
      "14219 ('by', 'ADP')\n",
      "14220 ('making', 'VERB')\n",
      "14221 ('them', 'PRON')\n",
      "14222 ('agree', 'VERB')\n",
      "14223 ('with', 'ADP')\n",
      "14224 ('the', 'DET')\n",
      "14225 ('later', 'ADJ')\n",
      "14226 ('ones', 'NOUN')\n",
      "14227 ('.', '')\n",
      "14228 ('As', 'CONJ')\n",
      "14229 ('for', 'ADP')\n",
      "14230 ('the', 'DET')\n",
      "14231 ('third', 'ADJ')\n",
      "14232 ('message', 'NOUN')\n",
      "14233 (',', '')\n",
      "14234 ('it', 'PRON')\n",
      "14235 ('referred', 'VERB')\n",
      "14236 ('to', 'ADP')\n",
      "14237 ('a', 'DET')\n",
      "14238 ('very', 'ADV')\n",
      "14239 ('simple', 'ADJ')\n",
      "14240 ('error', 'NOUN')\n",
      "14241 ('which', 'PRON')\n",
      "14242 ('could', 'VERB')\n",
      "14243 ('be', 'VERB')\n",
      "14244 ('set', 'VERB')\n",
      "14245 ('right', 'ADJ')\n",
      "14246 ('in', 'ADP')\n",
      "14247 ('a', 'DET')\n",
      "14248 ('couple', 'NOUN')\n",
      "14249 ('of', 'ADP')\n",
      "14250 ('minutes', 'NOUN')\n",
      "14251 ('.', '')\n",
      "14252 ('As', 'ADV')\n",
      "14253 ('short', 'ADJ')\n",
      "14254 ('a', 'DET')\n",
      "14255 ('time', 'NOUN')\n",
      "14256 ('ago', 'ADP')\n",
      "14257 ('as', 'ADP')\n",
      "14258 ('February', 'NOUN')\n",
      "14259 (',', '')\n",
      "14260 ('the', 'DET')\n",
      "14261 ('Ministry', 'NOUN')\n",
      "14262 ('of', 'ADP')\n",
      "14263 ('Plenty', 'NOUN')\n",
      "14264 ('had', 'VERB')\n",
      "14265 ('issued', 'VERB')\n",
      "14266 ('a', 'DET')\n",
      "14267 ('promise', 'NOUN')\n",
      "14268 ('(', '')\n",
      "14269 ('a', 'DET')\n",
      "14270 ('categorical', 'ADJ')\n",
      "14271 ('pledge', 'NOUN')\n",
      "14272 ('were', 'VERB')\n",
      "14273 ('the', 'DET')\n",
      "14274 ('official', 'ADJ')\n",
      "14275 ('words', 'NOUN')\n",
      "14276 (')', '')\n",
      "14277 ('that', 'CONJ')\n",
      "14278 ('there', 'PRON')\n",
      "14279 ('would', 'VERB')\n",
      "14280 ('be', 'VERB')\n",
      "14281 ('no', 'DET')\n",
      "14282 ('reduction', 'NOUN')\n",
      "14283 ('of', 'ADP')\n",
      "14284 ('the', 'DET')\n",
      "14285 ('chocolate', 'NOUN')\n",
      "14286 ('ration', 'NOUN')\n",
      "14287 ('during', 'ADP')\n",
      "14288 ('1984', 'NUM')\n",
      "14289 ('.', '')\n",
      "14290 ('Actually', 'ADV')\n",
      "14291 (',', '')\n",
      "14292 ('as', 'CONJ')\n",
      "14293 ('Winston', 'NOUN')\n",
      "14294 ('was', 'VERB')\n",
      "14295 ('aware', 'ADJ')\n",
      "14296 (',', '')\n",
      "14297 ('the', 'DET')\n",
      "14298 ('chocolate', 'NOUN')\n",
      "14299 ('ration', 'NOUN')\n",
      "14300 ('was', 'VERB')\n",
      "14301 ('to', 'ADP')\n",
      "14302 ('be', 'VERB')\n",
      "14303 ('reduced', 'VERB')\n",
      "14304 ('from', 'ADP')\n",
      "14305 ('thirty', 'NUM')\n",
      "14306 ('grammes', 'NOUN')\n",
      "14307 ('to', 'ADP')\n",
      "14308 ('twenty', 'NUM')\n",
      "14309 ('at', 'ADP')\n",
      "14310 ('the', 'DET')\n",
      "14311 ('end', 'NOUN')\n",
      "14312 ('of', 'ADP')\n",
      "14313 ('the', 'DET')\n",
      "14314 ('present', 'ADJ')\n",
      "14315 ('week', 'NOUN')\n",
      "14316 ('.', '')\n",
      "14317 ('All', 'DET')\n",
      "14318 ('that', 'PRON')\n",
      "14319 ('was', 'VERB')\n",
      "14320 ('needed', 'VERB')\n",
      "14321 ('was', 'VERB')\n",
      "14322 ('to', 'ADP')\n",
      "14323 ('substitute', 'VERB')\n",
      "14324 ('for', 'ADP')\n",
      "14325 ('the', 'DET')\n",
      "14326 ('original', 'ADJ')\n",
      "14327 ('promise', 'NOUN')\n",
      "14328 ('a', 'DET')\n",
      "14329 ('warning', 'NOUN')\n",
      "14330 ('that', 'CONJ')\n",
      "14331 ('it', 'PRON')\n",
      "14332 ('would', 'VERB')\n",
      "14333 ('probably', 'ADV')\n",
      "14334 ('be', 'VERB')\n",
      "14335 ('necessary', 'ADJ')\n",
      "14336 ('to', 'ADP')\n",
      "14337 ('reduce', 'VERB')\n",
      "14338 ('the', 'DET')\n",
      "14339 ('ration', 'NOUN')\n",
      "14340 ('at', 'ADP')\n",
      "14341 ('some', 'DET')\n",
      "14342 ('time', 'NOUN')\n",
      "14343 ('in', 'ADP')\n",
      "14344 ('April', 'NOUN')\n",
      "14345 ('.', '')\n",
      "14346 ('As', 'ADV')\n",
      "14347 ('soon', 'ADV')\n",
      "14348 ('as', 'CONJ')\n",
      "14349 ('Winston', 'NOUN')\n",
      "14350 ('had', 'VERB')\n",
      "14351 ('dealt', 'VERB')\n",
      "14352 ('with', 'ADP')\n",
      "14353 ('each', 'PRON')\n",
      "14354 ('of', 'ADP')\n",
      "14355 ('the', 'DET')\n",
      "14356 ('messages', 'NOUN')\n",
      "14357 (',', '')\n",
      "14358 ('he', 'PRON')\n",
      "14359 ('clipped', 'VERB')\n",
      "14360 ('his', 'DET')\n",
      "14361 ('speakwritten', 'ADJ')\n",
      "14362 ('corrections', 'NOUN')\n",
      "14363 ('to', 'ADP')\n",
      "14364 ('the', 'DET')\n",
      "14365 ('appropriate', 'ADJ')\n",
      "14366 ('copy', 'NOUN')\n",
      "14367 ('of', 'ADP')\n",
      "14368 ('the', 'DET')\n",
      "14369 ('Times', 'NOUN')\n",
      "14370 ('and', 'CONJ')\n",
      "14371 ('pushed', 'VERB')\n",
      "14372 ('them', 'PRON')\n",
      "14373 ('into', 'ADP')\n",
      "14374 ('the', 'DET')\n",
      "14375 ('pneumatic', 'ADJ')\n",
      "14376 ('tube', 'NOUN')\n",
      "14377 ('.', '')\n",
      "14378 ('Then', 'ADV')\n",
      "14379 (',', '')\n",
      "14380 ('with', 'ADP')\n",
      "14381 ('a', 'DET')\n",
      "14382 ('movement', 'NOUN')\n",
      "14383 ('which', 'PRON')\n",
      "14384 ('was', 'VERB')\n",
      "14385 ('as', 'ADV')\n",
      "14386 ('nearly', 'ADV')\n",
      "14387 ('as', 'CONJ')\n",
      "14388 ('possible', 'ADJ')\n",
      "14389 ('unconscious', 'ADJ')\n",
      "14390 (',', '')\n",
      "14391 ('he', 'PRON')\n",
      "14392 ('crumpled', 'VERB')\n",
      "14393 ('up', 'ADP')\n",
      "14394 ('the', 'DET')\n",
      "14395 ('original', 'ADJ')\n",
      "14396 ('message', 'NOUN')\n",
      "14397 ('and', 'CONJ')\n",
      "14398 ('any', 'DET')\n",
      "14399 ('notes', 'NOUN')\n",
      "14400 ('that', 'PRON')\n",
      "14401 ('he', 'PRON')\n",
      "14402 ('himself', 'PRON')\n",
      "14403 ('had', 'VERB')\n",
      "14404 ('made', 'VERB')\n",
      "14405 (',', '')\n",
      "14406 ('and', 'CONJ')\n",
      "14407 ('dropped', 'VERB')\n",
      "14408 ('them', 'PRON')\n",
      "14409 ('into', 'ADP')\n",
      "14410 ('the', 'DET')\n",
      "14411 ('memory', 'NOUN')\n",
      "14412 ('hole', 'NOUN')\n",
      "14413 ('to', 'ADP')\n",
      "14414 ('be', 'VERB')\n",
      "14415 ('devoured', 'VERB')\n",
      "14416 ('by', 'ADP')\n",
      "14417 ('the', 'DET')\n",
      "14418 ('flames', 'NOUN')\n",
      "14419 ('.', '')\n",
      "14420 ('What', 'PRON')\n",
      "14421 ('happened', 'VERB')\n",
      "14422 ('in', 'ADP')\n",
      "14423 ('the', 'DET')\n",
      "14424 ('unseen', 'ADJ')\n",
      "14425 ('labyrinth', 'NOUN')\n",
      "14426 ('to', 'ADP')\n",
      "14427 ('which', 'PRON')\n",
      "14428 ('the', 'DET')\n",
      "14429 ('pneumatic', 'ADJ')\n",
      "14430 ('tubes', 'NOUN')\n",
      "14431 ('led', 'VERB')\n",
      "14432 (',', '')\n",
      "14433 ('he', 'PRON')\n",
      "14434 ('did', 'VERB')\n",
      "14435 ('not', 'ADV')\n",
      "14436 ('know', 'VERB')\n",
      "14437 ('in', 'ADP')\n",
      "14438 ('detail', 'NOUN')\n",
      "14439 (',', '')\n",
      "14440 ('but', 'CONJ')\n",
      "14441 ('he', 'PRON')\n",
      "14442 ('did', 'VERB')\n",
      "14443 ('know', 'VERB')\n",
      "14444 ('in', 'ADP')\n",
      "14445 ('general', 'ADJ')\n",
      "14446 ('terms', 'NOUN')\n",
      "14447 ('.', '')\n",
      "14448 ('As', 'ADV')\n",
      "14449 ('soon', 'ADV')\n",
      "14450 ('as', 'CONJ')\n",
      "14451 ('all', 'DET')\n",
      "14452 ('the', 'DET')\n",
      "14453 ('corrections', 'NOUN')\n",
      "14454 ('which', 'PRON')\n",
      "14455 ('happened', 'VERB')\n",
      "14456 ('to', 'ADP')\n",
      "14457 ('be', 'VERB')\n",
      "14458 ('necessary', 'ADJ')\n",
      "14459 ('in', 'ADP')\n",
      "14460 ('any', 'DET')\n",
      "14461 ('particular', 'ADJ')\n",
      "14462 ('number', 'NOUN')\n",
      "14463 ('of', 'ADP')\n",
      "14464 ('the', 'DET')\n",
      "14465 ('Times', 'NOUN')\n",
      "14466 ('had', 'VERB')\n",
      "14467 ('been', 'VERB')\n",
      "14468 ('assembled', 'VERB')\n",
      "14469 ('and', 'CONJ')\n",
      "14470 ('collated', 'VERB')\n",
      "14471 (',', '')\n",
      "14472 ('that', 'DET')\n",
      "14473 ('number', 'NOUN')\n",
      "14474 ('would', 'VERB')\n",
      "14475 ('be', 'VERB')\n",
      "14476 ('reprinted', 'VERB')\n",
      "14477 (',', '')\n",
      "14478 ('the', 'DET')\n",
      "14479 ('original', 'ADJ')\n",
      "14480 ('copy', 'NOUN')\n",
      "14481 ('destroyed', 'VERB')\n",
      "14482 (',', '')\n",
      "14483 ('and', 'CONJ')\n",
      "14484 ('the', 'DET')\n",
      "14485 ('corrected', 'ADJ')\n",
      "14486 ('copy', 'NOUN')\n",
      "14487 ('placed', 'VERB')\n",
      "14488 ('on', 'ADP')\n",
      "14489 ('the', 'DET')\n",
      "14490 ('files', 'NOUN')\n",
      "14491 ('in', 'ADP')\n",
      "14492 ('its', 'DET')\n",
      "14493 ('stead', 'NOUN')\n",
      "14494 ('.', '')\n",
      "14495 ('This', 'DET')\n",
      "14496 ('process', 'NOUN')\n",
      "14497 ('of', 'ADP')\n",
      "14498 ('continuous', 'ADJ')\n",
      "14499 ('alteration', 'NOUN')\n",
      "14500 ('was', 'VERB')\n",
      "14501 ('applied', 'VERB')\n",
      "14502 ('not', 'ADV')\n",
      "14503 ('only', 'ADV')\n",
      "14504 ('to', 'ADP')\n",
      "14505 ('newspapers', 'NOUN')\n",
      "14506 (',', '')\n",
      "14507 ('but', 'CONJ')\n",
      "14508 ('to', 'ADP')\n",
      "14509 ('books', 'NOUN')\n",
      "14510 (',', '')\n",
      "14511 ('periodicals', 'NOUN')\n",
      "14512 (',', '')\n",
      "14513 ('pamphlets', 'NOUN')\n",
      "14514 (',', '')\n",
      "14515 ('posters', 'NOUN')\n",
      "14516 (',', '')\n",
      "14517 ('leaflets', 'NOUN')\n",
      "14518 (',', '')\n",
      "14519 ('films', 'NOUN')\n",
      "14520 (',', '')\n",
      "14521 ('sound-tracks', 'NOUN')\n",
      "14522 (',', '')\n",
      "14523 ('cartoons', 'NOUN')\n",
      "14524 (',', '')\n",
      "14525 ('photographs', 'NOUN')\n",
      "14526 ('-', '')\n",
      "14527 ('to', 'ADP')\n",
      "14528 ('every', 'DET')\n",
      "14529 ('kind', 'NOUN')\n",
      "14530 ('of', 'ADP')\n",
      "14531 ('literature', 'NOUN')\n",
      "14532 ('or', 'CONJ')\n",
      "14533 ('documentation', 'NOUN')\n",
      "14534 ('which', 'PRON')\n",
      "14535 ('might', 'VERB')\n",
      "14536 ('conceivably', 'ADV')\n",
      "14537 ('hold', 'VERB')\n",
      "14538 ('any', 'DET')\n",
      "14539 ('political', 'ADJ')\n",
      "14540 ('or', 'CONJ')\n",
      "14541 ('ideological', 'ADJ')\n",
      "14542 ('significance', 'NOUN')\n",
      "14543 ('.', '')\n",
      "14544 ('Day', 'NOUN')\n",
      "14545 ('by', 'ADP')\n",
      "14546 ('day', 'NOUN')\n",
      "14547 ('and', 'CONJ')\n",
      "14548 ('almost', 'ADV')\n",
      "14549 ('minute', 'NOUN')\n",
      "14550 ('by', 'ADP')\n",
      "14551 ('minute', 'NOUN')\n",
      "14552 ('the', 'DET')\n",
      "14553 ('past', 'NOUN')\n",
      "14554 ('was', 'VERB')\n",
      "14555 ('brought', 'VERB')\n",
      "14556 ('up', 'ADP')\n",
      "14557 ('to', 'ADP')\n",
      "14558 ('date', 'NOUN')\n",
      "14559 ('.', '')\n",
      "14560 ('In', 'ADP')\n",
      "14561 ('this', 'DET')\n",
      "14562 ('way', 'NOUN')\n",
      "14563 ('every', 'DET')\n",
      "14564 ('prediction', 'NOUN')\n",
      "14565 ('made', 'VERB')\n",
      "14566 ('by', 'ADP')\n",
      "14567 ('the', 'DET')\n",
      "14568 ('Party', 'NOUN')\n",
      "14569 ('could', 'VERB')\n",
      "14570 ('be', 'VERB')\n",
      "14571 ('shown', 'VERB')\n",
      "14572 ('by', 'ADP')\n",
      "14573 ('documentary', 'ADJ')\n",
      "14574 ('evidence', 'NOUN')\n",
      "14575 ('to', 'ADP')\n",
      "14576 ('have', 'VERB')\n",
      "14577 ('been', 'VERB')\n",
      "14578 ('correct', 'ADJ')\n",
      "14579 (',', '')\n",
      "14580 ('nor', 'CONJ')\n",
      "14581 ('was', 'VERB')\n",
      "14582 ('any', 'DET')\n",
      "14583 ('item', 'NOUN')\n",
      "14584 ('of', 'ADP')\n",
      "14585 ('news', 'NOUN')\n",
      "14586 (',', '')\n",
      "14587 ('or', 'CONJ')\n",
      "14588 ('any', 'DET')\n",
      "14589 ('expression', 'NOUN')\n",
      "14590 ('of', 'ADP')\n",
      "14591 ('opinion', 'NOUN')\n",
      "14592 (',', '')\n",
      "14593 ('which', 'PRON')\n",
      "14594 ('conflicted', 'VERB')\n",
      "14595 ('with', 'ADP')\n",
      "14596 ('the', 'DET')\n",
      "14597 ('needs', 'NOUN')\n",
      "14598 ('of', 'ADP')\n",
      "14599 ('the', 'DET')\n",
      "14600 ('moment', 'NOUN')\n",
      "14601 (',', '')\n",
      "14602 ('ever', 'ADV')\n",
      "14603 ('allowed', 'VERB')\n",
      "14604 ('to', 'ADP')\n",
      "14605 ('remain', 'VERB')\n",
      "14606 ('on', 'ADP')\n",
      "14607 ('record', 'NOUN')\n",
      "14608 ('.', '')\n",
      "14609 ('All', 'DET')\n",
      "14610 ('history', 'NOUN')\n",
      "14611 ('was', 'VERB')\n",
      "14612 ('a', 'DET')\n",
      "14613 ('palimpsest', 'NOUN')\n",
      "14614 (',', '')\n",
      "14615 ('scraped', 'VERB')\n",
      "14616 ('clean', 'ADJ')\n",
      "14617 ('and', 'CONJ')\n",
      "14618 ('reinscribed', 'VERB')\n",
      "14619 ('exactly', 'ADV')\n",
      "14620 ('as', 'ADV')\n",
      "14621 ('often', 'ADV')\n",
      "14622 ('as', 'CONJ')\n",
      "14623 ('was', 'VERB')\n",
      "14624 ('necessary', 'ADJ')\n",
      "14625 ('.', '')\n",
      "14626 ('In', 'ADP')\n",
      "14627 ('no', 'DET')\n",
      "14628 ('case', 'NOUN')\n",
      "14629 ('would', 'VERB')\n",
      "14630 ('it', 'PRON')\n",
      "14631 ('have', 'VERB')\n",
      "14632 ('been', 'VERB')\n",
      "14633 ('possible', 'ADJ')\n",
      "14634 (',', '')\n",
      "14635 ('once', 'CONJ')\n",
      "14636 ('the', 'DET')\n",
      "14637 ('deed', 'NOUN')\n",
      "14638 ('was', 'VERB')\n",
      "14639 ('done', 'VERB')\n",
      "14640 (',', '')\n",
      "14641 ('to', 'ADP')\n",
      "14642 ('prove', 'VERB')\n",
      "14643 ('that', 'CONJ')\n",
      "14644 ('any', 'DET')\n",
      "14645 ('falsification', 'NOUN')\n",
      "14646 ('had', 'VERB')\n",
      "14647 ('taken', 'VERB')\n",
      "14648 ('place', 'NOUN')\n",
      "14649 ('.', '')\n",
      "14650 ('The', 'DET')\n",
      "14651 ('largest', 'ADJ')\n",
      "14652 ('section', 'NOUN')\n",
      "14653 ('of', 'ADP')\n",
      "14654 ('the', 'DET')\n",
      "14655 ('Records', 'NOUN')\n",
      "14656 ('Department', 'NOUN')\n",
      "14657 (',', '')\n",
      "14658 ('far', 'ADV')\n",
      "14659 ('larger', 'ADJ')\n",
      "14660 ('than', 'ADP')\n",
      "14661 ('the', 'DET')\n",
      "14662 ('one', 'PRON')\n",
      "14663 ('on', 'ADP')\n",
      "14664 ('which', 'PRON')\n",
      "14665 ('Winston', 'NOUN')\n",
      "14666 ('worked', 'VERB')\n",
      "14667 (',', '')\n",
      "14668 ('consisted', 'VERB')\n",
      "14669 ('simply', 'ADV')\n",
      "14670 ('of', 'ADP')\n",
      "14671 ('persons', 'NOUN')\n",
      "14672 ('whose', 'PRON')\n",
      "14673 ('duty', 'NOUN')\n",
      "14674 ('it', 'PRON')\n",
      "14675 ('was', 'VERB')\n",
      "14676 ('to', 'ADP')\n",
      "14677 ('track', 'VERB')\n",
      "14678 ('down', 'ADV')\n",
      "14679 ('and', 'CONJ')\n",
      "14680 ('collect', 'VERB')\n",
      "14681 ('all', 'DET')\n",
      "14682 ('copies', 'NOUN')\n",
      "14683 ('of', 'ADP')\n",
      "14684 ('books', 'NOUN')\n",
      "14685 (',', '')\n",
      "14686 ('newspapers', 'NOUN')\n",
      "14687 (',', '')\n",
      "14688 ('and', 'CONJ')\n",
      "14689 ('other', 'DET')\n",
      "14690 ('documents', 'NOUN')\n",
      "14691 ('which', 'PRON')\n",
      "14692 ('had', 'VERB')\n",
      "14693 ('been', 'VERB')\n",
      "14694 ('superseded', 'VERB')\n",
      "14695 ('and', 'CONJ')\n",
      "14696 ('were', 'VERB')\n",
      "14697 ('due', 'ADJ')\n",
      "14698 ('for', 'ADP')\n",
      "14699 ('destruction', 'NOUN')\n",
      "14700 ('.', '')\n",
      "14701 ('A', 'DET')\n",
      "14702 ('number', 'NOUN')\n",
      "14703 ('of', 'ADP')\n",
      "14704 ('the', 'DET')\n",
      "14705 ('Times', 'NOUN')\n",
      "14706 ('which', 'PRON')\n",
      "14707 ('might', 'VERB')\n",
      "14708 (',', '')\n",
      "14709 ('because', 'CONJ')\n",
      "14710 ('of', 'ADP')\n",
      "14711 ('changes', 'NOUN')\n",
      "14712 ('in', 'ADP')\n",
      "14713 ('political', 'ADJ')\n",
      "14714 ('alignment', 'NOUN')\n",
      "14715 (',', '')\n",
      "14716 ('or', 'CONJ')\n",
      "14717 ('mistaken', 'ADJ')\n",
      "14718 ('prophecies', 'NOUN')\n",
      "14719 ('uttered', 'VERB')\n",
      "14720 ('by', 'ADP')\n",
      "14721 ('Big', 'ADJ')\n",
      "14722 ('Brother', 'NOUN')\n",
      "14723 (',', '')\n",
      "14724 ('have', 'VERB')\n",
      "14725 ('been', 'VERB')\n",
      "14726 ('rewritten', 'VERB')\n",
      "14727 ('a', 'DET')\n",
      "14728 ('dozen', 'NOUN')\n",
      "14729 ('times', 'NOUN')\n",
      "14730 ('still', 'ADV')\n",
      "14731 ('stood', 'VERB')\n",
      "14732 ('on', 'ADP')\n",
      "14733 ('the', 'DET')\n",
      "14734 ('files', 'NOUN')\n",
      "14735 ('bearing', 'VERB')\n",
      "14736 ('its', 'DET')\n",
      "14737 ('original', 'ADJ')\n",
      "14738 ('date', 'NOUN')\n",
      "14739 (',', '')\n",
      "14740 ('and', 'CONJ')\n",
      "14741 ('no', 'DET')\n",
      "14742 ('other', 'DET')\n",
      "14743 ('copy', 'NOUN')\n",
      "14744 ('existed', 'VERB')\n",
      "14745 ('to', 'ADP')\n",
      "14746 ('contradict', 'VERB')\n",
      "14747 ('it', 'PRON')\n",
      "14748 ('.', '')\n",
      "14749 ('Books', 'NOUN')\n",
      "14750 (',', '')\n",
      "14751 ('also', 'ADV')\n",
      "14752 (',', '')\n",
      "14753 ('were', 'VERB')\n",
      "14754 ('recalled', 'VERB')\n",
      "14755 ('and', 'CONJ')\n",
      "14756 ('rewritten', 'VERB')\n",
      "14757 ('again', 'ADV')\n",
      "14758 ('and', 'CONJ')\n",
      "14759 ('again', 'ADV')\n",
      "14760 (',', '')\n",
      "14761 ('and', 'CONJ')\n",
      "14762 ('were', 'VERB')\n",
      "14763 ('invariably', 'ADV')\n",
      "14764 ('reissued', 'VERB')\n",
      "14765 ('without', 'ADP')\n",
      "14766 ('any', 'DET')\n",
      "14767 ('admission', 'NOUN')\n",
      "14768 ('that', 'CONJ')\n",
      "14769 ('any', 'DET')\n",
      "14770 ('alteration', 'NOUN')\n",
      "14771 ('had', 'VERB')\n",
      "14772 ('been', 'VERB')\n",
      "14773 ('made', 'VERB')\n",
      "14774 ('.', '')\n",
      "14775 ('Even', 'ADV')\n",
      "14776 ('the', 'DET')\n",
      "14777 ('written', 'VERB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14778 ('instructions', 'NOUN')\n",
      "14779 ('which', 'PRON')\n",
      "14780 ('Winston', 'NOUN')\n",
      "14781 ('received', 'VERB')\n",
      "14782 (',', '')\n",
      "14783 ('and', 'CONJ')\n",
      "14784 ('which', 'PRON')\n",
      "14785 ('he', 'PRON')\n",
      "14786 ('invariably', 'ADV')\n",
      "14787 ('got', 'VERB')\n",
      "14788 ('rid', 'VERB')\n",
      "14789 ('of', 'ADP')\n",
      "14790 ('as', 'ADV')\n",
      "14791 ('soon', 'ADV')\n",
      "14792 ('as', 'CONJ')\n",
      "14793 ('he', 'PRON')\n",
      "14794 ('had', 'VERB')\n",
      "14795 ('dealt', 'VERB')\n",
      "14796 ('with', 'ADP')\n",
      "14797 ('them', 'PRON')\n",
      "14798 (',', '')\n",
      "14799 ('never', 'ADV')\n",
      "14800 ('stated', 'VERB')\n",
      "14801 ('or', 'CONJ')\n",
      "14802 ('implied', 'VERB')\n",
      "14803 ('that', 'CONJ')\n",
      "14804 ('an', 'DET')\n",
      "14805 ('act', 'NOUN')\n",
      "14806 ('of', 'ADP')\n",
      "14807 ('forgery', 'NOUN')\n",
      "14808 ('was', 'VERB')\n",
      "14809 ('to', 'ADP')\n",
      "14810 ('be', 'VERB')\n",
      "14811 ('committed', 'VERB')\n",
      "14812 (':', '')\n",
      "14813 ('always', 'ADV')\n",
      "14814 ('the', 'DET')\n",
      "14815 ('reference', 'NOUN')\n",
      "14816 ('was', 'VERB')\n",
      "14817 ('to', 'ADP')\n",
      "14818 ('slips', 'NOUN')\n",
      "14819 (',', '')\n",
      "14820 ('errors', 'NOUN')\n",
      "14821 (',', '')\n",
      "14822 ('misprints', 'NOUN')\n",
      "14823 (',', '')\n",
      "14824 ('or', 'CONJ')\n",
      "14825 ('misquotations', 'NOUN')\n",
      "14826 ('which', 'PRON')\n",
      "14827 ('it', 'PRON')\n",
      "14828 ('was', 'VERB')\n",
      "14829 ('necessary', 'ADJ')\n",
      "14830 ('to', 'ADP')\n",
      "14831 ('put', 'VERB')\n",
      "14832 ('right', 'ADJ')\n",
      "14833 ('in', 'ADP')\n",
      "14834 ('the', 'DET')\n",
      "14835 ('interests', 'NOUN')\n",
      "14836 ('of', 'ADP')\n",
      "14837 ('accuracy', 'NOUN')\n",
      "14838 ('.', '')\n",
      "14839 ('But', 'CONJ')\n",
      "14840 ('actually', 'ADV')\n",
      "14841 (',', '')\n",
      "14842 ('he', 'PRON')\n",
      "14843 ('thought', 'VERB')\n",
      "14844 ('as', 'CONJ')\n",
      "14845 ('he', 'PRON')\n",
      "14846 ('re-adjusted', 'ADJ')\n",
      "14847 ('the', 'DET')\n",
      "14848 ('Ministry', 'NOUN')\n",
      "14849 ('of', 'ADP')\n",
      "14850 ('Plenty', 'NOUN')\n",
      "14851 (\"'s\", 'ADP')\n",
      "14852 ('figures', 'NOUN')\n",
      "14853 (',', '')\n",
      "14854 ('it', 'PRON')\n",
      "14855 ('was', 'VERB')\n",
      "14856 ('not', 'ADV')\n",
      "14857 ('even', 'ADV')\n",
      "14858 ('forgery', 'NOUN')\n",
      "14859 ('.', '')\n",
      "14860 ('It', 'PRON')\n",
      "14861 ('was', 'VERB')\n",
      "14862 ('merely', 'ADV')\n",
      "14863 ('the', 'DET')\n",
      "14864 ('substitution', 'NOUN')\n",
      "14865 ('of', 'ADP')\n",
      "14866 ('one', 'NUM')\n",
      "14867 ('piece', 'NOUN')\n",
      "14868 ('of', 'ADP')\n",
      "14869 ('nonsense', 'NOUN')\n",
      "14870 ('for', 'ADP')\n",
      "14871 ('another', 'PRON')\n",
      "14872 ('.', '')\n",
      "14873 ('Most', 'PRON')\n",
      "14874 ('of', 'ADP')\n",
      "14875 ('the', 'DET')\n",
      "14876 ('material', 'NOUN')\n",
      "14877 ('that', 'PRON')\n",
      "14878 ('you', 'PRON')\n",
      "14879 ('were', 'VERB')\n",
      "14880 ('dealing', 'VERB')\n",
      "14881 ('with', 'ADP')\n",
      "14882 ('had', 'VERB')\n",
      "14883 ('no', 'DET')\n",
      "14884 ('connexion', 'NOUN')\n",
      "14885 ('with', 'ADP')\n",
      "14886 ('anything', 'PRON')\n",
      "14887 ('in', 'ADP')\n",
      "14888 ('the', 'DET')\n",
      "14889 ('real', 'ADJ')\n",
      "14890 ('world', 'NOUN')\n",
      "14891 (',', '')\n",
      "14892 ('not', 'ADV')\n",
      "14893 ('even', 'ADV')\n",
      "14894 ('the', 'DET')\n",
      "14895 ('kind', 'NOUN')\n",
      "14896 ('of', 'ADP')\n",
      "14897 ('connexion', 'NOUN')\n",
      "14898 ('that', 'PRON')\n",
      "14899 ('is', 'VERB')\n",
      "14900 ('contained', 'VERB')\n",
      "14901 ('in', 'ADP')\n",
      "14902 ('a', 'DET')\n",
      "14903 ('direct', 'ADJ')\n",
      "14904 ('lie', 'NOUN')\n",
      "14905 ('.', '')\n",
      "14906 ('Statistics', 'NOUN')\n",
      "14907 ('were', 'VERB')\n",
      "14908 ('just', 'ADV')\n",
      "14909 ('as', 'ADV')\n",
      "14910 ('much', 'ADV')\n",
      "14911 ('a', 'DET')\n",
      "14912 ('fantasy', 'NOUN')\n",
      "14913 ('in', 'ADP')\n",
      "14914 ('their', 'DET')\n",
      "14915 ('original', 'ADJ')\n",
      "14916 ('version', 'NOUN')\n",
      "14917 ('as', 'CONJ')\n",
      "14918 ('in', 'ADP')\n",
      "14919 ('their', 'DET')\n",
      "14920 ('rectified', 'VERB')\n",
      "14921 ('version', 'NOUN')\n",
      "14922 ('.', '')\n",
      "14923 ('A', 'DET')\n",
      "14924 ('great', 'ADJ')\n",
      "14925 ('deal', 'NOUN')\n",
      "14926 ('of', 'ADP')\n",
      "14927 ('the', 'DET')\n",
      "14928 ('time', 'NOUN')\n",
      "14929 ('you', 'PRON')\n",
      "14930 ('were', 'VERB')\n",
      "14931 ('expected', 'VERB')\n",
      "14932 ('to', 'ADP')\n",
      "14933 ('make', 'VERB')\n",
      "14934 ('them', 'PRON')\n",
      "14935 ('up', 'ADP')\n",
      "14936 ('out', 'ADP')\n",
      "14937 ('of', 'ADP')\n",
      "14938 ('your', 'DET')\n",
      "14939 ('head', 'NOUN')\n",
      "14940 ('.', '')\n",
      "14941 ('For', 'ADP')\n",
      "14942 ('example', 'NOUN')\n",
      "14943 (',', '')\n",
      "14944 ('the', 'DET')\n",
      "14945 ('Ministry', 'NOUN')\n",
      "14946 ('of', 'ADP')\n",
      "14947 ('Plenty', 'NOUN')\n",
      "14948 (\"'s\", 'ADP')\n",
      "14949 ('forecast', 'NOUN')\n",
      "14950 ('had', 'VERB')\n",
      "14951 ('estimated', 'VERB')\n",
      "14952 ('the', 'DET')\n",
      "14953 ('output', 'NOUN')\n",
      "14954 ('of', 'ADP')\n",
      "14955 ('boots', 'NOUN')\n",
      "14956 ('for', 'ADP')\n",
      "14957 ('the', 'DET')\n",
      "14958 ('quarter', 'NOUN')\n",
      "14959 ('at', 'ADP')\n",
      "14960 ('145', 'NUM')\n",
      "14961 ('million', 'NUM')\n",
      "14962 ('pairs', 'NOUN')\n",
      "14963 ('.', '')\n",
      "14964 ('The', 'DET')\n",
      "14965 ('actual', 'ADJ')\n",
      "14966 ('output', 'NOUN')\n",
      "14967 ('was', 'VERB')\n",
      "14968 ('given', 'VERB')\n",
      "14969 ('as', 'ADP')\n",
      "14970 ('sixty-two', 'NOUN')\n",
      "14971 ('millions', 'NOUN')\n",
      "14972 ('.', '')\n",
      "14973 ('Winston', 'NOUN')\n",
      "14974 (',', '')\n",
      "14975 ('however', 'ADV')\n",
      "14976 (',', '')\n",
      "14977 ('in', 'ADP')\n",
      "14978 ('rewriting', 'VERB')\n",
      "14979 ('the', 'DET')\n",
      "14980 ('forecast', 'NOUN')\n",
      "14981 (',', '')\n",
      "14982 ('marked', 'VERB')\n",
      "14983 ('the', 'DET')\n",
      "14984 ('figure', 'NOUN')\n",
      "14985 ('down', 'ADV')\n",
      "14986 ('to', 'ADP')\n",
      "14987 ('fifty-seven', 'NOUN')\n",
      "14988 ('millions', 'NOUN')\n",
      "14989 (',', '')\n",
      "14990 ('so', 'CONJ')\n",
      "14991 ('as', 'CONJ')\n",
      "14992 ('to', 'ADP')\n",
      "14993 ('allow', 'VERB')\n",
      "14994 ('for', 'ADP')\n",
      "14995 ('the', 'DET')\n",
      "14996 ('usual', 'ADJ')\n",
      "14997 ('claim', 'NOUN')\n",
      "14998 ('that', 'PRON')\n",
      "14999 ('the', 'DET')\n",
      "15000 ('quota', 'NOUN')\n",
      "15001 ('had', 'VERB')\n",
      "15002 ('been', 'VERB')\n",
      "15003 ('overfulfilled', 'ADJ')\n",
      "15004 ('.', '')\n",
      "15005 ('In', 'ADP')\n",
      "15006 ('any', 'DET')\n",
      "15007 ('case', 'NOUN')\n",
      "15008 (',', '')\n",
      "15009 ('sixty-two', 'NOUN')\n",
      "15010 ('millions', 'NOUN')\n",
      "15011 ('was', 'VERB')\n",
      "15012 ('no', 'ADV')\n",
      "15013 ('nearer', 'ADV')\n",
      "15014 ('the', 'DET')\n",
      "15015 ('truth', 'NOUN')\n",
      "15016 ('than', 'ADP')\n",
      "15017 ('fiftyseven', 'NOUN')\n",
      "15018 ('millions', 'NOUN')\n",
      "15019 (',', '')\n",
      "15020 ('or', 'CONJ')\n",
      "15021 ('than', 'ADP')\n",
      "15022 ('145', 'NUM')\n",
      "15023 ('millions', 'NOUN')\n",
      "15024 ('.', '')\n",
      "15025 ('Very', 'ADJ')\n",
      "15026 ('likely', 'ADV')\n",
      "15027 ('no', 'DET')\n",
      "15028 ('boots', 'NOUN')\n",
      "15029 ('had', 'VERB')\n",
      "15030 ('been', 'VERB')\n",
      "15031 ('produced', 'VERB')\n",
      "15032 ('at', 'ADP')\n",
      "15033 ('all', 'ADV')\n",
      "15034 ('.', '')\n",
      "15035 ('Likelier', 'ADJ')\n",
      "15036 ('still', 'ADV')\n",
      "15037 (',', '')\n",
      "15038 ('nobody', 'PRON')\n",
      "15039 ('knew', 'VERB')\n",
      "15040 ('how', 'ADV')\n",
      "15041 ('many', 'PRON')\n",
      "15042 ('had', 'VERB')\n",
      "15043 ('been', 'VERB')\n",
      "15044 ('produced', 'VERB')\n",
      "15045 (',', '')\n",
      "15046 ('much', 'ADV')\n",
      "15047 ('less', 'ADV')\n",
      "15048 ('cared', 'VERB')\n",
      "15049 ('.', '')\n",
      "15050 ('All', 'PRON')\n",
      "15051 ('one', 'PRON')\n",
      "15052 ('knew', 'VERB')\n",
      "15053 ('was', 'VERB')\n",
      "15054 ('that', 'CONJ')\n",
      "15055 ('every', 'DET')\n",
      "15056 ('quarter', 'NOUN')\n",
      "15057 ('astronomical', 'ADJ')\n",
      "15058 ('numbers', 'NOUN')\n",
      "15059 ('of', 'ADP')\n",
      "15060 ('boots', 'NOUN')\n",
      "15061 ('were', 'VERB')\n",
      "15062 ('produced', 'VERB')\n",
      "15063 ('on', 'ADP')\n",
      "15064 ('paper', 'NOUN')\n",
      "15065 (',', '')\n",
      "15066 ('while', 'CONJ')\n",
      "15067 ('perhaps', 'ADV')\n",
      "15068 ('half', 'DET')\n",
      "15069 ('the', 'DET')\n",
      "15070 ('population', 'NOUN')\n",
      "15071 ('of', 'ADP')\n",
      "15072 ('Oceania', 'NOUN')\n",
      "15073 ('went', 'VERB')\n",
      "15074 ('barefoot', 'ADV')\n",
      "15075 ('.', '')\n",
      "15076 ('And', 'CONJ')\n",
      "15077 ('so', 'CONJ')\n",
      "15078 ('it', 'PRON')\n",
      "15079 ('was', 'VERB')\n",
      "15080 ('with', 'ADP')\n",
      "15081 ('every', 'DET')\n",
      "15082 ('class', 'NOUN')\n",
      "15083 ('of', 'ADP')\n",
      "15084 ('recorded', 'VERB')\n",
      "15085 ('fact', 'NOUN')\n",
      "15086 (',', '')\n",
      "15087 ('great', 'ADJ')\n",
      "15088 ('or', 'CONJ')\n",
      "15089 ('small', 'ADJ')\n",
      "15090 ('.', '')\n",
      "15091 ('Everything', 'PRON')\n",
      "15092 ('faded', 'VERB')\n",
      "15093 ('away', 'ADV')\n",
      "15094 ('into', 'ADP')\n",
      "15095 ('a', 'DET')\n",
      "15096 ('shadow-world', 'NOUN')\n",
      "15097 ('in', 'ADP')\n",
      "15098 ('which', 'PRON')\n",
      "15099 (',', '')\n",
      "15100 ('finally', 'ADV')\n",
      "15101 (',', '')\n",
      "15102 ('even', 'ADV')\n",
      "15103 ('the', 'DET')\n",
      "15104 ('date', 'NOUN')\n",
      "15105 ('of', 'ADP')\n",
      "15106 ('the', 'DET')\n",
      "15107 ('year', 'NOUN')\n",
      "15108 ('had', 'VERB')\n",
      "15109 ('become', 'VERB')\n",
      "15110 ('uncertain', 'ADJ')\n",
      "15111 ('.', '')\n",
      "15112 ('Winston', 'NOUN')\n",
      "15113 ('glanced', 'VERB')\n",
      "15114 ('across', 'ADP')\n",
      "15115 ('the', 'DET')\n",
      "15116 ('hall', 'NOUN')\n",
      "15117 ('.', '')\n",
      "15118 ('In', 'ADP')\n",
      "15119 ('the', 'DET')\n",
      "15120 ('corresponding', 'ADJ')\n",
      "15121 ('cubicle', 'NOUN')\n",
      "15122 ('on', 'ADP')\n",
      "15123 ('the', 'DET')\n",
      "15124 ('other', 'DET')\n",
      "15125 ('side', 'NOUN')\n",
      "15126 ('a', 'DET')\n",
      "15127 ('small', 'ADJ')\n",
      "15128 (',', '')\n",
      "15129 ('precise-looking', 'ADJ')\n",
      "15130 (',', '')\n",
      "15131 ('dark-chinned', 'ADJ')\n",
      "15132 ('man', 'NOUN')\n",
      "15133 ('named', 'VERB')\n",
      "15134 ('Tillotson', 'NOUN')\n",
      "15135 ('was', 'VERB')\n",
      "15136 ('working', 'VERB')\n",
      "15137 ('steadily', 'ADV')\n",
      "15138 ('away', 'ADV')\n",
      "15139 (',', '')\n",
      "15140 ('with', 'ADP')\n",
      "15141 ('a', 'DET')\n",
      "15142 ('folded', 'VERB')\n",
      "15143 ('newspaper', 'NOUN')\n",
      "15144 ('on', 'ADP')\n",
      "15145 ('his', 'DET')\n",
      "15146 ('knee', 'NOUN')\n",
      "15147 ('and', 'CONJ')\n",
      "15148 ('his', 'DET')\n",
      "15149 ('mouth', 'NOUN')\n",
      "15150 ('very', 'ADV')\n",
      "15151 ('close', 'ADJ')\n",
      "15152 ('to', 'ADP')\n",
      "15153 ('the', 'DET')\n",
      "15154 ('mouthpiece', 'NOUN')\n",
      "15155 ('of', 'ADP')\n",
      "15156 ('the', 'DET')\n",
      "15157 ('speakwrite', 'NOUN')\n",
      "15158 ('.', '')\n",
      "15159 ('He', 'PRON')\n",
      "15160 ('had', 'VERB')\n",
      "15161 ('the', 'DET')\n",
      "15162 ('air', 'NOUN')\n",
      "15163 ('of', 'ADP')\n",
      "15164 ('trying', 'VERB')\n",
      "15165 ('to', 'ADP')\n",
      "15166 ('keep', 'VERB')\n",
      "15167 ('what', 'PRON')\n",
      "15168 ('he', 'PRON')\n",
      "15169 ('was', 'VERB')\n",
      "15170 ('saying', 'VERB')\n",
      "15171 ('a', 'DET')\n",
      "15172 ('secret', 'NOUN')\n",
      "15173 ('between', 'ADP')\n",
      "15174 ('himself', 'PRON')\n",
      "15175 ('and', 'CONJ')\n",
      "15176 ('the', 'DET')\n",
      "15177 ('telescreen', 'NOUN')\n",
      "15178 ('.', '')\n",
      "15179 ('He', 'PRON')\n",
      "15180 ('looked', 'VERB')\n",
      "15181 ('up', 'ADP')\n",
      "15182 (',', '')\n",
      "15183 ('and', 'CONJ')\n",
      "15184 ('his', 'DET')\n",
      "15185 ('spectacles', 'NOUN')\n",
      "15186 ('darted', 'VERB')\n",
      "15187 ('a', 'DET')\n",
      "15188 ('hostile', 'ADJ')\n",
      "15189 ('flash', 'NOUN')\n",
      "15190 ('in', 'ADP')\n",
      "15191 ('Winston', 'NOUN')\n",
      "15192 (\"'s\", 'ADP')\n",
      "15193 ('direction', 'NOUN')\n",
      "15194 ('.', '')\n",
      "15195 ('Winston', 'NOUN')\n",
      "15196 ('hardly', 'ADV')\n",
      "15197 ('knew', 'VERB')\n",
      "15198 ('Tillotson', 'NOUN')\n",
      "15199 (',', '')\n",
      "15200 ('and', 'CONJ')\n",
      "15201 ('had', 'VERB')\n",
      "15202 ('no', 'DET')\n",
      "15203 ('idea', 'NOUN')\n",
      "15204 ('what', 'DET')\n",
      "15205 ('work', 'NOUN')\n",
      "15206 ('he', 'PRON')\n",
      "15207 ('was', 'VERB')\n",
      "15208 ('employed', 'VERB')\n",
      "15209 ('on', 'ADP')\n",
      "15210 ('.', '')\n",
      "15211 ('People', 'NOUN')\n",
      "15212 ('in', 'ADP')\n",
      "15213 ('the', 'DET')\n",
      "15214 ('Records', 'NOUN')\n",
      "15215 ('Department', 'NOUN')\n",
      "15216 ('did', 'VERB')\n",
      "15217 ('not', 'ADV')\n",
      "15218 ('readily', 'ADV')\n",
      "15219 ('talk', 'VERB')\n",
      "15220 ('about', 'ADP')\n",
      "15221 ('their', 'DET')\n",
      "15222 ('jobs', 'NOUN')\n",
      "15223 ('.', '')\n",
      "15224 ('In', 'ADP')\n",
      "15225 ('the', 'DET')\n",
      "15226 ('long', 'ADJ')\n",
      "15227 (',', '')\n",
      "15228 ('windowless', 'NOUN')\n",
      "15229 ('hall', 'NOUN')\n",
      "15230 (',', '')\n",
      "15231 ('with', 'ADP')\n",
      "15232 ('its', 'DET')\n",
      "15233 ('double', 'ADJ')\n",
      "15234 ('row', 'NOUN')\n",
      "15235 ('of', 'ADP')\n",
      "15236 ('cubicles', 'NOUN')\n",
      "15237 ('and', 'CONJ')\n",
      "15238 ('its', 'DET')\n",
      "15239 ('endless', 'ADJ')\n",
      "15240 ('rustle', 'NOUN')\n",
      "15241 ('of', 'ADP')\n",
      "15242 ('papers', 'NOUN')\n",
      "15243 ('and', 'CONJ')\n",
      "15244 ('hum', 'NOUN')\n",
      "15245 ('of', 'ADP')\n",
      "15246 ('voices', 'NOUN')\n",
      "15247 ('murmuring', 'VERB')\n",
      "15248 ('into', 'ADP')\n",
      "15249 ('speakwrites', 'NOUN')\n",
      "15250 (',', '')\n",
      "15251 ('there', 'PRON')\n",
      "15252 ('were', 'VERB')\n",
      "15253 ('quite', 'ADV')\n",
      "15254 ('a', 'DET')\n",
      "15255 ('dozen', 'NOUN')\n",
      "15256 ('people', 'NOUN')\n",
      "15257 ('whom', 'PRON')\n",
      "15258 ('Winston', 'NOUN')\n",
      "15259 ('did', 'VERB')\n",
      "15260 ('not', 'ADV')\n",
      "15261 ('even', 'ADV')\n",
      "15262 ('know', 'VERB')\n",
      "15263 ('by', 'ADP')\n",
      "15264 ('name', 'NOUN')\n",
      "15265 (',', '')\n",
      "15266 ('though', 'CONJ')\n",
      "15267 ('he', 'PRON')\n",
      "15268 ('daily', 'ADV')\n",
      "15269 ('saw', 'VERB')\n",
      "15270 ('them', 'PRON')\n",
      "15271 ('hurrying', 'VERB')\n",
      "15272 ('to', 'ADP')\n",
      "15273 ('and', 'CONJ')\n",
      "15274 ('fro', 'ADV')\n",
      "15275 ('in', 'ADP')\n",
      "15276 ('the', 'DET')\n",
      "15277 ('corridors', 'NOUN')\n",
      "15278 ('or', 'CONJ')\n",
      "15279 ('gesticulating', 'VERB')\n",
      "15280 ('in', 'ADP')\n",
      "15281 ('the', 'DET')\n",
      "15282 ('Two', 'NUM')\n",
      "15283 ('Minutes', 'NOUN')\n",
      "15284 ('Hate', 'NOUN')\n",
      "15285 ('.', '')\n",
      "15286 ('He', 'PRON')\n",
      "15287 ('knew', 'VERB')\n",
      "15288 ('that', 'CONJ')\n",
      "15289 ('in', 'ADP')\n",
      "15290 ('the', 'DET')\n",
      "15291 ('cubicle', 'NOUN')\n",
      "15292 ('next', 'ADJ')\n",
      "15293 ('to', 'ADP')\n",
      "15294 ('him', 'PRON')\n",
      "15295 ('the', 'DET')\n",
      "15296 ('little', 'ADJ')\n",
      "15297 ('woman', 'NOUN')\n",
      "15298 ('with', 'ADP')\n",
      "15299 ('sandy', 'ADJ')\n",
      "15300 ('hair', 'NOUN')\n",
      "15301 ('toiled', 'VERB')\n",
      "15302 ('day', 'NOUN')\n",
      "15303 ('in', 'ADP')\n",
      "15304 ('day', 'NOUN')\n",
      "15305 ('out', 'ADP')\n",
      "15306 (',', '')\n",
      "15307 ('simply', 'ADV')\n",
      "15308 ('at', 'ADP')\n",
      "15309 ('tracking', 'VERB')\n",
      "15310 ('down', 'ADV')\n",
      "15311 ('and', 'CONJ')\n",
      "15312 ('deleting', 'VERB')\n",
      "15313 ('from', 'ADP')\n",
      "15314 ('the', 'DET')\n",
      "15315 ('Press', 'NOUN')\n",
      "15316 ('the', 'DET')\n",
      "15317 ('names', 'NOUN')\n",
      "15318 ('of', 'ADP')\n",
      "15319 ('people', 'NOUN')\n",
      "15320 ('who', 'PRON')\n",
      "15321 ('had', 'VERB')\n",
      "15322 ('been', 'VERB')\n",
      "15323 ('vaporized', 'VERB')\n",
      "15324 ('and', 'CONJ')\n",
      "15325 ('were', 'VERB')\n",
      "15326 ('therefore', 'ADV')\n",
      "15327 ('considered', 'VERB')\n",
      "15328 ('never', 'ADV')\n",
      "15329 ('to', 'ADP')\n",
      "15330 ('have', 'VERB')\n",
      "15331 ('existed', 'VERB')\n",
      "15332 ('.', '')\n",
      "15333 ('There', 'PRON')\n",
      "15334 ('was', 'VERB')\n",
      "15335 ('a', 'DET')\n",
      "15336 ('certain', 'DET')\n",
      "15337 ('fitness', 'NOUN')\n",
      "15338 ('in', 'ADP')\n",
      "15339 ('this', 'PRON')\n",
      "15340 (',', '')\n",
      "15341 ('since', 'CONJ')\n",
      "15342 ('her', 'DET')\n",
      "15343 ('own', 'ADJ')\n",
      "15344 ('husband', 'NOUN')\n",
      "15345 ('had', 'VERB')\n",
      "15346 ('been', 'VERB')\n",
      "15347 ('vaporized', 'VERB')\n",
      "15348 ('a', 'DET')\n",
      "15349 ('couple', 'NOUN')\n",
      "15350 ('of', 'ADP')\n",
      "15351 ('years', 'NOUN')\n",
      "15352 ('earlier', 'ADJ')\n",
      "15353 ('.', '')\n",
      "15354 ('And', 'CONJ')\n",
      "15355 ('a', 'DET')\n",
      "15356 ('few', 'DET')\n",
      "15357 ('cubicles', 'NOUN')\n",
      "15358 ('away', 'ADV')\n",
      "15359 ('a', 'DET')\n",
      "15360 ('mild', 'ADJ')\n",
      "15361 (',', '')\n",
      "15362 ('ineffectual', 'ADJ')\n",
      "15363 (',', '')\n",
      "15364 ('dreamy', 'ADJ')\n",
      "15365 ('creature', 'NOUN')\n",
      "15366 ('named', 'VERB')\n",
      "15367 ('Ampleforth', 'ADV')\n",
      "15368 (',', '')\n",
      "15369 ('with', 'ADP')\n",
      "15370 ('very', 'ADV')\n",
      "15371 ('hairy', 'ADJ')\n",
      "15372 ('ears', 'NOUN')\n",
      "15373 ('and', 'CONJ')\n",
      "15374 ('a', 'DET')\n",
      "15375 ('surprising', 'ADJ')\n",
      "15376 ('talent', 'NOUN')\n",
      "15377 ('for', 'ADP')\n",
      "15378 ('juggling', 'VERB')\n",
      "15379 ('with', 'ADP')\n",
      "15380 ('rhymes', 'NOUN')\n",
      "15381 ('and', 'CONJ')\n",
      "15382 ('metres', 'NOUN')\n",
      "15383 (',', '')\n",
      "15384 ('was', 'VERB')\n",
      "15385 ('engaged', 'VERB')\n",
      "15386 ('in', 'ADP')\n",
      "15387 ('producing', 'VERB')\n",
      "15388 ('garbled', 'ADJ')\n",
      "15389 ('versions', 'NOUN')\n",
      "15390 ('-', '')\n",
      "15391 ('definitive', 'ADJ')\n",
      "15392 ('texts', 'NOUN')\n",
      "15393 (',', '')\n",
      "15394 ('they', 'PRON')\n",
      "15395 ('were', 'VERB')\n",
      "15396 ('called', 'VERB')\n",
      "15397 ('-', '')\n",
      "15398 ('of', 'ADP')\n",
      "15399 ('poems', 'NOUN')\n",
      "15400 ('which', 'PRON')\n",
      "15401 ('had', 'VERB')\n",
      "15402 ('become', 'VERB')\n",
      "15403 ('ideologically', 'ADV')\n",
      "15404 ('offensive', 'ADJ')\n",
      "15405 (',', '')\n",
      "15406 ('but', 'CONJ')\n",
      "15407 ('which', 'PRON')\n",
      "15408 ('for', 'ADP')\n",
      "15409 ('one', 'NUM')\n",
      "15410 ('reason', 'NOUN')\n",
      "15411 ('or', 'CONJ')\n",
      "15412 ('another', 'PRON')\n",
      "15413 ('were', 'VERB')\n",
      "15414 ('to', 'ADP')\n",
      "15415 ('be', 'VERB')\n",
      "15416 ('retained', 'VERB')\n",
      "15417 ('in', 'ADP')\n",
      "15418 ('the', 'DET')\n",
      "15419 ('anthologies', 'NOUN')\n",
      "15420 ('.', '')\n",
      "15421 ('And', 'CONJ')\n",
      "15422 ('this', 'DET')\n",
      "15423 ('hall', 'NOUN')\n",
      "15424 (',', '')\n",
      "15425 ('with', 'ADP')\n",
      "15426 ('its', 'DET')\n",
      "15427 ('fifty', 'NUM')\n",
      "15428 ('workers', 'NOUN')\n",
      "15429 ('or', 'CONJ')\n",
      "15430 ('thereabouts', 'ADV')\n",
      "15431 (',', '')\n",
      "15432 ('was', 'VERB')\n",
      "15433 ('only', 'ADV')\n",
      "15434 ('one', 'NUM')\n",
      "15435 ('sub-section', 'NOUN')\n",
      "15436 (',', '')\n",
      "15437 ('a', 'DET')\n",
      "15438 ('single', 'ADJ')\n",
      "15439 ('cell', 'NOUN')\n",
      "15440 (',', '')\n",
      "15441 ('as', 'CONJ')\n",
      "15442 ('it', 'PRON')\n",
      "15443 ('were', 'VERB')\n",
      "15444 (',', '')\n",
      "15445 ('in', 'ADP')\n",
      "15446 ('the', 'DET')\n",
      "15447 ('huge', 'ADJ')\n",
      "15448 ('complexity', 'NOUN')\n",
      "15449 ('of', 'ADP')\n",
      "15450 ('the', 'DET')\n",
      "15451 ('Records', 'NOUN')\n",
      "15452 ('Department', 'NOUN')\n",
      "15453 ('.', '')\n",
      "15454 ('Beyond', 'ADV')\n",
      "15455 (',', '')\n",
      "15456 ('above', 'ADV')\n",
      "15457 (',', '')\n",
      "15458 ('below', 'ADV')\n",
      "15459 (',', '')\n",
      "15460 ('were', 'VERB')\n",
      "15461 ('other', 'DET')\n",
      "15462 ('swarms', 'NOUN')\n",
      "15463 ('of', 'ADP')\n",
      "15464 ('workers', 'NOUN')\n",
      "15465 ('engaged', 'VERB')\n",
      "15466 ('in', 'ADP')\n",
      "15467 ('an', 'DET')\n",
      "15468 ('unimaginable', 'ADJ')\n",
      "15469 ('multitude', 'NOUN')\n",
      "15470 ('of', 'ADP')\n",
      "15471 ('jobs', 'NOUN')\n",
      "15472 ('.', '')\n",
      "15473 ('There', 'PRON')\n",
      "15474 ('were', 'VERB')\n",
      "15475 ('the', 'DET')\n",
      "15476 ('huge', 'ADJ')\n",
      "15477 ('printingshops', 'NOUN')\n",
      "15478 ('with', 'ADP')\n",
      "15479 ('their', 'DET')\n",
      "15480 ('sub-editors', 'NOUN')\n",
      "15481 (',', '')\n",
      "15482 ('their', 'DET')\n",
      "15483 ('typography', 'NOUN')\n",
      "15484 ('experts', 'NOUN')\n",
      "15485 (',', '')\n",
      "15486 ('and', 'CONJ')\n",
      "15487 ('their', 'DET')\n",
      "15488 ('elaborately', 'ADV')\n",
      "15489 ('equipped', 'VERB')\n",
      "15490 ('studios', 'NOUN')\n",
      "15491 ('for', 'ADP')\n",
      "15492 ('the', 'DET')\n",
      "15493 ('faking', 'VERB')\n",
      "15494 ('of', 'ADP')\n",
      "15495 ('photographs', 'NOUN')\n",
      "15496 ('.', '')\n",
      "15497 ('There', 'PRON')\n",
      "15498 ('was', 'VERB')\n",
      "15499 ('the', 'DET')\n",
      "15500 ('tele-programmes', 'NOUN')\n",
      "15501 ('section', 'NOUN')\n",
      "15502 ('with', 'ADP')\n",
      "15503 ('its', 'DET')\n",
      "15504 ('engineers', 'NOUN')\n",
      "15505 (',', '')\n",
      "15506 ('its', 'DET')\n",
      "15507 ('producers', 'NOUN')\n",
      "15508 (',', '')\n",
      "15509 ('and', 'CONJ')\n",
      "15510 ('its', 'DET')\n",
      "15511 ('teams', 'NOUN')\n",
      "15512 ('of', 'ADP')\n",
      "15513 ('actors', 'NOUN')\n",
      "15514 ('specially', 'ADV')\n",
      "15515 ('chosen', 'VERB')\n",
      "15516 ('for', 'ADP')\n",
      "15517 ('their', 'DET')\n",
      "15518 ('skill', 'NOUN')\n",
      "15519 ('in', 'ADP')\n",
      "15520 ('imitating', 'VERB')\n",
      "15521 ('voices', 'NOUN')\n",
      "15522 ('.', '')\n",
      "15523 ('There', 'PRON')\n",
      "15524 ('were', 'VERB')\n",
      "15525 ('the', 'DET')\n",
      "15526 ('armies', 'NOUN')\n",
      "15527 ('of', 'ADP')\n",
      "15528 ('reference', 'NOUN')\n",
      "15529 ('clerks', 'NOUN')\n",
      "15530 ('whose', 'PRON')\n",
      "15531 ('job', 'NOUN')\n",
      "15532 ('was', 'VERB')\n",
      "15533 ('simply', 'ADV')\n",
      "15534 ('to', 'ADP')\n",
      "15535 ('draw', 'VERB')\n",
      "15536 ('up', 'ADP')\n",
      "15537 ('lists', 'NOUN')\n",
      "15538 ('of', 'ADP')\n",
      "15539 ('books', 'NOUN')\n",
      "15540 ('and', 'CONJ')\n",
      "15541 ('periodicals', 'NOUN')\n",
      "15542 ('which', 'PRON')\n",
      "15543 ('were', 'VERB')\n",
      "15544 ('due', 'ADJ')\n",
      "15545 ('for', 'ADP')\n",
      "15546 ('recall', 'NOUN')\n",
      "15547 ('.', '')\n",
      "15548 ('There', 'PRON')\n",
      "15549 ('were', 'VERB')\n",
      "15550 ('the', 'DET')\n",
      "15551 ('vast', 'ADJ')\n",
      "15552 ('repositories', 'NOUN')\n",
      "15553 ('where', 'CONJ')\n",
      "15554 ('the', 'DET')\n",
      "15555 ('corrected', 'VERB')\n",
      "15556 ('documents', 'NOUN')\n",
      "15557 ('were', 'VERB')\n",
      "15558 ('stored', 'VERB')\n",
      "15559 (',', '')\n",
      "15560 ('and', 'CONJ')\n",
      "15561 ('the', 'DET')\n",
      "15562 ('hidden', 'VERB')\n",
      "15563 ('furnaces', 'NOUN')\n",
      "15564 ('where', 'CONJ')\n",
      "15565 ('the', 'DET')\n",
      "15566 ('original', 'ADJ')\n",
      "15567 ('copies', 'NOUN')\n",
      "15568 ('were', 'VERB')\n",
      "15569 ('destroyed', 'VERB')\n",
      "15570 ('.', '')\n",
      "15571 ('And', 'CONJ')\n",
      "15572 ('somewhere', 'ADV')\n",
      "15573 ('or', 'CONJ')\n",
      "15574 ('other', 'DET')\n",
      "15575 (',', '')\n",
      "15576 ('quite', 'ADV')\n",
      "15577 ('anonymous', 'ADJ')\n",
      "15578 (',', '')\n",
      "15579 ('there', 'PRON')\n",
      "15580 ('were', 'VERB')\n",
      "15581 ('the', 'DET')\n",
      "15582 ('directing', 'VERB')\n",
      "15583 ('brains', 'NOUN')\n",
      "15584 ('who', 'PRON')\n",
      "15585 ('co-ordinated', 'VERB')\n",
      "15586 ('the', 'DET')\n",
      "15587 ('whole', 'ADJ')\n",
      "15588 ('effort', 'NOUN')\n",
      "15589 ('and', 'CONJ')\n",
      "15590 ('laid', 'VERB')\n",
      "15591 ('down', 'ADV')\n",
      "15592 ('the', 'DET')\n",
      "15593 ('lines', 'NOUN')\n",
      "15594 ('of', 'ADP')\n",
      "15595 ('policy', 'NOUN')\n",
      "15596 ('which', 'PRON')\n",
      "15597 ('made', 'VERB')\n",
      "15598 ('it', 'PRON')\n",
      "15599 ('necessary', 'ADJ')\n",
      "15600 ('that', 'CONJ')\n",
      "15601 ('this', 'DET')\n",
      "15602 ('fragment', 'NOUN')\n",
      "15603 ('of', 'ADP')\n",
      "15604 ('the', 'DET')\n",
      "15605 ('past', 'NOUN')\n",
      "15606 ('should', 'VERB')\n",
      "15607 ('be', 'VERB')\n",
      "15608 ('preserved', 'VERB')\n",
      "15609 (',', '')\n",
      "15610 ('that', 'CONJ')\n",
      "15611 ('one', 'PRON')\n",
      "15612 ('falsified', 'VERB')\n",
      "15613 (',', '')\n",
      "15614 ('and', 'CONJ')\n",
      "15615 ('the', 'DET')\n",
      "15616 ('other', 'NOUN')\n",
      "15617 ('rubbed', 'VERB')\n",
      "15618 ('out', 'ADP')\n",
      "15619 ('of', 'ADP')\n",
      "15620 ('existence', 'NOUN')\n",
      "15621 ('.', '')\n",
      "15622 ('And', 'CONJ')\n",
      "15623 ('the', 'DET')\n",
      "15624 ('Records', 'NOUN')\n",
      "15625 ('Department', 'NOUN')\n",
      "15626 (',', '')\n",
      "15627 ('after', 'ADP')\n",
      "15628 ('all', 'PRON')\n",
      "15629 (',', '')\n",
      "15630 ('was', 'VERB')\n",
      "15631 ('itself', 'PRON')\n",
      "15632 ('only', 'ADV')\n",
      "15633 ('a', 'DET')\n",
      "15634 ('single', 'ADJ')\n",
      "15635 ('branch', 'NOUN')\n",
      "15636 ('of', 'ADP')\n",
      "15637 ('the', 'DET')\n",
      "15638 ('Ministry', 'NOUN')\n",
      "15639 ('of', 'ADP')\n",
      "15640 ('Truth', 'NOUN')\n",
      "15641 (',', '')\n",
      "15642 ('whose', 'PRON')\n",
      "15643 ('primary', 'ADJ')\n",
      "15644 ('job', 'NOUN')\n",
      "15645 ('was', 'VERB')\n",
      "15646 ('not', 'ADV')\n",
      "15647 ('to', 'ADP')\n",
      "15648 ('reconstruct', 'VERB')\n",
      "15649 ('the', 'DET')\n",
      "15650 ('past', 'NOUN')\n",
      "15651 ('but', 'CONJ')\n",
      "15652 ('to', 'ADP')\n",
      "15653 ('supply', 'VERB')\n",
      "15654 ('the', 'DET')\n",
      "15655 ('citizens', 'NOUN')\n",
      "15656 ('of', 'ADP')\n",
      "15657 ('Oceania', 'NOUN')\n",
      "15658 ('with', 'ADP')\n",
      "15659 ('newspapers', 'NOUN')\n",
      "15660 (',', '')\n",
      "15661 ('films', 'NOUN')\n",
      "15662 (',', '')\n",
      "15663 ('textbooks', 'NOUN')\n",
      "15664 (',', '')\n",
      "15665 ('telescreen', 'NOUN')\n",
      "15666 ('programmes', 'NOUN')\n",
      "15667 (',', '')\n",
      "15668 ('plays', 'NOUN')\n",
      "15669 (',', '')\n",
      "15670 ('novels', 'NOUN')\n",
      "15671 ('-', '')\n",
      "15672 ('with', 'ADP')\n",
      "15673 ('every', 'DET')\n",
      "15674 ('conceivable', 'ADJ')\n",
      "15675 ('kind', 'NOUN')\n",
      "15676 ('of', 'ADP')\n",
      "15677 ('information', 'NOUN')\n",
      "15678 (',', '')\n",
      "15679 ('instruction', 'NOUN')\n",
      "15680 (',', '')\n",
      "15681 ('or', 'CONJ')\n",
      "15682 ('entertainment', 'NOUN')\n",
      "15683 (',', '')\n",
      "15684 ('from', 'ADP')\n",
      "15685 ('a', 'DET')\n",
      "15686 ('statue', 'NOUN')\n",
      "15687 ('to', 'ADP')\n",
      "15688 ('a', 'DET')\n",
      "15689 ('slogan', 'NOUN')\n",
      "15690 (',', '')\n",
      "15691 ('from', 'ADP')\n",
      "15692 ('a', 'DET')\n",
      "15693 ('lyric', 'ADJ')\n",
      "15694 ('poem', 'NOUN')\n",
      "15695 ('to', 'ADP')\n",
      "15696 ('a', 'DET')\n",
      "15697 ('biological', 'ADJ')\n",
      "15698 ('treatise', 'NOUN')\n",
      "15699 (',', '')\n",
      "15700 ('and', 'CONJ')\n",
      "15701 ('from', 'ADP')\n",
      "15702 ('a', 'DET')\n",
      "15703 ('child', 'NOUN')\n",
      "15704 (\"'s\", 'ADP')\n",
      "15705 ('spelling-book', 'NOUN')\n",
      "15706 ('to', 'ADP')\n",
      "15707 ('a', 'DET')\n",
      "15708 ('Newspeak', 'ADJ')\n",
      "15709 ('dictionary', 'NOUN')\n",
      "15710 ('.', '')\n",
      "15711 ('And', 'CONJ')\n",
      "15712 ('the', 'DET')\n",
      "15713 ('Ministry', 'NOUN')\n",
      "15714 ('had', 'VERB')\n",
      "15715 ('not', 'ADV')\n",
      "15716 ('only', 'ADV')\n",
      "15717 ('to', 'ADP')\n",
      "15718 ('supply', 'VERB')\n",
      "15719 ('the', 'DET')\n",
      "15720 ('multifarious', 'ADJ')\n",
      "15721 ('needs', 'NOUN')\n",
      "15722 ('of', 'ADP')\n",
      "15723 ('the', 'DET')\n",
      "15724 ('Party', 'NOUN')\n",
      "15725 (',', '')\n",
      "15726 ('but', 'CONJ')\n",
      "15727 ('also', 'ADV')\n",
      "15728 ('to', 'ADP')\n",
      "15729 ('repeat', 'VERB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15730 ('the', 'DET')\n",
      "15731 ('whole', 'ADJ')\n",
      "15732 ('operation', 'NOUN')\n",
      "15733 ('at', 'ADP')\n",
      "15734 ('a', 'DET')\n",
      "15735 ('lower', 'ADJ')\n",
      "15736 ('level', 'NOUN')\n",
      "15737 ('for', 'ADP')\n",
      "15738 ('the', 'DET')\n",
      "15739 ('benefit', 'NOUN')\n",
      "15740 ('of', 'ADP')\n",
      "15741 ('the', 'DET')\n",
      "15742 ('proletariat', 'NOUN')\n",
      "15743 ('.', '')\n",
      "15744 ('There', 'PRON')\n",
      "15745 ('was', 'VERB')\n",
      "15746 ('a', 'DET')\n",
      "15747 ('whole', 'ADJ')\n",
      "15748 ('chain', 'NOUN')\n",
      "15749 ('of', 'ADP')\n",
      "15750 ('separate', 'ADJ')\n",
      "15751 ('departments', 'NOUN')\n",
      "15752 ('dealing', 'VERB')\n",
      "15753 ('with', 'ADP')\n",
      "15754 ('proletarian', 'ADJ')\n",
      "15755 ('literature', 'NOUN')\n",
      "15756 (',', '')\n",
      "15757 ('music', 'NOUN')\n",
      "15758 (',', '')\n",
      "15759 ('drama', 'NOUN')\n",
      "15760 (',', '')\n",
      "15761 ('and', 'CONJ')\n",
      "15762 ('entertainment', 'NOUN')\n",
      "15763 ('generally', 'ADV')\n",
      "15764 ('.', '')\n",
      "15765 ('Here', 'ADV')\n",
      "15766 ('were', 'VERB')\n",
      "15767 ('produced', 'VERB')\n",
      "15768 ('rubbishy', 'ADJ')\n",
      "15769 ('newspapers', 'NOUN')\n",
      "15770 ('containing', 'VERB')\n",
      "15771 ('almost', 'ADV')\n",
      "15772 ('nothing', 'PRON')\n",
      "15773 ('except', 'ADP')\n",
      "15774 ('sport', 'NOUN')\n",
      "15775 (',', '')\n",
      "15776 ('crime', 'NOUN')\n",
      "15777 ('and', 'CONJ')\n",
      "15778 ('astrology', 'NOUN')\n",
      "15779 (',', '')\n",
      "15780 ('sensational', 'ADJ')\n",
      "15781 ('five-cent', 'ADJ')\n",
      "15782 ('novelettes', 'NOUN')\n",
      "15783 (',', '')\n",
      "15784 ('films', 'NOUN')\n",
      "15785 ('oozing', 'VERB')\n",
      "15786 ('with', 'ADP')\n",
      "15787 ('sex', 'NOUN')\n",
      "15788 (',', '')\n",
      "15789 ('and', 'CONJ')\n",
      "15790 ('sentimental', 'ADJ')\n",
      "15791 ('songs', 'NOUN')\n",
      "15792 ('which', 'PRON')\n",
      "15793 ('were', 'VERB')\n",
      "15794 ('composed', 'VERB')\n",
      "15795 ('entirely', 'ADV')\n",
      "15796 ('by', 'ADP')\n",
      "15797 ('mechanical', 'ADJ')\n",
      "15798 ('means', 'NOUN')\n",
      "15799 ('on', 'ADP')\n",
      "15800 ('a', 'DET')\n",
      "15801 ('special', 'ADJ')\n",
      "15802 ('kind', 'NOUN')\n",
      "15803 ('of', 'ADP')\n",
      "15804 ('kaleidoscope', 'NOUN')\n",
      "15805 ('known', 'VERB')\n",
      "15806 ('as', 'ADP')\n",
      "15807 ('a', 'DET')\n",
      "15808 ('versificator', 'NOUN')\n",
      "15809 ('.', '')\n",
      "15810 ('There', 'PRON')\n",
      "15811 ('was', 'VERB')\n",
      "15812 ('even', 'ADV')\n",
      "15813 ('a', 'DET')\n",
      "15814 ('whole', 'ADJ')\n",
      "15815 ('sub-section', 'NOUN')\n",
      "15816 ('-', '')\n",
      "15817 ('Pornosec', 'NOUN')\n",
      "15818 (',', '')\n",
      "15819 ('it', 'PRON')\n",
      "15820 ('was', 'VERB')\n",
      "15821 ('called', 'VERB')\n",
      "15822 ('in', 'ADP')\n",
      "15823 ('Newspeak', 'NOUN')\n",
      "15824 ('-', '')\n",
      "15825 ('engaged', 'VERB')\n",
      "15826 ('in', 'ADP')\n",
      "15827 ('producing', 'VERB')\n",
      "15828 ('the', 'DET')\n",
      "15829 ('lowest', 'ADJ')\n",
      "15830 ('kind', 'NOUN')\n",
      "15831 ('of', 'ADP')\n",
      "15832 ('pornography', 'NOUN')\n",
      "15833 (',', '')\n",
      "15834 ('which', 'PRON')\n",
      "15835 ('was', 'VERB')\n",
      "15836 ('sent', 'VERB')\n",
      "15837 ('out', 'ADP')\n",
      "15838 ('in', 'ADP')\n",
      "15839 ('sealed', 'VERB')\n",
      "15840 ('packets', 'NOUN')\n",
      "15841 ('and', 'CONJ')\n",
      "15842 ('which', 'PRON')\n",
      "15843 ('no', 'DET')\n",
      "15844 ('Party', 'NOUN')\n",
      "15845 ('member', 'NOUN')\n",
      "15846 (',', '')\n",
      "15847 ('other', 'ADJ')\n",
      "15848 ('than', 'ADP')\n",
      "15849 ('those', 'PRON')\n",
      "15850 ('who', 'PRON')\n",
      "15851 ('worked', 'VERB')\n",
      "15852 ('on', 'ADP')\n",
      "15853 ('it', 'PRON')\n",
      "15854 (',', '')\n",
      "15855 ('was', 'VERB')\n",
      "15856 ('permitted', 'VERB')\n",
      "15857 ('to', 'ADP')\n",
      "15858 ('look', 'VERB')\n",
      "15859 ('at', 'ADP')\n",
      "15860 ('.', '')\n",
      "15861 ('Three', 'NUM')\n",
      "15862 ('messages', 'NOUN')\n",
      "15863 ('had', 'VERB')\n",
      "15864 ('slid', 'VERB')\n",
      "15865 ('out', 'ADP')\n",
      "15866 ('of', 'ADP')\n",
      "15867 ('the', 'DET')\n",
      "15868 ('pneumatic', 'ADJ')\n",
      "15869 ('tube', 'NOUN')\n",
      "15870 ('while', 'CONJ')\n",
      "15871 ('Winston', 'NOUN')\n",
      "15872 ('was', 'VERB')\n",
      "15873 ('working', 'VERB')\n",
      "15874 (',', '')\n",
      "15875 ('but', 'CONJ')\n",
      "15876 ('they', 'PRON')\n",
      "15877 ('were', 'VERB')\n",
      "15878 ('simple', 'ADJ')\n",
      "15879 ('matters', 'NOUN')\n",
      "15880 (',', '')\n",
      "15881 ('and', 'CONJ')\n",
      "15882 ('he', 'PRON')\n",
      "15883 ('had', 'VERB')\n",
      "15884 ('disposed', 'VERB')\n",
      "15885 ('of', 'ADP')\n",
      "15886 ('them', 'PRON')\n",
      "15887 ('before', 'CONJ')\n",
      "15888 ('the', 'DET')\n",
      "15889 ('Two', 'NUM')\n",
      "15890 ('Minutes', 'NOUN')\n",
      "15891 ('Hate', 'NOUN')\n",
      "15892 ('interrupted', 'VERB')\n",
      "15893 ('him', 'PRON')\n",
      "15894 ('.', '')\n",
      "15895 ('When', 'CONJ')\n",
      "15896 ('the', 'DET')\n",
      "15897 ('Hate', 'NOUN')\n",
      "15898 ('was', 'VERB')\n",
      "15899 ('over', 'ADJ')\n",
      "15900 ('he', 'PRON')\n",
      "15901 ('returned', 'VERB')\n",
      "15902 ('to', 'ADP')\n",
      "15903 ('his', 'DET')\n",
      "15904 ('cubicle', 'NOUN')\n",
      "15905 (',', '')\n",
      "15906 ('took', 'VERB')\n",
      "15907 ('the', 'DET')\n",
      "15908 ('Newspeak', 'ADJ')\n",
      "15909 ('Dictionary', 'NOUN')\n",
      "15910 ('from', 'ADP')\n",
      "15911 ('the', 'DET')\n",
      "15912 ('shelf', 'NOUN')\n",
      "15913 (',', '')\n",
      "15914 ('pushed', 'VERB')\n",
      "15915 ('the', 'DET')\n",
      "15916 ('speakwrite', 'NOUN')\n",
      "15917 ('to', 'ADP')\n",
      "15918 ('one', 'NUM')\n",
      "15919 ('side', 'NOUN')\n",
      "15920 (',', '')\n",
      "15921 ('cleaned', 'VERB')\n",
      "15922 ('his', 'DET')\n",
      "15923 ('spectacles', 'NOUN')\n",
      "15924 (',', '')\n",
      "15925 ('and', 'CONJ')\n",
      "15926 ('settled', 'VERB')\n",
      "15927 ('down', 'ADV')\n",
      "15928 ('to', 'ADP')\n",
      "15929 ('his', 'DET')\n",
      "15930 ('main', 'ADJ')\n",
      "15931 ('job', 'NOUN')\n",
      "15932 ('of', 'ADP')\n",
      "15933 ('the', 'DET')\n",
      "15934 ('morning', 'NOUN')\n",
      "15935 ('.', '')\n",
      "15936 ('Winston', 'NOUN')\n",
      "15937 (\"'s\", 'ADP')\n",
      "15938 ('greatest', 'ADJ')\n",
      "15939 ('pleasure', 'NOUN')\n",
      "15940 ('in', 'ADP')\n",
      "15941 ('life', 'NOUN')\n",
      "15942 ('was', 'VERB')\n",
      "15943 ('in', 'ADP')\n",
      "15944 ('his', 'DET')\n",
      "15945 ('work', 'NOUN')\n",
      "15946 ('.', '')\n",
      "15947 ('Most', 'PRON')\n",
      "15948 ('of', 'ADP')\n",
      "15949 ('it', 'PRON')\n",
      "15950 ('was', 'VERB')\n",
      "15951 ('a', 'DET')\n",
      "15952 ('tedious', 'ADJ')\n",
      "15953 ('routine', 'NOUN')\n",
      "15954 (',', '')\n",
      "15955 ('but', 'CONJ')\n",
      "15956 ('included', 'VERB')\n",
      "15957 ('in', 'ADP')\n",
      "15958 ('it', 'PRON')\n",
      "15959 ('there', 'PRON')\n",
      "15960 ('were', 'VERB')\n",
      "15961 ('also', 'ADV')\n",
      "15962 ('jobs', 'NOUN')\n",
      "15963 ('so', 'ADV')\n",
      "15964 ('difficult', 'ADJ')\n",
      "15965 ('and', 'CONJ')\n",
      "15966 ('intricate', 'ADJ')\n",
      "15967 ('that', 'CONJ')\n",
      "15968 ('you', 'PRON')\n",
      "15969 ('could', 'VERB')\n",
      "15970 ('lose', 'VERB')\n",
      "15971 ('yourself', 'PRON')\n",
      "15972 ('in', 'ADP')\n",
      "15973 ('them', 'PRON')\n",
      "15974 ('as', 'CONJ')\n",
      "15975 ('in', 'ADP')\n",
      "15976 ('the', 'DET')\n",
      "15977 ('depths', 'NOUN')\n",
      "15978 ('of', 'ADP')\n",
      "15979 ('a', 'DET')\n",
      "15980 ('mathematical', 'ADJ')\n",
      "15981 ('problem', 'NOUN')\n",
      "15982 ('-', '')\n",
      "15983 ('delicate', 'ADJ')\n",
      "15984 ('pieces', 'NOUN')\n",
      "15985 ('of', 'ADP')\n",
      "15986 ('forgery', 'NOUN')\n",
      "15987 ('in', 'ADP')\n",
      "15988 ('which', 'PRON')\n",
      "15989 ('you', 'PRON')\n",
      "15990 ('had', 'VERB')\n",
      "15991 ('nothing', 'PRON')\n",
      "15992 ('to', 'ADP')\n",
      "15993 ('guide', 'VERB')\n",
      "15994 ('you', 'PRON')\n",
      "15995 ('except', 'ADP')\n",
      "15996 ('your', 'DET')\n",
      "15997 ('knowledge', 'NOUN')\n",
      "15998 ('of', 'ADP')\n",
      "15999 ('the', 'DET')\n",
      "16000 ('principles', 'NOUN')\n",
      "16001 ('of', 'ADP')\n",
      "16002 ('Ingsoc', 'NOUN')\n",
      "16003 ('and', 'CONJ')\n",
      "16004 ('your', 'DET')\n",
      "16005 ('estimate', 'NOUN')\n",
      "16006 ('of', 'ADP')\n",
      "16007 ('what', 'PRON')\n",
      "16008 ('the', 'DET')\n",
      "16009 ('Party', 'NOUN')\n",
      "16010 ('wanted', 'VERB')\n",
      "16011 ('you', 'PRON')\n",
      "16012 ('to', 'ADP')\n",
      "16013 ('say', 'VERB')\n",
      "16014 ('.', '')\n",
      "16015 ('Winston', 'NOUN')\n",
      "16016 ('was', 'VERB')\n",
      "16017 ('good', 'ADJ')\n",
      "16018 ('at', 'ADP')\n",
      "16019 ('this', 'DET')\n",
      "16020 ('kind', 'NOUN')\n",
      "16021 ('of', 'ADP')\n",
      "16022 ('thing', 'NOUN')\n",
      "16023 ('.', '')\n",
      "16024 ('On', 'ADP')\n",
      "16025 ('occasion', 'NOUN')\n",
      "16026 ('he', 'PRON')\n",
      "16027 ('had', 'VERB')\n",
      "16028 ('even', 'ADV')\n",
      "16029 ('been', 'VERB')\n",
      "16030 ('entrusted', 'VERB')\n",
      "16031 ('with', 'ADP')\n",
      "16032 ('the', 'DET')\n",
      "16033 ('rectification', 'NOUN')\n",
      "16034 ('of', 'ADP')\n",
      "16035 ('the', 'DET')\n",
      "16036 ('Times', 'NOUN')\n",
      "16037 ('leading', 'ADJ')\n",
      "16038 ('articles', 'NOUN')\n",
      "16039 (',', '')\n"
     ]
    }
   ],
   "source": [
    "## ----------- II ----------- #\n",
    "#test label creator\n",
    "bubu2=[]\n",
    "dev_labels = []\n",
    "tag_counter = 0\n",
    "counter_label = 0\n",
    "for idx3, k in enumerate(data):\n",
    "    #print(idx3, k)\n",
    "    for idx4, m in enumerate(k):\n",
    "        #print(tag_counter,m)\n",
    "        if (40*0)-1 < tag_counter < 40*401:\n",
    "            if tag_counter in(5920,7200):\n",
    "                print(tag_counter,m)\n",
    "                bubu2.append(\"'s\")\n",
    "                dev_labels.append('VERB')\n",
    "            elif tag_counter == 10760:\n",
    "                bubu2.append(\"'s\")\n",
    "                dev_labels.append('ADP')\n",
    "                print(\"s',ADP\") \n",
    "            elif tag_counter == 8360:\n",
    "                bubu2.append(\"'m\")\n",
    "                dev_labels.append('VERB')\n",
    "                print(\"m,VERB\")\n",
    "            elif tag_counter == 11286:\n",
    "                bubu2.append(\"3\")\n",
    "                dev_labels.append('NUM')\n",
    "                print(\"3,NUM\")\n",
    "                bubu2.append(\",\")\n",
    "                dev_labels.append('')\n",
    "                bubu2.append(\"000\")\n",
    "                dev_labels.append('NUM')\n",
    "            elif tag_counter == 13297:\n",
    "                bubu2.append(\"W\")\n",
    "                dev_labels.append('NOUN')\n",
    "                bubu2.append(\".\")\n",
    "                dev_labels.append('')\n",
    "            elif m[0] !=  \"'s\" and  m[0] != \"'ve\" and  m[0] != \"'t\" and m[0] !=  \"'d\" and m[0] !=  \"'m\" and m[0] !=  \"'re\" and m[0] !=  \"'ave\"and m[0] !=  \"'ll\" and m[0] !=  \"'em\" :\n",
    "                if m[0] == '...':\n",
    "                    bubu2.append('.')\n",
    "                    dev_labels.append('')\n",
    "                    bubu2.append('.')\n",
    "                    dev_labels.append('')\n",
    "                    print('')  \n",
    "                elif tag_counter in (13888,13895,13907,13913,16062):\n",
    "                    bubu2.append('17')\n",
    "                    dev_labels.append('NUM')\n",
    "                    bubu2.append('.')\n",
    "                    dev_labels.append('')\n",
    "                    bubu2.append('3')\n",
    "                    dev_labels.append('NUM')\n",
    "                    bubu2.append('.')\n",
    "                    dev_labels.append('')\n",
    "                bubu2.append(m[0])\n",
    "                dev_labels.append(m[1])\n",
    "                #print(ww[tag_counter])\n",
    "            print(tag_counter,m)\n",
    "        tag_counter += 1\n",
    "        counter_label +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-water",
   "metadata": {},
   "source": [
    "The below code checks whether the two match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "parliamentary-semiconductor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winston's Winston 510\n",
      "people's people 576\n",
      "Winston's Winston 594\n",
      "tomorrow's tomorrow 1392\n",
      "child's child 2883\n",
      "O'Brien's O'Brien 3663\n",
      "prize-fighter's prize-fighter 3668\n",
      "O'Brien's O'Brien 3694\n",
      "one's one 3894\n",
      "one's one 3906\n",
      "Party's Party 4058\n",
      "Winston's Winston 4128\n",
      "Goldstein's Goldstein 4403\n",
      "Goldstein's Goldstein 4468\n",
      "O'Brien's O'Brien 4867\n",
      "Goldstein's Goldstein 4934\n",
      "one's one 5055\n",
      "Winston's Winston 5098\n",
      "one's one 5276\n",
      "one's one 5299\n",
      "sheep's sheep 5470\n",
      "everyone's everyone 5691\n",
      ". ... 5779\n",
      ". ... 5784\n",
      ". ... 5933\n",
      "O'Brien's O'Brien 6027\n",
      "O'Brien's O'Brien 6181\n",
      "else's else 6188\n",
      "it's it 7375\n",
      "Winston's Winston 7394\n",
      "It's It 7572\n",
      "he'd he 7676\n",
      "He's He 7693\n",
      "Winston's Winston 7706\n",
      "I'm I 7947\n",
      "boy's boy 8119\n",
      "You're You 8130\n",
      "You're You 8138\n",
      "You're You 8142\n",
      "I'll I 8147\n",
      "I'll I 8151\n",
      "I'll I 8155\n",
      "boy's boy 8216\n",
      "They're They 8307\n",
      "that's that 8318\n",
      "woman's woman 8522\n",
      "O'Brien's O'Brien 9011\n",
      "morning's morning 9046\n",
      ",'t , 9303\n",
      ",'t , 9327\n",
      "father's father 10355\n",
      "one's one 10681\n",
      "mother's mother 10783\n",
      "women's women 11021\n",
      ". ... 11468\n",
      "Winston's Winston 11481\n",
      "father's father 11759\n",
      "to'ave to 12095\n",
      "trusted'em trusted 12096\n",
      "That's That 12107\n",
      "trusting'em trusting 12111\n",
      "to'ave to 12122\n",
      "let's let 12859\n",
      ". ... 12889\n",
      "You're You 13269\n",
      "That's That 13277\n",
      "Winston's Winston 13304\n",
      "That's That 13377\n",
      "I'm I 13391\n",
      "I've I 13394\n",
      "That's That 13495\n",
      "that's that 13500\n",
      "day's day 13553\n",
      "Winston's Winston 13651\n",
      "84 17.3.84 13836\n",
      "19 17 13843\n",
      "12 3 13845\n",
      "83 19.12.83 13847\n",
      "14 17 13859\n",
      "2 3 13861\n",
      "84 14.2.84 13863\n",
      "3 17 13869\n",
      "12 3 13871\n",
      "83 3.12.83 13873\n",
      "Brother's Brother 14082\n",
      "Today's Today 14144\n",
      "Winston's Winston 14168\n",
      "Plenty's Plenty 14807\n",
      "Plenty's Plenty 14903\n",
      "Winston's Winston 15146\n",
      "child's child 15657\n",
      "Winston's Winston 15889\n",
      "['a' 'biological' 'treatise' ',' 'and' 'from' 'a' \"child's\"\n",
      " 'spelling-book' 'to']\n",
      "['DET' 'ADJ' 'NOUN' '' 'CONJ' 'ADP' 'DET' 'NOUN' 'NOUN' 'ADP']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 15650 is out of bounds for dimension 0 with size 40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-bcd51cda5e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_set_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15650\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15660\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15650\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15660\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15650\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15659\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15659\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15650 is out of bounds for dimension 0 with size 40"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(extra_set_list):\n",
    "    if not x == bubu2[idx]:\n",
    "        print(x, bubu2[idx], idx)\n",
    "       #break\n",
    "print(extra_set_list[15650:15660])\n",
    "print(dev_labels[15650:15660])\n",
    "print(tens[15650][0])\n",
    "print(tens[15659][0])\n",
    "print(dev_labels[15659])\n",
    "print(extra_set_list[15659])\n",
    "\n",
    "#Taking a section of the tensor, and corresponding labels that we know match for trial\n",
    "xx = np.copy(tens[0:15659])\n",
    "yy = np.copy(dev_labels[0:15659])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-migration",
   "metadata": {},
   "source": [
    "Removing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "id": "collectible-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15922, 768)\n",
      "(15922,)\n",
      "(15952, 768)\n",
      "(15952,)\n"
     ]
    }
   ],
   "source": [
    "#Before removing any nan values (shape)\n",
    "print(np.shape(xx))\n",
    "print(np.shape(yy))\n",
    "#After removing nan values (shape)\n",
    "print(np.shape(xx[~np.isnan(xx).any(axis=1),:]))\n",
    "print(np.shape(yy[~np.isnan(xx[:,0])]))\n",
    "\n",
    "#Removing any NaN values for both x and corresponding labels\n",
    "yy = yy[~np.isnan(xx[:,0])]\n",
    "xx = xx[~np.isnan(xx).any(axis=1),:]\n",
    "\n",
    "#Check shape again and that they match\n",
    "print(np.shape(xx))\n",
    "print(np.shape(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "id": "laughing-brush",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "(15922, 768)\n",
      "(15992,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15922, 768), (15922,))"
      ]
     },
     "execution_count": 1598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning to another variable for splitting\n",
    "fun_train = xx\n",
    "fun_label =  yy\n",
    "np.shape(fun_train),np.shape(fun_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-angel",
   "metadata": {},
   "source": [
    "Splitting dataset to train and test - shuffle: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "id": "purple-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TEST_SIZE = 0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(fun_train, fun_label, test_size=TEST_SIZE, shuffle=True,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-width",
   "metadata": {},
   "source": [
    "Label encoder: (only required for keras sequential layers below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sustainable-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encoder(train_labels, test_labels):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(np.concatenate((train_labels,test_labels)))\n",
    "    \n",
    "    #transform\n",
    "\t#train_label_enc = le.transform(train_labels)\n",
    "\t#test_label_enc = le.transform(test_labels)\n",
    "\n",
    "    #transform + one-hot\n",
    "\ttrain_label_enc = np_utils.to_categorical(le.transform(train_labels))\n",
    "\ttest_label_enc = np_utils.to_categorical(le.transform(test_labels))\n",
    "    \n",
    "\treturn train_label_enc, test_label_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "id": "prime-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_traini, Y_testi = label_encoder(Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-lighter",
   "metadata": {},
   "source": [
    "Scaling to experiment below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "id": "current-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-palestine",
   "metadata": {},
   "source": [
    "Below using logistic regression on training set composed of embeddings and coresponding POS tags. Encoding not required for logistic regression (inbuilt). Commented out some accuracies below for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "id": "paperback-trial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc 0.7525476140276899\n",
      "test_acc 0.6126804770872567\n",
      "left_out_set_acc 0.62\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000000)\n",
    "clf.fit(X_scaled[0:-100], Y_train[0:-100])\n",
    "dev_pred_labels = clf.predict(X_test_scaled)\n",
    "\n",
    "print('train_acc',clf.score(X_scaled[0:-100], Y_train[0:-100]))\n",
    "print('test_acc',clf.score(X_test_scaled,Y_test))\n",
    "print('left_out_set_acc',clf.score(X_scaled[-100:],Y_train[-100:]))\n",
    "\n",
    "#print('acc', accuracy_score(Y_test ,dev_pred_labels))\n",
    "\n",
    "#For partial dataset:\n",
    "# train_acc 0.9802\n",
    "# test_acc 0.4919735599622285\n",
    "\n",
    "# for whole dataset:\n",
    "#train_acc 0.7923755513547575\n",
    "#test_acc 0.5873465533522191\n",
    "\n",
    "#with standard scaling:\n",
    "#train_acc 0.7864944339424491\n",
    "#test_acc 0.6005665722379604\n",
    "\n",
    "#and no shuffling\n",
    "#train_acc 0.7827137156059651\n",
    "#test_acc 0.6203966005665722"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-bracelet",
   "metadata": {},
   "source": [
    "Confusion matrix to see what is being misclassified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "id": "sufficient-dispute",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[122,   2,   8,   4,   4,   7,  10,   0,   9,  12,   0],\n",
       "       [ 10,  60,   7,   6,   1,   5,  16,   0,   0,   5,   0],\n",
       "       [  8,  10, 117,   9,   6,  17,  15,   1,  10,  20,   0],\n",
       "       [  7,   4,   6,  49,   7,   2,  12,   0,   6,  11,   0],\n",
       "       [  6,   1,   1,   6,  41,   4,   8,   1,   2,   5,   0],\n",
       "       [  7,   4,  12,   6,   0, 141,  25,   1,   4,  11,   0],\n",
       "       [ 33,  10,  17,   4,   6,  19, 187,   0,   7,   8,   0],\n",
       "       [  3,   0,   0,   2,   0,   2,   3,   8,   1,   1,   0],\n",
       "       [  4,   3,   5,   2,   2,   5,  10,   2,  89,  12,   0],\n",
       "       [ 15,   6,  12,  11,   9,   8,  18,   0,  14, 163,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1]])"
      ]
     },
     "execution_count": 1585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test,dev_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "id": "growing-thomson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14329, 768)\n",
      "(1593, 768)\n",
      "(14329, 11)\n",
      "(1593, 11)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "\n",
    "print(np.shape(Y_traini))\n",
    "print(np.shape(Y_testi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-carolina",
   "metadata": {},
   "source": [
    "Tried implementing a sequential layer with one dense layer (vocab size) and classification layer (with softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amazing-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional,Flatten, Dense, TimeDistributed, Dropout, Activation,SimpleRNN, LSTM\n",
    "\n",
    "model = Sequential ()\n",
    "#model.add(Bidirectional(LSTM(64, return_sequences = True)))\n",
    "model.add(Dense(768, activation='linear'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "#model.add(Dense(11, activation='sigmoid'))\n",
    "#model.add(Dropout(0.4))\n",
    "#model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "#model.add(TimeDistributed(Dense(11, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "introductory-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dressed-dodge",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (14329, 768)              590592    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (14329, 11)               8459      \n",
      "=================================================================\n",
      "Total params: 599,051\n",
      "Trainable params: 599,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build((14329, 768))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-resource",
   "metadata": {},
   "source": [
    "Output results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "id": "horizontal-accessory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "448/448 [==============================] - 5s 8ms/step - loss: 3.9788 - accuracy: 0.5404 - val_loss: 1.5532 - val_accuracy: 0.5920\n",
      "Epoch 2/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.3383 - accuracy: 0.6605 - val_loss: 1.2964 - val_accuracy: 0.6880\n",
      "Epoch 3/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1911 - accuracy: 0.6835 - val_loss: 1.3620 - val_accuracy: 0.6529\n",
      "Epoch 4/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1680 - accuracy: 0.6911 - val_loss: 1.3475 - val_accuracy: 0.6384\n",
      "Epoch 5/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.1820 - accuracy: 0.6795 - val_loss: 1.4591 - val_accuracy: 0.6215\n",
      "Epoch 6/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1820 - accuracy: 0.6815 - val_loss: 1.4434 - val_accuracy: 0.6516\n",
      "Epoch 7/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.1747 - accuracy: 0.6843 - val_loss: 1.4007 - val_accuracy: 0.6359\n",
      "Epoch 8/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.1621 - accuracy: 0.6879 - val_loss: 1.3579 - val_accuracy: 0.6453\n",
      "Epoch 9/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.1494 - accuracy: 0.6900 - val_loss: 1.4095 - val_accuracy: 0.6428\n",
      "Epoch 10/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1491 - accuracy: 0.6882 - val_loss: 1.3772 - val_accuracy: 0.6378\n",
      "Epoch 11/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1706 - accuracy: 0.6786 - val_loss: 1.3769 - val_accuracy: 0.6598\n",
      "Epoch 12/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.1428 - accuracy: 0.6878 - val_loss: 1.4205 - val_accuracy: 0.6441\n",
      "Epoch 13/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1160 - accuracy: 0.6941 - val_loss: 1.3606 - val_accuracy: 0.6541\n",
      "Epoch 14/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1529 - accuracy: 0.6838 - val_loss: 1.4138 - val_accuracy: 0.6139\n",
      "Epoch 15/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.1261 - accuracy: 0.6904 - val_loss: 1.4667 - val_accuracy: 0.6234\n",
      "Epoch 16/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1266 - accuracy: 0.6920 - val_loss: 1.3519 - val_accuracy: 0.6692\n",
      "Epoch 17/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1180 - accuracy: 0.6863 - val_loss: 1.4190 - val_accuracy: 0.6460\n",
      "Epoch 18/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1332 - accuracy: 0.6851 - val_loss: 1.3998 - val_accuracy: 0.6453\n",
      "Epoch 19/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1048 - accuracy: 0.6896 - val_loss: 1.4210 - val_accuracy: 0.6503\n",
      "Epoch 20/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0935 - accuracy: 0.6947 - val_loss: 1.3744 - val_accuracy: 0.6441\n",
      "Epoch 21/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1002 - accuracy: 0.6915 - val_loss: 1.5049 - val_accuracy: 0.6246\n",
      "Epoch 22/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1007 - accuracy: 0.6903 - val_loss: 1.4610 - val_accuracy: 0.6089\n",
      "Epoch 23/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0847 - accuracy: 0.6945 - val_loss: 1.4189 - val_accuracy: 0.6472\n",
      "Epoch 24/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0903 - accuracy: 0.6865 - val_loss: 1.5237 - val_accuracy: 0.6453\n",
      "Epoch 25/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.1121 - accuracy: 0.6886 - val_loss: 1.4010 - val_accuracy: 0.6522\n",
      "Epoch 26/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0809 - accuracy: 0.6841 - val_loss: 1.4392 - val_accuracy: 0.6190\n",
      "Epoch 27/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0835 - accuracy: 0.6947 - val_loss: 1.4533 - val_accuracy: 0.6516\n",
      "Epoch 28/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0819 - accuracy: 0.6898 - val_loss: 1.4183 - val_accuracy: 0.6328\n",
      "Epoch 29/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0632 - accuracy: 0.6939 - val_loss: 1.4438 - val_accuracy: 0.6422\n",
      "Epoch 30/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0822 - accuracy: 0.6939 - val_loss: 1.5229 - val_accuracy: 0.6296\n",
      "Epoch 31/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0694 - accuracy: 0.6977 - val_loss: 1.5522 - val_accuracy: 0.6045\n",
      "Epoch 32/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0724 - accuracy: 0.6928 - val_loss: 1.4736 - val_accuracy: 0.6202\n",
      "Epoch 33/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0501 - accuracy: 0.6939 - val_loss: 1.4739 - val_accuracy: 0.6503\n",
      "Epoch 34/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0926 - accuracy: 0.6864 - val_loss: 1.5246 - val_accuracy: 0.5982\n",
      "Epoch 35/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0484 - accuracy: 0.6969 - val_loss: 1.4856 - val_accuracy: 0.6409\n",
      "Epoch 36/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0570 - accuracy: 0.6967 - val_loss: 1.4919 - val_accuracy: 0.5932\n",
      "Epoch 37/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0879 - accuracy: 0.6834 - val_loss: 1.5245 - val_accuracy: 0.6290\n",
      "Epoch 38/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0522 - accuracy: 0.7012 - val_loss: 1.6332 - val_accuracy: 0.5895\n",
      "Epoch 39/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0607 - accuracy: 0.6954 - val_loss: 1.4509 - val_accuracy: 0.6227\n",
      "Epoch 40/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0653 - accuracy: 0.6861 - val_loss: 1.4508 - val_accuracy: 0.6384\n",
      "Epoch 41/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0575 - accuracy: 0.6904 - val_loss: 1.5350 - val_accuracy: 0.6409\n",
      "Epoch 42/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0703 - accuracy: 0.6946 - val_loss: 1.5107 - val_accuracy: 0.5982\n",
      "Epoch 43/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0685 - accuracy: 0.6925 - val_loss: 1.5582 - val_accuracy: 0.6089\n",
      "Epoch 44/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0308 - accuracy: 0.7001 - val_loss: 1.6158 - val_accuracy: 0.5938\n",
      "Epoch 45/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0819 - accuracy: 0.6894 - val_loss: 1.5523 - val_accuracy: 0.6447\n",
      "Epoch 46/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0412 - accuracy: 0.6946 - val_loss: 1.5324 - val_accuracy: 0.6384\n",
      "Epoch 47/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0318 - accuracy: 0.7019 - val_loss: 1.4907 - val_accuracy: 0.6573\n",
      "Epoch 48/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0520 - accuracy: 0.6901 - val_loss: 1.5247 - val_accuracy: 0.6491\n",
      "Epoch 49/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0600 - accuracy: 0.6943 - val_loss: 1.4885 - val_accuracy: 0.6497\n",
      "Epoch 50/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0283 - accuracy: 0.7042 - val_loss: 1.5652 - val_accuracy: 0.6146\n",
      "Epoch 51/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0444 - accuracy: 0.6908 - val_loss: 1.5108 - val_accuracy: 0.6353\n",
      "Epoch 52/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0557 - accuracy: 0.6905 - val_loss: 1.5724 - val_accuracy: 0.6460\n",
      "Epoch 53/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0282 - accuracy: 0.7038 - val_loss: 1.6244 - val_accuracy: 0.5945\n",
      "Epoch 54/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0495 - accuracy: 0.6926 - val_loss: 1.6238 - val_accuracy: 0.6234\n",
      "Epoch 55/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0705 - accuracy: 0.6902 - val_loss: 1.5580 - val_accuracy: 0.5882\n",
      "Epoch 56/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0317 - accuracy: 0.6952 - val_loss: 1.5527 - val_accuracy: 0.6177\n",
      "Epoch 57/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0455 - accuracy: 0.6995 - val_loss: 1.6185 - val_accuracy: 0.6246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0440 - accuracy: 0.6926 - val_loss: 1.6146 - val_accuracy: 0.6095\n",
      "Epoch 59/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0323 - accuracy: 0.7024 - val_loss: 1.5656 - val_accuracy: 0.6190\n",
      "Epoch 60/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0414 - accuracy: 0.6994 - val_loss: 1.5353 - val_accuracy: 0.6227\n",
      "Epoch 61/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0716 - accuracy: 0.6886 - val_loss: 1.6860 - val_accuracy: 0.6246\n",
      "Epoch 62/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0764 - accuracy: 0.6904 - val_loss: 1.5964 - val_accuracy: 0.6265\n",
      "Epoch 63/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0361 - accuracy: 0.6892 - val_loss: 1.6011 - val_accuracy: 0.5800\n",
      "Epoch 64/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0235 - accuracy: 0.6948 - val_loss: 1.5279 - val_accuracy: 0.6516\n",
      "Epoch 65/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0427 - accuracy: 0.6958 - val_loss: 1.6177 - val_accuracy: 0.6246\n",
      "Epoch 66/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0689 - accuracy: 0.6915 - val_loss: 1.5874 - val_accuracy: 0.6077\n",
      "Epoch 67/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0285 - accuracy: 0.6993 - val_loss: 1.5837 - val_accuracy: 0.6164\n",
      "Epoch 68/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0569 - accuracy: 0.6949 - val_loss: 1.5907 - val_accuracy: 0.6271\n",
      "Epoch 69/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0229 - accuracy: 0.7038 - val_loss: 1.6001 - val_accuracy: 0.6453\n",
      "Epoch 70/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0417 - accuracy: 0.7048 - val_loss: 1.5633 - val_accuracy: 0.6303\n",
      "Epoch 71/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0182 - accuracy: 0.6994 - val_loss: 1.6120 - val_accuracy: 0.6190\n",
      "Epoch 72/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0071 - accuracy: 0.7031 - val_loss: 1.5680 - val_accuracy: 0.6215\n",
      "Epoch 73/400\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 1.0331 - accuracy: 0.6989 - val_loss: 1.6188 - val_accuracy: 0.6434\n",
      "Epoch 74/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.0503 - accuracy: 0.6930 - val_loss: 1.6198 - val_accuracy: 0.6215\n",
      "Epoch 75/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0446 - accuracy: 0.7007 - val_loss: 1.6039 - val_accuracy: 0.5989\n",
      "Epoch 76/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0508 - accuracy: 0.6947 - val_loss: 1.7335 - val_accuracy: 0.6478\n",
      "Epoch 77/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0666 - accuracy: 0.6909 - val_loss: 1.6465 - val_accuracy: 0.6020\n",
      "Epoch 78/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0476 - accuracy: 0.6967 - val_loss: 1.7033 - val_accuracy: 0.6171\n",
      "Epoch 79/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0328 - accuracy: 0.6979 - val_loss: 1.6686 - val_accuracy: 0.6328\n",
      "Epoch 80/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.0261 - accuracy: 0.6980 - val_loss: 1.6600 - val_accuracy: 0.6102\n",
      "Epoch 81/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.0352 - accuracy: 0.6953 - val_loss: 1.6610 - val_accuracy: 0.6058\n",
      "Epoch 82/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0253 - accuracy: 0.6964 - val_loss: 1.6454 - val_accuracy: 0.6347\n",
      "Epoch 83/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0246 - accuracy: 0.7047 - val_loss: 1.6905 - val_accuracy: 0.6121\n",
      "Epoch 84/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0149 - accuracy: 0.7038 - val_loss: 1.5937 - val_accuracy: 0.6171\n",
      "Epoch 85/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0257 - accuracy: 0.7017 - val_loss: 1.6403 - val_accuracy: 0.6221\n",
      "Epoch 86/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0269 - accuracy: 0.6968 - val_loss: 1.6561 - val_accuracy: 0.6001\n",
      "Epoch 87/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0061 - accuracy: 0.7080 - val_loss: 1.6668 - val_accuracy: 0.5907\n",
      "Epoch 88/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.0126 - accuracy: 0.6976 - val_loss: 1.6911 - val_accuracy: 0.5888\n",
      "Epoch 89/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.0345 - accuracy: 0.7004 - val_loss: 1.7272 - val_accuracy: 0.5731\n",
      "Epoch 90/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0319 - accuracy: 0.6919 - val_loss: 1.6649 - val_accuracy: 0.6008\n",
      "Epoch 91/400\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 1.0345 - accuracy: 0.6943 - val_loss: 1.6179 - val_accuracy: 0.6378\n",
      "Epoch 92/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0013 - accuracy: 0.7075 - val_loss: 1.6917 - val_accuracy: 0.6039\n",
      "Epoch 93/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0384 - accuracy: 0.6979 - val_loss: 1.6882 - val_accuracy: 0.6491\n",
      "Epoch 94/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0107 - accuracy: 0.7061 - val_loss: 1.7097 - val_accuracy: 0.6259\n",
      "Epoch 95/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0376 - accuracy: 0.6977 - val_loss: 1.6785 - val_accuracy: 0.6196\n",
      "Epoch 96/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0131 - accuracy: 0.7019 - val_loss: 1.7148 - val_accuracy: 0.6378\n",
      "Epoch 97/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0350 - accuracy: 0.6942 - val_loss: 1.7493 - val_accuracy: 0.6466\n",
      "Epoch 98/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0080 - accuracy: 0.7019 - val_loss: 1.6958 - val_accuracy: 0.5882\n",
      "Epoch 99/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0151 - accuracy: 0.6998 - val_loss: 1.6784 - val_accuracy: 0.5857\n",
      "Epoch 100/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0126 - accuracy: 0.7039 - val_loss: 1.7144 - val_accuracy: 0.6127\n",
      "Epoch 101/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0324 - accuracy: 0.6962 - val_loss: 1.6698 - val_accuracy: 0.6102\n",
      "Epoch 102/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0286 - accuracy: 0.7031 - val_loss: 1.7174 - val_accuracy: 0.5794\n",
      "Epoch 103/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0150 - accuracy: 0.7022 - val_loss: 1.6887 - val_accuracy: 0.6390\n",
      "Epoch 104/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0065 - accuracy: 0.7025 - val_loss: 1.7705 - val_accuracy: 0.5938\n",
      "Epoch 105/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0316 - accuracy: 0.6948 - val_loss: 1.7134 - val_accuracy: 0.6064\n",
      "Epoch 106/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0396 - accuracy: 0.6976 - val_loss: 1.7154 - val_accuracy: 0.5556\n",
      "Epoch 107/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0136 - accuracy: 0.6941 - val_loss: 1.6749 - val_accuracy: 0.6190\n",
      "Epoch 108/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0186 - accuracy: 0.6992 - val_loss: 1.7075 - val_accuracy: 0.5957\n",
      "Epoch 109/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0201 - accuracy: 0.7011 - val_loss: 1.6683 - val_accuracy: 0.6058\n",
      "Epoch 110/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0077 - accuracy: 0.7085 - val_loss: 1.7211 - val_accuracy: 0.5675\n",
      "Epoch 111/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0030 - accuracy: 0.7086 - val_loss: 1.7197 - val_accuracy: 0.5838\n",
      "Epoch 112/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0181 - accuracy: 0.6978 - val_loss: 1.6172 - val_accuracy: 0.6114\n",
      "Epoch 113/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0003 - accuracy: 0.7058 - val_loss: 1.6559 - val_accuracy: 0.6158\n",
      "Epoch 114/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0272 - accuracy: 0.6950 - val_loss: 1.7646 - val_accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0020 - accuracy: 0.7047 - val_loss: 1.6841 - val_accuracy: 0.5788\n",
      "Epoch 116/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0495 - accuracy: 0.6882 - val_loss: 1.7650 - val_accuracy: 0.6077\n",
      "Epoch 117/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0089 - accuracy: 0.7058 - val_loss: 1.6619 - val_accuracy: 0.5976\n",
      "Epoch 118/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9868 - accuracy: 0.7087 - val_loss: 1.6225 - val_accuracy: 0.6077\n",
      "Epoch 119/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0100 - accuracy: 0.7033 - val_loss: 1.7078 - val_accuracy: 0.6089\n",
      "Epoch 120/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0239 - accuracy: 0.6952 - val_loss: 1.7113 - val_accuracy: 0.6095\n",
      "Epoch 121/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0351 - accuracy: 0.6954 - val_loss: 1.7348 - val_accuracy: 0.6321\n",
      "Epoch 122/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0109 - accuracy: 0.6993 - val_loss: 1.7375 - val_accuracy: 0.6064\n",
      "Epoch 123/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0226 - accuracy: 0.6948 - val_loss: 1.6825 - val_accuracy: 0.5913\n",
      "Epoch 124/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0096 - accuracy: 0.6957 - val_loss: 1.7139 - val_accuracy: 0.6083\n",
      "Epoch 125/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0166 - accuracy: 0.7006 - val_loss: 1.7287 - val_accuracy: 0.6221\n",
      "Epoch 126/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0229 - accuracy: 0.6939 - val_loss: 1.7416 - val_accuracy: 0.6014\n",
      "Epoch 127/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0178 - accuracy: 0.7018 - val_loss: 1.6918 - val_accuracy: 0.6208\n",
      "Epoch 128/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0182 - accuracy: 0.6985 - val_loss: 1.7927 - val_accuracy: 0.6064\n",
      "Epoch 129/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0259 - accuracy: 0.6978 - val_loss: 1.7329 - val_accuracy: 0.6240\n",
      "Epoch 130/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0331 - accuracy: 0.6965 - val_loss: 1.7137 - val_accuracy: 0.6234\n",
      "Epoch 131/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0266 - accuracy: 0.7006 - val_loss: 1.7468 - val_accuracy: 0.6259\n",
      "Epoch 132/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9968 - accuracy: 0.7071 - val_loss: 1.6468 - val_accuracy: 0.6227\n",
      "Epoch 133/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9898 - accuracy: 0.7064 - val_loss: 1.6416 - val_accuracy: 0.6296\n",
      "Epoch 134/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9905 - accuracy: 0.7021 - val_loss: 1.6907 - val_accuracy: 0.6077\n",
      "Epoch 135/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0079 - accuracy: 0.7002 - val_loss: 1.7936 - val_accuracy: 0.5844\n",
      "Epoch 136/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0122 - accuracy: 0.7011 - val_loss: 1.7614 - val_accuracy: 0.6139\n",
      "Epoch 137/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0145 - accuracy: 0.7023 - val_loss: 1.7365 - val_accuracy: 0.6089\n",
      "Epoch 138/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0128 - accuracy: 0.7013 - val_loss: 1.7563 - val_accuracy: 0.6001\n",
      "Epoch 139/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0317 - accuracy: 0.7015 - val_loss: 1.7312 - val_accuracy: 0.5938\n",
      "Epoch 140/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0184 - accuracy: 0.7012 - val_loss: 1.8305 - val_accuracy: 0.6095\n",
      "Epoch 141/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0073 - accuracy: 0.7014 - val_loss: 1.7862 - val_accuracy: 0.6026\n",
      "Epoch 142/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0141 - accuracy: 0.7026 - val_loss: 1.7221 - val_accuracy: 0.6158\n",
      "Epoch 143/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0013 - accuracy: 0.7038 - val_loss: 1.7500 - val_accuracy: 0.6208\n",
      "Epoch 144/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9800 - accuracy: 0.7159 - val_loss: 1.7877 - val_accuracy: 0.5851\n",
      "Epoch 145/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0002 - accuracy: 0.7023 - val_loss: 1.7737 - val_accuracy: 0.6466\n",
      "Epoch 146/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0072 - accuracy: 0.6971 - val_loss: 1.7338 - val_accuracy: 0.6095\n",
      "Epoch 147/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9999 - accuracy: 0.7025 - val_loss: 1.7136 - val_accuracy: 0.6227\n",
      "Epoch 148/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0032 - accuracy: 0.7037 - val_loss: 1.7635 - val_accuracy: 0.6026\n",
      "Epoch 149/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9934 - accuracy: 0.7050 - val_loss: 1.7529 - val_accuracy: 0.5882\n",
      "Epoch 150/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0242 - accuracy: 0.7010 - val_loss: 1.7392 - val_accuracy: 0.6296\n",
      "Epoch 151/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0165 - accuracy: 0.6978 - val_loss: 1.7579 - val_accuracy: 0.5920\n",
      "Epoch 152/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0120 - accuracy: 0.7015 - val_loss: 1.6691 - val_accuracy: 0.6221\n",
      "Epoch 153/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9784 - accuracy: 0.7115 - val_loss: 1.7173 - val_accuracy: 0.6083\n",
      "Epoch 154/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0102 - accuracy: 0.7057 - val_loss: 1.7375 - val_accuracy: 0.6409\n",
      "Epoch 155/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9844 - accuracy: 0.7100 - val_loss: 1.7313 - val_accuracy: 0.6020\n",
      "Epoch 156/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0016 - accuracy: 0.6958 - val_loss: 1.7456 - val_accuracy: 0.6077\n",
      "Epoch 157/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0341 - accuracy: 0.6940 - val_loss: 1.8515 - val_accuracy: 0.6177\n",
      "Epoch 158/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0122 - accuracy: 0.7033 - val_loss: 1.7655 - val_accuracy: 0.6428\n",
      "Epoch 159/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0128 - accuracy: 0.7082 - val_loss: 1.8370 - val_accuracy: 0.5782\n",
      "Epoch 160/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0418 - accuracy: 0.6941 - val_loss: 1.7661 - val_accuracy: 0.6114\n",
      "Epoch 161/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0064 - accuracy: 0.7030 - val_loss: 1.8060 - val_accuracy: 0.5568\n",
      "Epoch 162/400\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 0.9953 - accuracy: 0.7009 - val_loss: 1.7603 - val_accuracy: 0.6202\n",
      "Epoch 163/400\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 0.9970 - accuracy: 0.7051 - val_loss: 1.8233 - val_accuracy: 0.6001\n",
      "Epoch 164/400\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 0.9946 - accuracy: 0.7071 - val_loss: 1.7916 - val_accuracy: 0.6284\n",
      "Epoch 165/400\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 0.9909 - accuracy: 0.7082 - val_loss: 1.7764 - val_accuracy: 0.6309\n",
      "Epoch 166/400\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 1.0054 - accuracy: 0.7011 - val_loss: 1.7589 - val_accuracy: 0.5970\n",
      "Epoch 167/400\n",
      "448/448 [==============================] - 2s 5ms/step - loss: 1.0002 - accuracy: 0.7073 - val_loss: 1.7453 - val_accuracy: 0.6152\n",
      "Epoch 168/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0056 - accuracy: 0.7010 - val_loss: 1.7651 - val_accuracy: 0.6114\n",
      "Epoch 169/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0177 - accuracy: 0.6988 - val_loss: 1.8116 - val_accuracy: 0.6183\n",
      "Epoch 170/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9913 - accuracy: 0.7053 - val_loss: 1.8565 - val_accuracy: 0.5505\n",
      "Epoch 171/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0041 - accuracy: 0.7034 - val_loss: 1.7397 - val_accuracy: 0.6033\n",
      "Epoch 172/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9967 - accuracy: 0.6999 - val_loss: 1.7845 - val_accuracy: 0.6234\n",
      "Epoch 173/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0118 - accuracy: 0.7028 - val_loss: 1.8096 - val_accuracy: 0.5945\n",
      "Epoch 174/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9967 - accuracy: 0.7049 - val_loss: 1.8051 - val_accuracy: 0.5556\n",
      "Epoch 175/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0132 - accuracy: 0.7007 - val_loss: 1.7274 - val_accuracy: 0.5913\n",
      "Epoch 176/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9950 - accuracy: 0.7052 - val_loss: 1.7813 - val_accuracy: 0.5863\n",
      "Epoch 177/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0145 - accuracy: 0.7062 - val_loss: 1.7892 - val_accuracy: 0.6070\n",
      "Epoch 178/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0131 - accuracy: 0.7006 - val_loss: 1.8007 - val_accuracy: 0.6108\n",
      "Epoch 179/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0140 - accuracy: 0.6975 - val_loss: 1.7643 - val_accuracy: 0.6083\n",
      "Epoch 180/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0015 - accuracy: 0.7046 - val_loss: 1.7623 - val_accuracy: 0.6409\n",
      "Epoch 181/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9860 - accuracy: 0.7041 - val_loss: 1.7682 - val_accuracy: 0.6139\n",
      "Epoch 182/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9855 - accuracy: 0.7148 - val_loss: 1.8078 - val_accuracy: 0.6390\n",
      "Epoch 183/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9987 - accuracy: 0.7074 - val_loss: 1.7342 - val_accuracy: 0.6190\n",
      "Epoch 184/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9882 - accuracy: 0.7093 - val_loss: 1.8032 - val_accuracy: 0.6171\n",
      "Epoch 185/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0124 - accuracy: 0.7051 - val_loss: 1.8419 - val_accuracy: 0.6077\n",
      "Epoch 186/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0123 - accuracy: 0.7043 - val_loss: 1.7884 - val_accuracy: 0.6215\n",
      "Epoch 187/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0037 - accuracy: 0.7044 - val_loss: 1.8185 - val_accuracy: 0.6390\n",
      "Epoch 188/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9978 - accuracy: 0.7021 - val_loss: 1.8013 - val_accuracy: 0.5888\n",
      "Epoch 189/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0049 - accuracy: 0.6987 - val_loss: 1.8702 - val_accuracy: 0.6014\n",
      "Epoch 190/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0152 - accuracy: 0.7038 - val_loss: 1.7425 - val_accuracy: 0.6290\n",
      "Epoch 191/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0145 - accuracy: 0.7021 - val_loss: 1.8281 - val_accuracy: 0.6171\n",
      "Epoch 192/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0057 - accuracy: 0.7001 - val_loss: 1.7529 - val_accuracy: 0.6152\n",
      "Epoch 193/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0206 - accuracy: 0.6987 - val_loss: 1.8811 - val_accuracy: 0.5530\n",
      "Epoch 194/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0120 - accuracy: 0.6985 - val_loss: 1.7997 - val_accuracy: 0.5995\n",
      "Epoch 195/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9830 - accuracy: 0.7100 - val_loss: 1.7462 - val_accuracy: 0.6259\n",
      "Epoch 196/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0047 - accuracy: 0.6983 - val_loss: 1.7586 - val_accuracy: 0.6077\n",
      "Epoch 197/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9903 - accuracy: 0.7080 - val_loss: 1.8573 - val_accuracy: 0.5945\n",
      "Epoch 198/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0025 - accuracy: 0.7002 - val_loss: 1.8053 - val_accuracy: 0.6252\n",
      "Epoch 199/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0046 - accuracy: 0.7055 - val_loss: 1.7621 - val_accuracy: 0.5920\n",
      "Epoch 200/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0192 - accuracy: 0.6965 - val_loss: 1.8366 - val_accuracy: 0.6083\n",
      "Epoch 201/400\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 1.0121 - accuracy: 0.7051 - val_loss: 1.8649 - val_accuracy: 0.6102\n",
      "Epoch 202/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0126 - accuracy: 0.7014 - val_loss: 1.8300 - val_accuracy: 0.6177\n",
      "Epoch 203/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9847 - accuracy: 0.7040 - val_loss: 1.8034 - val_accuracy: 0.6271\n",
      "Epoch 204/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9973 - accuracy: 0.7047 - val_loss: 1.8030 - val_accuracy: 0.6058\n",
      "Epoch 205/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9880 - accuracy: 0.7064 - val_loss: 1.7577 - val_accuracy: 0.5976\n",
      "Epoch 206/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0009 - accuracy: 0.7081 - val_loss: 1.7754 - val_accuracy: 0.6064\n",
      "Epoch 207/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9964 - accuracy: 0.7054 - val_loss: 1.8116 - val_accuracy: 0.5857\n",
      "Epoch 208/400\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 1.0022 - accuracy: 0.7040 - val_loss: 1.8002 - val_accuracy: 0.6208\n",
      "Epoch 209/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0180 - accuracy: 0.6970 - val_loss: 1.7924 - val_accuracy: 0.6146\n",
      "Epoch 210/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0192 - accuracy: 0.7001 - val_loss: 1.8635 - val_accuracy: 0.5687\n",
      "Epoch 211/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0081 - accuracy: 0.7029 - val_loss: 1.7914 - val_accuracy: 0.6133\n",
      "Epoch 212/400\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 1.0080 - accuracy: 0.7027 - val_loss: 1.8313 - val_accuracy: 0.5951\n",
      "Epoch 213/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9878 - accuracy: 0.7102 - val_loss: 1.7844 - val_accuracy: 0.5913\n",
      "Epoch 214/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9933 - accuracy: 0.7007 - val_loss: 1.7622 - val_accuracy: 0.6303\n",
      "Epoch 215/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9969 - accuracy: 0.7053 - val_loss: 1.8604 - val_accuracy: 0.5932\n",
      "Epoch 216/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0185 - accuracy: 0.7032 - val_loss: 1.7775 - val_accuracy: 0.6334\n",
      "Epoch 217/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0038 - accuracy: 0.7070 - val_loss: 1.7550 - val_accuracy: 0.5957\n",
      "Epoch 218/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9987 - accuracy: 0.7046 - val_loss: 1.7888 - val_accuracy: 0.5888\n",
      "Epoch 219/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9737 - accuracy: 0.7076 - val_loss: 1.8733 - val_accuracy: 0.5662\n",
      "Epoch 220/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9915 - accuracy: 0.7097 - val_loss: 1.8209 - val_accuracy: 0.6008\n",
      "Epoch 221/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9825 - accuracy: 0.7065 - val_loss: 1.8851 - val_accuracy: 0.6064\n",
      "Epoch 222/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0087 - accuracy: 0.7028 - val_loss: 1.8206 - val_accuracy: 0.6434\n",
      "Epoch 223/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0169 - accuracy: 0.6997 - val_loss: 1.8471 - val_accuracy: 0.6271\n",
      "Epoch 224/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0112 - accuracy: 0.7060 - val_loss: 1.8539 - val_accuracy: 0.6033\n",
      "Epoch 225/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9918 - accuracy: 0.7051 - val_loss: 1.8023 - val_accuracy: 0.5888\n",
      "Epoch 226/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9810 - accuracy: 0.7148 - val_loss: 1.8569 - val_accuracy: 0.6397\n",
      "Epoch 227/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 3s 8ms/step - loss: 0.9805 - accuracy: 0.7044 - val_loss: 1.8383 - val_accuracy: 0.5945\n",
      "Epoch 228/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9977 - accuracy: 0.7019 - val_loss: 1.8900 - val_accuracy: 0.5687\n",
      "Epoch 229/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9952 - accuracy: 0.7029 - val_loss: 1.7922 - val_accuracy: 0.5851\n",
      "Epoch 230/400\n",
      "448/448 [==============================] - 5s 10ms/step - loss: 0.9971 - accuracy: 0.7033 - val_loss: 1.7687 - val_accuracy: 0.5995\n",
      "Epoch 231/400\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 0.9843 - accuracy: 0.7082 - val_loss: 1.8323 - val_accuracy: 0.5650\n",
      "Epoch 232/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9904 - accuracy: 0.7115 - val_loss: 1.8873 - val_accuracy: 0.5794\n",
      "Epoch 233/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0178 - accuracy: 0.6996 - val_loss: 1.7985 - val_accuracy: 0.6045\n",
      "Epoch 234/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0173 - accuracy: 0.6978 - val_loss: 1.8984 - val_accuracy: 0.5656\n",
      "Epoch 235/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0330 - accuracy: 0.6898 - val_loss: 1.8692 - val_accuracy: 0.5907\n",
      "Epoch 236/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0082 - accuracy: 0.7012 - val_loss: 1.8024 - val_accuracy: 0.6196\n",
      "Epoch 237/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9797 - accuracy: 0.7083 - val_loss: 1.8389 - val_accuracy: 0.5876\n",
      "Epoch 238/400\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 1.0055 - accuracy: 0.7013 - val_loss: 1.8829 - val_accuracy: 0.5851\n",
      "Epoch 239/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0174 - accuracy: 0.6997 - val_loss: 1.7674 - val_accuracy: 0.6014\n",
      "Epoch 240/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.0074 - accuracy: 0.6992 - val_loss: 1.8821 - val_accuracy: 0.6290\n",
      "Epoch 241/400\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 0.9968 - accuracy: 0.7052 - val_loss: 1.9301 - val_accuracy: 0.6296\n",
      "Epoch 242/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9813 - accuracy: 0.7191 - val_loss: 1.7889 - val_accuracy: 0.6051\n",
      "Epoch 243/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9873 - accuracy: 0.7079 - val_loss: 1.8013 - val_accuracy: 0.5964\n",
      "Epoch 244/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0238 - accuracy: 0.7007 - val_loss: 1.8919 - val_accuracy: 0.5825\n",
      "Epoch 245/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9851 - accuracy: 0.7055 - val_loss: 1.9118 - val_accuracy: 0.6039\n",
      "Epoch 246/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9738 - accuracy: 0.7117 - val_loss: 1.8174 - val_accuracy: 0.6033\n",
      "Epoch 247/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 1.0082 - accuracy: 0.7009 - val_loss: 1.8320 - val_accuracy: 0.6064\n",
      "Epoch 248/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9961 - accuracy: 0.7126 - val_loss: 1.8325 - val_accuracy: 0.5926\n",
      "Epoch 249/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9790 - accuracy: 0.7085 - val_loss: 1.8329 - val_accuracy: 0.5681\n",
      "Epoch 250/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9749 - accuracy: 0.7101 - val_loss: 1.8223 - val_accuracy: 0.6108\n",
      "Epoch 251/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9705 - accuracy: 0.7133 - val_loss: 1.8777 - val_accuracy: 0.6378\n",
      "Epoch 252/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0206 - accuracy: 0.7012 - val_loss: 1.8593 - val_accuracy: 0.5982\n",
      "Epoch 253/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0194 - accuracy: 0.7035 - val_loss: 1.9030 - val_accuracy: 0.5568\n",
      "Epoch 254/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0049 - accuracy: 0.7056 - val_loss: 1.8582 - val_accuracy: 0.6108\n",
      "Epoch 255/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0225 - accuracy: 0.6976 - val_loss: 1.7783 - val_accuracy: 0.6039\n",
      "Epoch 256/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9821 - accuracy: 0.7120 - val_loss: 1.8309 - val_accuracy: 0.5932\n",
      "Epoch 257/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9878 - accuracy: 0.7112 - val_loss: 1.8082 - val_accuracy: 0.6121\n",
      "Epoch 258/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9901 - accuracy: 0.7057 - val_loss: 1.8303 - val_accuracy: 0.5970\n",
      "Epoch 259/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9973 - accuracy: 0.7070 - val_loss: 1.8566 - val_accuracy: 0.6058\n",
      "Epoch 260/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0039 - accuracy: 0.7048 - val_loss: 1.8363 - val_accuracy: 0.5863\n",
      "Epoch 261/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0035 - accuracy: 0.7033 - val_loss: 1.8758 - val_accuracy: 0.5982\n",
      "Epoch 262/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9918 - accuracy: 0.7049 - val_loss: 1.9076 - val_accuracy: 0.6070\n",
      "Epoch 263/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0001 - accuracy: 0.7035 - val_loss: 1.8381 - val_accuracy: 0.6227\n",
      "Epoch 264/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9820 - accuracy: 0.7111 - val_loss: 1.8070 - val_accuracy: 0.6340\n",
      "Epoch 265/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0156 - accuracy: 0.7018 - val_loss: 1.8213 - val_accuracy: 0.5995\n",
      "Epoch 266/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0103 - accuracy: 0.7013 - val_loss: 1.7794 - val_accuracy: 0.6208\n",
      "Epoch 267/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0002 - accuracy: 0.7008 - val_loss: 1.8312 - val_accuracy: 0.5819\n",
      "Epoch 268/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0116 - accuracy: 0.7051 - val_loss: 1.8829 - val_accuracy: 0.6008\n",
      "Epoch 269/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9962 - accuracy: 0.7018 - val_loss: 1.9603 - val_accuracy: 0.5292\n",
      "Epoch 270/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0371 - accuracy: 0.6938 - val_loss: 1.8966 - val_accuracy: 0.5982\n",
      "Epoch 271/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0052 - accuracy: 0.7055 - val_loss: 1.8389 - val_accuracy: 0.6158\n",
      "Epoch 272/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9854 - accuracy: 0.7062 - val_loss: 1.8762 - val_accuracy: 0.6089\n",
      "Epoch 273/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9720 - accuracy: 0.7090 - val_loss: 1.8272 - val_accuracy: 0.6221\n",
      "Epoch 274/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9910 - accuracy: 0.7063 - val_loss: 1.8258 - val_accuracy: 0.5813\n",
      "Epoch 275/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9968 - accuracy: 0.7016 - val_loss: 1.8457 - val_accuracy: 0.6227\n",
      "Epoch 276/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9772 - accuracy: 0.7051 - val_loss: 1.7979 - val_accuracy: 0.6095\n",
      "Epoch 277/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9979 - accuracy: 0.7013 - val_loss: 1.8255 - val_accuracy: 0.5951\n",
      "Epoch 278/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9922 - accuracy: 0.7074 - val_loss: 1.7936 - val_accuracy: 0.6051\n",
      "Epoch 279/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0089 - accuracy: 0.7029 - val_loss: 1.8423 - val_accuracy: 0.6171\n",
      "Epoch 280/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0530 - accuracy: 0.6911 - val_loss: 1.8300 - val_accuracy: 0.5750\n",
      "Epoch 281/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9970 - accuracy: 0.7069 - val_loss: 1.9032 - val_accuracy: 0.5970\n",
      "Epoch 282/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9801 - accuracy: 0.7092 - val_loss: 1.8475 - val_accuracy: 0.6133\n",
      "Epoch 283/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0303 - accuracy: 0.7070 - val_loss: 1.8212 - val_accuracy: 0.6127\n",
      "Epoch 284/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9862 - accuracy: 0.7064 - val_loss: 1.8539 - val_accuracy: 0.6164\n",
      "Epoch 285/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9837 - accuracy: 0.7078 - val_loss: 1.8720 - val_accuracy: 0.6001\n",
      "Epoch 286/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9850 - accuracy: 0.7043 - val_loss: 1.8233 - val_accuracy: 0.6265\n",
      "Epoch 287/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9885 - accuracy: 0.7076 - val_loss: 1.8127 - val_accuracy: 0.5989\n",
      "Epoch 288/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0043 - accuracy: 0.6996 - val_loss: 1.8399 - val_accuracy: 0.6196\n",
      "Epoch 289/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0043 - accuracy: 0.6968 - val_loss: 1.8905 - val_accuracy: 0.5825\n",
      "Epoch 290/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0051 - accuracy: 0.7010 - val_loss: 1.8415 - val_accuracy: 0.5932\n",
      "Epoch 291/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9791 - accuracy: 0.7055 - val_loss: 1.8625 - val_accuracy: 0.5869\n",
      "Epoch 292/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9863 - accuracy: 0.7134 - val_loss: 1.8107 - val_accuracy: 0.6303\n",
      "Epoch 293/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0139 - accuracy: 0.7003 - val_loss: 1.8988 - val_accuracy: 0.5907\n",
      "Epoch 294/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0015 - accuracy: 0.7061 - val_loss: 1.8099 - val_accuracy: 0.5920\n",
      "Epoch 295/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9949 - accuracy: 0.7040 - val_loss: 1.8030 - val_accuracy: 0.5995\n",
      "Epoch 296/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9981 - accuracy: 0.7037 - val_loss: 1.8557 - val_accuracy: 0.6051\n",
      "Epoch 297/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0123 - accuracy: 0.6951 - val_loss: 1.9412 - val_accuracy: 0.6240\n",
      "Epoch 298/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0283 - accuracy: 0.6963 - val_loss: 1.8411 - val_accuracy: 0.6221\n",
      "Epoch 299/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9865 - accuracy: 0.7030 - val_loss: 1.9405 - val_accuracy: 0.5794\n",
      "Epoch 300/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9768 - accuracy: 0.7123 - val_loss: 1.8820 - val_accuracy: 0.6127\n",
      "Epoch 301/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9806 - accuracy: 0.7124 - val_loss: 1.8745 - val_accuracy: 0.5794\n",
      "Epoch 302/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0164 - accuracy: 0.6984 - val_loss: 1.8761 - val_accuracy: 0.6265\n",
      "Epoch 303/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0008 - accuracy: 0.7020 - val_loss: 1.8080 - val_accuracy: 0.5989\n",
      "Epoch 304/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9959 - accuracy: 0.6980 - val_loss: 1.8165 - val_accuracy: 0.6026\n",
      "Epoch 305/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9891 - accuracy: 0.7028 - val_loss: 1.8736 - val_accuracy: 0.6139\n",
      "Epoch 306/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9933 - accuracy: 0.7082 - val_loss: 1.8255 - val_accuracy: 0.6058\n",
      "Epoch 307/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0017 - accuracy: 0.7043 - val_loss: 1.8679 - val_accuracy: 0.6020\n",
      "Epoch 308/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9556 - accuracy: 0.7170 - val_loss: 1.8915 - val_accuracy: 0.5694\n",
      "Epoch 309/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9843 - accuracy: 0.7102 - val_loss: 1.7833 - val_accuracy: 0.6014\n",
      "Epoch 310/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9732 - accuracy: 0.7112 - val_loss: 1.8493 - val_accuracy: 0.5938\n",
      "Epoch 311/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9973 - accuracy: 0.7042 - val_loss: 1.8999 - val_accuracy: 0.5989\n",
      "Epoch 312/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0009 - accuracy: 0.7031 - val_loss: 1.8534 - val_accuracy: 0.6139\n",
      "Epoch 313/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9908 - accuracy: 0.7041 - val_loss: 1.8666 - val_accuracy: 0.5945\n",
      "Epoch 314/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0082 - accuracy: 0.7002 - val_loss: 2.0436 - val_accuracy: 0.6146\n",
      "Epoch 315/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0305 - accuracy: 0.6991 - val_loss: 1.8464 - val_accuracy: 0.6064\n",
      "Epoch 316/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0201 - accuracy: 0.6984 - val_loss: 1.8774 - val_accuracy: 0.5895\n",
      "Epoch 317/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9998 - accuracy: 0.7074 - val_loss: 1.9220 - val_accuracy: 0.5612\n",
      "Epoch 318/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9970 - accuracy: 0.7054 - val_loss: 1.8875 - val_accuracy: 0.5857\n",
      "Epoch 319/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9933 - accuracy: 0.7043 - val_loss: 1.8928 - val_accuracy: 0.6296\n",
      "Epoch 320/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9670 - accuracy: 0.7138 - val_loss: 1.8992 - val_accuracy: 0.5800\n",
      "Epoch 321/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0134 - accuracy: 0.6992 - val_loss: 1.8306 - val_accuracy: 0.6227\n",
      "Epoch 322/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9661 - accuracy: 0.7106 - val_loss: 1.8145 - val_accuracy: 0.6095\n",
      "Epoch 323/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9794 - accuracy: 0.7043 - val_loss: 1.8989 - val_accuracy: 0.6196\n",
      "Epoch 324/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9721 - accuracy: 0.7098 - val_loss: 1.8605 - val_accuracy: 0.5938\n",
      "Epoch 325/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9906 - accuracy: 0.7100 - val_loss: 1.8700 - val_accuracy: 0.6177\n",
      "Epoch 326/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9728 - accuracy: 0.7121 - val_loss: 1.8319 - val_accuracy: 0.5876\n",
      "Epoch 327/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9923 - accuracy: 0.7027 - val_loss: 1.8719 - val_accuracy: 0.6064\n",
      "Epoch 328/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0226 - accuracy: 0.7018 - val_loss: 1.8354 - val_accuracy: 0.6146\n",
      "Epoch 329/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0133 - accuracy: 0.6976 - val_loss: 1.9263 - val_accuracy: 0.5938\n",
      "Epoch 330/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9838 - accuracy: 0.7084 - val_loss: 1.9302 - val_accuracy: 0.6051\n",
      "Epoch 331/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 0.9895 - accuracy: 0.7038 - val_loss: 1.8612 - val_accuracy: 0.6089\n",
      "Epoch 332/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9968 - accuracy: 0.7041 - val_loss: 1.8404 - val_accuracy: 0.6089\n",
      "Epoch 333/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 0.9994 - accuracy: 0.7023 - val_loss: 1.8845 - val_accuracy: 0.5819\n",
      "Epoch 334/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9731 - accuracy: 0.7092 - val_loss: 1.8173 - val_accuracy: 0.6183\n",
      "Epoch 335/400\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 0.9910 - accuracy: 0.7088 - val_loss: 1.9479 - val_accuracy: 0.5267\n",
      "Epoch 336/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9859 - accuracy: 0.7059 - val_loss: 1.8159 - val_accuracy: 0.5913\n",
      "Epoch 337/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9714 - accuracy: 0.7064 - val_loss: 1.8237 - val_accuracy: 0.6114\n",
      "Epoch 338/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0041 - accuracy: 0.7033 - val_loss: 1.8399 - val_accuracy: 0.6516\n",
      "Epoch 339/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9906 - accuracy: 0.7030 - val_loss: 1.9222 - val_accuracy: 0.5656\n",
      "Epoch 340/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0002 - accuracy: 0.7018 - val_loss: 1.8481 - val_accuracy: 0.6240\n",
      "Epoch 341/400\n",
      "448/448 [==============================] - 4s 9ms/step - loss: 1.0033 - accuracy: 0.7054 - val_loss: 1.8810 - val_accuracy: 0.5744\n",
      "Epoch 342/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9931 - accuracy: 0.7036 - val_loss: 1.8835 - val_accuracy: 0.5964\n",
      "Epoch 343/400\n",
      "448/448 [==============================] - 4s 8ms/step - loss: 1.0065 - accuracy: 0.6990 - val_loss: 1.9973 - val_accuracy: 0.6014\n",
      "Epoch 344/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 1.0046 - accuracy: 0.7067 - val_loss: 1.8733 - val_accuracy: 0.6190\n",
      "Epoch 345/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 0.9871 - accuracy: 0.7102 - val_loss: 1.8862 - val_accuracy: 0.5857\n",
      "Epoch 346/400\n",
      "448/448 [==============================] - 3s 8ms/step - loss: 0.9944 - accuracy: 0.7000 - val_loss: 1.8328 - val_accuracy: 0.6234\n",
      "Epoch 347/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9773 - accuracy: 0.7091 - val_loss: 1.8648 - val_accuracy: 0.6108\n",
      "Epoch 348/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9900 - accuracy: 0.7090 - val_loss: 1.8698 - val_accuracy: 0.6139\n",
      "Epoch 349/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9787 - accuracy: 0.7113 - val_loss: 2.0198 - val_accuracy: 0.5731\n",
      "Epoch 350/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9933 - accuracy: 0.7055 - val_loss: 1.8937 - val_accuracy: 0.6390\n",
      "Epoch 351/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9813 - accuracy: 0.7105 - val_loss: 1.9111 - val_accuracy: 0.5970\n",
      "Epoch 352/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9965 - accuracy: 0.7065 - val_loss: 1.9527 - val_accuracy: 0.5863\n",
      "Epoch 353/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9836 - accuracy: 0.7109 - val_loss: 1.9631 - val_accuracy: 0.5687\n",
      "Epoch 354/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0149 - accuracy: 0.6962 - val_loss: 1.8666 - val_accuracy: 0.6234\n",
      "Epoch 355/400\n",
      "448/448 [==============================] - 6s 13ms/step - loss: 0.9864 - accuracy: 0.7071 - val_loss: 1.8784 - val_accuracy: 0.6202\n",
      "Epoch 356/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9780 - accuracy: 0.7116 - val_loss: 1.8291 - val_accuracy: 0.5819\n",
      "Epoch 357/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9896 - accuracy: 0.7038 - val_loss: 1.9897 - val_accuracy: 0.6146\n",
      "Epoch 358/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9732 - accuracy: 0.7125 - val_loss: 1.9142 - val_accuracy: 0.5794\n",
      "Epoch 359/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0102 - accuracy: 0.6991 - val_loss: 1.8775 - val_accuracy: 0.6290\n",
      "Epoch 360/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9695 - accuracy: 0.7086 - val_loss: 1.8830 - val_accuracy: 0.6190\n",
      "Epoch 361/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9677 - accuracy: 0.7121 - val_loss: 1.8638 - val_accuracy: 0.6284\n",
      "Epoch 362/400\n",
      "448/448 [==============================] - 3s 7ms/step - loss: 0.9941 - accuracy: 0.7095 - val_loss: 1.8408 - val_accuracy: 0.6008\n",
      "Epoch 363/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9902 - accuracy: 0.7088 - val_loss: 1.9387 - val_accuracy: 0.6353\n",
      "Epoch 364/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0004 - accuracy: 0.7045 - val_loss: 1.9939 - val_accuracy: 0.6139\n",
      "Epoch 365/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9977 - accuracy: 0.6983 - val_loss: 1.9096 - val_accuracy: 0.6277\n",
      "Epoch 366/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9904 - accuracy: 0.7050 - val_loss: 1.8740 - val_accuracy: 0.5895\n",
      "Epoch 367/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9858 - accuracy: 0.7029 - val_loss: 1.8456 - val_accuracy: 0.6303\n",
      "Epoch 368/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9787 - accuracy: 0.7126 - val_loss: 1.9052 - val_accuracy: 0.6014\n",
      "Epoch 369/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9749 - accuracy: 0.7125 - val_loss: 1.8509 - val_accuracy: 0.6365\n",
      "Epoch 370/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9963 - accuracy: 0.7033 - val_loss: 1.9057 - val_accuracy: 0.6033\n",
      "Epoch 371/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9935 - accuracy: 0.6994 - val_loss: 1.9200 - val_accuracy: 0.5920\n",
      "Epoch 372/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9617 - accuracy: 0.7179 - val_loss: 1.8895 - val_accuracy: 0.5945\n",
      "Epoch 373/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9966 - accuracy: 0.7029 - val_loss: 1.9804 - val_accuracy: 0.5512\n",
      "Epoch 374/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9955 - accuracy: 0.7041 - val_loss: 1.9159 - val_accuracy: 0.5907\n",
      "Epoch 375/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9729 - accuracy: 0.7108 - val_loss: 1.9405 - val_accuracy: 0.6139\n",
      "Epoch 376/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9748 - accuracy: 0.7075 - val_loss: 1.9584 - val_accuracy: 0.5857\n",
      "Epoch 377/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9861 - accuracy: 0.7028 - val_loss: 2.0748 - val_accuracy: 0.5405\n",
      "Epoch 378/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0030 - accuracy: 0.7037 - val_loss: 1.8724 - val_accuracy: 0.5970\n",
      "Epoch 379/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9798 - accuracy: 0.7086 - val_loss: 1.8636 - val_accuracy: 0.6070\n",
      "Epoch 380/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9867 - accuracy: 0.7109 - val_loss: 1.9059 - val_accuracy: 0.6095\n",
      "Epoch 381/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9838 - accuracy: 0.7099 - val_loss: 1.9358 - val_accuracy: 0.5876\n",
      "Epoch 382/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9822 - accuracy: 0.7113 - val_loss: 1.9468 - val_accuracy: 0.5662\n",
      "Epoch 383/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9922 - accuracy: 0.7044 - val_loss: 2.1227 - val_accuracy: 0.5876\n",
      "Epoch 384/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0458 - accuracy: 0.6954 - val_loss: 1.9953 - val_accuracy: 0.5694\n",
      "Epoch 385/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9884 - accuracy: 0.7164 - val_loss: 1.9171 - val_accuracy: 0.6127\n",
      "Epoch 386/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9745 - accuracy: 0.7113 - val_loss: 1.9124 - val_accuracy: 0.5938\n",
      "Epoch 387/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9858 - accuracy: 0.7094 - val_loss: 1.8783 - val_accuracy: 0.6077\n",
      "Epoch 388/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9765 - accuracy: 0.7073 - val_loss: 1.9259 - val_accuracy: 0.5706\n",
      "Epoch 389/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9737 - accuracy: 0.7099 - val_loss: 2.0182 - val_accuracy: 0.5637\n",
      "Epoch 390/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0033 - accuracy: 0.6945 - val_loss: 1.9677 - val_accuracy: 0.5700\n",
      "Epoch 391/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9761 - accuracy: 0.7079 - val_loss: 1.8938 - val_accuracy: 0.6171\n",
      "Epoch 392/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9919 - accuracy: 0.7063 - val_loss: 1.8853 - val_accuracy: 0.6083\n",
      "Epoch 393/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9899 - accuracy: 0.7080 - val_loss: 1.9563 - val_accuracy: 0.6259\n",
      "Epoch 394/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 1.0035 - accuracy: 0.7076 - val_loss: 1.9763 - val_accuracy: 0.6259\n",
      "Epoch 395/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9739 - accuracy: 0.7139 - val_loss: 1.9247 - val_accuracy: 0.5995\n",
      "Epoch 396/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9722 - accuracy: 0.7112 - val_loss: 1.9100 - val_accuracy: 0.5775\n",
      "Epoch 397/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9946 - accuracy: 0.7056 - val_loss: 1.9154 - val_accuracy: 0.5876\n",
      "Epoch 398/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9868 - accuracy: 0.7092 - val_loss: 1.9680 - val_accuracy: 0.5825\n",
      "Epoch 399/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9817 - accuracy: 0.7055 - val_loss: 1.9531 - val_accuracy: 0.5838\n",
      "Epoch 400/400\n",
      "448/448 [==============================] - 3s 6ms/step - loss: 0.9925 - accuracy: 0.7060 - val_loss: 1.8855 - val_accuracy: 0.6121\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_traini, batch_size=32, epochs=400, validation_data=(X_test,Y_testi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-jefferson",
   "metadata": {},
   "source": [
    "Trial to predict a section taken out from of X_train to see if results are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "id": "sticky-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xnew= X_train[-500:]\n",
    "# ynew = np.argmax(model.predict(Xnew), axis=-1)\n",
    "\n",
    "# for i in range(len(Xnew)):\n",
    "# \tprint(\"Predicted=%s, Actual=%s\" % ( ynew[i],Y_traini[-500:][i]))\n",
    " \n",
    "# #print(ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "announced-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-drive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-startup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
